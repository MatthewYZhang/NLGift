{"qid": "9a923e94373f79fa80e5", "term": "Celery", "description": "species of plant", "question": "Could you make the kitchen 'holy trinity' without celery?", "answer": false, "facts": ["The 'Holy Trinity' in cooking is a base used for soups, stews, and more.", "The ingredients of the Holy Trinity base are onions, bell peppers, and celery."], "decomposition": ["What ingredients are part of the culinary holy trinity?", "Is celery absent from #1?"], "evidence": [[[["Holy trinity (cuisine)-3"]], [["Holy trinity (cuisine)-3"], "operation"]], [[["Holy trinity (cuisine)-1"]], ["operation"]], [[["Holy trinity (cuisine)-1"]], ["operation"]]]}
{"qid": "a1a92c378396180e190c", "term": "Supreme Court of the United States", "description": "Highest court in the United States", "question": "Has a neanderthal ever served on the Supreme Court of the United States?", "answer": false, "facts": ["The Supreme Court was established in 1789.", "Neanderthals are primitive humans that lived 40,000 years ago."], "decomposition": ["How long ago did Neanderthals live?", "How long ago was the Supreme Court of the United States formed?", "Is #2 greater than #1?"], "evidence": [[[["Neanderthal-1"]], [["Supreme Court of the United States-2"]], ["operation"]], [[["Neanderthal-1"]], [["Supreme Court of the United States-2"]], ["operation"]], [[["Neanderthal-1"]], [["Supreme Court of the United States-8"]], ["operation"]]]}
{"qid": "000275e7aa81e30885e7", "term": "Numerology", "description": "any study of the purported divine, mystical or other special relationship between a number and some coinciding observed (or perceived) events", "question": "Has numerology helped shape hotel layouts?", "answer": true, "facts": ["Numerology is the study of numbers and how they relate to events.", "Numbers such as 3 and 7 hold biblical significance.", "Numbers such as 6 and 13 are said to be unlucky.", "The thirteenth floor is a designation of a level of a multi-level building that is often omitted in countries where the number 13 is considered unlucky.", "Many hotels do not have thirteenth floors because of the enduring superstition."], "decomposition": ["What numbers are often considered unlucky?", "What number is usually omitted in numbering hotel floors?", "Is #2 part of #1?"], "evidence": [[[["13 (number)-14"], "no_evidence"], [["13 (number)-14"]], ["operation"]], [[["13 (number)-14"]], [["13 (number)-14", "Thirteenth floor-2"]], ["operation"]], [[["13 (number)-16", "Number of the Beast-1"], "no_evidence"], [["Thirteenth floor-7"]], ["operation"]]]}
{"qid": "7b82cd99c7c68aa1b022", "term": "Confederate States Army", "description": "Southern army in American Civil War", "question": "Are there Americans still enlisted in the Confederate States Army?", "answer": false, "facts": ["The Confederate States Army disbanded in 1865.", "The last living confederate soldier died in 1951."], "decomposition": ["What is the present status of the Confederate States Army?", "Considering #1, can there still be anyone enlisted?"], "evidence": [[[["Confederate States of America-8"]], ["operation"]], [[["Confederate States Army-5"]], ["operation"]], [[["Confederate States Army-1", "Confederate States Army-5"]], ["operation"]]]}
{"qid": "e12a00a2c45fcb4f38e7", "term": "Othello", "description": "play by Shakespeare", "question": "Would Othello be Shakespeare's play to buy Scheherazade most time with king?", "answer": false, "facts": ["Scheherazade was a character in Middle Eastern folklore that delayed her execution by telling the king long stories.", "Shakespeare's play Othello contained 26,450 words.", "Hamlet is Shakespeare's longest play consisting of 4000 lines and 30,000 words."], "decomposition": ["How long is Othello?", "Are all of Shakespeare's other plays shorter than #1?"], "evidence": [[[["Othello-41"], "no_evidence"], [["Shakespeare's plays-1"], "no_evidence", "operation"]], [[["Othello-20"], "no_evidence"], [["Hamlet-2", "The Comedy of Errors-1"], "no_evidence", "operation"]], [[["Othello-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "c4a9e56df5b83e483769", "term": "Brazilian Navy", "description": "Naval warfare branch of Brazil's military forces", "question": "Could modern Brazilian Navy have hypothetically turned the tide in Battle of Actium?", "answer": true, "facts": ["The Battle of Actium saw Mark Antony's army lose to Octavian.", "Octavian's army had 400 ships, 16000 infantry, and 3,000 archers.", "The Brazilian Navy has over 80,000 personnel, including 16,000 marines.", "Several Brazilian Navy ships are armed with explosive torpedoes. "], "decomposition": ["What was the result of the Battle of Actium?", "In #1, how many resources did the Octavian's army have?", " How many resources does the Brazilian Navy have? ", "Is #3 significantly more than #2?"], "evidence": [[[["Battle of Actium-26"]], [["Battle of Actium-14"]], [["Brazilian Navy-55", "Brazilian Navy-56"]], ["operation"]], [[["Battle of Actium-2"]], [["Battle of Actium-12"]], [["Brazilian Navy-55"]], ["operation"]], [[["Battle of Actium-2"]], [["Battle of Actium-12"]], [["Brazilian Navy-56"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "b747938f597b09e43603", "term": "Go (game)", "description": "Abstract strategy board game for two players", "question": "Did origin dynasty of Go precede Jia Sidao?", "answer": true, "facts": ["Go is a strategy game that originated in the Zhou dynasty.", "The Zhou dynasty lasted from 1046 BC \u2013 256 BC.", "Jia Sidao was a chancellor during the late Song dynasty.", "The Song dynasty started in 960 AD and lasted until 1279 AD."], "decomposition": ["During which Chinese dynasty did the game Go originate?", "Which Chinese dynasty was Jia Sidao a part of during his lifetime?", "Did #1 precede #2?"], "evidence": [[[["Go (game)-1"]], [["Jia Sidao-1"]], ["operation"]], [[["History of Go-9"]], [["Jia Sidao-1"]], [["Government of the Han dynasty-1", "Song dynasty-1"]]], [[["History of Go-4"]], [["Jia Sidao-1"]], ["operation"]]]}
{"qid": "2c0ad6834e39382c2e4f", "term": "Equator", "description": "Intersection of a sphere's surface with the plane perpendicular to the sphere's axis of rotation and midway between the poles", "question": "Is most coffee produced South of the Equator?", "answer": true, "facts": ["The countries with the highest coffee production are in South America.", "Almost all of South America is in the Southern Hemisphere."], "decomposition": ["Which countries produce the most coffee?", "Which hemisphere are most of #1 located?", "Is #2 south of the equator?"], "evidence": [[[["Coffee-45"], "no_evidence"], ["no_evidence"], [["Brazil-43"], "no_evidence", "operation"]], [[["Coffee-5"], "no_evidence"], [["Southern Hemisphere-9"]], [["Southern Hemisphere-1"], "operation"]], [[["Coffee-5"]], [["Southern Hemisphere-9"]], [["Southern Hemisphere-9"]]]]}
{"qid": "c497b4a83bc55a840e6c", "term": "Carrot", "description": "Root vegetable, usually orange in color", "question": "Are raw carrots better for maximizing vitamin A intake?", "answer": false, "facts": [" 3% of the \u03b2-carotene in raw carrots is released during digestion, which can be improved to 39% by pulping, cooking and adding cooking oil", "Retinal is a form of Vitamin A", "Human bodies break down \u03b2-carotene into retinal"], "decomposition": ["What is the source of Vitamin A in carrots?", "Is absorption of #1 reduced by cooking?"], "evidence": [[[["Vitamin A-13"]], [["Carrot-35"], "operation"]], [[["Carrot-42"]], ["no_evidence", "operation"]], [[["Carrot-42"]], [["Carotene-9"]]]]}
{"qid": "6ad52c1f34bebab2cbba", "term": "Uniting Church in Australia", "description": "christian denomination", "question": "Was Muhammed a member of the Uniting Church in Australia?", "answer": false, "facts": ["The Uniting Church in Australia is a combination of Methodist and Presbyterian congregations.", "Methodists and Presbyterians are Christians.", "Muhammed was the Muslim prophet and was not a Christian."], "decomposition": ["Which religion was Muhammed a prophet in?", "What is the religion of the members of the Uniting Church in Australia?", "Is #1 the same as #2?"], "evidence": [[[["Last prophet-2"]], [["Uniting Church in Australia-23"]], ["operation"]], [[["Muhammad-1"]], [["Uniting Church in Australia-1"]], ["operation"]], [[["Muhammad-1"]], [["Uniting Church in Australia-1"]], ["operation"]]]}
{"qid": "8f12cd3797d27f250b00", "term": "Banana", "description": "edible fruit", "question": "Were plants crucial for The King of Rock'n Roll's snack with bananas?", "answer": true, "facts": ["Elvis Presley is known as The King of Rock'n Roll.", "Elvis Presley loved to eat peanut butter and bananas.", "Bananas come from banana plants.", "Peanut butter comes from peanuts, which come from peanut plants."], "decomposition": ["Who is commonly referred to as The King of Rock 'n Roll?", "Which snacks was #1 known to take with bananas?", "Are #2 plants products or made from them?"], "evidence": [[[["King of Rock and Roll (disambiguation)-1"]], [["Elvis Presley-86"]], [["Peanut butter, banana and bacon sandwich-1"]]], [[["Elvis Presley-1"]], [["Elvis Presley-86"]], [["Peanut butter-1"], "operation"]], [[["Elvis Presley-1"]], [["Elvis Presley-86"]], [["Peanut butter-1", "Peanut-1"]]]]}
{"qid": "d05b8ed82dbe1583b16c", "term": "Parent", "description": "father or mother", "question": "Does a person need to be a parent to become a grandparent?", "answer": true, "facts": ["Parents care for their children.", "When the children grow up and have kids of their own, the parents become grandparents to those kids.", "A person who is not a parent has no kids, therefore nobody to produce grandchildren for them."], "decomposition": ["What must a person have in order to be known as a grandparent?", "What would the parents of #1 be to the person?", "Must one be a parent to have #2?"], "evidence": [[[["Grandparent-1"]], [["Grandparent-1"]], [["Grandparent-1"]]], [[["Parent-7"], "no_evidence"], [["Parent-1"]], ["operation"]], [[["Grandparent-1"]], [["Child-2"]], [["Parent-1"], "operation"]]]}
{"qid": "1675495e9a3ed30329bd", "term": "Rabbi", "description": "teacher of Torah in Judaism", "question": "Would a rabbi worship martyrs Ranavalona I killed?", "answer": false, "facts": ["Rabbis are teachers of Judaism.", "Ranavalona I, ruler of Madagascar, killed many Christians that were later determined by the church to be martyrs.", "Judaism does not have a group of saints and martyrs that are prayed to like Christianity.."], "decomposition": ["Which religion are rabbis teachers of?", "Which religion were the matyrs killed by Ranavalona I adherents of?", "Do adherent of #1 worship matyrs like those of #2?"], "evidence": [[[["Rabbi-1"]], [["Christianity in Madagascar-13"]], ["operation"]], [[["Rabbi-1"]], [["Christianity in Madagascar-13"]], ["operation"]], [[["Rabbi-1"]], [["Christianity in Madagascar-13"]], ["no_evidence"]]]}
{"qid": "56464972cc1e47ef8a66", "term": "Jerry Seinfeld", "description": "American comedian and actor", "question": "Does Jerry Seinfeld hang out at the Budweiser Party Deck?", "answer": false, "facts": ["The Budweiser Party Deck is a social gathering spot in Yankee Stadium", "Yankee Stadium is home to the New York Yankees baseball team", "Jerry Seinfeld is a fan of the New York Mets"], "decomposition": ["Where is The Budweiser Party Deck located?", "Which sports team is #1 home to?", "Is Jerry Seinfeld a fan of #2?"], "evidence": [[[["Appalachian Power Park-14"]], [["Appalachian Power Park-1"]], [["Jerry Seinfeld-28"], "operation"]], [[["Yankee Stadium-22"]], [["Yankee Stadium-1"]], [["Jerry Seinfeld-28"]]], [[["Appalachian Power Park-14"]], [["Appalachian Power Park-1"]], [["Jerry Seinfeld-28"], "operation"]]]}
{"qid": "c03e06230ef966bacf58", "term": "Alice's Adventures in Wonderland", "description": "book by Lewis Carroll", "question": "Did Alice's Adventures in Wonderland inspire Macbeth?", "answer": false, "facts": ["Alice's Adventures in Wonderland was published in 1865", "Macbeth was first performed in 1606"], "decomposition": ["When was Alice's Adventures in Wonderland first published?", "When was Macbeth first performed?", "Is #1 before #2?"], "evidence": [[[["Alice's Adventures in Wonderland-1"]], [["Macbeth-1"]], ["operation"]], [[["Alice's Adventures in Wonderland-3"]], [["Macbeth-32"]], ["operation"]], [[["Alice's Adventures in Wonderland-1"]], [["Macbeth-1"]], ["operation"]]]}
{"qid": "4db6d375c79e86c2818e", "term": "Sony", "description": "Japanese multinational conglomerate corporation", "question": "Did Sony definitively win the video game war against Sega?", "answer": true, "facts": ["Sony is the maker of the Playstation which has sold over 108 million PS4 units by March 2020.", "Sega's last console, the Sega Dreamcast, was discontinued in 2001.", "Sony Playstation competed with Sega's Dreamcast and Saturn systems in the 1990s.", "Sega now makes games for its former competitor, Sony, including Team Sonic Racing in 2019.", "At the height of the console wars, Sega Saturn sold 9.5 million units while Sony Playstation sold 102 million units."], "decomposition": ["How many console did Sega Saturn sell?", "How many console did Sony Playstation?", "Is #2 greater than #1?"], "evidence": [[[["Sega Saturn-25"], "no_evidence"], [["PlayStation-2"]], ["operation"]], [[["Sega Saturn-3"]], [["PlayStation-81"]], [["PlayStation-81"]]], [[["Sega Saturn-3"]], [["PlayStation (console)-2"]], ["operation"]]]}
{"qid": "48628a79ac6d18460f36", "term": "Eric Clapton", "description": "English musician, singer, songwriter, and guitarist", "question": "Did Eric Clapton have similar taste in women to one of the Beatles?", "answer": true, "facts": ["The Beatles consisted of John Lennon, Paul McCartney, George Harrison, and Ringo Starr.", "George Harrison was married to Pattie Boyd from 1966-1977.", "Eric Clapton married Pattie Boyd in 1979."], "decomposition": ["Who are the spouses Eric Clapton has had?", "Who are the spouses the members of the Beatles have had?", "Is #1 listed in #2?"], "evidence": [[[["Eric Clapton-78"]], [["George Harrison-4"]], ["operation"]], [[["Eric Clapton-78"]], [["George Harrison-4"]], ["operation"]], [[["Eric Clapton-78"]], [["Pattie Boyd-1"], "no_evidence"], ["operation"]]]}
{"qid": "4a8361174e3f01cf8c2e", "term": "Achilles", "description": "Greek mythological hero", "question": "Was Achilles a direct descendent of Gaia?", "answer": true, "facts": ["Achilles was the son of a Nereid. ", "The Nereids were the 50 daughters of Nereus.", "Nereus was the eldest son of the union between Gaia and Pontus."], "decomposition": ["Who were Achilles' parents?", "Who were the children of Gaia?", "Were any of #1 the children of #2?"], "evidence": [[[["Achilles-1"]], [["Gaia-1", "Nereus-1"]], [["Thetis-1"], "operation"]], [[["Achilles-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Achilles-1"]], [["Nereus-1"]], [["Thetis-1"], "operation"]]]}
{"qid": "85fc2b42b1fb20762db4", "term": "Amy Winehouse", "description": "English singer and songwriter", "question": "Did Amy Winehouse always perform live perfectly?", "answer": false, "facts": ["Amy Winehouse was known for getting intoxicated before an during sets.", "Amy Winehouse forgot the lyrics to her songs during her last performance."], "decomposition": ["Is Amy Winehouse known for always being sober and coordinated on stage?"], "evidence": [[[["Amy Winehouse-16"]]], [[["Amy Winehouse-16"]]], [[["Amy Winehouse-16"]]]]}
{"qid": "918f19d38c16251343fc", "term": "Subway (restaurant)", "description": "American fast food chain", "question": "Was Subway involved in a pedophilia scandal?", "answer": true, "facts": ["In 2000, Jared Fogle became a national spokesman for Subway after he lost a lot of weight eating only Subway sandwiches.", "In 2015, Fogle was found guilty of child molestation and possession of child pornography, and Subway terminated its relationship with him."], "decomposition": ["Who was the famous spokesman for Subway?", "What crimes did #1 commit?", "Are #2 directly related to pedophilia?"], "evidence": [[[["Subway (restaurant)-30"]], [["Jared Fogle-3"]], [["Pedophilia-12"], "operation"]], [[["Jared Fogle-1"]], [["Jared Fogle-3"]], [["Child sex tourism-1", "Pedophilia-1"]]], [[["Jared Fogle-6"]], [["Jared Fogle-25"]], [["Jared Fogle-25"]]]]}
{"qid": "162458ca6672c642a00f", "term": "Prophet", "description": "person claiming to speak for divine beings", "question": "Did the leader of Heaven's Gate consider himself a prophet?", "answer": true, "facts": ["The leader of Heaven's Gate was Marshall Applewhite.", "Marshall Applewhite said he was called to be a messenger of the divine."], "decomposition": ["Who was the leader of Heaven's Gate?", "What did #1 say he was called upon to do?", "What is the definition of a prophet?", "Is #2 the same as #3?"], "evidence": [[[["Marshall Applewhite-1"]], [["Marshall Applewhite-10", "Marshall Applewhite-2"]], [["Prophet-1"]], ["operation"]], [[["Heaven's Gate (religious group)-1"]], [["Marshall Applewhite-13"]], [["Prophet-1"]], ["operation"]], [[["Heaven's Gate (religious group)-1"]], [["Marshall Applewhite-20"]], [["Prophet-1"]], ["operation"]]]}
{"qid": "8079e0f884664d724347", "term": "Hornet", "description": "Genus of eusocial wasp", "question": "Do hornets provide meaningful data for oceanographers?", "answer": false, "facts": ["Hornets live on land", "Oceanographers study oceans"], "decomposition": ["Where do hornets live?", "What do oceanographers study?", "Is #1 the same as #2?"], "evidence": [[[["Hornet-2", "Hornet-8"]], [["Oceanography-1"]], ["operation"]], [[["Hornet-2"]], [["Oceanography-1"]], ["operation"]], [[["Hornet-2"]], [["Oceanography-1"]], ["operation"]]]}
{"qid": "85300febfe21ecdcc5b1", "term": "Wolverine", "description": "Species of the family Mustelidae", "question": "Would a Wolverine and a Lynx be hard to tell apart?", "answer": false, "facts": ["Wolverines have rounded ears and a bear-like appearance.", "Lynxes have a feline body with pointed ears."], "decomposition": ["What are the physical characteristics of wolverines?", "What are the physical characteristics of lynxes?", "Is there any significant overlap between #1 and #2?"], "evidence": [[[["Wolverine-6"]], [["Lynx-3"]], ["operation"]], [[["Wolverine-6"]], [["Lynx-4"]], [["Lynx-4", "Wolverine-6"], "operation"]], [[["Wolverine-6"]], [["Lynx-3", "Lynx-4"]], ["operation"]]]}
{"qid": "a96d28e1221bfbcf50a9", "term": "CT scan", "description": "medical imaging procedure which uses X-rays to produce cross-sectional images", "question": "Would an uninsured person be more likely than an insured person to decline a CT scan?", "answer": true, "facts": ["Without insurance, a CT scan can cost up to $5,000.", "Most insurance companies will cover or reimburse the cost of a CT scan."], "decomposition": ["Typically how much does it cost to get a CT scan without insurance?", "On average, how much does it cost to get a CT scan with insurance?", "Is #2 less than #1?"], "evidence": [[[["Full-body CT scan-12"]], [["Full-body CT scan-12"]], ["operation"]], [[["CT scan-53"], "no_evidence"], [["CT scan-53"], "no_evidence"], ["operation"]], [[["CT scan-53"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "6a8f77c62222517534f5", "term": "Panic of 1907", "description": "three-week financial crisis in the United States", "question": "Was the father of social security system serving in the white house during the Panic of 1907?", "answer": false, "facts": ["The father of social security system is Franklin D. Roosevelt. ", "Franklin D. Roosevelt was in Columbia Law School in 1907. "], "decomposition": ["Who is the father of the social security system?", "What position serves in the White House?", "When did #1 serve as #2?", "Is 1907 in the range of #3?"], "evidence": [[[["Franklin D. Roosevelt-3"]], [["White House-1"]], [["Franklin D. Roosevelt-1"]], ["operation"]], [[["Edwin E. Witte-1"]], [["Edwin E. Witte-12"]], [["Edwin E. Witte-12"], "no_evidence"], ["operation"]], [[["Social Security (United States)-1"]], [["White House-1"]], [["Franklin D. Roosevelt-1"]], ["operation"]]]}
{"qid": "db6ede282f42b088fef7", "term": "Sophist", "description": "Specific kind of teacher in both Ancient Greece and in the Roman Empire", "question": "Would a sophist use an \u00e9p\u00e9e?", "answer": false, "facts": ["A sophist is a specific kind of teacher in ancient Greece, in the fifth and fourth centuries BC.", "Sophists specialized in using the tools of philosophy and rhetoric, though other sophists taught subjects such as music, athletics and mathematics.", "An \u00e9p\u00e9e is a sword used in fencing.", "The \u00e9p\u00e9e was not developed until the 19th century."], "decomposition": ["How long ago were the sophists around?", "How long ago was the epee developed?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Sophist-1"]], [["\u00c9p\u00e9e-15"]], ["operation"]], [[["Sophist-1"]], [["\u00c9p\u00e9e-1"]], ["operation"]], [[["Sophist-1"]], [["\u00c9p\u00e9e-16"]], ["operation"]]]}
{"qid": "b7c897e34556ecccbc47", "term": "Ice", "description": "water frozen into the solid state", "question": "Did Ice make people rich?", "answer": true, "facts": ["Trading ice was common in the 1800s.", "People created industries harvesting and selling ice.", "Some ice sellers became extremely rich. "], "decomposition": ["In the 1800's, what item was commonly traded?", "Did some people become rich off of selling #1?"], "evidence": [[[["Ice trade-1"]], [["Ice trade-10"]]], [[["Ice-48"], "no_evidence"], [["Ice-49"], "operation"]], [[["Ice trade-1"]], [["Ice trade-2"]]]]}
{"qid": "a98478f4c66dea748297", "term": "Reality", "description": "Sum or aggregate of all that is real or existent", "question": "Could Plato have agreed with the beliefs of Jainism?", "answer": true, "facts": ["One principle of reality in Jainism is karma, or asrava.", "Jainism began around 500 B.C.", "Plato was born around 428 B.C., so he was alive while Jainism existed.", "Plato believed in karma and reincarnation."], "decomposition": ["What are the major beliefs in Jainism?", "What were Plato's major beliefs?", "When did Jainism begin?", "When was Plato born?", "Is there an overlap between #1 and #2, and is #4 more recent than #3?"], "evidence": [[[["Jainism-1"]], [["Plato-43"]], [["Jainism-1"]], [["Plato-1"]], ["operation"]], [[["Jainism-4"], "no_evidence"], [["Plato-3"], "no_evidence"], [["Jainism-61"]], [["Plato-1"]], ["operation"]], [[["Jainism-2"]], [["Plato-3", "Plato-39", "Plato-43"], "no_evidence"], [["Jainism-1"]], [["Plato-1"]], ["no_evidence", "operation"]]]}
{"qid": "c51fd5841358ded6eaec", "term": "Ten Commandments", "description": "Set of biblical principles relating to ethics and worship, which play a fundamental role in the Abrahamic religions", "question": "Were the Ten commandments the part of the bible that Jewish people do not believe in?", "answer": false, "facts": ["The Jewish religion regards the Old Testament as their holy book.", "The New Testament of the bible is not acknowledged by Jewish religious people.", "The Ten Commandments are in the Old Testamanet."], "decomposition": ["What parts of the Bible do Jews not accept?", "What part of the Bible are the Ten Commandments in?", "Is #2 also listed in #1?"], "evidence": [[[["Old Testament-32"]], [["Ten Commandments-50"]], ["operation"]], [[["Christianity and Judaism-13"]], [["Ten Commandments-1"]], ["operation"]], [[["Old Testament-1"]], [["Book of Exodus-12"]], ["operation"]]]}
{"qid": "7776349dede20a0d6405", "term": "Pope Alexander VI", "description": "Pope of the Catholic Church 1492\u20131503", "question": "Was Pope Alexander VI's origin country least represented in papal history?", "answer": false, "facts": ["Pope Alexander VI, born Rodrigo Borgia, was born in a town in eastern Spain.", "There have been two Popes whose origins are from Spain, including Pope Alexander VI and Pope Callixtus III.", "Pope John Paul II was born in Poland.", "Pope John Paul II is the only pope of Polish origin."], "decomposition": ["What is Pope Alexander VI's home country?", "How many popes have come from #1?", "Is it the case that no countries have produced a non-zero number of popes that is less than #2?"], "evidence": [[[["Pope Alexander VI-2"]], [["Pope Alexander VI-2", "Pope Callixtus III-2"], "no_evidence"], [["Pope-51"], "operation"]], [[["Pope Alexander VI-2"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Pope Alexander VI-1"]], [["House of Borgia-8", "Pope Callixtus I-1"], "no_evidence"], [["Pope Francis-1"], "no_evidence", "operation"]]]}
{"qid": "497c4922b0552d7c5693", "term": "Argon", "description": "Chemical element with atomic number 18", "question": "Is Argon near Neon on the periodic table of elements?", "answer": true, "facts": ["Argon is a noble gas.", "Neon is a noble gas. ", "The noble gases are all clumped together on the periodic table of elements."], "decomposition": ["What group of the periodic table is argon in?", "What group of the periodic table is neon in?", "Is #1 the same as #2?"], "evidence": [[[["Noble gas-1"]], [["Noble gas-1"]], ["operation"]], [[["Argon-1"]], [["Noble gas-1", "Noble gas-2"]], ["operation"]], [[["Argon-1"]], [["Neon-21"]], [["Group (periodic table)-5"]]]]}
{"qid": "ca1bbc7b71d286760acd", "term": "Kangaroo", "description": "\u0441ommon name of family of marsupials", "question": "Do Australians ride Kangaroos to work?", "answer": false, "facts": ["Kangaroos can become aggressive if they feel a human is too close or is threatening them.", "There are no parking areas or stalls for Kangaroos in Australia. ", "It would be considered animal abuse to ride on a kangaroo and leave it at one's job."], "decomposition": ["Do kangaroos live freely with people?", "Are there any kangaroo parking lots in Australia?", "Is #1 or #2 positive?"], "evidence": [[[["Kangaroo-38"]], ["no_evidence"], [["Kangaroo-38"]]], [[["Kangaroo-35"], "no_evidence"], [["Parking lot-1"], "no_evidence"], ["operation"]], [[["Red kangaroo-10"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "d03daae5b38423aec74c", "term": "Mongols", "description": "ethnic group of central Asia", "question": "Would a packed Wembley stadium be likely to have a descendant of the Mongols inside?", "answer": true, "facts": ["Wembley stadium has a capacity of 90,000 people.", "The Mongols were an ethnic group that dominated the 13th and 14th centuries.", "Genghis Khan was the founder of the Mongol Empire.", "Geneticists have determined that 1 in every 200 men are descended from Genghis Khan."], "decomposition": ["What is the capacity of the Wembley stadium?", "Who is the founder of the Mongol empire?", "What is the minimum number of men within which at least one descendant of #2 is found?", "Is #1 divided by #3 greater than or equal to one?"], "evidence": [[[["Wembley Stadium-2"]], [["Mongol Empire-2"]], ["no_evidence"], ["operation"]], [[["Wembley Stadium-2"]], [["Mongol Empire-2"]], [["Descent from Genghis Khan-22"], "no_evidence"], ["no_evidence", "operation"]], [[["Wembley Stadium-2"]], [["Mongol Empire-2"]], [["Descent from Genghis Khan-22"]], ["operation"]]]}
{"qid": "ed91d5142b8037b07abb", "term": "Dosa", "description": "Thin pancakes originating from South India", "question": "Would lumberjacks get full after eating three dosa?", "answer": false, "facts": ["Dosa are thin rice pancakes from South India.", "One dosa is approximately 110 calories.", "The average lumberjack would eat 8000 calories per day."], "decomposition": ["What is a Dosa?", "How many calories are in #1?", "How many calories does a lumberjack need per day?", "Is 3 times #2 a significant amount of #3?"], "evidence": [[[["Dosa-1"]], ["no_evidence"], [["Food energy-14"]], ["operation"]], [[["Dosa-1"]], ["no_evidence"], ["no_evidence"], ["operation"]], [[["Dosa-1"]], ["no_evidence"], [["Food energy-14", "Lumberjack-1"], "no_evidence"], ["operation"]]]}
{"qid": "9422300529f87f9917bf", "term": "Benjamin Franklin", "description": "American polymath and a Founding Father of the United States", "question": "Is Benjamin Franklin a prime candidate to have his statues removed by Black Lives Matter movement?", "answer": true, "facts": ["The Black Lives Matter movement is a social movement advocating for racial equality.", "Benjamin Franklin, a famous founding father, has his image on many monuments and on American currency.", "Members of the Black Lives Matter movement petitioned for statues of Christopher Columbus to be removed due to his subjugation of Native Americans.", "Benjamin Franklin's 1730s newspaper, The Philadelphia Gazette, posted ads for black slaves.", "Benjamin Franklin owned two slaves, George and King, who worked as personal servants."], "decomposition": ["What social issue motivates the Black Lives Matter movement?", "Did Benjamin Franklin act against achieving #1?"], "evidence": [[[["Black Lives Matter-10"]], [["Benjamin Franklin-135", "Benjamin Franklin-136"]]], [[["Black Lives Matter-14"], "no_evidence"], [["Benjamin Franklin-5"], "operation"]], [[["Black Lives Matter-10"]], [["Benjamin Franklin-5"], "operation"]]]}
{"qid": "026a34caa057f988a881", "term": "Michael Crichton", "description": "American author, screenwriter, film director", "question": "Was Michael Crichton ever in danger of flunking out of Harvard as an undergraduate?", "answer": false, "facts": ["Scholastic probation or academic dismissal, sometimes known as flunking out, is the termination of students at a higher educational institution as the result of poor academic achievement.", "Michael Crichton obtained his bachelor's degree in biological anthropology summa cum laude in 1964.", "Summa cum laude is the highest distinction a person can achieve in college for academic success.", "Someone who achieves summa cum laude cannot have even a single semester of poor grades."], "decomposition": ["What grade is considered flunking in US colleges?", "What honors did Michael Crichton graduate with?", "Can someone achieve #2 with grades of #1?"], "evidence": [[[["Academic grading in the United States-18"]], [["Michael Crichton-7"]], [["Academic grading in the United States-18", "Michael Crichton-7"]]], [[["Grading systems by country-216"], "no_evidence"], [["Michael Crichton-7"]], [["Latin honors-5"], "operation"]], [[["Grading systems by country-216"]], [["Michael Crichton-7"]], [["Latin honors-5"], "operation"]]]}
{"qid": "7bb579fa94d5f0d58ae1", "term": "Blues", "description": "Musical form and music genre", "question": "Were Depeche Mode heavily influenced by blues music?", "answer": false, "facts": ["Blues incorporated spirituals, work songs, field hollers, shouts, chants, and rhymed simple narrative ballads and was derived from African-Americans.", "Blues music uses instruments like slide guitar, harmonica, piano, and bass drums.", "Depeche Mode are a British pop synth group.", "Depeche Mode uses computer synthesizers to create their unique sound as well as heavy rock guitars.", "Depeche Mode was influenced by The Cure, and Ultravox, new wave rock bands."], "decomposition": ["What kind of songs and instruments are associated with Blues?", "What kind of musical instruments does the Depeche Mode use to create music?", "Is #2 very similar to #1?"], "evidence": [[[["Blues-37"]], [["Depeche Mode-35"]], ["operation"]], [[["Blues-1"]], [["Depeche Mode-1"]], ["operation"]], [[["Blues-1"], "no_evidence"], [["Depeche Mode-6"]], ["operation"]]]}
{"qid": "2fd3aa5d2672c8c5350c", "term": "The Doctor (Doctor Who)", "description": "fictional character from Doctor Who", "question": "Does The Doctor keep his ship in his childhood home?", "answer": false, "facts": ["The Doctor grew up on a planet called Gallifrey.", "The planet Gallifrey was destroyed in a time war.", "The Doctor's ship doesn't require docking."], "decomposition": ["Where is The Doctor's childhood home?", "Can The Doctor still visit #1?"], "evidence": [[[["The Doctor (Doctor Who)-7"]], [["Gallifrey-30"], "operation"]], [[["Doctor Who-53"], "no_evidence"], ["operation"]], [[["The Doctor (Doctor Who)-7"]], [["Gallifrey-3"]]]]}
{"qid": "e7730031d304759520ba", "term": "Prussia", "description": "state in Central Europe between 1525\u20131947", "question": "Was the Euro used in Prussia?", "answer": false, "facts": ["Prussia was formally abolished in 1947.", "The Euro was introduced in 1992."], "decomposition": ["When was Prussia formally abolished?", "When was the Euro introduced?", "Is #2 before #1?"], "evidence": [[[["Prussia-1"]], [["Euro-18"]], ["operation"]], [[["Monarchies in Europe-27"]], [["Euro-23"]], ["operation"]], [[["Prussia-2"]], [["Euro-5"]], ["operation"]]]}
{"qid": "b978c4051673fd21035b", "term": "Aldi", "description": "Germany-based supermarket chain", "question": "Are Aldi's foods discounted due to being out of date?", "answer": false, "facts": ["Aldi cuts costs by charging for bags, buying in bulk, and by avoiding brand name items. ", "Aldi removes spoiled or expired foods from their shelves immediately upon identification."], "decomposition": ["How does Aldi cut cost?", "Is selling discounted food part of #1?"], "evidence": [[[["Aldi-33"]], [["Aldi-25", "Aldi-27"], "operation"]], [[["Aldi-5"]], ["operation"]], [[["Aldi-27"]], [["Aldi-27"]]]]}
{"qid": "0e2f272f72871428cc90", "term": "Space Race", "description": "Competition between the USSR and the USA to explore space", "question": "Did Al Unser Jr. win the Space Race?", "answer": false, "facts": ["Al Unser Jr. is a race car driver", "The Space Race was the competition between the Soviet Union and United States over space exploration"], "decomposition": ["What two entities were part of the Space Race?", "Is Al Unser Jr. either of #1?"], "evidence": [[[["Space Race-1"]], [["Al Unser Jr.-1"], "operation"]], [[["Space Race-1"]], [["Al Unser Jr.-1"], "operation"]], [[["Space Race-1"]], ["operation"]]]}
{"qid": "cdc41c9bae19c441248d", "term": "Easter", "description": "Major Christian festival celebrating the resurrection of Jesus", "question": "Does Adam Sandler skip celebrating Easter?", "answer": true, "facts": ["Adam Sandler is Jewish.", "Jewish religious people do not celebrate Easter."], "decomposition": ["Easter is usually celebrated by people of which religion?", "What is Adam Sandler's religion?", "Is #1 different from #2?"], "evidence": [[[["Easter-6"]], [["Adam Sandler-26"]], ["operation"]], [[["Easter-58"]], [["Adam Sandler-26"]], ["operation"]], [[["Easter-2"]], [["Adam Sandler-5"]], ["operation"]]]}
{"qid": "f4a336168f5165de7f0d", "term": "Northern fur seal", "description": "The largest fur seal in the northern hemisphere", "question": "Is a northern fur seal needing emergency surgery in July likely a safe anesthesia candidate?", "answer": true, "facts": ["Northern fur seals fast throughout the mating season", "It is recommended that patients, including animals, fast for a time before surgery that requires anesthesia ", "Peak mating season for northern fur seals occurs in June and July"], "decomposition": ["What is recommended for patients needing anesthesia?", "What do northern fur seals do in July?", "Does #2 include #1?"], "evidence": [[[["Anesthesia-12"]], [["Northern fur seal-17"]], ["operation"]], [[["Anesthesia-7"]], [["Northern fur seal-17"]], ["operation"]], [[["Anesthesia-34"], "no_evidence"], [["Northern fur seal-17"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "068379affae04debca2b", "term": "Nepalese Civil War", "description": "civil war in Nepal between 1996 and 2006", "question": "Did the Nepalese Civil War take place near India?", "answer": true, "facts": ["The Nepalese Civil War happened in Nepal.", "Nepal is a country that shares a border with India."], "decomposition": ["Where did the Nepalese Civil War take place?", "Is #1 near India?"], "evidence": [[[["Nepalese Civil War-1"]], [["Nepal-1"], "operation"]], [[["Nepalese Civil War-1"]], [["Nepal-1"]]], [[["Nepalese Civil War-1"]], [["Nepal-1"], "operation"]]]}
{"qid": "24aa6050c1ed0405e663", "term": "Baptism", "description": "Christian rite of admission and adoption, almost invariably with the use of water", "question": "Can Immersion Baptism lead to a death like Jeff Buckley's?", "answer": true, "facts": ["Immersion Baptism is the practice of submerging people underwater for a religious ritual.", "Jeff Buckley was an acclaimed singer that died of drowning in 1997.", "A baby in Moldova died from Immersion Baptism in 2010."], "decomposition": ["How did Jeff Buckley die?", "How is immersion baptism performed?", "Are the circumstances surrounding #1 similar to that of #2?"], "evidence": [[[["Jeff Buckley-3"]], [["Immersion baptism-1"]], ["operation"]], [[["Jeff Buckley-36"]], [["Immersion baptism-4"]], [["Immersion baptism-4"], "operation"]], [[["Jeff Buckley-3"]], [["Immersion baptism-2"]], [["Drowning-1", "Swimming-1"], "operation"]]]}
{"qid": "1eeb5b135e7120037e70", "term": "Fair trade", "description": "form of trade", "question": "Is the United States the largest exporter of Fair Trade products?", "answer": false, "facts": ["Fair trade is an arrangement designed to help producers in developing countries achieve good trading.", "The United States is not considered a developing country."], "decomposition": ["What countries can use the designation \"fair trade\" for their goods? ", "Does the US have the designation in #1?"], "evidence": [[[["European Fair Trade Association-1"], "no_evidence"], ["operation"]], [[["Fair trade-5"], "no_evidence"], ["no_evidence", "operation"]], [[["Fair trade-1"]], [["Developed country-3", "Developing country-1"]]]]}
{"qid": "1857d2f86cc49c8eb728", "term": "Euphoria", "description": "mental and emotional condition in which a person experiences intense feelings of well-being, elation, happiness and excitement", "question": "Is euphoria associated with drug addiction?", "answer": true, "facts": ["Euphoria is a state of unusually extreme happiness.", "Several drugs are known to artificially induce this reaction including cannabis and opium."], "decomposition": ["What is euphoria?", "Do some drugs create the feeling of #1?"], "evidence": [[[["Euphoria-1"]], [["Euphoria-15"]]], [[["Euphoria-19"]], [["Euphoria-19"]]], [[["Euphoria-1"]], [["Euphoria-15", "Euphoria-16"], "operation"]]]}
{"qid": "32c562173099f5c2345f", "term": "Goblin shark", "description": "Deep-sea shark", "question": "Can a Goblin shark hypothetically ride a bike if it had limbs?", "answer": false, "facts": ["A Goblin shark weighs around 460 pounds.", "The weight capacity of the average bike is 300 pounds."], "decomposition": ["What is the average weight of a goblin? ", "What is the average weight a bike can hold? ", "Is #1 less than #2?"], "evidence": [[[["Goblin shark-8"], "no_evidence"], [["Birdy (bicycle)-11"], "no_evidence"], ["operation"]], [[["Goblin shark-1", "Goblin shark-8"]], [["Outline of bicycles-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Goblin shark-8"]], [["Bicycle-26"], "no_evidence"], ["operation"]]]}
{"qid": "721d168ff5cc0b18c31b", "term": "Tonsillitis", "description": "Inflammation of the tonsils", "question": "Can fish get Tonsillitis?", "answer": false, "facts": ["Tonsils are a pair of soft tissue masses located at the rear of the throat", "Tonsillitis is the inflammation of tonsils.", "Fish do not have tonsils.", "Tonsils are only found in mammals. "], "decomposition": ["What does Tonsillitis affect?", "What kinds of animals are #1 found in?", "Are fish #2?"], "evidence": [[[["Tonsillitis-1"]], [["Tonsil-2"]], ["operation"]], [[["Tonsillitis-1"]], [["Tonsil-3"]], ["operation"]], [[["Tonsillitis-1"]], [["Tonsil-3"]], [["Fish-1"], "operation"]]]}
{"qid": "a2272d539335ff78b429", "term": "Potato", "description": "plant species producing the tuber used as a staple food", "question": "Can Tame Impala's studio band play a proper game of Hot Potato?", "answer": false, "facts": ["Hot Potato is a game in which two or more people toss a potato until the music stops.", "Tame Impala is a band with one member, multi-instrumentalist Kevin Parker."], "decomposition": ["How many studio members are in Tame Impala's band?", "What is the minimum number of people that can play hot potato?", "Is #1 greater than or equal to #2?"], "evidence": [[[["Tame Impala-1"]], [["Hot potato-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Tame Impala-1"]], [["Hot potato-1"]], ["operation"]], [[["Tame Impala-1"]], [["Hot potato-1"], "no_evidence"], ["operation"]]]}
{"qid": "1fe4d0d2911c40065b89", "term": "Johnny Carson", "description": "American talk show host and comedian", "question": "Could Johnny Carson's children fill out a water polo team?", "answer": false, "facts": ["Johnny Carson had 3 children.", "Water polo teams consist of 7 players."], "decomposition": ["How many children does Johnny Carson have?", "How many people are needed to fill out a water polo team?", "Is #1 greater than or equal to #2?"], "evidence": [[[["Johnny Carson-55"]], [["Water polo-1"]], ["operation"]], [[["Johnny Carson-55"]], [["Water polo-1"]], ["operation"]], [[["Johnny Carson-55"]], [["Water polo-9"]], ["operation"]]]}
{"qid": "4ab77024b00c43ab7445", "term": "Thesis", "description": "document submitted in support of candidature for an academic degree", "question": "Could R. Kelly write a college thesis?", "answer": false, "facts": ["A college thesis is a long and complicated written document.", "R. Kelly claims to be illiterate, which means he cannot read and write. "], "decomposition": ["What does writing a college thesis require a person be able to do?", "What does R. Kelly claim to be?", "Can someone who is #2 do #1?"], "evidence": [[[["Reading-1"]], [["R. Kelly-9"]], [["Dyslexia-20"]]], [[["Thesis-1"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Thesis-1"], "no_evidence"], [["R. Kelly-9"]], [["Dyslexia-1"], "operation"]]]}
{"qid": "9d279701351e38e0400f", "term": "United States Secretary of State", "description": "U.S. cabinet member and head of the U.S. State Department", "question": "Can United States Secretary of State do crimes in U.K. without being arrested?", "answer": true, "facts": ["Diplomatic Immunity allows for diplomats in other countries to not be tried for their transgressions.", "Countries that signed the Vienna Convention on Diplomatic Relations allow for Diplomatic Immunity.", "All UN member states besides Palau, The Solomon Islands, and South Sudan have signed the Vienna Convention on Diplomatic Relations treaty.", "The U.K. is one of the original UN member nations."], "decomposition": ["Under which agreement is modern diplomatic immunity applicable?", "Which countries have signed #1?", "Is the U.K. included in #2?"], "evidence": [[[["Diplomatic immunity-14"]], [["Vienna Convention on Consular Relations-7"], "no_evidence"], ["no_evidence", "operation"]], [[["Diplomatic immunity-11", "Diplomatic immunity-14", "Diplomatic immunity-17"], "no_evidence"], [["Vienna Convention on Diplomatic Relations-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Diplomatic immunity-14"]], [["Vienna Convention on Diplomatic Relations-8"], "no_evidence"], [["Diplomatic immunity-10", "Diplomatic immunity-53"], "operation"]]]}
{"qid": "b59da272353e651cf2eb", "term": "Christmas Eve", "description": "Evening or entire day before Christmas Day", "question": "Would a Bulgarian priest eat a four-course meal on Christmas Eve?", "answer": false, "facts": ["A four-course meal consists of a soup, an appetizer, an entr\u00e9e, and dessert.", "The Bulgarian Christmas Eve meal has an odd number of dishes and an odd number of people sitting around the table."], "decomposition": ["Is the number of dishes served at a Bulgarian Christmas Eve meal odd or even?", "Is the number \"four\" odd or even?", "Is #1 the same as #2?"], "evidence": [[[["Christmas Eve-20"]], [["4-3"]], ["operation"]], [[["Christmas Eve-20"]], [["4-3"]], ["operation"]], [[["Christmas Eve-20"]], [["Parity (mathematics)-1"]], ["operation"]]]}
{"qid": "5d2e46bc031e1ccf88b4", "term": "Spaghetti", "description": "Type of pasta", "question": "Is it unusual to eat spaghetti without a fork?", "answer": true, "facts": ["Spaghetti noodles are long and thin, they are difficult to scoop and must be twirled.", "Spaghetti is never served in a restaurant without a fork."], "decomposition": ["Is Spaghetti usually eaten using a fork?"], "evidence": [[[["Spaghetti-1"], "no_evidence"]], [[["Italian cuisine-17", "Spaghetti-1"], "no_evidence", "operation"]], [[["Spaghetti-15"], "no_evidence"]]]}
{"qid": "e4c256ba753cb8d4fca3", "term": "Evander Holyfield", "description": "American boxer", "question": "Did Mike Tyson do something very different than McGruff's slogan to Evander Holyfield in 1997?", "answer": false, "facts": ["McGruff was an animated dog spokesman for the National Crime Prevention Council.", "McGruff's slogan was, \"Take a bite out of crime.\"", "Mike Tyson was disqualified in a 1997 boxing bout against Evander Holyfield for taking a bite out of his ear."], "decomposition": ["What is the slogan of McGruff?", "What did Mike Tyson do to Evander Holyfield during their match?", "Is #2 an action that occurs in #1?"], "evidence": [[[["McGruff the Crime Dog-7"]], [["Evander Holyfield-4"]], ["operation"]], [[["McGruff the Crime Dog-7"]], [["Mike Tyson-37"]], ["operation"]], [[["McGruff the Crime Dog-7"]], [["Evander Holyfield vs. Mike Tyson II-1"]], ["operation"]]]}
{"qid": "62239530032e5e88b8a7", "term": "Oceanography", "description": "The study of the physical and biological aspects of the ocean", "question": "Does an individual oceanographer study many sciences?", "answer": true, "facts": ["Study of the oceans involve many fields or science.", "To properly study their specific topic of research, an oceanographer must understand how their science interacts with the other involved sciences."], "decomposition": ["What other fields of science does oceanography cover?", "Does an individual oceanographer have to understand all of #1 to properly understand oceanography?"], "evidence": [[[["Oceanography-1"]], ["operation"]], [[["Oceanography-1"]], [["Oceanography-1"]]], [[["Oceanography-1"]], ["operation"]]]}
{"qid": "6ae9ff023bf054219f6f", "term": "Al-Farabi", "description": "Philosopher in 10th century Central Asia", "question": "Did Al-Farabi ever meet Mohammed?", "answer": false, "facts": ["Al-Farabi was born in 872 AD.", "Mohammed died in 832 AD."], "decomposition": ["How long ago did Mohammed die?", "When was Al-Farabi born?", "Is #1 before #2?"], "evidence": [[[["Muhammad-63"]], [["Al-Farabi-1"]], ["operation"]], [[["Muhammad-1"]], [["Al-Farabi-1"]], ["operation"]], [[["Mohammed ibn Mohammed Alami-1"]], [["Al-Farabi-9"], "no_evidence"], ["operation"]]]}
{"qid": "e48be839783682257024", "term": "Tony Bennett", "description": "American singer", "question": "Did Tony Bennett have more children than he had wives?", "answer": true, "facts": ["Tony Bennett had four children.", "Tony Bennet has had three wives."], "decomposition": ["How many children has Tony Bennett had?", "How many wives has Tony Bennett had?", "Is #1 greater than #2?"], "evidence": [[[["Tony Bennett-13", "Tony Bennett-27"]], [["Tony Bennett-13", "Tony Bennett-27", "Tony Bennett-43"]], ["operation"]], [[["Tony Bennett-13", "Tony Bennett-27"]], [["Tony Bennett-29", "Tony Bennett-43"]], ["operation"]], [[["Sandra Grant Bennett-2"], "no_evidence"], [["Tony Bennett-27"], "no_evidence"], ["operation"]]]}
{"qid": "46a30058a6a81a3b08df", "term": "Cheshire", "description": "County of England", "question": "Do citizens of Cheshire sing La Marseillaise?", "answer": false, "facts": ["Cheshire is a county located in England in the United Kingdom", "La Marseillaise is the national anthem of France"], "decomposition": ["Which song is referred to as 'La Marseillaise'?", "#1 is usually sung by the citizens of which country?", "Which country is Cheshire located in?", "Is #2 the same as #3?"], "evidence": [[[["La Marseillaise-3"]], [["La Marseillaise-3"]], [["Cheshire-53"]], [["Cheshire-54"], "operation"]], [[["La Marseillaise-1"]], [["La Marseillaise-1"]], [["Cheshire-1"]], ["operation"]], [[["La Marseillaise-1"]], [["La Marseillaise-1"]], [["Cheshire-1"]], ["operation"]]]}
{"qid": "946d0b97a56bbe7acca2", "term": "Chives", "description": "edible species of plant", "question": "Are there any chives hypothetically good for battling vampires?", "answer": true, "facts": ["Vampires in folklore have a weakness to garlic.", "Chives, an edible plant species, come in a number of varieties.", "Garlic chives are a variant of chives first found in China thousands of years ago."], "decomposition": ["What items are used to ward off vampires according to folklore?", "What are the varieties of chives that exist?", "Is any of #1 included in #2?"], "evidence": [[[["Garlic-61"]], [["Garlic-1"]], [["Garlic-1"], "operation"]], [[["Vampire-16"]], [["Chives-1"]], ["operation"]], [[["Garlic-61"]], [["Allium-1"]], ["operation"]]]}
{"qid": "28104d8b40e83617cd2a", "term": "Memory", "description": "information stored in the mind, or the mental processes involved in receiving, storing, and retrieving this information", "question": "Do quadragenarian's have little memory capacity?", "answer": false, "facts": ["Quadragenarians are people that are in their 40s.", "As people age, their memory can get worse.", "Half of people over age 50 have mild to severe memory loss.", "Ken Jennings was 46 years old when he won Jeopardy! The Greatest of All Time tournament."], "decomposition": ["How old do people generally get before their memory capacity starts getting limited?", "Quadragenarians are people within what age-range?", "Is #1 within or less than the range of #2?"], "evidence": [[[["Memory-54"]], [["2015 Chama Cha Mapinduzi presidential primaries-6"]], ["operation"]], [[["Memory-54"]], [["Aging and society-3"], "no_evidence"], ["no_evidence"]], [[["Old age-26"], "no_evidence"], ["no_evidence"], ["operation"]]]}
{"qid": "d4803e3857fb8b51df5b", "term": "Fraktur", "description": "Typeface", "question": "Does Fraktur have a sordid history?", "answer": true, "facts": ["Fraktur is a type of font that originated in Germany.", "Fraktur was used on official Nazi documents.", "Fraktur was used on the cover of Hitler's Mein Kampf."], "decomposition": ["What is Fraktur?", "Which group in Germany used #1 for their official documents?", "Did #2 have a sordid past?"], "evidence": [[[["Fraktur-1"]], [["Fraktur-10"]], ["operation"]], [[["Fraktur-1"]], [["Fraktur-10"]], [["The Holocaust-1"]]], [[["Fraktur-1"]], [["Fraktur-10"]], [["Jewish ghettos in German-occupied Poland-3"], "operation"]]]}
{"qid": "9224ee338a77834434c9", "term": "Kidney", "description": "internal organ in most animals, including vertebrates and some invertebrates", "question": "Can a quarter fit inside of a human kidney?", "answer": true, "facts": ["Kidney stones are hard mineral deposits that can form in the kidneys.", "The largest kidney stone ever recorded was 13 cm wide.", "The diameter of a quarter is 2.4 cm."], "decomposition": ["How big is the largest kidney stone ever recorded?", "How wide is a quarter?", "Is #1 larger than #2?"], "evidence": [[[["Kidney stone disease-46"], "no_evidence"], [["Quarter (United States coin)-1"]], ["operation"]], [["no_evidence"], [["Quarter (United States coin)-3"]], ["operation"]], [[["Kidney-1"]], [["Quarter (United States coin)-1"]], ["operation"]]]}
{"qid": "9d445747557bf9d8786e", "term": "Julia Roberts", "description": "American actress and producer", "question": "Did Julia Roberts practice blast beats as a child?", "answer": false, "facts": ["Julia Roberts played the clarinet in her school band.", "Blast beats are a drum beat that originated in hardcore punk and grindcore, and is often associated with certain styles of extreme metal, namely black metal and death metal."], "decomposition": ["What instrument did Julia Roberts play as a child?", "What instrument does Blast Beats simulate?", "Is #1 the same as #2?"], "evidence": [[[["Julia Roberts-7"]], [["Blast beat-1"]], ["operation"]], [[["Julia Roberts-7"]], [["Blast beat-1"]], ["operation"]], [[["Julia Roberts-7"]], [["Blast beat-6"]], ["operation"]]]}
{"qid": "d9b4f68792ef86249d18", "term": "Wednesday", "description": "Day of the week", "question": "Did Wednesday have something to do with Thor?", "answer": true, "facts": ["Wednesday is the middle of the modern work week and comes from the name Wodan.", "The Germanic god Woden is also known as Wodanaz or Odin.", "Odin, in Norse mythology, was the father of Thor."], "decomposition": ["Which Germanic god is the name 'Wednesday' etymologically related to?", "Is #1 related to Thor?"], "evidence": [[[["Wednesday-5"]], [["Odin-4"]]], [[["Wednesday-1"]], [["Thor-3"], "operation"]], [[["Wednesday-5"]], [["Odin-4"]]]]}
{"qid": "2da278a3d315ec89e21c", "term": "Marxism", "description": "Economic and sociopolitical worldview based on the works of Karl Marx", "question": "Are right wing Amreicans opposed to marxism?", "answer": true, "facts": ["Right Wing Americans view socialism as an enemy to civil liberties and the economy.", "Socialism is a tenant of Marxism, giving workers the means of the production."], "decomposition": ["What stance do most right-wing Americans take towards socialism?", "Is #1 against that which Marxists proposes on the subject?"], "evidence": [[[["Right-wing politics-7"]], [["Marxism-21"], "operation"]], [[["Conservatism-1", "Conservatism-7"]], [["Means of production-5"], "operation"]], [[["Right-wing politics-7"]], [["Timeline of Karl Marx-2"]]]]}
{"qid": "e26a5601edb90a738d56", "term": "Futurama", "description": "American animated sitcom for the Fox Broadcasting Company and Comedy Central", "question": "Will Futurama surpass the number of episodes of The Simpsons by the end of 2020?", "answer": false, "facts": ["Futurama was cancelled in 2013.", "The Simpsons is still creating new episodes as of May 2020.", "Futurama aired 140 total episodes.", "The Simpsons has aired over 600 episodes."], "decomposition": ["How many episodes of Futurama have been produced to date?", "How many episodes of the Simpsons has been produced to date?", "Is #1 greater than #2?"], "evidence": [[[["Meanwhile (Futurama)-1"]], [["The Simpsons-3"]], ["operation"]], [[["Futurama-2", "Futurama-3"], "no_evidence"], [["History of The Simpsons-4"]], ["operation"]], [[["Futurama (season 1)-2"], "no_evidence"], [["History of The Simpsons-4"]], ["operation"]]]}
{"qid": "93264708b0d600fb9650", "term": "Copper", "description": "Chemical element with atomic number 29", "question": "Would a fungal life-form be threatened by a pigment from copper?", "answer": true, "facts": ["Verdigris is a pigment made from copper", "Verdigris is also used as a fungicide "], "decomposition": ["Which element is the pigment verdigris derived from?", "Is #1 copper and verdigris also used as a fungicide?"], "evidence": [[[["Verdigris-1"]], [["Verdigris-6"]]], [[["Verdigris-1"]], [["Copper-5", "Verdigris-6"], "operation"]], [[["Verdigris-1"]], [["Copper-5", "Verdigris-6"], "operation"]]]}
{"qid": "ebbf0b9ffffd08d812e5", "term": "Spice Girls", "description": "British girl group", "question": "Tata Hexa can accomodate every Spice Girl?", "answer": true, "facts": ["The Spice Girls is a five woman musical group from Britain.", "The Tata Hexa is a car with 6 and 7 seat capacities."], "decomposition": ["How many women are in the Spice Girls group?", "How many people can the Tata Hexa seat?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Spice Girls-1"]], [["Tata Aria-2", "Tata Aria-5"], "no_evidence"], ["operation"]], [[["Spice Girls-1"]], [["Tata Hexa-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Spice Girls-1"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "add18119b84e567fed05", "term": "Joker (character)", "description": "Fictional character in the DC Universe", "question": "Is the Joker in a healthy romantic relationship?", "answer": false, "facts": ["Healthy relationships are characterized by mutual trust and respect.", "The Joker is dating Harley Quinn.", "The Joker frequently abuses and talks down to Harley."], "decomposition": ["Who is the Joker in a relationship with?", "Does the Joker respect #1?", "Is respect necessary in a healthy romantic relationship?", "Are #2 and #3 the same?"], "evidence": [[[["Joker (character)-27"]], [["Joker (character)-53"]], [["Interpersonal relationship-21"]], ["operation"]], [[["Joker (character)-3"]], [["Joker (character)-3"]], ["no_evidence"], ["operation"]], [[["Harley Quinn-1"]], [["Harley Quinn-2"]], ["no_evidence", "operation"], ["operation"]]]}
{"qid": "43e781a9076ad3f1d415", "term": "Family of Barack Obama", "description": "List of members of the family of Barack Obama", "question": "Can Family of Barack Obama ride comfortably in 2020 Jaguar F Type?", "answer": false, "facts": ["Barack Obama has a wife and two children.", "The 2020 Jaguar F Type is a car that seats two people."], "decomposition": ["How many people are in Barack Obama's immediate family?", "How many people can sit in a 2020 Jaguar F Type?", "Is #2 greater than #1?"], "evidence": [[[["Family of Barack Obama-2"], "no_evidence"], [["Jaguar F-Type-13"], "no_evidence"], ["no_evidence"]], [[["Family of Barack Obama-5"]], [["Car-42"]], ["operation"]], [[["Barack Obama-15"]], [["Jaguar F-Type-1"]], ["operation"]]]}
{"qid": "17b8fa74f450c4d0e56b", "term": "Alice in Wonderland (1951 film)", "description": "1951 American animated musical fantasy film produced by Walt Disney Productions", "question": "Does Disney's Alice in Wonderland involve the celebration of a holiday?", "answer": true, "facts": ["In the movie, Alice meets the Mad Hatter.", "The Mad Hatter is having a tea party to celebrate his Unbirthday.", "The Unbirthday is a holiday which happens every day of the year which is not the subject's actual birthday."], "decomposition": ["What celebrations were featured in the Disney movie Alice in Wonderland?", "Is any of #1 an holiday?"], "evidence": [[[["Alice in Wonderland (1951 film)-7"]], ["operation"]], [[["Alice in Wonderland (franchise)-14"]], [["Birthday-1"], "operation"]], [[["Alice in Wonderland (1951 film)-9"], "no_evidence"], ["operation"]]]}
{"qid": "1051df8b6730dcd1b34f", "term": "Game (hunting)", "description": "animal hunted for sport or for food", "question": "Would a customer be happy if their grocery store meat tasted like game?", "answer": false, "facts": ["\"Gamey\" is a word used to describe meat with a grassier, more wild taste.", "Gaminess in supermarket meat is very unusual.", "Many people find game to be unpleasant in taste."], "decomposition": ["Which kind of meat is referred to as game?", "Are grocery store customers accustomed to #1?"], "evidence": [[[["Game (hunting)-6"]], [["Meat-1"]]], [[["Game (hunting)-1"]], [["Game (hunting)-5"], "no_evidence"]], [[["Game (hunting)-1"]], ["no_evidence", "operation"]]]}
{"qid": "79af6e281b295c2a2e85", "term": "Simon Cowell", "description": "English reality television judge, television producer and music executive", "question": "Can Simon Cowell vote for the next Supreme Court judge?", "answer": false, "facts": ["The Supreme Court is the highest court in the USA.", "Simon Cowell is a British talent competition judge.", "Members of the Supreme Court are appointed, rather than elected."], "decomposition": ["Who appoints US Supreme Court judges?", "Is Simon Cowell currently serving as #1?"], "evidence": [[[["Appointments Clause-1"]], [["Simon Cowell-27", "Simon Cowell-43"], "operation"]], [[["Appointment and confirmation to the Supreme Court of the United States-3"]], [["Simon Cowell-1"]]], [[["Supreme Court of the United States-2"]], [["Donald Trump-1"]]]]}
{"qid": "80ba3ad84b318f16f34c", "term": "The Atlantic", "description": "Magazine and multi-platform publisher based in Washington, D.C.", "question": "Could you read The Atlantic magazine during the Games of the XXII Olympiad?", "answer": true, "facts": ["The Atlantic magazine, founded in 1857, still publishes as of May 2020.", "The XXII Olympiad was the official name for the 1980 Summer Olympics."], "decomposition": ["When was The Atlantic Magazine founded?", "When was the XXII Olypiad?", "Is #2 after #1?"], "evidence": [[[["The Atlantic-1"]], [["1980 Summer Olympics-1"]], ["operation"]], [[["The Atlantic-1"]], [["1980 Summer Olympics-1"]], ["operation"]], [[["The Atlantic-1"]], [["1980 Summer Olympics-1"]], ["operation"]]]}
{"qid": "3763c0523e44d02ff1e3", "term": "QR code", "description": "trademark for a type of matrix barcode", "question": "Do you have to put on glasses to read a QR code?", "answer": false, "facts": ["Glasses are used to improve one's vision capabilities.", "QR codes are not readable by humans and have to be read by machines or programs."], "decomposition": ["Can a human read QR codes?"], "evidence": [[["no_evidence", "operation"]], [[["QR code-5"]]], [[["QR code-1"]]]]}
{"qid": "cda85328c8825e86d3f0", "term": "Astronomer", "description": "Scientist who studies celestial bodies", "question": "Does Nintendo's link ever see an astronomer?", "answer": true, "facts": ["Link is the main character of the Nintendo franchise 'Zelda\".", "In \"Legend of Zelda: Majora's Mask\" Link meets an astronomer in an observatory."], "decomposition": ["Which game is Link from?", "In #1, did link meet an astronomer?"], "evidence": [[[["The Legend of Zelda-24"]], [["Universe of The Legend of Zelda-60"], "no_evidence", "operation"]], [[["Link (The Legend of Zelda)-1"]], ["no_evidence"]], [[["Link (The Legend of Zelda)-1"]], ["no_evidence", "operation"]]]}
{"qid": "1700bc2c9529a12bd026", "term": "Naruto", "description": "Japanese manga and anime series", "question": "Could you watch Naruto and Puzzle Place on the same channel?", "answer": false, "facts": ["Puzzle Place aired on PBS between 1995 and 1998.", "Naruto aired on Cartoon Network in 2005."], "decomposition": ["What channel did Puzzle Place air on?", "What channel did Naruto air on?", "Is #1 the same as #2?"], "evidence": [[[["The Puzzle Place-1"]], [["Naruto-2"]], ["operation"]], [[["The Puzzle Place-1"]], [["Naruto-2"]], ["operation"]], [[["The Puzzle Place-1"]], [["Naruto-24"]], ["operation"]]]}
{"qid": "4dd3a8a73cc4786cd638", "term": "Stork", "description": "family of birds", "question": "Do storks need golden toads to survive?", "answer": false, "facts": ["Storks feed on a number of reptiles, amphibians, and ammals, and insects.", "The golden toad is an amphibian.", "The golden toad is a rare animal that has not been seen since 1989."], "decomposition": ["What is the most current population estimate of storks?", "What is the most current population estimate of golden toads?", "If storks exclusively ate golden toads, would #2 have been enough to sustain #1?"], "evidence": [[[["Stork-1"], "no_evidence"], [["Golden toad-1"]], ["operation"]], [[["Stork-10"], "no_evidence"], [["Golden toad-1"]], ["no_evidence", "operation"]], [[["Stork-1"], "no_evidence"], [["Golden toad-2"], "no_evidence"], ["operation"]]]}
{"qid": "8c754ab507b269281c30", "term": "Eiffel Tower", "description": "Tower located on the Champ de Mars in Paris, France", "question": "Was the Eiffel tower used as a symbol of the French Revolution?", "answer": false, "facts": ["The French Revolution took place 1789-1799.", "The Eiffel Tower was built a century later in 1888."], "decomposition": ["When was the French Revolution?", "When was the Eiffel Tower built?", "Is #2 before #1?"], "evidence": [[[["French Revolution-1"]], [["Eiffel Tower-2"]], ["operation"]], [[["French Revolution-1"]], [["Eiffel Tower-2"]], ["operation"]], [[["French Revolution-1"]], [["Eiffel Tower-2"]], ["operation"]]]}
{"qid": "0782cde19737531d14fe", "term": "University of Pittsburgh", "description": "American state-related research university located in Pittsburgh, Pennsylvania", "question": "Is University of Pittsburgh easier to enter than FBI?", "answer": true, "facts": ["The University of Pittsburgh has around a 60% acceptance rate.", "The FBI estimated accepting 900 agents out of 16000 applicants in 2019."], "decomposition": ["What percent of applicants does University of Pittsburgh accept?", "How many applications did the FBI get in 2019?", "Out of #2, how many were accepted?", "What is #3 divided by #2?", "Is #1 greater than #4?"], "evidence": [[["no_evidence"], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"], ["no_evidence", "operation"]], [[["University of Pittsburgh-2"], "no_evidence"], [["Federal Bureau of Investigation-59"], "no_evidence"], ["no_evidence"], ["operation"], ["operation"]], [[["University of Pittsburgh-35"], "no_evidence"], [["Federal Bureau of Investigation-61"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"], ["no_evidence", "operation"]]]}
{"qid": "2ed0dd0664d4583389bc", "term": "Horseradish", "description": "species of plant", "question": "Does horseradish have a fetlock?", "answer": false, "facts": ["Horseradish is a type of plant that is used as a condiment.", "Fetlock is the common name used for a joint found in horses."], "decomposition": ["What kingdom is horseradish in?", "Where is a fetlock found?", "What kingdom is #2 in?", "is #1 the same as #3?"], "evidence": [[[["Horseradish-1"], "no_evidence"], [["Fetlock-1"]], [["Horse-1"], "no_evidence"], ["operation"]], [[["Horseradish-4"]], [["Fetlock-1"]], [["Horse-48"], "no_evidence"], ["operation"]], [[["Horseradish-1"], "no_evidence"], [["Fetlock-1"]], [["Horse-1"], "no_evidence"], ["operation"]]]}
{"qid": "ee5be0cf3e643eb6b699", "term": "Olive oil", "description": "liquid fat extracted by pressing olives", "question": "Can olive oil kill rabies?", "answer": false, "facts": ["Olive oil is a fat used in cooking.", "Olive oil is made up of palmitic acid which is a weak acid found in plants and animals.", "Rabies is a disease from an infected animal bite.", "Rabies is treated by a shot containing immunoglobuin, a protein that is found in plasma cells.", "Plasma cells are found in the bone marrow of humans."], "decomposition": ["What is used to treat rabies?", "What is olive oil made of?", "Are any of #2 present in #1?"], "evidence": [[[["Rabies-31"]], [["Olive oil-1"]], ["operation"]], [[["Rabies-30", "Rabies-33"]], [["Olive oil-1"]], ["operation"]], [[["Rabies-30"]], [["Olive oil-3"]], ["operation"]]]}
{"qid": "c69a3eeea9743e782831", "term": "Supreme Court of the United States", "description": "Highest court in the United States", "question": "Do members of the Supreme Court of the United States have longer terms than most senators?", "answer": true, "facts": ["Senators, on average, serve for 10 years.", "Supreme Court Justices serve for their entire life.", "The average term for a Supreme court justice is 16 years."], "decomposition": ["How many years is in a term for a U.S. Senator?", "What is the term for a Supreme Court justice?", "Is #1 a shorter term than #2?"], "evidence": [[[["United States Senate-2"]], [["Supreme Court of the United States-31"]], ["operation"]], [[["United States Senate-16"]], [["Supreme Court of the United States-2"]], ["operation"]], [[["Member of Congress-3"]], [["Supreme Court of the United States-2"]], ["operation"]]]}
{"qid": "d7bac31bafedfe9de6ee", "term": "Alfa Romeo", "description": "Italian automotive manufacturer", "question": "Can you order an Alfa Romeo at Starbucks?", "answer": false, "facts": ["Alfa Romeo is a brand of automobile", "Starbucks sells coffee, tea, food, and some drink products like thermoses"], "decomposition": ["What kind of product is an Alfa Romeo?", "What kind of goods does Starbucks sell?", "Is #1 found in #2?"], "evidence": [[[["Alfa Romeo Giulietta (940)-1"]], [["Starbucks-1"]], ["operation"]], [[["Alfa Romeo-1"]], [["Starbucks-1"]], ["operation"]], [[["Alfa Romeo-1"]], [["Starbucks-1"]], ["operation"]]]}
{"qid": "f4256dffd78da0d7fdf8", "term": "Hair", "description": "protein filament that grows from follicles found in the dermis, or skin", "question": "Do skeletons have hair?", "answer": false, "facts": ["Hair grows from the skin.", "Skeletons are a structure of multiple bones.", "Bones do not grow hair. "], "decomposition": ["Where does hair grow from?", "What are skeletons made out of?", "Does #2 have #1?"], "evidence": [[[["Dermis-1", "Hair-1"]], [["Skeleton-1", "Skeleton-19"]], ["operation"]], [[["Hair-6"]], [["Skeleton-19"], "no_evidence"], ["operation"]], [[["Hair-1"]], [["Skeleton-14"]], ["operation"]]]}
{"qid": "69e0b6f868ee71314fc1", "term": "Marco Rubio", "description": "United States Senator from Florida", "question": "Does Marco Rubio have a close relationship with Allah?", "answer": false, "facts": ["Marco Rubio adheres to the religious sect of Christianity known as Catholicism.", "Catholics and other Christians worship God.", "Allah is worshiped by believers of Islam."], "decomposition": ["What is Marco Rubio's religion?", "Which deity does #1 worship?", "Is #2 Allah?"], "evidence": [[[["Marco Rubio-86"]], [["Catholic Church-2"]], [["God in Islam-13"], "operation"]], [[["Marco Rubio-7"]], [["God in Catholicism-38"]], ["operation"]], [[["Marco Rubio-86"]], [["Christianity-1"]], ["operation"]]]}
{"qid": "79595ffe6b93c5e84056", "term": "Selfie", "description": "Photographic self-portrait", "question": "Are selfies more dangerous than plague in modern times?", "answer": true, "facts": ["There are an average of 7 human plague cases reported each year according to the CDC.", "Selfies have caused people to fall off of cliffs while trying to get the perfect picture.", "From October 2011 and November 2017, there were 259 selfie deaths in 137 incidents."], "decomposition": ["How many cases of the plague are there yearly?", "How many people die yearly while taking selfies?", "Is #2 greater than #1?"], "evidence": [[[["Epidemiology of plague-23"]], ["no_evidence"], ["operation"]], [[["Epidemiology of plague-23"], "operation"], ["no_evidence"], ["no_evidence"]], [[["Epidemiology of plague-1"]], [["Selfie-53"], "no_evidence"], ["operation"]]]}
{"qid": "d1c8f0835896d18c99c2", "term": "Martin Luther", "description": "Saxon priest, monk and theologian, seminal figure in Protestant Reformation", "question": "If Martin Luther did one theses a day would he run out in half a year?", "answer": true, "facts": ["Martin Luther published a list of 95 theses as his critique of the church.", "There are approximately 182 days in 6 months."], "decomposition": ["How many theses did Martin Luther publish in a list?", "How many days are in a year?", "What is #2 divided by 2?", "Is #1 less than #3?"], "evidence": [[[["Martin Luther-1"]], [["Year-4"]], ["operation"], ["operation"]], [[["Ninety-five Theses-1"]], [["Calendar year-2"]], ["operation"], ["operation"]], [[["Martin Luther-1"]], [["Year-3"]], ["operation"], ["operation"]]]}
{"qid": "7daa137a9509cb6c211a", "term": "Billionaire", "description": "person who has a net worth of at least one billion (1,000,000,000) units of a given currency", "question": "Is Cambodia too expensive for 2020 richest billionaire to own?", "answer": false, "facts": ["The richest billionaire in 2020 is Jeff Bezos.", "Jeff Bezos has an estimated worth of 145 billion dollars.", "GDP is a measure of how much the economy of a country is worth.", "Cambodia has an estimated GDP of 28 billion in 2020."], "decomposition": ["Who is currently the richest person alive?", "What is the net worth of #1?", "What is the GDP of Cambodia?", "Is #2 less than #3?"], "evidence": [[[["Jeff Bezos-1"]], [["Jeff Bezos-1"]], [["Cambodia-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Jeff Bezos-1"]], [["Jeff Bezos-28"]], [["Thailand and the International Monetary Fund-2"], "no_evidence"], ["operation"]], [[["Jeff Bezos-1"]], [["Jeff Bezos-1"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "43302ebc930b722c112b", "term": "Osama bin Laden", "description": "Co-founder of al-Qaeda", "question": "Does Osama bin Laden put a wafer on his tongue every Sunday?", "answer": false, "facts": ["Osama bin Laden was an Islamic fundamentalist", "The practice of putting a wafer on your tongue is called Communion", "Communion is a Christian religious practice", "Christians commonly attend religious services on Sunday"], "decomposition": ["What is the practice of putting a wafer on your tongue called?", "What religion practices #1 on Sundays?", "Does Osama bin Laden practice #2?"], "evidence": [[[["Eucharist-1"]], [["Christianity-37"]], [["Osama bin Laden-1"]]], [[["Eucharist-65"]], [["Eucharist-1"]], [["Osama bin Laden-1"], "operation"]], [[["Eucharist-95"]], [["Eucharist-1"]], [["Osama bin Laden-10"], "operation"]]]}
{"qid": "cbc489c97e6797962787", "term": "Martyr", "description": "person who suffers persecution and death for advocating, refusing to renounce, and/or refusing to advocate a belief or cause, usually a religious one", "question": "Can a martyr saint have been excommunicated?", "answer": true, "facts": ["Joan of Arc was excommunicated by the Catholic Church in 1431.", "Joan of Arc was declared a martyr in 1456 after an investigation ordered by King Charles VII.", "Joan of Arc was canonized a Saint by the Catholic Church on May 16, 1920."], "decomposition": ["Is Joan of Arc considered a matyr?", "Was she initially excommunicated by the Catholic Church?", "Is #1 or #2 negative?"], "evidence": [[[["Canonization of Joan of Arc-1"]], [["Canonization of Joan of Arc-2"]], ["operation"]], [[["Joan of Arc-3"]], [["Heresy-3", "Joan of Arc-37"], "no_evidence"], ["operation"]], [[["Joan of Arc-3"]], [["Canonization of Joan of Arc-2"]], ["operation"]]]}
{"qid": "3295844627a9bd1b9135", "term": "The Matrix", "description": "1999 science fiction action film directed by the Wachowskis", "question": "Was Harry Potter a better investment than The Matrix for Warner Bros.?", "answer": true, "facts": ["Warner Bros. distributes several movie franchises including The Matrix, Harry Potter, and The Dark Knight.", "The Matrix had 2 sequels.", "Harry Potter had 7 sequels and several spin-offs.", "Harry Potter and the Deathly Hallows \u2013 Part 2 is Warner Bros. highest grossing film worldwide with a box office gross of $1,342,932,398."], "decomposition": ["How much did the Harry Potter (film series) gross?", "How much did the The Matrix (franchise) gross?", "Is #1 greater than #2?"], "evidence": [[[["Harry Potter (film series)-4"]], [["The Matrix (franchise)-4"]], ["operation"]], [[["Harry Potter (film series)-4"]], [["The Matrix (franchise)-4"]], ["operation"]], [[["Harry Potter-3"], "no_evidence"], [["The Matrix-36"]], ["operation"]]]}
{"qid": "8e03ed9fce31618b095a", "term": "Apollo", "description": "God in Greek mythology", "question": "Could all of the famous Apollo's hypothetically defeat all of the famous D'Artagnan's?", "answer": true, "facts": ["The famous D'artagnan was a musketeer based on a count that served Louis XIV", "There are at least three famous Apollo's: Apollo Creed, Apollo (Greek mythology), and Apollo Crews.", "Apollo, the Greek god of the sun and healing, is immortal."], "decomposition": ["Who were the famous D'artagnan?", "Who were the famous Apollos?", "What special power did one of the #2's have?", "Can #1 be defeated by someone who is #3?"], "evidence": [[[["Charles de Batz de Castelmore d'Artagnan-1"]], [["Apollo-1"]], [["Apollo-155"]], [["Apollo-155", "Charles de Batz de Castelmore d'Artagnan-3"]]], [[["Charles de Batz de Castelmore d'Artagnan-1"], "no_evidence"], [["Apollo (band)-1", "Apollo program-2", "Apollo-1"], "no_evidence"], [["Apollo-183", "Coronis (lover of Apollo)-3"], "no_evidence"], ["no_evidence", "operation"]], [[["Charles de Batz de Castelmore d'Artagnan-1"]], [["Apollo Creed-1", "Apollo-1"]], [["Apollo-208"], "no_evidence"], ["operation"]]]}
{"qid": "11714d45205c86d31910", "term": "Uppsala", "description": "Place in Uppland, Sweden", "question": "Can the city of Miami fit inside Uppsala?", "answer": false, "facts": ["Miami measures 55.25 mi\u00b2.", "Uppsala has an area of 18.83 mi\u00b2. "], "decomposition": ["What is the area of Miami?", "What is the area of Uppsala?", "Is #1 less than or equal to #2?"], "evidence": [[[["Miami-15"]], ["no_evidence"], ["operation"]], [[["Miami-1"]], [["Uppsala-1"], "no_evidence"], ["operation"]], [[["Miami-1"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "55bcf8e81e775bac5a4e", "term": "DARPA", "description": "Agency of the U.S. Department of Defense responsible for the development of new technologies", "question": "Did DARPA influence Albert Einstein? ", "answer": false, "facts": ["DARPA is an agency in the US focused on defense and new technologies.", "DARPA was founded in 1958 under Dwight D Eisenhower.", "Albert Einstein was a famous physicist who died in 1955."], "decomposition": ["When was DARPA formed?", "When did Albert Einstein die?", "Is #1 before #2?"], "evidence": [[[["DARPA-2"]], [["Albert Einstein-1"]], ["operation"]], [[["DARPA-2"]], [["Albert Einstein-1"]], ["operation"]], [[["DARPA-2"]], [["Albert Einstein-1"]], ["operation"]]]}
{"qid": "694ac8d334fc4545ee31", "term": "Kurt Cobain", "description": "American singer, composer, and musician", "question": "Did Kurt Cobain's music genre survive after his death?", "answer": true, "facts": ["Kurt Cobain was the lead singer of Nirvana.", "Nirvana's music is classified as Grunge rock.", "Kurt Cobain died on April 5, 1994.", "Some of the major Grunge rock bands included Alice in Chains, Pearl Jam, and Soundgarden.", "Alice in Chains and Pearl Jam released their latest albums in 2018 and 2020 respectively."], "decomposition": ["What is the musiucal genre associated with both Kurt Cobain and Pearl Jam?", "What year did Kurt Cobain die? ", "Did Pearl Jam release a #1 genre album after #2?", "Is #3 yes?"], "evidence": [[[["Grunge-2"]], [["Kurt Cobain-1"]], [["No Code-1"]], [["No Code-1"]]], [[["Kurt Cobain-2", "Pearl Jam-2"]], [["Kurt Cobain-55"]], [["Vitalogy-9"], "no_evidence"], ["operation"]], [[["Grunge-2"]], [["Kurt Cobain-1"]], [["Lightning Bolt (Pearl Jam album)-11"]], ["operation"]]]}
{"qid": "d47120efd0f09badd848", "term": "Menthol", "description": "chemical compound", "question": "Is menthol associated with Christmas?", "answer": true, "facts": ["Menthol is the chemical in mint products that give mint its characteristic cool and tangy taste.", "Peppermint is a popular candy flavor during Christmas season."], "decomposition": ["What is a popular candy flavor during Christmas?", "Is menthol an ingredient in #1?"], "evidence": [[[["Candy cane-1"]], [["Peppermint-2"]]], [[["Candy cane-1"]], [["Menthol-1"]]], [[["Candy cane-1"], "no_evidence"], ["operation"]]]}
{"qid": "722dc38bd849d8b6ec0f", "term": "Reproduction", "description": "Biological process by which new organisms are generated from one or more parent organisms", "question": "Are those incapable of reproduction incapable of parenthood?", "answer": false, "facts": ["Surrogates are women who will carry a baby to term for a family seeking to adopt.", "Many children are put into the adoption and foster system every year and are always available to adopt, independent of the parents reproductive status."], "decomposition": ["What do surrogate mothers do?", "What purpose do adoption and foster systems serve?", "Do #1 and #2 fail to help couples incapable of reproduction become parents?"], "evidence": [[[["Mother-11"]], [["Adoption-8"]], ["operation"]], [[["Surrogacy-1", "Surrogacy-2"]], [["Adoption-1", "Foster care-1"]], ["operation"]], [[["Surrogacy-1"]], [["Adoption-1"]], ["no_evidence"]]]}
{"qid": "34630e83060d07bec4e0", "term": "Plastic", "description": "material of a wide range of synthetic or semi-synthetic organic solids", "question": "Do beeswax alternatives to cling wrap use plsatic?", "answer": false, "facts": ["Beeswax food wrapping is typically made of two ingredients.", "Beeswax food wrap is composed of cotton fabric and beeswax.", "Neither cotton nor beeswax contains plastic."], "decomposition": ["What are the components of Beeswax food wrap?", "Do any among #1 contain plastic?"], "evidence": [[[["Beeswax wrap-1"]], ["operation"]], [[["Beeswax wrap-1"]], ["operation"]], [[["Beeswax wrap-8"]], ["operation"]]]}
{"qid": "bf4bc8f3c5953306874d", "term": "Onion", "description": "vegetable", "question": "Would a blooming onion be possible with a shallot?", "answer": false, "facts": ["A blooming onion is a dish for sharing, featuring a sliced and deep fried onion made to resemble petals.", "A shallot is very small and would only make a few \"petals\""], "decomposition": ["What characteristics of onions are important when making blooming onion dish?", "Do the characteristics of shallot match with all of #1?"], "evidence": [[[["Blooming onion-1"]], [["Shallot-1"], "no_evidence", "operation"]], [[["Blooming onion-1"], "no_evidence"], [["Shallot-7"], "no_evidence", "operation"]], [[["Blooming onion-1"]], [["Shallot-14"], "no_evidence", "operation"]]]}
{"qid": "dae25ebc5462a52b5c17", "term": "Harry Potter and the Philosopher's Stone", "description": "1997 fantasy novel by J. K. Rowling", "question": "Did children read Harry Potter and the Philosopher's Stone during the Albanian Civil War?", "answer": true, "facts": ["Harry Potter and the Philosopher's Stone was a 1997 children's fantasy book.", "The Albanian Civil War, also called the Albanian Civil Unrest, happened in 1997."], "decomposition": ["What year was Harry Potter and the Philosopher's Stone published?", "What year was the Albanian Civil War?", "Did #1 not after #2?"], "evidence": [[[["Harry Potter and the Philosopher's Stone-35"]], [["Albanian Civil War-6"], "no_evidence"], [["Albanian Civil War-6", "Harry Potter and the Philosopher's Stone-35"], "operation"]], [[["Harry Potter and the Philosopher's Stone-2"]], [["Albanian Civil War-1"]], ["operation"]], [[["Harry Potter and the Philosopher's Stone-2"]], [["Albanian Civil War-1"]], ["operation"]]]}
{"qid": "6de352d79466276a1d06", "term": "Sand cat", "description": "Small wild cat", "question": "Do sand cats avoid eating all of the prey of eels?", "answer": false, "facts": ["Sand cats eat a number of animals including insects, birds, hares, and reptiles.", "Eels prey on fish, worms, frogs, and lizards.", "Lizards are a type of reptile."], "decomposition": ["What does the sand cat's diet consist of?", "What does the eel's diet consist of?", "Are any of the foods in #2 a subtype of a food in #1?", "Is it not the case that #3 is \"yes\"?"], "evidence": [[[["Sand cat-48", "Sand cat-49", "Sand cat-51"]], [["American eel-4"]], [["Invertebrate-1"], "operation"], ["operation"]], [[["Sand cat-48", "Sand cat-49", "Sand cat-50"]], [["Electric eel-18", "Moray eel-8"]], ["operation"], ["operation"]], [[["Sand cat-48"]], [["Eel-1", "European conger-4"], "no_evidence"], ["operation"], ["operation"]]]}
{"qid": "765107a950759075813a", "term": "Winemaking", "description": "the production of wine, starting with the selection of the fruit, its fermentation into alcohol, and the bottling of the finished liquid", "question": "Do people remember Lucille Ball's winemaking as successful?", "answer": false, "facts": ["Lucille Ball was the star of \"I Love Lucy\".", "On \"I Love Lucy\", Lucille's character fails miserably while stomping grapes for wine."], "decomposition": ["What show was Lucille Ball a star of?", "On #1, was Lucille's character successful in making wine?"], "evidence": [[[["Lucille Ball-1"]], [["Grape treading-3"], "no_evidence", "operation"]], [[["I Love Lucy-1"]], [["Grape treading-3"], "no_evidence", "operation"]], [[["Lucille Ball-24"]], ["no_evidence"]]]}
{"qid": "33858996585a4d2ab95e", "term": "Ludacris", "description": "American rapper and actor", "question": "Does Ludacris have Greek heritage?", "answer": true, "facts": ["Ludacris's real name is Christopher Brian Bridges", "Christopher is a name derived from Greek origins"], "decomposition": ["What is Ludacris's real name?", "Where is #1 derived from?"], "evidence": [[[["Ludacris-1"]], ["no_evidence"]], [[["Ludacris-1"]], [["Christopher-1"]]], [[["Ludacris-1"]], [["Ludacris-3"], "operation"]]]}
{"qid": "399d5e61740a8a93dbe7", "term": "Reproduction", "description": "Biological process by which new organisms are generated from one or more parent organisms", "question": "Is it true that gay male couples cannot naturally reproduce?", "answer": false, "facts": ["Gay men can have any of the various sex organs that humans have.", "Trans men will sometimes become pregnant with their significant other before transitioning medically. "], "decomposition": ["What defines a male gender?", "What organs are needed to impregnate someone?", "What organs are needed to carry a pregnancy?", "Does #1 exclude persons with either of #2 or #3?"], "evidence": [[[["Male-4"]], [["Sex organ-1"]], [["Uterus-1"]], ["operation"]], [[["Gender-1"]], [["Male reproductive system-2"]], [["Female reproductive system-1"]], ["operation"]], [[["Male-1"]], [["Male reproductive system-2"]], [["Female reproductive system-1", "Pregnancy-1"]], ["operation"]]]}
{"qid": "90e6d4060a0b911fe436", "term": "PayPal", "description": "Online financial services company based in San Jose, California", "question": "Would it be unusual to use paypal for drug deals?", "answer": true, "facts": ["Paypal prohibits the use of their platform for drugs or drug paraphernalia. ", "Using paypal leaves a digital footprint of any drug purchase."], "decomposition": ["Which kind of payments are prohibited on Paypal?", "Does #1 include payment for drug deals?"], "evidence": [[["no_evidence"], ["operation"]], [[["PayPal-55"]], ["operation"]], [[["Reception of WikiLeaks-37"], "no_evidence"], ["operation"]]]}
{"qid": "a21a4ba185d355de3e26", "term": "Moli\u00e8re", "description": "17th-century French playwright and actor", "question": "Was Moliere Queen Margot's ill fated lover?", "answer": false, "facts": ["Queen Margot is a character in Alexande Dumas's La Reine Margot.", "Queen Margot keeps the head of her executed lover.", "Joseph Boniface de La M\u00f4le, nicknamed La Mole, was executed as a conspirator against Queen Margot's kingdom.", "Queen Margot is set during the St. Bartholomew's Day Massacre which occurred in 1572.", "Moliere was born in 1622."], "decomposition": ["In what work by Alexande Dumas does Queen Margot appear?", "When was #1 written?", "In what year was Moliere born?", "Is #3 before #2?"], "evidence": [[[["La Reine Margot (novel)-1"]], [["La Reine Margot (novel)-1"]], [["Moli\u00e8re-1"]], ["operation"]], [[["La Reine Margot (novel)-1", "La Reine Margot (novel)-3"]], [["La Reine Margot (novel)-1", "La Reine Margot (novel)-3"]], [["Moli\u00e8re-1"]], ["operation"]], [[["La Reine Margot (novel)-1", "La Reine Margot (novel)-5"]], [["La Reine Margot (novel)-1"]], [["Moli\u00e8re-1"]], ["operation"]]]}
{"qid": "21305b3d437a146b0b2d", "term": "1960", "description": "Year", "question": "Were there footprints on the moon in 1960?", "answer": false, "facts": ["The first man to walk on the moon was aboard Apollo 11.", "Apollo 11 took off in 1969."], "decomposition": ["When did humans first land on the moon?", "Is #1 before or in 1960?"], "evidence": [[[["Moon landing-2"]], ["operation"]], [[["Moon landing-2"]], ["operation"]], [[["Apollo 11-1"]], ["operation"]]]}
{"qid": "c2f573c79ceab25e8fcd", "term": "Strawberry", "description": "edible fruit", "question": "Can a strawberry get worms similar to dogs?", "answer": true, "facts": ["Strawberry can suffer from black root rot and nematodes.", "Dogs can suffer from a variety of worms including roundworms that lay eggs on them.", "Nematodes are parasites that are also called roundworms and ascarids.", "Nematodes are parasites that feed off of strawberry plants."], "decomposition": ["What types of worms can strawberries become infected with?", "What types of worms can dogs become infected with?", "Are any of #1 present in #2?"], "evidence": [[[["Ditylenchus dipsaci-6"], "no_evidence"], [["Dog-18"]], ["no_evidence", "operation"]], [[["Strawberry-26"]], [["Worm-7"]], [["Worm-7"]]], [["no_evidence"], [["Dog-18"]], ["no_evidence", "operation"]]]}
{"qid": "e1f10b57579fa6a92aa9", "term": "Martin Luther", "description": "Saxon priest, monk and theologian, seminal figure in Protestant Reformation", "question": "Did Martin Luther believe in Satan?", "answer": true, "facts": ["Martin Luther was a Protestant.", "Satan is also known as the devil.", "Protestants traditionally have believed in the devil as a being. "], "decomposition": ["What religion was Martin Luther?", "Do #1's believe in the existence of a non-human evil being (Satan, Beelzebub, the devil, etc)?"], "evidence": [[[["Martin Luther-1"]], [["Antichrist-1"], "no_evidence", "operation"]], [[["Martin Luther-12"]], [["Augustinians-1", "Devil-9"], "operation"]], [[["Martin Luther-111"]], [["Satan-32"]]]]}
{"qid": "3f8a1bd6bf3a967cdeb6", "term": "Spinal cord", "description": "long, thin, tubular structure made up of nervous tissue", "question": "Would a hedgehog avoid animals without a spinal cord?", "answer": false, "facts": ["A hedgehog has a wide ranging diet including birds, toads, slugs, and snails.", "Slugs are animals known as invertebrates because they have no backbones."], "decomposition": ["What animals do hedgehog mainly eats?", "Out of #1, do all animals have a spinal cord?"], "evidence": [[[["Hedgehog-11"]], [["Frog-54", "Vertebrate-1"], "operation"]], [[["Hedgehog-11"]], ["no_evidence", "operation"]], [[["Hedgehog-11"]], ["operation"]]]}
{"qid": "606181aacf5722b85a0a", "term": "Mona Lisa", "description": "Painting by Leonardo da Vinci", "question": "After viewing the Mona Lisa, could you get lunch nearby on foot?", "answer": true, "facts": ["The Mona Lisa is housed in The Louvre.", "There are many restaurants within walking distance of The Louvre."], "decomposition": ["Where is the Mona Lisa located?", "Is #1 a place likely to have at least a restaurant/hotel nearby?"], "evidence": [[[["Mona Lisa-54"]], [["Louvre-60"]]], [[["Mona Lisa-29"]], [["Louvre-60"]]], [[["Louvre-1", "Mona Lisa-2"]], ["operation"]]]}
{"qid": "76f183dc037e7b30e2a2", "term": "Pi", "description": "Ratio of the circumference of a circle to its diameter", "question": "Was Pi an acceptable number of children in 1980s China?", "answer": false, "facts": ["Pi, the ratio of a circle's circumference to diameter, is equal to 3.14.", "In the 1980's China instituted a one-child policy.", "People that violated China's one child policy were fined heavily and some were sterilized."], "decomposition": ["How many children were Chinese parents limited to by the One-child policy in the 1980s?", "What is the value of the number pi?", "Is #2 less than or equal to #1?"], "evidence": [[[["One-child policy-1"]], [["Pi-1"]], ["operation"]], [[["One-child policy-1"]], [["Pi-1"]], ["operation"]], [[["One-child policy-1"]], [["Pi-1"]], ["operation"]]]}
{"qid": "bbdc84df46a82a583e06", "term": "The Great Gatsby", "description": "1925 novel by F. Scott Fitzgerald", "question": "When Hugh Jackman was a teacher, would he have taught The Great Gatsby?", "answer": false, "facts": ["The Great Gatsby is often taught in high school English classes. ", "Hugh Jackman worked as a school gym teacher before he was an actor."], "decomposition": ["What classes did Hugh Jackman teach?", "In what classes is The Great Gatsby taught?", "Are any of the classes listed in #1 also listed in #2?"], "evidence": [[[["Hugh Jackman-4"], "no_evidence"], [["The Great Gatsby-23"], "no_evidence"], ["no_evidence"]], [[["Hugh Jackman-4"]], [["The Great Gatsby-1", "The Great Gatsby-3"], "no_evidence"], ["no_evidence", "operation"]], [[["Hugh Jackman-4"]], [["English studies-1"]], ["operation"]]]}
{"qid": "3570d57f16a40488ff42", "term": "Judo", "description": "modern martial art, combat and Olympic sport", "question": "Do silicone suits make judo difficult?", "answer": true, "facts": ["Judo is a martial art that requires combatants to grip their opponents and throw them in various ways.", "Judo practitioners traditionally wear an outfit called a gi, which opponents use to grip and throw.", "Silicone is one of the slipperiest substances on the planet."], "decomposition": ["What maneuvers are required to do Judo?", "What characteristics does an article of clothing need to have in order to do #1 effectively?", "What characteristics does a silicone suit have? ", "Is #3 excluded from #2?"], "evidence": [[[["Judo-1"]], [["Keikogi-1"], "no_evidence"], [["Silicone rubber-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Leopold's maneuvers-6"], "no_evidence"], ["no_evidence"], [["Silicone-47"]], ["operation"]], [[["Judo-1"]], [["Judo-48"]], [["Silicone-1"]], ["operation"]]]}
{"qid": "ed81a7d100d85c51ccae", "term": "Marlboro (cigarette)", "description": "cigarette brand", "question": "Are the colors on Marlboro package found on French flag?", "answer": false, "facts": ["The colors of the Marlboro package are red, white, and black.", "The French flag has the colors red, white, and blue."], "decomposition": ["What are the colors of a Marlboro package?", "What are the colors of the French flag?", "Is #1 identical to #2?"], "evidence": [[[["Marlboro (cigarette)-12", "Marlboro (cigarette)-15", "Marlboro (cigarette)-17"]], [["Flag of France-1"]], ["operation"]], [[["Marlboro (cigarette)-17"]], [["Flag of France-1"]], ["operation"]], [[["Marlboro (cigarette)-17"]], [["Flag of France-1"]], ["operation"]]]}
{"qid": "fdff69018a970c7f3bbc", "term": "Homelessness", "description": "circumstance when people desire a permanent dwelling but do not have one", "question": "Does Antarctica have a lot of problems relating to homelessness?", "answer": false, "facts": ["Antarctica has no permanent residents.", "Exposure to the elements would be deadly for homeless people during certain times of year."], "decomposition": ["What do homeless people lack?", "Does the weather in Antarctica support life without #1?"], "evidence": [[[["Homelessness-1"]], [["Antarctica-2"], "operation"]], [[["Homelessness-1"]], [["Antarctica-47"]]], [[["Homelessness-6"]], [["Antarctica-43", "Climate of Antarctica-10", "Homelessness-6"]]]]}
{"qid": "98a30c58fdff7676076c", "term": "Biochemistry", "description": "study of chemical processes in living organisms", "question": "Does Biochemistry study gluons?", "answer": false, "facts": ["Biochemistry studies role, function, and structure of biomolecules.", "Gluon, the so-called messenger particle of the strong nuclear force, which binds sub-atomic particles known as quarks within the protons and neutrons of stable matter as well as within heavier, short-lived particles created at high energies.", "biomolecules are comprised of atoms. "], "decomposition": ["What are gluons?", "What things are studied in biochemistry?", "Is #1 included in #2?"], "evidence": [[[["Gluon-1"]], [["Biochemistry-1"]], ["operation"]], [[["Gluon-1"]], [["Biochemistry-2"], "no_evidence"], ["operation"]], [[["Gluon-1"]], [["Biochemistry-1", "Biochemistry-4"]], ["operation"]]]}
{"qid": "06724dc213e0dae715f5", "term": "Amazon (company)", "description": "American electronic commerce and cloud computing company", "question": "Could one Amazon share ever buy twenty year Netflix subscription?", "answer": true, "facts": ["Amazon stock has reached as high as $2,500 a share as of June 2020.", "The basic Netflix subscription package costs $8.99 a month as of 2020."], "decomposition": ["What is the cost of a monthly Netflix subscription?", "How many months are there in a year?", "What is #2 multiplied by 20 and then multiplied by #1?", "What is the highest price Amazon stock has ever reached?", "Is #4 greater than #3?"], "evidence": [[[["Netflix-49"]], [["Month-38"]], ["operation"], ["no_evidence"], ["operation"]], [[["Netflix-55"]], [["Year-47"]], ["operation"], [["Amazon (company)-78"], "no_evidence"], ["no_evidence", "operation"]], [[["Netflix-49"]], [["Fiscal year-73"]], ["operation"], ["no_evidence"], ["operation"]]]}
{"qid": "280da2485d6504022d34", "term": "Eid al-Fitr", "description": "Islamic holiday that marks the end of Ramadan", "question": "Is Eid al-Fitr holiday inappropriate to watch entire US Office?", "answer": true, "facts": ["Eid al-Fitr is an Islamic holiday dedicated to prayer.", "Eid al_fitr lasts from 1 to 3 days depending on the country.", "The entire US Office tv show would take 4 days, three hours, and 30 minutes to watch."], "decomposition": ["How long does Eid al-Fitr last?", "What is the run time of the Office?", "Is #2 longer than #1?"], "evidence": [[[["Eid al-Fitr-4"]], [["The Office (American TV series)-2"], "no_evidence"], ["operation"]], [[["Eid al-Fitr-4"]], [["Finale (The Office)-1", "The Office (American TV series)-8"]], ["operation"]], [[["Eid al-Fitr-1"]], [["The Office-1"]], ["operation"]]]}
{"qid": "ce01c88f5d2c29a80cb3", "term": "Clown", "description": "A comic performer often for children's entertainment", "question": "Would Stephen King fans be likely to own an image of a clown?", "answer": true, "facts": ["Stephen King wrote a popular book called \"It\" about an evil clown.", "\"It\" has been made into two major films and has been merchandised. "], "decomposition": ["Who is the antagonist of popular Stephen King's book 'It'?", "Is #1 a clown?"], "evidence": [[[["It (novel)-1"]], ["operation"]], [[["It (character)-1"]], ["operation"]], [[["It (character)-1"]], [["It (character)-4"]]]]}
{"qid": "888f196932de7a192d61", "term": "Sloth", "description": "tree dwelling animal noted for slowness", "question": "Will a sloth explode if it's not upside down?", "answer": false, "facts": ["sloth can climb trees in various positions.", "sloth can crawl along the ground on their stomachs. "], "decomposition": ["What are some common positions that a sloth can stay in?", "Is all of #1 upside down in orientation?"], "evidence": [[[["Sloth-4"], "no_evidence"], ["no_evidence", "operation"]], [[["Sloth-1"]], [["Sloth-1"]]], [[["Sloth-1", "Sloth-2"]], ["operation"]]]}
{"qid": "d20362599347f39a08e5", "term": "Ku Klux Klan", "description": "American white supremacy group", "question": "Would the Ku Klux Klan welcome Opal Tometi into their group?", "answer": false, "facts": ["The Ku Klux Klan is an American white supremacist hate group whose primary targets are African Americans, as well as Jews, immigrants, leftists, and homosexuals.", "Opal Tometi is an African American woman.", "Opal Tometi is a co-founder of Black Lives Matter.", "Black Lives Matter (BLM) is a decentralized movement advocating for non-violent civil disobedience in protest against incidents of police brutality and all racially motivated violence against African-American people."], "decomposition": ["Which groups of people are enemies of the Ku Klux Klan?", "What is Opal Tometi's ethnicity?", "Is #2 absent from #1?"], "evidence": [[[["Ku Klux Klan-1"]], [["Opal Tometi-1", "Opal Tometi-4"]], ["operation"]], [[["Ku Klux Klan-1"]], [["Opal Tometi-1"]], ["operation"]], [[["Ku Klux Klan-1"]], [["Opal Tometi-8"]], ["operation"]]]}
{"qid": "a0eb63776f7720ec0bcc", "term": "Parsifal", "description": "opera in three acts by Richard Wagner", "question": "Was the subject of Parsifal taken from British folklore?", "answer": true, "facts": ["Parsifal was loosely based on a poem about Percival", "Percival was a Knight of the Round Table", "King Arthur and the Knights of the Round Table were products of British folklore"], "decomposition": ["What was the opera 'Parsifal' based on?", "Who is the main character in #1?", "Which group is #2 part of?", "Did #3 originate from British folklore?"], "evidence": [[[["Parsifal-1"]], [["Parzival-1"]], [["Percival-1"]], [["Knights of the Round Table-1"]]], [[["Parsifal-1"]], [["Percival-1"]], [["Knights of the Round Table-1"]], ["operation"]], [[["Parsifal-5"]], [["Parsifal-34"]], [["Parsifal-33"]], [["Knight-4"]]]]}
{"qid": "990bc1e418fff10f8d51", "term": "Parachuting", "description": "action sport of exiting an aircraft and returning to Earth using a parachute", "question": "Can parachuting amateurs ignore hurricane force winds bulletins?", "answer": false, "facts": ["A hurricane force wind warning is issued by the National Weather Service for winds above 74 mph ", "Solo student parachuters are prohibited from jumping in winds exceeding 14 mph"], "decomposition": ["What's the minimum wind speed above which the National Weather Service issues hurricane force wind warnings?", "What's the maximum wind speed in which a solo student parachuter can jump?", "Is #2 greater than #1?"], "evidence": [[[["Hurricane force wind warning-1"]], [["Parachuting-21"]], ["operation"]], [[["Saffir\u2013Simpson scale-2"]], [["Parachuting-21"]], ["operation"]], [[["Hurricane force wind warning-1"]], [["Parachute-36"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "5554641266a87ca41ef9", "term": "French Defence", "description": "Chess opening", "question": "Can French Defence initial move defend against four move checkmate?", "answer": false, "facts": ["The French Defence involves moving pawn in front of the queen forward two spaces.", "The four move checkmate involves moving the queen and bishop to crowd the king.", "The four move checkmate cannot be defended by pawn in front of queen."], "decomposition": ["Which move is first played in the French defense in chess?", "What are some common techniques for making a four move checkmate in chess?", "Can #1 be used to defend against any of #2?"], "evidence": [[[["French Defence-3"]], [["Scholar's mate-10", "Scholar's mate-3"], "no_evidence"], ["operation"]], [[["French Defence-2"]], [["Scholar's mate-2"]], [["Scholar's mate-8"], "operation"]], [[["French Defence-2"], "no_evidence"], [["Scholar's mate-10", "Scholar's mate-2", "Scholar's mate-9"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "21ebbfdbb95747f3763f", "term": "Autumn", "description": "one of the Earth's four temperate seasons, occurring between summer and winter", "question": "Is Autumn a good time to collect bear pelts in US?", "answer": false, "facts": ["Autumn runs from September to the end of December in the US.", "Bears go into hibernation from September through April and are scarcely seen."], "decomposition": ["What months does Autumn occur in the US?", "Where do bear pelts come from?", "What months can #2 be easily seen in the US?", "Do #1 and #3 overlap?"], "evidence": [[[["Autumn-3"]], [["Bear hunting-17"]], [["Brown bear-27"]], [["Autumn-1", "Brown bear-27"]]], [[["Autumn-3"]], [["Bear hunting-23"]], ["no_evidence"], ["operation"]], [[["Autumn-1"]], [["American black bear-1", "Grizzly bear-1"]], [["Bear-39"], "no_evidence"], ["operation"]]]}
{"qid": "987260ffef60cb2c5439", "term": "Pearl Harbor", "description": "Harbor on the island of Oahu, Hawaii", "question": "Is Pearl Harbor the mythical home of a shark goddess?", "answer": true, "facts": ["The native Hawaiian people believed Pearl Harbor was the home of Ka\u02bbahupahau.", "Ka\u02bbahupahau is a shark goddess in Hawaiian legends. "], "decomposition": ["What did the native Hawaiian people believe Pearl Harbor was home to?", "What was #1?", "IS #2 the same as a shark goddess?"], "evidence": [[[["Pearl Harbor-2"]], [["Pearl Harbor-2"]], [["Pearl Harbor-2"]]], [[["Pearl Harbor-2"]], [["Pearl Harbor-2"]], ["operation"]], [[["Pearl Harbor-2"]], [["Pearl Harbor-2"]], ["operation"]]]}
{"qid": "f740fed84da8bd24301a", "term": "Sarah", "description": "Biblical character", "question": "Did Methuselah live at least 800 years as long as Sarah?", "answer": true, "facts": ["The biblical Sarah lived to the age of 127.", "The biblical Methuselah lived to 969 years of age."], "decomposition": ["At what age did Methuselah die?", "At what age did Sarah die?", "What is the difference between #1 and #2?", "Is #3 at least 800?"], "evidence": [[[["Methuselah-1"]], [["Sarah-11"]], ["operation"], ["operation"]], [[["Methuselah-1"]], [["Sarah-11"]], ["operation"], ["operation"]], [[["Methuselah-1"]], [["Sarah-11"]], ["operation"], ["operation"]]]}
{"qid": "41450dbd623437269f8f", "term": "Depression (mood)", "description": "state of low mood and fatigue", "question": "Would a Monoamine Oxidase candy bar cheer up a depressed friend?", "answer": false, "facts": ["Depression is caused by low levels of serotonin, dopamine and norepinephrine.", "Monoamine Oxidase breaks down neurotransmitters and lowers levels of serotonin, dopamine and norepinephrine."], "decomposition": ["Depression is caused by low levels of what chemicals?", "Monoamine Oxidase has an effect on what chemicals?", "Of the chemicals listed in both #1 and #2, does Monoamine Oxidase raise their levels?"], "evidence": [[[["Monoamine oxidase-8"]], [["Monoamine oxidase-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Depression (mood)-13"]], [["Monoamine oxidase-8"]], [["Serotonin-36"], "operation"]], [[["Biology of depression-1"]], [["Monoamine oxidase-7"]], ["operation"]]]}
{"qid": "f5c0f0f85f624d9f8016", "term": "Dessert", "description": "A course that concludes a meal; usually sweet", "question": "Is dessert eaten before breakfast?", "answer": false, "facts": ["Desserts are sweets.", "Meals generally begin with savory foods, and sweets eaten after."], "decomposition": ["What is a dessert?", "Are #1 usually sweet or salty?", "Do meals generally begin with foods that are #2?"], "evidence": [[[["Dessert-1"]], [["Dessert-1"]], ["no_evidence", "operation"]], [[["Dessert-1"]], [["Dessert-1"]], ["operation"]], [[["Dessert-1"]], [["Dessert-2"]], [["Breakfast-85"], "no_evidence"]]]}
{"qid": "10bcf9c1d9026f741f75", "term": "Supreme Court of Canada", "description": "highest court of Canada", "question": "Can the Supreme Court of Canada fight a Lucha trios match?", "answer": true, "facts": ["A Lucha trios match requires at least two teams of three wrestlers each", "The Supreme Court of Canada has nine justices"], "decomposition": ["How many Justices are in the Supreme Court of Canada?", "What is the total number of people needed to fight in a Lucha trios match?", "Is #1 greater than or equal to #2?"], "evidence": [[[["Supreme Court of Canada-5"]], [["Lucha libre-16"]], ["operation"]], [[["Supreme Court of Canada-5"]], [["Lucha libre-1"]], ["operation"]], [[["Supreme Court of Canada-30"]], [["Lucha libre-1"]], ["operation"]]]}
{"qid": "7b84d2bc643ddc2085f0", "term": "Noah's Ark", "description": "the vessel in the Genesis flood narrative", "question": "WIll Noah's Ark hypothetically sail through flooded Lincoln Tunnel?", "answer": false, "facts": ["Scholars have determined Noah's Ark to be 75 feet wide.", "Each lane of the Lincoln Tunnel is 21 feet wide."], "decomposition": ["What is the width of the Lincoln tunnel?", "What is the width of the Noah's ark?", "Is #1 greater than #2?"], "evidence": [[[["Lincoln Tunnel-5"]], [["Cubit-1", "Noah's Ark-3"]], ["operation"]], [[["Lincoln Tunnel-5"]], [["Cubit-13", "Noah's Ark-3"]], ["operation"]], [[["Lincoln Tunnel-5"]], [["Noah's Ark-3"], "no_evidence"], ["operation"]]]}
{"qid": "85a77e70dd0e86d50995", "term": "Aldi", "description": "Germany-based supermarket chain", "question": "Should you bring your own bags to Aldi?", "answer": true, "facts": ["Unlike most grocery stores, Aldi charges customers for use of paper bags.", "Aldi does not supply shopping carts without a deposit, so shopping bags are a good alternative."], "decomposition": ["In US Aldi stores, how do customers get shopping bags?", "How do customers get shopping carts?", "Do #1 and #2 cost money or value?"], "evidence": [[["no_evidence"], ["no_evidence"], ["no_evidence"]], [[["Aldi-23"], "no_evidence"], [["Aldi-23"], "no_evidence"], ["operation"]], [[["Aldi-1"], "no_evidence"], [["Aldi-32"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "7b0a9a729b42f74e95aa", "term": "Reiki", "description": "Pseudoscientific healing technique", "question": "Can Reiki be stored in a bottle?", "answer": false, "facts": ["Reiki practitioners use a technique called palm healing or hands-on healing through which a \"universal energy\" is said to be transferred through the palms of the practitioner to the patient in order to encourage emotional or physical healing.", "Medications are typically stored in pill bottles."], "decomposition": ["What basic property must a thing have to be able to be stored in a bottle?", "By definition, Reiki is a pseudoscientific healing what?", "Do #2's have the property stated in #1?"], "evidence": [[[["Bottle-1"]], [["Reiki-2"]], ["operation"]], [["no_evidence"], [["Reiki-1"]], ["operation"]], [[["Bottle-1"]], [["Reiki-1"]], ["operation"]]]}
{"qid": "edb5e626587433a2edc2", "term": "Astronaut", "description": "Person who commands, pilots, or serves as a crew member of a spacecraft", "question": "Has every astronaut survived their space journey?", "answer": false, "facts": ["In 1986, the space shuttle Challenger exploded during launch, killing all astronauts aboard.", "In 2003, the space shuttle Columbia also exploded, again killing its entire crew.", "Various other space flights have resulted in fatal disasters."], "decomposition": ["How many astronauts have died during a mission?", "Is #1 equal to zero?"], "evidence": [[[["Astronaut-59"]], ["operation"]], [[["Astronaut-59"]], [["Astronaut-59"], "operation"]], [[["Astronaut-59"]], ["operation"]]]}
{"qid": "e5b8fb5f2431ac1396ec", "term": "Lenovo", "description": "Chinese multinational technology company", "question": "Could a monolingual American read Lenovo's native name?", "answer": false, "facts": ["Lenovo's native name is \u8054\u60f3\u96c6\u56e2\u6709\u9650\u516c\u53f8.", "Someone who is monolingual only speaks one language.", "The typical monolingual American would only be able to read English.", "Someone who can only read English is therefore unable to read Chinese."], "decomposition": ["What is Lenovo's native name?", "What language is #1 in?", "What language does a monolingual American speak?", "Is #3 the same as #2?"], "evidence": [[[["Lenovo-51"]], [["Lenovo-1"]], [["American English-2"]], ["operation"]], [[["Lenovo-1"], "no_evidence"], [["Chinese language-1"], "no_evidence"], [["American English-2"]], ["operation"]], [[["Lenovo-51"]], [["Lenovo-51"]], [["Official language-39"]], ["operation"]]]}
{"qid": "54f5fd17d9a2373f68b1", "term": "Ivan the Terrible", "description": "Grand Prince of Moscow and 1st Tsar of Russia", "question": "Has Ivan the Terrible flown to Europe?", "answer": false, "facts": ["Ivan the Terrible was the 1st Tsar of Russia.", "Ivan the Terrible died in 1584.", "The first confirmed person to fly was Jean Francois Pilatre de Rozier in 1783."], "decomposition": ["When did Ivan the Terrible die?", "When was the airplane invented?", "Is #2 before #1?"], "evidence": [[[["Ivan the Terrible-1"]], [["Airplane-2"]], ["operation"]], [[["Ivan the Terrible-1"]], [["Airplane-2"]], ["operation"]], [[["Ivan the Terrible-1"]], [["Airplane-14"]], ["operation"]]]}
{"qid": "2780b837af5373ff2cb4", "term": "The Matrix", "description": "1999 science fiction action film directed by the Wachowskis", "question": "Will Gremlins sequels tie number of Matrix sequels?", "answer": true, "facts": ["The Matrix films had two sequels.", "Gremlins has one sequel, Gremlins 2: The New Batch.", "The script for a Gremlins 3 is being written by Carl Ellsworth."], "decomposition": ["How many sequels did The Matrix have?", "How many sequels did Gremlins have?", "How many Gremlins movies are currently being worked on?", "What is the sum of #2 and #3?", "Is #4 equal to #1?"], "evidence": [[[["The Matrix (franchise)-1"]], [["Gremlins-48"]], [["Gremlins-51"]], [["The Matrix (franchise)-1"]], [["The Matrix (franchise)-1"]]], [[["The Matrix (franchise)-1"]], [["Gremlins-2"]], [["Gremlins: Secrets of the Mogwai-2"], "operation"], ["operation"], ["operation"]], [[["The Matrix (franchise)-1"]], [["Gremlins-2"]], [["Gremlins 2: The New Batch-46"]], ["operation"], ["operation"]]]}
{"qid": "e40cbe4b89942e256377", "term": "Jerry Seinfeld", "description": "American comedian and actor", "question": "Did Jerry Seinfeld have reason to cheer in 1986?", "answer": true, "facts": ["Jerry Seinfeld is a fan of the New York Mets baseball team", "The New York Mets won a World Series title in 1986"], "decomposition": ["Do fans cheer if their team wins?", "Is Jerry Seinfeld a NY Mets fan?", "Did the NY Mets win the World Series in 1986?", "Is #1, #2 and #3 \"yes\"?"], "evidence": [[[["Cheering-20"]], [["Jerry Seinfeld-28"]], [["1986 World Series-4"]], ["operation"]], [[["Cheering-18"], "no_evidence"], [["Jerry Seinfeld-28"]], [["1986 World Series-1"]], ["operation"]], [[["Cheering-1"]], [["The Boyfriend (Seinfeld)-2"]], [["1986 World Series-1"]], ["operation"]]]}
{"qid": "76d3f6c91518061deb7d", "term": "Drum", "description": "type of musical instrument of the percussion family", "question": "Would a cattle farmer be useful to a drum maker?", "answer": true, "facts": ["Cattle are often slaughtered for meat and other products, like leather.", "Drums are often made with leather."], "decomposition": ["Which animal products would a drum maker need?", "Are #1 commonly obtained from cattle?"], "evidence": [[[["Drumhead-3"], "no_evidence"], [["Leather-1"]]], [[["Drumhead-5"]], ["operation"]], [[["Drum-7"]], [["Drum-7", "Leather-5"]]]]}
{"qid": "7cf376afb78c20dd6f18", "term": "Stanford University", "description": "Private research university in Stanford, California", "question": "Was John Gall from same city as Stanford University?", "answer": true, "facts": ["John Gall is a former major league baseball player born in Stanford, California.", "Stanford University was founded by Leland and Jane Stanford  in Stanford, California."], "decomposition": ["Where was John Gall (baseball player) born?", "Where is Stanford University located?", "Is #1 the same as #2?"], "evidence": [[[["John Gall (baseball)-2"]], [["Stanford University-1"]], ["operation"]], [[["John Gall (baseball)-2"]], [["Stanford University-1"]], ["operation"]], [[["John Gall (baseball)-2"]], [["Stanford University-1"]], ["operation"]]]}
{"qid": "e32511f311bfd294ebf1", "term": "John Key", "description": "38th Prime Minister of New Zealand", "question": "Could John Key issue an executive order in the USA?", "answer": false, "facts": ["An executive order is a means of issuing federal directives in the United States, used by the president of the United States.", "To serve as president of the United States, one must be a natural-born citizen of the United States.", "John Key was born in Auckland, New Zealand."], "decomposition": ["Who can issue executive orders in the USA?", "What are the requirements to become #1?", "Does John Key satisfy all of #2?"], "evidence": [[[["Executive order-1"]], [["President of the United States-37"], "no_evidence"], [["John Key-1"], "no_evidence"]], [[["Federal government of the United States-18"]], [["President of the United States-38"]], [["John Key-1"]]], [[["Executive order-1"]], [["President of the United States-38"]], [["John Key-5"]]]]}
{"qid": "be5ba924348f83b5df96", "term": "United Airlines", "description": "Airline in the United States", "question": "Was United Airlines blameless in worst crash in history?", "answer": true, "facts": ["The Tenerife Airport disaster is the deadliest crash in aviation history.", "The Tenerife Airport disaster involved a Boeing plane and a Pan Am plane.", "Pan Am airlines competed with United Airlines and other US companies.", "Boeing is an American multinational corporation that designs and sells airplanes, rockets, satellites,and missiles."], "decomposition": ["Which aviation accident is considered the worst in aviation history?", "Is United Airlines excluded from #1?"], "evidence": [[[["Tenerife airport disaster-1"]], ["operation"]], [[["Tenerife airport disaster-1"]], [["United Airlines-1"], "operation"]], [[["Tenerife-36"]], [["Tenerife airport disaster-3"]]]]}
{"qid": "2b45a624da84a288d37e", "term": "Wednesday", "description": "Day of the week", "question": "Are all Wednesdays in a year enough to read Bible 15 times?", "answer": true, "facts": ["There are 52 Wednesdays in a year.", "There are 1,248 hours over all the Wednesdays in a year.", "The Old Testament of the Bible takes an average of 52 hours to read.", "The New Testament of the Bible takes an average of 18 hours to read."], "decomposition": ["How many Wednesdays are there in a year?", "What is #1 multiplied by 24?", "How long does it take to read the old testament?", "How long does it take to read the new testament?", "Is #2 greater than or equal to: #3 plus #4?"], "evidence": [[[["Year-57"]], ["operation"], [["Old Testament-2"], "no_evidence"], [["New Testament-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Week-10"]], ["operation"], [["New Testament-11", "Old Testament-2"], "no_evidence"], [["New Testament-9"], "no_evidence"], ["operation"]], [[["Year-66"], "no_evidence"], ["operation"], [["Protestant Bible-15"], "no_evidence"], [["Protestant Bible-15"], "no_evidence"], ["operation"]]]}
{"qid": "ef67433aeac38f7fada4", "term": "Tokyo Tower", "description": "observation tower", "question": "Did Tokyo Tower designers appreciate Stephen Sauvestre?", "answer": true, "facts": ["Tokyo Tower is a communications tower in Japan, built in 1958, that was inspired by the Eiffel Tower.", "Stephen Sauvestre was the architect of the the Eiffel Tower which was competed in 1889."], "decomposition": ["Which architectural design is Stephen Sauvestre famous for?", "Was #1 influential in the design of the Tokyo Tower?"], "evidence": [[[["Stephen Sauvestre-1"]], [["Tokyo Tower-1"]]], [[["Stephen Sauvestre-3"]], ["operation"]], [[["Stephen Sauvestre-1"]], [["Tokyo Tower-1"]]]]}
{"qid": "a63e6bc5afd5080b5a70", "term": "Harvey Milk", "description": "American politician who became a martyr in the gay community", "question": "Could a cow produce Harvey Milk?", "answer": false, "facts": ["Harvey Milk was a human being.", "Cows are not human beings.", "Only human beings can produce offspring which are also human beings."], "decomposition": ["What products can be derived from cows?", "Is Harvey Milk a kind of any of #1?"], "evidence": [[[["Cattle-2"]], [["Harvey Milk-1"], "operation"]], [[["Milk-32"]], [["Harvey Milk-1"], "operation"]], [[["Cattle-2"]], ["operation"]]]}
{"qid": "770d0ae34440013dcf8e", "term": "Ethiopian cuisine", "description": "Culinary traditions of Ethiopia", "question": "Is shrimp prevalent in Ethiopian cuisine?", "answer": false, "facts": ["Ethiopian cuisine specializes in vegetables and spicy meat dishes.", "Ethiopia is a landlocked country without access to seas or oceans."], "decomposition": ["What kind of aquatic environments are shrimp caught in?", "Does the geography of Ethiopia include any of #1?"], "evidence": [[[["Shrimp-2"]], [["Ethiopia-91"]]], [[["Shrimp and prawn as food-1"]], [["Ethiopia-1"], "operation"]], [[["Shrimp-8"]], [["Ethiopia-90"], "no_evidence"]]]}
{"qid": "d4b9a903cd99f477a219", "term": "Athena", "description": "ancient Greek goddess of wisdom and war", "question": "Is Freya a combination of Athena and Aphrodite?", "answer": true, "facts": ["Athena was the Greek goddess of war.", "Aphrodite was the Greek goddess of love.", "Freya was the Norse goddess of war, love, and fertility."], "decomposition": ["What was Athena the Greek goddess of?", "What was Aphrodite's specialty?", "What was Freya the Norse goddess of?", "Does #3 have part of the same answer as #1 and #2?"], "evidence": [[[["Athena-1"]], [["Aphrodite-1"]], [["Freyja-1"]], ["no_evidence"]], [[["Athena-1"]], [["Aphrodite-1"]], [["Freyja-1"]], ["operation"]], [[["Athena-1"]], [["Aphrodite-1"]], [["Freyja-1"]], ["operation"]]]}
{"qid": "a969716a48788439f917", "term": "HIV", "description": "Human retrovirus, cause of AIDS", "question": "Would fans of Jonathan Larson be unaware of HIV?", "answer": false, "facts": ["Jonathan Larson died of AIDS in 1996.", "Jonathan Larson produced music and plays about HIV, AIDS, and poverty."], "decomposition": ["What works did Jonathan Larson produce?", "Do all of #1 avoid the topic of HIV?"], "evidence": [[[["Jonathan Larson-1"]], [["Tick, Tick... Boom!-12"], "operation"]], [[["Jonathan Larson-1"]], [["Rent (musical)-1"]]], [[["Jonathan Larson-1"]], [["Rent (musical)-1"], "operation"]]]}
{"qid": "01c27885cede6741bc53", "term": "The CW", "description": "American broadcast television network", "question": "Did Supernatural break 2001 CW debuting shows seasons record?", "answer": true, "facts": ["Smallville debuted on the CW in 2001.", "Smallville had the record of most CW seasons for a show with 10.", "Supernatural concluded its run with its record breaking 15th season on the CW."], "decomposition": ["What was the debuting shows in a seasons record as of 2001 for CW?", "What was Supernatural's highest debuting shows in a season?", "Is #2 higher than #1?"], "evidence": [[[["The WB-16"], "no_evidence"], [["Supernatural (American TV series)-2"], "no_evidence"], ["no_evidence", "operation"]], [[["The CW-8"], "no_evidence"], [["Supernatural (American TV series)-102", "Supernatural (season 1)-20"], "no_evidence"], ["operation"]], [[["One Tree Hill (TV series)-4"]], [["Supernatural (American TV series)-2"]], ["operation"]]]}
{"qid": "b3ef76f4c5ea1f4ca066", "term": "Sunday", "description": "day of the week", "question": "Is Christmas always celebrated on a Sunday?", "answer": false, "facts": ["Christmas is always celebrated on December 25.", "A specific date on the calendar rotates to the following day of the week each year.", "Christmas can therefore be any day of the week."], "decomposition": ["What date does Christmas fall on each year?", "Does #1 always fall on a Sunday?"], "evidence": [[[["Christmas-1"]], [["Sunday-1"], "operation"]], [[["Christmas-3"]], [["Christmas-3"]]], [[["Christmas-1"]], [["Christmas Sunday-2"]]]]}
{"qid": "ab1cd501d3590b46c009", "term": "Bob Marley", "description": "Jamaican singer-songwriter", "question": "Can you find Bob Marley's face in most smoke shops?", "answer": true, "facts": ["Bob Marley's face is on the packaging of a popular brand of rolling papers.", "Bob Marley is a popular graphic to print on t-shirts for sale to smokers."], "decomposition": ["On what items is Bob Marley's face commonly found?", "Are some of #1 sold in most smoke shops?"], "evidence": [[["no_evidence"], [["Tobacconist-1"]]], [["no_evidence"], ["no_evidence", "operation"]], [[["Bob Marley-1"]], [["Head shop-1", "Tobacconist-1"], "operation"]]]}
{"qid": "3836171bc71856136668", "term": "White", "description": "color", "question": "Can paresthesia be caused by a white pigment?", "answer": true, "facts": ["Tingling in the hands or feet is a type of paresthesia", "Lead white exposure can lead to lead poisoning", "Symptoms of lead poisoning include tingling in the hands and feet"], "decomposition": ["What kinds of white pigment have adverse health effects?", "What are the symptoms of paresthesia?", "Can any of #1 cause #2?"], "evidence": [[[["Lead paint-7"]], [["Paresthesia-1"]], [["Lead poisoning-1"], "operation"]], [["no_evidence"], [["Paresthesia-1"]], ["no_evidence", "operation"]], [[["Powder-11"], "no_evidence"], [["Paresthesia-1"]], ["operation"]]]}
{"qid": "b77170e15c0b1bd72340", "term": "Durian", "description": "genus of plants", "question": "Are Durian fruits an olfactory delight?", "answer": false, "facts": ["Durian is a plant type that produces several kinds of fruit.", "Olfactory refers to the human sense of smell.", "Pleasant smells according to polls include flowers and sweet foods.", "Durian fruits have been banned in Singapore due to its overwhelming smell."], "decomposition": ["What kind of smell is the durian known for?", "Is #1 pleasant?"], "evidence": [[[["Durian-3"]], ["operation"]], [[["Durian-3"]], ["operation"]], [[["Durian-3"]], [["Durian-3"]]]]}
{"qid": "3ca0a58b1697a63521b6", "term": "Rick and Morty", "description": "Animated sitcom", "question": "Can you watch Rick and Morty in Mariana Trench?", "answer": true, "facts": ["Rick and Morty is available in blu-ray format.", "You can play blu-ray on a laptop computer ", "It is possible to go to Mariana Trench inside a deep-diving submersible vehicle with a laptop."], "decomposition": ["What portable media format is Rick and Morty available in?", "What electronics do deep-diving submersibles have?", "Can any of #1 be played on any of #2?"], "evidence": [[[["Rick and Morty-28"]], [["Deep-submergence vehicle-1"], "no_evidence"], ["operation"]], [[["Rick and Morty-27"]], [["DVD player-1", "Submersible-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Rick and Morty-28"]], [["Deep diving-11"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "614b682ff2b6ddd9ecba", "term": "Marco Polo", "description": "Italian explorer and merchant noted for travel to central and eastern Asia", "question": "Do you often hear Marco Polo's name shouted near water?", "answer": true, "facts": ["\"Marco Polo\" is a popular game among children and adults played while swimming.", "To play \"Marco Polo\", one person shouts \"Marco\" and the other shouts \"Polo\" while avoiding being tagged."], "decomposition": ["What is the game Marco Polo?", "When is #1 typically played?", "Does #2 occur near or in water?"], "evidence": [[[["Marco Polo (game)-1"]], [["Marco Polo (game)-1"]], [["Swimming pool-1"]]], [[["Marco Polo (game)-1", "Marco Polo (game)-2"]], ["no_evidence"], ["operation"]], [[["Marco Polo (game)-2"]], [["Marco Polo (game)-2"]], [["Marco Polo (game)-2"]]]]}
{"qid": "2cc610b9b07a0ac0f378", "term": "Himalayas", "description": "Mountain range in Asia", "question": "Did any of religions in which Himalayas are sacred originate in 19th century?", "answer": false, "facts": ["The Himalaya mountains are sacred to three religions: Hinduism, Buddhism, and Jainism.", "Hinduism was first synthesized around 500 BC.", "Jainism began in the 6th century BC.", "Buddhism originated around the 5th century BC."], "decomposition": ["Which religions believe that the Himalayas are sacred?", "When did #1 originate?", "Are any of #2 equal to the 19th century?"], "evidence": [[[["Himalayas-36"], "no_evidence"], [["Hinduism-1", "Jainism-1"], "no_evidence"], ["operation"]], [[["Himalayas-40"]], [["Buddhism-11", "Hinduism-7", "Jainism-29", "Sikhism-6"], "no_evidence"], ["operation"]], [[["Himalayas-36"], "no_evidence"], [["Hindu art-7"], "no_evidence"], ["operation"]]]}
{"qid": "70e7c1ad517f7f78d21d", "term": "Very Large Telescope", "description": "telescope in the Atacama Desert, Chile", "question": "Can the Very Large Telescope observe the largest mountain on Earth?", "answer": false, "facts": ["The Very Large Telescope observes outer space.", "The largest mountain on earth is underneath the ocean."], "decomposition": ["What area does the Very Large Telescope observe?", "Is the answer to #1 the same as earth?"], "evidence": [[[["Very Large Telescope-3"]], ["operation"]], [[["Very Large Telescope-3"]], ["operation"]], [[["Very Large Telescope-1"]], ["operation"]]]}
{"qid": "668c900cd1405a15d60b", "term": "Guitarist", "description": "person who plays the guitar", "question": "Does being good at guitar hero make you a good guitarist?", "answer": false, "facts": ["Guitar Hero is a game that features a guitar-shaped controller with buttons that the player must hit in time with a song.", "Guitars as instruments do not have any buttons, but have strings that must be strummed in a particular way to create sound."], "decomposition": ["How is a guitar played?", "How is Guitar Hero played?", "Do the steps in #1 match those of #2?"], "evidence": [[[["Guitar-1"]], [["Guitar Hero-44"]], ["operation"]], [[["Guitar-1"]], [["Guitar controller-1"]], ["operation"]], [[["Guitar-1"]], [["Guitar Hero-1"]], ["operation"]]]}
{"qid": "b01c95ce0b47590fd29a", "term": "Emulator", "description": "system that emulates a real system such that the behavior closely resembles the behavior of the real system", "question": "Are classic nintendo games for emulator legal?", "answer": false, "facts": ["Distribution of copyrighted games by anyone other than the owner is considered theft.", "Nintendo has not released any games for emulators."], "decomposition": ["Who owns the copyright for classic Nintendo games?", "Has #1 issued any versions of classic Nintendo games for emulators?"], "evidence": [[[["Nintendo Switch-65"], "no_evidence"], ["no_evidence"]], [[["Video game console emulator-5"], "no_evidence"], [["NES Classic Edition-1"], "no_evidence", "operation"]], [[["NES Classic Edition-17"], "no_evidence"], [["Video game-42"], "no_evidence", "operation"]]]}
{"qid": "dd3cb87f907f758229ec", "term": "Polymath", "description": "Individual whose knowledge spans a significant number of subjects", "question": "Would Tony Stark be considered a polymath?", "answer": true, "facts": ["A polymath is a person who has knowledge in a wide variety of subjects.", "Tony Stark is considered a genius in mathematics, engineering, computer science, and physics, as well as demonstrating skills in metalworking, engine design, and genetics."], "decomposition": ["What does one have to have to be considered a polymath?", "Does Tony Stark have #1?"], "evidence": [[[["Polymath-1"]], [["Iron Man-2"], "operation"]], [[["Polymath-1"]], [["Tony Stark (Marvel Cinematic Universe)-1"]]], [[["Polymath-1"]], [["Iron Man-71"], "operation"]]]}
{"qid": "00f951d01196c2e77fe6", "term": "Presidency of Richard Nixon", "description": "American cabinet", "question": "Would the high school class of 2010 have lived through the Presidency of Richard Nixon?", "answer": false, "facts": ["People in the high school class of 2010 were born between 1991 and 1993.", "Richard Nixon was President of the United States until 1974."], "decomposition": ["When was Richard Nixon president of the US until?", "What year range would the high school class of 2010 be born in?", "Is #1 in #2?"], "evidence": [[[["Richard Nixon-1"]], [["Secondary education in the United States-36"], "no_evidence"], ["operation"]], [[["Richard Nixon-1"]], [["Secondary education-1"], "no_evidence"], ["operation"]], [[["Richard Nixon-46"]], ["no_evidence"], ["operation"]]]}
{"qid": "45db806b7177c71f659f", "term": "Great Depression", "description": "20th-century worldwide economic depression", "question": "Could all the unemployed people due to 1933 Great Depression fit in Tiger Stadium?", "answer": false, "facts": ["There were approximately 15 million people unemployed in 1933 due to the Great Depression.", "In the 1930s Tiger Stadium had a capacity around 50,000."], "decomposition": ["How many people became unemployed due to 1933 Great Depression?", "What is the seating capacity of Tiger Stadium?", "Is #1 less than or equal to #2?"], "evidence": [[[["Recession of 1937\u201338-2", "United States-1"], "no_evidence"], [["Tiger Stadium (LSU)-18"]], ["operation"]], [[["Great Depression-65"], "no_evidence"], [["Tiger Stadium (LSU)-11"]], ["operation"]], [[["Unemployment-139"], "no_evidence"], [["Tiger Stadium (Detroit)-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "777828272c5e0915f4d1", "term": "Ivan the Terrible", "description": "Grand Prince of Moscow and 1st Tsar of Russia", "question": "Did Ivan the Terrible's father and grandfather have nicer nicknames?", "answer": true, "facts": ["Ivan the Terrible was nicknamed terrible because of his harsh rule.", "Ivan the Terrible's father, Vasili III Ivanovich, was nicknamed Vasili the Adequate.", "Ivan the Terrible's grandfather, Ivan III Vasilyevich, was nicknamed Ivan the Great."], "decomposition": ["Who was Ivan the Terrible's father?", "Who was the father of #1?", "Do #1 and #2 have nicer nicknames than \"the Terrible\"?"], "evidence": [[[["Vasili III of Russia-1"]], [["Ivan III of Russia-1", "Vasili III of Russia-1"]], ["operation"]], [[["Vasili III of Russia-1"]], [["Vasili III of Russia-1"]], [["Vasili III of Russia-1"], "operation"]], [[["Vasili III of Russia-1"]], [["Ivan III of Russia-1"]], ["operation"]]]}
{"qid": "8ab96f428e06984bf0c6", "term": "Keyboard layout", "description": "any specific mechanical, visual, or functional arrangement of the keys of a keyboard or typewriter", "question": "Could someone with fine motor control issues benefit from an altered keyboard layout?", "answer": true, "facts": ["Fine motor control involves making small, precise movements like painting or typing. ", "The standard keyboard layout is designed to be used by someone without any motor control issues.", "There are modified keyboards for multiple types of disability."], "decomposition": ["What types of keyboard layouts exist?", "Among #1, which keyboard layouts are optimized for disabilities?", "Are any of #2 better for those with limited fine motor control?"], "evidence": [[[["Keyboard layout-170", "Keyboard layout-43", "Keyboard layout-52"]], [["Keyboard layout-170"]], [["Keyboard layout-170"], "no_evidence"]], [[["Keyboard layout-33"]], [["Keyboard layout-170"]], [["Keyboard layout-170"]]], [[["Computer keyboard-27"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "ec13093ea857962c647f", "term": "Palm Beach, Florida", "description": "Town in Florida, United States", "question": "Could Palm Beach be held in the palm of your hand?", "answer": false, "facts": ["Palm Beach has a total area of 8.12 square miles.", "The average palm is around 3 inches in length.", "There are 63360 inches in a mile."], "decomposition": ["What is the total area of Palm Beach?", "What is the maximum area that can be held on the palm of a human hand?", "Is #1 greater than or equal to #2?"], "evidence": [[[["Palm Beach, Florida-17"]], ["no_evidence"], ["operation"]], [[["Palm Beach, Florida-53"]], [["Human body-6"]], ["operation"]], [[["Palm Beach, Florida-17"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "377427ca79b717bdcb83", "term": "Snoop Dogg", "description": "American rapper", "question": "Did Snoop Dogg refuse to make music with rival gang members?", "answer": false, "facts": ["American rapper Snoop Dogg is a member of the Crips gang.", "The Crips are enemies of their rival gang, The Bloods.", "Rapper, The Game is a member of The Bloods gang.", "Tha Blue Carpet Treatment was a Snoop Dogg mixtape featuring the song California Vacation.", "Snoop Dogg collaborates with Xzibit and The Game on the song California Vacation."], "decomposition": ["What is the name of the gang that Snoop Dogg is part of?", "Which gang is the rival of #1?", "In Snoop Dogg's song California Vacation, which rapper did he collaborate with?", "Is #3 not associated with #2?"], "evidence": [[[["Snoop Dogg-7"]], [["Crips-14"]], [["Doctor's Advocate-4"], "no_evidence"], [["The Game (rapper)-5"], "operation"]], [[["Snoop Dogg-7"]], [["Crips-3"]], [["Doctor's Advocate-10"], "no_evidence"], [["The Game (rapper)-5"], "operation"]], [[["Snoop Dogg-7"]], [["Crips-3"]], [["Doctor's Advocate-4"]], [["The Game (rapper)-5"]]]]}
{"qid": "a0d0c2ac289c7a59911d", "term": "Lactobacillus", "description": "genus of bacteria", "question": "Is overfeeding Lactobacillus unwise for people without dental insurance?", "answer": true, "facts": ["Lactobacillus species convert sugars they digest to lactic acid ", "The lactic acid of some Lactobacillus species is associated with tooth decay", "Dental procedures can be expensive without insurance"], "decomposition": ["What are the products of Lactobacillus?", "What conditions are caused by #1?", "What medical procedures would be required to fix #2?", "Would #3 be more affordable with dental insurance?"], "evidence": [[[["Lactobacillus-1"]], [["Lactic acid-5"]], [["Tooth decay-77"]], [["Dental insurance-1"]]], [[["Lactobacillus-1", "Lactobacillus-2"]], [["Lactic acid bacteria-14"]], [["Tooth decay-77"]], [["Dental insurance-1"]]], [[["Lactobacillus-10"]], [["Lactobacillus-10"]], [["Tooth decay-76"]], [["Dental insurance-1"]]]]}
{"qid": "55c54e04a9446aaf6b45", "term": "Chocolate brownie", "description": "A square, baked, chocolate dessert", "question": "Should children be kept from \"special brownies\"?", "answer": true, "facts": ["\"Special brownies\" typically refer to brownies that have been laced with THC.", "THC is an active component of cannabis, a drug meant for adults only."], "decomposition": ["What are \"special brownies\" made from that makes them special?", "Who is #1 made specifically for?", "Are children allowed to have things meant for #2?"], "evidence": [[[["Cannabis edible-1"]], [["Cannabis edible-2"]], ["no_evidence"]], [[["Cannabis edible-11"]], [["Cannabis edible-2"]], [["Cannabis edible-7"], "operation"]], [[["Cannabis edible-6"]], [["Medical cannabis-30"]], [["Medical cannabis-30"]]]]}
{"qid": "30ebf73bc3294792f8de", "term": "Society", "description": "Social group involved in persistent social interaction", "question": "In American society, will a bachelor's degree often include a leap year?", "answer": true, "facts": ["Leap years occur every four years.", "In American society, a bachelor's degree takes about four years."], "decomposition": ["Leap years occur after how many years' interval?", "How many years does an average bachelor's degree take in the US?", "Is #2 divided by #1 greater than or equal to one?"], "evidence": [[[["Leap year-16"]], [["Bachelor's degree-1"]], ["operation"]], [[["Leap year-6"]], [["Bachelor's degree-37"]], ["operation"]], [[["Leap year-2"]], [["Bachelor's degree-1", "Bachelor's degree-37"]], ["operation"]]]}
{"qid": "848941fb02c8818a4e1f", "term": "Porsche", "description": "automotive brand manufacturing subsidiary of Volkswagen", "question": "Could a Porsche 992 Turbo S defeat Usain Bolt in a 100 meter sprint?", "answer": true, "facts": ["The Porsche 992 Turbo S can accelerate to 62 mph in 2.7 seconds.", "Usain Bolt's top speed ever measured is 27.79 mph."], "decomposition": ["What is the max speed of a Porsche 992 Turbo S?", "What is Bolt's top speed?", "Is #1 faster than #2?"], "evidence": [[[["Porsche 992-8"]], [["Usain Bolt-106"]], ["operation"]], [[["Porsche 992-8"]], [["Footspeed-4"]], ["operation"]], [[["Porsche 992-8"]], [["Usain Bolt-106"]], ["operation"]]]}
{"qid": "a40dafa5d3114a101432", "term": "Darth Vader", "description": "fictional character in the Star Wars franchise", "question": "Can Darth Vader hypothetically outdunk Bill Walton without using The Force?", "answer": false, "facts": ["The Force allows a Jedi to move objects with their mind.", "Darth Vader is 6'2\" tall.", "Former basketball player Bill Walton is a towering 6'11\" tall.", "The NBA basketball rim is 10 feet high."], "decomposition": ["What characteristic determines someone's ability to dunk?", "What is Darth Vader's measurement of #1?", "What is Bill Walton's measurement of #1?", "Is #2 greater than #3?"], "evidence": [[[["Human height-1"]], [["Darth Vader-8"], "no_evidence"], [["Bill Walton-5"]], ["operation"]], [[["Slam dunk-5"]], [["Darth Vader-3", "David Prowse-2"], "no_evidence"], [["Bill Walton-5"]], ["operation"]], [[["Slam dunk-5"]], [["Darth Vader-8"], "no_evidence"], [["Bill Walton-5"]], ["operation"]]]}
{"qid": "913bb87c30feb6484679", "term": "Gettysburg Battlefield", "description": "site of the Battle of Gettysburg during the American Civil War", "question": "Would a Superbowl Football Game be crowded on the Gettysburg Battlefield?", "answer": false, "facts": ["Football fields used in the Super Bowl are 100 yards long. ", "The Gettysburg Battlefield is over 5 miles long.", "There are 1760 yards in a mile."], "decomposition": ["How long is the football field superbowl?", "How long is the Gettysburg Battlefield?", "Is #1 the same as #2?"], "evidence": [[[["Comparison of American football and rugby league-6"]], [["Gettysburg Battlefield-2"]], ["operation"]], [[["Football pitch-4"]], [["Gettysburg Battlefield-2"]], ["operation"]], [[["American football-11"]], [["Gettysburg Battlefield-1"], "no_evidence"], ["operation"]]]}
{"qid": "05046d2981f68118f047", "term": "Mona Lisa", "description": "Painting by Leonardo da Vinci", "question": "Is the Mona Lisa in the same museum as the Venus de Milo?", "answer": true, "facts": ["The Mona Lisa is in the Louvre.", "The Venus de Milo is in the Louvre."], "decomposition": ["What museum stores the Mona Lisa?", "What museum stores the Venus de Milo?", "Is #1 the same as #2?"], "evidence": [[[["Mona Lisa-54"]], [["Venus de Milo-2"]], ["operation"]], [[["Mona Lisa-18"]], [["Venus de Milo-17"]], ["operation"]], [[["Mona Lisa-2"]], [["Venus de Milo-2"]], ["operation"]]]}
{"qid": "c565654d56d2c1bb3532", "term": "Water skiing", "description": "surface water sport", "question": "Can you go water skiing on Venus?", "answer": false, "facts": ["Water skiing requires sufficient area on a smooth stretch of water, one or two skis, a tow boat with tow rope, two or three people, and a personal flotation device.", "Venus has a mean surface temperature of 863 \u00b0F.", "There may have been substantial quantities of liquid water on the surface of Venus at one point, but after a period of 600 million to several billion years, a runaway greenhouse effect was caused by the evaporation of that original water."], "decomposition": ["What is the basic requirement for water skiing?", "Is #1 present on Venus in sufficient quantities?"], "evidence": [[[["Water skiing-1"]], [["Venus-20"], "operation"]], [[["Water skiing-1"]], [["Venus-2"], "operation"]], [[["Water skiing-1"]], [["Venus-2"]]]]}
{"qid": "99853e416a63527f954e", "term": "San Diego County, California", "description": "County in California, United States", "question": "Is San Diego County the home of a Shamu?", "answer": true, "facts": ["Shamu is the name of Sea World's mascot orca.", "Every Sea World has a Shamu.", "There is a Sea World location in San Diego."], "decomposition": ["What is Shamu the name of?", "Where can you find #1?", "Is there a #2 in San Diego?"], "evidence": [[[["Shamu-1"]], [["SeaWorld San Diego-1", "SeaWorld-1"]], ["operation"]], [[["Shamu-1"]], [["Captive killer whales-19"]], [["SeaWorld San Diego-1"]]], [[["Shamu-1"]], [["SeaWorld San Diego-27"]], [["SeaWorld San Diego-27"], "operation"]]]}
{"qid": "378ccb7bc29c9ce4eea0", "term": "Menthol", "description": "chemical compound", "question": "Does menthol make cigarettes less addictive?", "answer": false, "facts": ["The addition of menthol to cigarettes does not reduce the amount of nicotine in them.", "Menthol itself is an addictive chemical. ", "Nicotine is the primary addictive component of cigarettes."], "decomposition": ["What is the primary addictive components in cigarettes?", "Does addition of menthol cause a reduction in #1?"], "evidence": [[[["Cigarette-3"]], [["Menthol cigarette-32"]]], [[["Nicotine-11"]], [["Menthol cigarette-29"]]], [[["Cigarette-1"]], [["Menthol cigarette-29"]]]]}
{"qid": "5a5ccd78ba4d4af27bc6", "term": "Bucharest", "description": "Capital of Romania", "question": "Is Bucharest located south of Egypt?", "answer": false, "facts": ["Bucharest, Romania is located in Eastern Europe.", "Egypt is located in Africa.", "Most of Africa is south of Europe."], "decomposition": ["What country is Bucharest located in?", "Is #1 south of Egypt?"], "evidence": [[[["Bucharest-5"]], [["Romania-1"]]], [[["Bucharest-1"]], [["Egypt-1"], "operation"]], [[["Bucharest-1"]], ["operation"]]]}
{"qid": "d15cac26462700b9d6ca", "term": "Jackfruit", "description": "species of plant", "question": "Can jackfruit be used as a weapon?", "answer": true, "facts": ["Jackfruit is the fruit of a species of plant called the Jacktree.", "Jackfruit can weigh up to one hundred and twenty pounds.", "Jackfruit is covered in little spikes.", "Jackfruit can be thrown or flung at an enemy.", "A weapon is a thing that is used to cause bodily harm."], "decomposition": ["What are the prominent physical features of a jackfruit?", "Does #1 make it a suitable weapon?"], "evidence": [[[["Jackfruit-2"]], ["operation"]], [[["Jackfruit-12"]], [["Tubercle-1"], "operation"]], [[["Jackfruit-12"]], [["Jackfruit-12", "Weapon-2"], "no_evidence"]]]}
{"qid": "9450ed6bc48b134956c5", "term": "Gray whale", "description": "species of mammal", "question": "Would a Gray Whale fit easily in an above ground pool?", "answer": false, "facts": ["Gray whales are, on average, 39ft long.", "The average above ground pool is 10-33ft in diameter. "], "decomposition": ["What is the average size of an above ground pool?", "What is the size of average gray whale?", "Is #2 smaller than #1?"], "evidence": [[[["Swimming pool-18"]], [["Gray whale-7"]], ["operation"]], [[["Swimming pool-1", "Swimming pool-23"], "no_evidence"], [["Gray whale-1"]], ["operation"]], [[["Swimming pool-23"], "no_evidence"], [["Gray whale-1"]], ["operation"]]]}
{"qid": "763ef31236d06e080681", "term": "James Bond", "description": "Media franchise about a British spy", "question": "Do the James Bond and Doctor Who series have a similarity in format?", "answer": true, "facts": ["The character of James Bond has been played by numerous actors. ", "The character of The Doctor from Doctor Who has been played by many actors."], "decomposition": ["Who has played James Bond?", "Who has played the Doctor? ", "Are multiple actors listed for #1 and #2?"], "evidence": [[[["Portrayal of James Bond in film-4"]], [["The Doctor (Doctor Who)-111"]], ["operation"]], [[["Portrayal of James Bond in film-4"]], [["The Doctor (Doctor Who)-1"]], ["operation"]], [[["James Bond-2"], "no_evidence"], [["The Doctor (Doctor Who)-1"], "no_evidence"], ["operation"]]]}
{"qid": "2b6cfeac9f6533f0409e", "term": "Markhor", "description": "species of mammal", "question": "Could a markhor give birth three times in a single year?", "answer": false, "facts": ["The gestation period of a markhor lasts 135\u2013170 days.", "There are 365 days in a year."], "decomposition": ["What is the gestation period of a Markhor?", "How many days are in a year?", "Can #1 be divided into #2 at least 3 times"], "evidence": [[[["Markhor-6"]], [["Calendar year-2"]], [["Calendar year-2", "Markhor-6"], "operation"]], [[["Markhor-6"]], [["Year-3"]], ["operation"]], [[["Markhor-6"]], [["Year-3"]], ["operation"]]]}
{"qid": "20693ee66ad7ca890e08", "term": "Egyptian pyramids", "description": "Ancient pyramid-shaped masonry structures located in Egypt", "question": "Do the Egyptian pyramids look the same from outside as they did when new?", "answer": false, "facts": ["When originally built, the Great Pyramids had a thin surface of limestone covering the bricks, making them shine in the sun.", "Over the centuries, the limestone layer has been removed by thieves and erosion, exposing the more common stone bricks underneath."], "decomposition": ["When originally built, what was the outer layer of the Great Pyramids covered in?", "Is #1 able to withstand erosion over time?"], "evidence": [[[["Great Pyramid of Giza-2"]], [["Limestone-18"], "operation"]], [[["Great Pyramid of Giza-2"]], [["Limestone-32"]]], [[["Egyptian pyramids-9"]], [["Limestone-2"], "operation"]]]}
{"qid": "aef16532a9009fd318e2", "term": "The Jackson 5", "description": "American pop music family group", "question": "Was The Jackson 5 bigger family band than The Isley Brothers?", "answer": true, "facts": ["The Jackson 5 has sold over 100 million albums worldwide.", "The Eisley Brothers have sold over 18 million albums.", "The Jackson 5 consisted of Jackie, Tito, Jermaine, Marlon and Michael.", "The Isley Brothers consisted of brothers O'Kelly, Rudolph. Ronald, and Vernon."], "decomposition": ["How many albums has the Jackson 5 sold?", "How many albums has the Eisley Brothers sold?", "How many people were in the Jackson 5?", "How many people made up the Eisley Brothers?", "Is #1 greater than #2 and is #3 greater than #4?"], "evidence": [[[["The Jackson 5-4"]], [["The Isley Brothers-5"]], [["Ronnie Rancifer-1"]], [["The Isley Brothers-4"]], ["operation"]], [[["The Jackson 5-4"]], [["The Isley Brothers-5"]], [["The Jackson 5-1"]], [["The Isley Brothers-1"]], ["operation"]], [[["The Jackson 5-4"]], [["The Isley Brothers-5"]], [["The Jackson 5-1"]], [["The Isley Brothers-4"]], ["operation"]]]}
{"qid": "cdcb51a6a8a0b9cdb2a9", "term": "Pharmacy", "description": "academic discipline studying preparation and dispensation of medicinal", "question": "Is ID required to get all medications from all pharmacies?", "answer": false, "facts": ["Controlled substance prescriptions can require an ID for pickup depending on state law.", "Non controlled substances can be picked up without ID by anybody who knows the patient information.", "State laws regarding pharmacies ID restrictions are not the same across the country."], "decomposition": ["Which category of medications usually require an ID for pickup?", "What are the regulations guiding #1 across states in the US?", "Are #2 the same across all states?"], "evidence": [[[["Medication-37"]], [["Medication-37", "Over-the-counter drug-5"]], [["Over-the-counter drug-5"], "no_evidence"]], [[["Controlled Substances Act-45"]], [["Combat Methamphetamine Epidemic Act of 2005-6"]], [["Controlled Substances Act-14"], "operation"]], [[["Opiate-1"], "no_evidence"], [["Uniform Controlled Substances Act-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "7a8b380af91f1ff5bb21", "term": "Sonnet", "description": "form of poetry with fourteen lines; by the thirteenth century it signified a poem of fourteen lines that follows a strict rhyme scheme and specific structure", "question": "Can Jabberwocky be considered a sonnet?", "answer": false, "facts": ["A sonnet is a fourteen line poem that follows certain rhyme schemes.", "Jabberwocky is an 1871 poem by Lewis Carroll.", "Jabberwocky is a 28 line poem that uses nonsense words."], "decomposition": ["How many lines does a sonnet have?", "How many lines did the poem Jabberwocky have?", "Is #1 the same as #2?"], "evidence": [[[["Sonnet-2"]], [["Jabberwocky-21"], "no_evidence"], ["operation"]], [[["Sonnet-2"]], [["Jabberwocky-1", "Jabberwocky-21"]], ["operation"]], [[["Sonnet-2"]], [["Jabberwocky-21"], "no_evidence"], ["operation"]]]}
{"qid": "39e49e586745cbe07870", "term": "Fair trade", "description": "form of trade", "question": "Did Medieval English lords engage in fair trade with peasants?", "answer": false, "facts": ["Fair trade is a system in which fair prices are paid to the producers of a product.", "English lords had peasants working on their manors and the peasants were indentured servants.", "The peasants had few rights, were unpaid, and had to even ask their lord for permission to marry."], "decomposition": ["What is fair trade?", "Are peasants able to participate in #1 with Lords?"], "evidence": [[[["Fair trade-1"]], [["Peasant-1"], "no_evidence"]], [[["Fair trade-1"], "no_evidence"], [["Peasant-8"], "no_evidence", "operation"]], [[["Fair trade-1"]], ["no_evidence", "operation"]]]}
{"qid": "7aa52a80b601b46bd48f", "term": "September", "description": "ninth month in the Julian and Gregorian calendars", "question": "Could you brew beer from start to finish in the month of September?", "answer": false, "facts": ["Brewing a batch of beer takes at least 5 weeks.", "There are 30 days, or 4 1/2 weeks, in the month of September."], "decomposition": ["How long does it take to brew a batch of beer?", "How many weeks does September have?", "Is #2 longer than #1?"], "evidence": [[[["Brewing-36"]], [["September-1"]], ["operation"]], [[["Beer-45"], "no_evidence"], [["September-1"]], ["operation"]], [[["Beer-19"]], [["September-3"]], ["operation"]]]}
{"qid": "10d718862227bef4a6ed", "term": "Chives", "description": "edible species of plant", "question": "Could chives be mistaken for grass?", "answer": true, "facts": ["Chives grow upwards in thin green cylindrical shoots. ", "Grass grows upwards in thin green flat shoots."], "decomposition": ["What is the shape and color of Chives?", "What is the shape and color of grass?", "Is #1 the same as #2?"], "evidence": [[[["Chives-4"]], ["no_evidence"], ["operation"]], [[["Chives-4"], "no_evidence"], [["Poaceae-42"], "no_evidence"], ["operation"]], [[["Chives-6"]], [["Poaceae-15"], "no_evidence"], ["operation"]]]}
{"qid": "5b8d0f04c83745464141", "term": "Snow leopard", "description": "species of mammal", "question": "Can a snow leopard eat twice its own body weight?", "answer": true, "facts": ["The average snow leopard weighs 72 pounds.", "The favorite food of snow leopards is an ibex.", "The average weight of an ibex is 150 pounds."], "decomposition": ["How much do snow leopards weigh on average?", "What is a snow leopard's favorite food?", "How much does #2 weigh?", "Is #3 at least twice as much as #1?"], "evidence": [[[["Snow leopard-17"]], [["Snow leopard-31"]], [["Bharal-3"]], [["Bharal-3", "Snow leopard-17"]]], [[["Snow leopard-17"]], [["Snow leopard-31"]], [["Snow leopard-31"]], ["no_evidence", "operation"]], [[["Snow leopard-17"]], [["Snow leopard-31"]], [["Snow leopard-31"]], ["operation"]]]}
{"qid": "162e5f5ec0f9d4a91cf8", "term": "Richard III of England", "description": "15th-century King of England", "question": "Was Richard III ruler of Adelaide?", "answer": false, "facts": ["Richard III was King of England and Lord of Ireland from 1483-1485.", "Adelaide is a city in South Australia."], "decomposition": ["When was Richard III ruler of England?", "What country is Adelaide in?", "When was #2 ruled by England?", "Does #1 and #3 overlap?"], "evidence": [[[["Richard III of England-1"]], [["Adelaide-1"]], [["Australia-2"]], ["operation"]], [[["Richard III of England-1"]], [["Adelaide-1"]], [["Australia-11"]], ["operation"]], [[["Richard III of England-1"]], [["Adelaide-1"]], [["Australia-14"]], ["operation"]]]}
{"qid": "7281474f2760dce03f39", "term": "Crane (bird)", "description": "family of birds", "question": "Can crane slamdunk?", "answer": false, "facts": ["Crane are a type of bird. ", "Slamdunking is a basketball maneuver in which the player puts the basketball in the basket with one or two hands above the rim.", "Birds don't have hands."], "decomposition": ["What is a slamdunk?", "What body parts are needed to perform #1?", "Do cranes have #2?"], "evidence": [[[["Slam dunk-1"]], [["Slam dunk-6"]], [["Crane (bird)-1"], "operation"]], [[["Slam dunk-1"]], [["Hand-1"]], [["Crane (bird)-1"], "operation"]], [[["Slam dunk-1"]], [["Slam dunk-1"]], [["Crane (bird)-1"], "no_evidence"]]]}
{"qid": "9deedbba0ca784be1855", "term": "Amtrak", "description": "Intercity rail operator in the United States", "question": "Does Amtrak operate four wheel vehicles?", "answer": true, "facts": ["Amtrak is a transportation service.", "Amtrak transports people with trains and buses.", "A bus is a four wheel vehicle. "], "decomposition": ["What kinds of vehicles does Amtrak use?", "Do any of #1 have four wheels?"], "evidence": [[[["Amtrak-1"]], [["Wheelset (rail transport)-1"], "operation"]], [[["International (Amtrak train)-14"]], [["Wheelset (rail transport)-1"]]], [[["Amtrak-3"]], ["no_evidence", "operation"]]]}
{"qid": "2787ada17c12601bcd0c", "term": "Abstract art", "description": "Art with a degree of independence from visual references in the world", "question": "Can photography be considered abstract art?", "answer": false, "facts": ["Abstract art is a form of modern art that does not reflect images of our every day world.", "Abstract art relies on exaggerated colors and shapes.", "Photography is an art that uses cameras to take pictures of events unfolding in the real world."], "decomposition": ["What kind of events/scenarios is depicted in abstract art?", "What kind of imagery does photography capture?", "Is #1 very similar to #2?"], "evidence": [[[["Abstract art-5"]], [["Photography-1"]], ["operation"]], [[["Abstract art-1", "Abstract art-3"]], [["Photography-1", "Photography-2"]], ["operation"]], [[["Abstract art-1"]], [["Photography-68"]], ["operation"]]]}
{"qid": "3a343ae8735fc81f0377", "term": "March", "description": "third month in the Julian and Gregorian calendars", "question": "Is March named after Jupiter's son in Roman mythology?", "answer": true, "facts": ["March is named after the Roman god Mars.", "Mars was the son of the Roman gods Jupiter and Juno."], "decomposition": ["Who are the sons of Jupiter in Roman mythology?", "Who is the month of March named after?", "Is #2 included in #1?"], "evidence": [[[["Hercules-1", "Mars (mythology)-1", "Vulcan (mythology)-41"]], [["March-1"]], ["operation"]], [[["Jupiter (mythology)-106"]], [["Apollo-25"], "no_evidence"], ["operation"]], [[["Mars (mythology)-7"]], [["Martius (month)-1"]], ["operation"]]]}
{"qid": "8ab34c769a8b1209b86f", "term": "Pea", "description": "species of plant", "question": "Does Soylent use Pea for their source of protein? ", "answer": false, "facts": ["Soylent is a meal replacement drink that offers 20mg protein.", "The protein in Soylent is derived from Soy."], "decomposition": ["What type of protein does Soylent use?", "Is #1 the same as pea protein?"], "evidence": [[[["Soylent (meal replacement)-1", "Soylent (meal replacement)-16"], "no_evidence"], ["no_evidence", "operation"]], [[["Soylent (meal replacement)-3"]], [["Pea-10"], "operation"]], [[["Soylent (meal replacement)-3"]], ["operation"]]]}
{"qid": "e9d41346aa0123ca54a7", "term": "Klingon", "description": "Fictional species in Star Trek", "question": "Did Klingons appear in the movie The Last Jedi?", "answer": false, "facts": ["Klingons are a race in the fictional universe of Star Trek.", "The Last Jedi is a movie set in the fictional universe of Star Wars."], "decomposition": ["Which fictional universe do the Klingons exist in?", "Which fictional universe is The Last Jedi movie set in?", "Is #1 the same as #2?"], "evidence": [[[["Klingon-2"]], [["Star Wars: The Last Jedi-1"]], ["operation"]], [[["Klingon-1"]], [["Star Wars: The Last Jedi-1"]], ["operation"]], [[["Klingon-1"]], [["Star Wars: The Last Jedi-1"]], ["operation"]]]}
{"qid": "64f18d020f552f7dd4ec", "term": "Judge", "description": "official who presides over court proceedings", "question": "Would an Orthodox Presbyterian object to 1700s judge's attire?", "answer": true, "facts": ["Judges in the 1700s wore powdered wigs and large robes during court proceedings.", "Many Orthodox Presbyterians argue that the Bible prohibits adornment such as wigs and jewelry.", "The 1 Timothy 2:8-9 Bible verse warns against adorning oneself with objects."], "decomposition": ["What attire did judges in the 1700's wear?", "What things are prohibited by Orthodox Presbyterians?", "Are some elements of #1 also found in #2?"], "evidence": [[[["Wig-16"]], ["no_evidence"], ["operation"]], [[["Court dress-110"]], ["no_evidence"], ["operation"]], [[["Wig-16"], "no_evidence"], [["Orthodox Presbyterian Church-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "d92862b94dffc52378e4", "term": "Taco Bell", "description": "American fast-food chain", "question": "Can you purchase a dish with injera at Taco Bell?", "answer": false, "facts": ["Taco Bell serves a variety of Mexican and Tex-Mex foods that include tacos, burritos, quesadillas, and nachos.", "Injera is a sour fermented flatbread with a slightly spongy texture, traditionally made out of teff flour.", "Injera is part of Ethiopian cuisine."], "decomposition": ["What kind of food is Taco Bell known to serve?", "Which country is #1 most associated with?", "Which country is Injera native to?", "Is #2 the same as #3?"], "evidence": [[[["Taco Bell-1"]], [["Taco Bell-1"]], [["Injera-1"]], ["operation"]], [[["Taco Bell-1"]], [["Taco Bell-1"]], [["Injera-1"]], ["operation"]], [[["Taco Bell-1"]], [["Mexican cuisine-6", "Tex-Mex-1"]], [["Pancake-7"]], ["operation"]]]}
{"qid": "d6ab89d323e040b5a28a", "term": "Groundhog Day", "description": "Traditional method of weather prediction", "question": "At Christmastime, do some films remind us that groundhog day is approaching?", "answer": true, "facts": ["Jack Frost is a 1979 stop motion Christmas film.", "In Jack Frost, the groundhog is a character and gets his own song reminding people of his own holiday."], "decomposition": ["What is the name of a stop motion Christmas film that was released in 1979?", "In #1, what does the groundhog get?", "Does #2 remind people of Groundhog Day?"], "evidence": [[[["Jack Frost (TV special)-1"]], [["Jack Frost (TV special)-6"]], ["operation"]], [[["Jack Frost (TV special)-1"]], [["Jack Frost (TV special)-2", "Jack Frost (TV special)-6"]], ["operation"]], [[["Jack Frost (TV special)-1"]], [["Jack Frost (TV special)-2"]], ["operation"]]]}
{"qid": "0a32d7cfde6cec332fd6", "term": "ABBA", "description": "Swedish pop group", "question": "Could ABBA play a mixed doubles tennis game against each other?", "answer": true, "facts": ["ABBA contained two male and two female members.", "Mixed doubles tennis games consist of two teams of one man and one woman on each."], "decomposition": ["How many men and women are required to participate in a mixed doubles tennis game?", "How many men and women are members of the ABBA group?", "Is #2 at least equal to #1?"], "evidence": [[[["Mixed doubles-1", "Mixed-sex sports-12"]], [["ABBA-1", "ABBA-2"]], ["operation"]], [[["Types of tennis match-4"]], [["ABBA-2"]], ["operation"]], [[["Mixed doubles-1"]], [["ABBA-1", "Agnetha F\u00e4ltskog-11"]], ["operation"]]]}
{"qid": "6cc5056659f843124e0b", "term": "Waiting staff", "description": "staff serving in restaurant or private homes", "question": "Are there some countries where waiting staff need no tip?", "answer": true, "facts": ["In Japan, leaving a tip for a server is considered rude.", "In Denmark, servers and wait staff are well paid and tipping is very uncommon."], "decomposition": ["In how many countries is it socially acceptable to not tip the waiting staff?", "Is #1 greater than one?"], "evidence": [[[["Gratuity-15", "Gratuity-18", "Gratuity-36", "Gratuity-48"]], ["operation"]], [[["Gratuity-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Gratuity-19"]], ["operation"]]]}
{"qid": "7c5daad08c46d9410a81", "term": "French people", "description": "People from France", "question": "Can a student from Smithtown's Cleary School understand the speech of a French person?", "answer": false, "facts": ["French is a romance language that originated in France.", "The Cleary School in Smithtown New York is a school for the deaf."], "decomposition": ["The Cleary School in Smithtown, New York is for students with which disability?", "Can a person with #1 perceive or understand speech?"], "evidence": [[[["Deaf education-25"]], ["operation"]], [[["Deaf education-25", "Hearing loss-1"]], ["operation"]], [[["Deaf education-25"]], [["Physical disability-7"], "operation"]]]}
{"qid": "1ac4c639f88bcaeccfbb", "term": "Scrabble", "description": "board game with words", "question": "Does monster name in West African Folklore that witches send into villages set Scrabble record?", "answer": false, "facts": ["An obia is a monster in West African folklore described as being a massive animal that witches send into villages to kidnap young girls and wear their skin for a coat.", "Obia generates 6 points in Scrabble.", "Oxyphenbutazone is said to be the highest scoring scrabble word worth 1,458 points."], "decomposition": ["What is the name of the monster in West African Folklore that witches send into villages?", "What is the highest scoring word in Scrabble?", "Is #1 the same as #2?"], "evidence": [[[["Obia (folklore)-2"]], [["Scrabble-76"]], ["operation"]], [[["Obia (folklore)-2"]], [["Scrabble-76"]], ["operation"]], [[["Obia (folklore)-2"]], [["Scrabble-76"]], ["operation"]]]}
{"qid": "810d006c5cb0e27081c8", "term": "Goldstone Deep Space Communications Complex", "description": "United States historic place", "question": "Do the telescopes at Goldstone Deep Space Communications Complex work the night shift?", "answer": true, "facts": ["The night shift is considered to be the hours of 11pm - 7am.", "The telescopes at Goldstone Deep Space Communications Complex are running 24 hours a day."], "decomposition": ["What hours are typically considered the night shift?", "What hours do the telescopes at Goldstone Deep Space Communications Complex run?", "Is there any overlap between #1 and #2?"], "evidence": [[[["Shift work-11"]], [["Goldstone Deep Space Communications Complex-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Shift work-11"], "no_evidence"], ["no_evidence"], ["operation"]], [["no_evidence"], [["Astronomy-2", "Goldstone Deep Space Communications Complex-1"], "no_evidence"], ["no_evidence"]]]}
{"qid": "64b4d43fa8671c798921", "term": "Cucumber", "description": "species of plant", "question": "Are all cucumbers the same texture?", "answer": false, "facts": ["Kirby cucumbers are known for being covered in bumps.", "English cucumbers are usually covered in ridges."], "decomposition": ["What texture do kirby cucumbers have?", "What texture do English cucumbers have?", "Is #1 the same as #2?"], "evidence": [[[["Cucumber-11"]], [["Cucumber-14", "European cucumber-1", "European cucumber-2"]], ["operation"]], [["no_evidence"], [["European cucumber-3"], "no_evidence"], ["operation"]], [[["Cucumber-9"], "no_evidence"], [["Cucumber-14"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "a4ae401042cea6e3ef15", "term": "Rice pudding", "description": "Dish made from rice mixed with water or milk", "question": "Is most store bought rice pudding made with brown rice?", "answer": false, "facts": ["Brown rice is more expensive than white rice. ", "Most store bought rice pudding is white in color.", "Brown rice, when cooked, is light brown in color."], "decomposition": ["Which rice pudding is most commonly purchased in stores?", "What color is #1", "Which types of rice are commonly used to make rice pudding?", "Is the one among #3 having color of #2 brown rice?"], "evidence": [[[["Rice pudding-10"]], ["no_evidence"], [["Rice pudding-10"]], ["operation"]], [[["Rice pudding-17"], "no_evidence"], ["no_evidence", "operation"], [["Rice pudding-4"]], ["operation"]], [[["Rice pudding-10", "Rice pudding-17"]], [["Rice pudding-4"]], [["Rice pudding-4"]], ["operation"]]]}
{"qid": "3aecd30e1212e2985d4b", "term": "Guitarist", "description": "person who plays the guitar", "question": "Do guitarists need both hands to play?", "answer": true, "facts": ["The left hand typically positions the chords on the fretboard.", "The right hand plays the strings, either strumming a whole chord or finger-picking individual strings.", "The position of the left hand on the fretboard changes the tones of the strings played by the right hand, so both hands are necessary."], "decomposition": ["Which musical instrument do guitarists play?", "How many hands are typically used to play #1?", "Is #2 equal to two?"], "evidence": [[[["Guitarist-1"]], [["Guitarist-2", "Guitarist-3"]], ["no_evidence", "operation"]], [[["Guitarist-1"]], [["Guitar-1"]], ["operation"]], [[["Guitarist-1"]], [["Guitar-1"]], ["operation"]]]}
{"qid": "fa1e09fee5546d5b7b65", "term": "Kelly Clarkson", "description": "American singer-songwriter, actress, and television personality", "question": "Would Kelly Clarkson's voice shake glass?", "answer": true, "facts": ["Glass vibrates at its resonant frequency which is around a middle C note.", "Kelly Clarkson has an impressive three octave vocal range.", "Kelly Clarkson's Never Enough is in the key of A-flat.", "A-flat is above middle C in terms of notes."], "decomposition": ["At what note would glass start to vibrate?", "In Kelly Clarkson's song Never Enough, what key is the song sung in?", "Is #2 above #1?"], "evidence": [[[["Acoustic resonance-51"], "no_evidence"], [["Never Again (Kelly Clarkson song)-5"]], ["operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Crystallophone-2", "Resonance-1", "Resonance-8"], "no_evidence"], [["Kelly Clarkson-9"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "8cf9e4fddb2265d2ed89", "term": "Mongoose", "description": "family of mammals", "question": "Does a mongoose have natural camouflage for desert?", "answer": true, "facts": ["The most common fur colors of mongooses are brown and gray.", "The Desert Camouflage color is made of Caf\u00e9 Au Lait brown and Pastel Gray."], "decomposition": ["What colors are mongoose?", "What colors are desert camouflage?", "Is #1 included in #2?"], "evidence": [[[["Mongoose-5"]], [["Desert Camouflage Uniform-1"]], [["Desert Camouflage Uniform-1", "Mongoose-5"]]], [[["Egyptian mongoose-2"], "no_evidence"], [["Desert Camouflage Uniform-1"]], ["operation"]], [[["Indian brown mongoose-2"], "no_evidence"], [["Desert Camouflage Uniform-1"]], ["operation"]]]}
{"qid": "4a915ea5d025292cd7ec", "term": "Serfdom", "description": "status of peasants under feudalism", "question": "Did Japanese serfdom have higher status than English counterpart?", "answer": true, "facts": ["Serfs in Medieval England were peasants that were indentured servants to their lords.", "Serfs were often harshly treated and had little legal redress against the actions of their lords.", "Japanese serfs were farmers and fishermen.", "Japanese believed that serfs produced food, which was depended on by all classes, therefore, they worked harder."], "decomposition": ["How did English lords treat their serfs?", "What did the Japanese recognize serfs as?", "Is #2 higher in importance than #1?"], "evidence": [[[["Serfdom-2"]], [["Serfdom-5"]], ["operation"]], [[["Serfdom-2"]], [["Manorialism-17"]], ["operation"]], [[["Serfdom-2"], "no_evidence"], [["Sh\u014den-8", "Sh\u014den-9"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "95b91109c6228074725b", "term": "United Airlines", "description": "Airline in the United States", "question": "Are there tearjerkers about United Airlines flights?", "answer": true, "facts": ["Tearjerkers typically refer to a genre of movie. ", "United Airlines flight 93 was involved in a terrorist attack in 2001.", "Several flights memorialize the passengers of Flight 93,."], "decomposition": ["What do tearjerkers refer to?", "Which United Airlines flight was involved in a terrorist attack in 2001?", "Are there any #1 in memory of the passengers of #2?"], "evidence": [[[["Melodrama-1"], "no_evidence"], [["September 11 attacks-2"]], [["United 93 (film)-1"], "no_evidence", "operation"]], [[["Melodrama-1"]], [["American Airlines Flight 11-1", "American Airlines Flight 77-1", "United Airlines Flight 175-1", "United Airlines Flight 93-1"]], ["no_evidence", "operation"]], [[["Tearjerker-1"]], [["United Airlines Flight 811-29"]], [["United Airlines Flight 811-29"]]]]}
{"qid": "9576ab36999e196b87bb", "term": "EastEnders", "description": "British soap opera", "question": "Is it possible to binge entire EastEnders series without water?", "answer": false, "facts": ["British TV series EastEnders has over 6,000 episodes as of 2020.", "It would take approximately 125 days to binge watch the entire EastEnders TV series.", "A human can last only 4 days without water."], "decomposition": ["How many days can a human last without water?", "How many episodes are there in the EastEnders series?", "How many days would it take to binge watch #2 average-length episodes?", "Is #3 less than or equal to #1?"], "evidence": [[[["Survival skills-13"]], ["no_evidence"], [["EastEnders-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Dehydration-2"], "no_evidence"], [["EastEnders-1"], "no_evidence"], ["no_evidence", "operation"], ["no_evidence", "operation"]], [[["Dehydration-2"], "no_evidence"], [["EastEnders-86"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "f286dde2dc9fae70eba9", "term": "Bull shark", "description": "Species of fish", "question": "Does bull shark bite hurt worse than crocodile bite?", "answer": false, "facts": ["The bull shark has the highest weight for weight bite of all cartilaginous fish at 5,914 newtons.", "Crocodile slam their jaws shut with 3,700 pounds per square inch (psi), or 16,460 newtons, of bite force."], "decomposition": ["What is the weight bite of a bull shark?", "What is the weight bite of a Crocodile?", "Is #1 less than #2?"], "evidence": [[[["Bull shark-9"]], [["Crocodile-24"]], ["operation"]], [[["Bull shark-9"]], [["Crocodile-24"]], ["operation"]], [[["Bull shark-9"], "operation"], [["Crocodile-24"]], ["operation"]]]}
{"qid": "7f435c65e98ee7f07b85", "term": "Cornwall", "description": "County of England", "question": "Was John George Bice's birthplace near Cornwall?", "answer": true, "facts": ["Politician John George Bice was born in Callington.", "Cornwall is a place located in South West England.", "Callington is a small town in South East Cornwall."], "decomposition": ["Where was John George Bice born?", "Is #1 located close to Cornwall?"], "evidence": [[[["John George Bice-2"]], ["operation"]], [[["John George Bice-2"]], [["John George Bice-2"]]], [[["John George Bice-2"]], [["Callington-1"]]], [[["John George Bice-2"]], [["John George Bice-2"]]]]}
{"qid": "fee20d28322885672ccf", "term": "Bob Marley", "description": "Jamaican singer-songwriter", "question": "Is sunscreen unhelpful for the condition that killed Bob Marley?", "answer": true, "facts": ["Bob Marley died of acral lentiginous melanoma ", "Acral lentiginous melanoma occurs on skin that may not have any sun exposure "], "decomposition": ["What disease killed Bob Marley?", "What is the cause of #1?", "Would sunscreen help with preventing #2?"], "evidence": [[[["Bob Marley-4"]], [["Acral lentiginous melanoma-4"]], ["no_evidence", "operation"]], [[["Bob Marley-4"]], [["Acral lentiginous melanoma-1"]], ["operation"]], [[["Bob Marley-26"]], [["Acral lentiginous melanoma-4"]], [["Acral lentiginous melanoma-1"]]]]}
{"qid": "91bb99711affe05abe7b", "term": "Samsung", "description": "South Korean multinational conglomerate", "question": "Is Samsung accountable to shareholders?", "answer": true, "facts": ["Samsung is a publicly traded company.", "Publicly traded companies are ultimately accountable to shareholders. "], "decomposition": ["What kind of company is Samsung?", "Are #1's accountable to shareholders?"], "evidence": [[[["Samsung Electronics-1"], "no_evidence"], ["operation"]], [[["Samsung-1"]], [["Conglomerate (company)-21"], "operation"]], [[["Samsung-14"], "operation"], ["operation"]]]}
{"qid": "149617ff1b645db0e871", "term": "Reza Shah", "description": "Shah of Iran, Founder of the Imperial state of iran", "question": "Could Reza Shah be related to Queen Elizabeth I?", "answer": false, "facts": ["Queen Elizabeth I was from English parents.", "Reza Shah was Mazanderani.", "Mazanderani people are indigenous people of Iran.", "Iran is nearly 4,000 miles from England."], "decomposition": ["Where are Queen Elizabeth I's parents from?", "Where is Reza Shah's family from?", "Is #1 near #2?"], "evidence": [[[["Anne Boleyn-6", "Elizabeth I of England-6", "Henry VIII of England-5"]], [["Reza Shah-4"]], [["England-1", "Iran-1"]]], [[["Elizabeth I (disambiguation)-1"]], [["Reza Shah-4"]], [["Elizabeth I (disambiguation)-1"]]], [[["Elizabeth I of England-6"]], [["Reza Shah-4"]], ["operation"]]]}
{"qid": "9eec85fab510de606494", "term": "Elon Musk", "description": "American industrialist and investor", "question": "Has Elon Musk's hairline changed?", "answer": true, "facts": ["When Elon Musk was much younger, he was clearly balding.", "Elon Musk does not show any signs of balding as of 2020."], "decomposition": ["What feature of Elon Musk's hair was notable when he was younger?", "Is #1 no longer observable in present times?"], "evidence": [[[["Elon Musk-5"], "no_evidence"], ["no_evidence", "operation"]], [[["Elon Musk-1"], "no_evidence"], [["Hair loss-4"], "no_evidence", "operation"]], [["no_evidence"], ["no_evidence"]]]}
{"qid": "0a4fa11abccd8dd84dc8", "term": "Leopard cat", "description": "Small wild cat", "question": "Are Leopard cats in less dire straits than Bornean Orangutan?", "answer": true, "facts": ["Leopard cats are classified as Least Concern on IUCN endangered list.", "Bornean Orangutan's are classified as Endangered on IUCN endangered list."], "decomposition": ["What are the recognized threats to the Bornean orangutan?", "What are the recognized threats to the leopard cat?", "Is #1 worse than #2?"], "evidence": [[[["Bornean orangutan-25"]], [["Leopard cat-28"]], [["Bornean orangutan-26", "Leopard cat-30"]]], [[["Bornean orangutan-26"]], [["Leopard-3"]], [["Bornean orangutan-25"], "no_evidence", "operation"]], [[["Bornean orangutan-2"]], [["Leopard cat-1"]], ["operation"]]]}
{"qid": "1331f2020fafcdb794c6", "term": "Thesis", "description": "document submitted in support of candidature for an academic degree", "question": "Would a thesis paper be unusual to assign to kindergartners? ", "answer": true, "facts": ["Kindergartners are usually between 4 and 6 years of age.", "Kindergartners are tasked with learning the alphabet and how to write their own names."], "decomposition": ["What skill set is required to create a thesis paper?", "What skill set do kindergartners possess?", "Are all the skills in #1 also found in #2?"], "evidence": [[[["Thesis-1"], "no_evidence"], [["Kindergarten-89"], "no_evidence"], ["operation"]], [[["Thesis-15"]], [["Kindergarten-29"]], [["Kindergarten-29"], "operation"]], [[["Thesis-17"]], [["Cognitive development-23", "Kindergarten-29"]], [["Cognitive development-23"], "operation"]]]}
{"qid": "f7b1cc5b3fab95aa1be4", "term": "Breast cancer", "description": "cancer that originates in the mammary gland", "question": "Is breast cancer associated with a ribbon?", "answer": true, "facts": ["Breast cancer is one of many diseases associated with a specific color of ribbon.", "Breast cancer's ribbon is pink."], "decomposition": ["Which diseases are associated with a (certain color of) ribbon?", "Is breast cancer included in #1?"], "evidence": [[[["Awareness ribbon-3"]], ["operation"]], [[["Awareness ribbon-3"]], ["operation"]], [[["Awareness ribbon-15"]], [["Awareness ribbon-15"]]]]}
{"qid": "f231532fe17fd971d1e6", "term": "Wonder Woman (2017 film)", "description": "American superhero film directed by Patty Jenkins", "question": "Is a Boeing 737 cost covered by Wonder Woman (2017 film) box office receipts?", "answer": true, "facts": ["The average cost of a US Boeing 737 plane is 1.6 million dollars.", "Wonder Woman (2017 film) grossed over 800 million dollars at the box office."], "decomposition": ["How much does a Boeing 737 cost?", "How much did the 2017 movie Wonder Woman gross?", "Is #2 greater than #1?"], "evidence": [[["no_evidence"], [["Wonder Woman (2017 film)-3"]], ["no_evidence", "operation"]], [["no_evidence"], [["Wonder Woman (2017 film)-3"]], ["operation"]], [[["Boeing 737-13"], "no_evidence"], [["Wonder Woman (2017 film)-31"]], ["operation"]]]}
{"qid": "80562274b771c2c50ebd", "term": "Napoleonic Wars", "description": "Series of early 19th century European wars", "question": "Was a nuclear bomb used in the Napoleonic Wars?", "answer": false, "facts": ["The Napoleonic Wars took place between 1803 and 1815.", "Nuclear bombs have only been used in warfare twice, both times in 1945."], "decomposition": ["When was the Napoleonic Wars?", "What year were nuclear bombs used in war?", "Is #2 in the range of years of #1?"], "evidence": [[[["Napoleonic Wars-1"]], [["Nuclear weapon-2"]], ["operation"]], [[["Napoleonic Wars-1"]], [["Nuclear weapons debate-1"]], ["operation"]], [[["Napoleonic Wars-1"]], [["Nuclear weapon-2"]], ["operation"]]]}
{"qid": "e9b635db671e0c1be8d9", "term": "Pancreas", "description": "A glandular organ that plays a role in the digestive and endocrine systems of vertebrates.", "question": "Can pancreas removal cause bankruptcy?", "answer": true, "facts": ["Pancreas removal is a medical procedure.", "Medical procedures are expensive in come countries. ", "Expensive procedures can cause debt.", "Debt can cause bankruptcy. "], "decomposition": ["What medical procedures are involved when a pancreas be removed?", "In what places are #1 sometimes directly paid for by the patient?", "Among any of #2, what consequences exist for medical debt?", "Is bankruptcy included in #3?"], "evidence": [[[["General surgery-1"]], [["Health care systems by country-55"]], [["Medical debt-4"]], ["operation"]], [[["Pancreatectomy-4"]], [["Medical debt-4"]], [["Medical debt-4"]], ["operation"]], [[["Pancreas-37", "Pancreas-44"], "no_evidence"], [["Health care in the United States-4"], "no_evidence"], [["Health care in the United States-14"], "no_evidence"], ["operation"]]]}
{"qid": "c253256fe0d8014da333", "term": "Alfa Romeo", "description": "Italian automotive manufacturer", "question": "Would an Alfa Romeo vehicle fit inside a barn?", "answer": true, "facts": ["Alfa Romeo makes cars.", "Barns are large enough to hold a car."], "decomposition": ["What is the average length of an Alfa Romeo?", "What is the average size of a barn?", "Is #1 smaller than #2?"], "evidence": [[[["Alfa Romeo-46"], "no_evidence"], ["no_evidence"], ["operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Alfa Romeo-1"], "no_evidence"], [["Barn-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "15271da5457a404509c4", "term": "Force", "description": "Any action that tends to maintain or alter the motion of an object", "question": "Can a cheetah generate enough force to topple Big Show?", "answer": true, "facts": ["Big Show is a professional wrestler that weighs 383 pounds.", "Force is equal to mass times acceleration.", "An adult Cheetah weighs around 160 pounds.", "An adult Cheetah can run up to 58 MPH."], "decomposition": ["How much does Big Show weigh?", "How much does a cheetah weigh?", "How fast can a cheetah run?", "Is the force produced by a mass of #2 and a speed of #3 enough to knock over something that weighs #1?"], "evidence": [[["no_evidence"], [["Cheetah-1"]], [["Cheetah-1"]], ["operation"]], [[["Big Show-4"], "no_evidence"], [["Cheetah-1"]], [["Cheetah-1"]], [["Acceleration-13"], "operation"]], [[["Big Show-4"], "no_evidence"], [["Cheetah-1"]], [["Cheetah-15"]], ["operation"]]]}
{"qid": "e93c7827b7789c989e99", "term": "The Powerpuff Girls", "description": "American animated television series", "question": "In most Mennonite homes, would children know of The Powerpuff Girls?", "answer": false, "facts": ["Mennonites are a religious with similar beliefs to Amish groups.", "Mennonites do not prohibit or view the use of technology as a sin.", "Most Mennonites avoid using television sets at home."], "decomposition": ["On what devices can one watch The Powerpuff Girls?", "What modern items do Mennonites prohibit themselves from using?", "Is #1 different from #2?"], "evidence": [[[["The Powerpuff Girls-1"]], [["Mennonites-59"], "no_evidence"], ["operation"]], [[["The Powerpuff Girls-1"]], [["Mennonites-59"]], ["operation"]], [[["Mennonites-59"]], [["Mennonites-59"], "no_evidence"], ["operation"]]]}
{"qid": "5e13590738c00273d4d7", "term": "Darth Vader", "description": "fictional character in the Star Wars franchise", "question": "Could Darth Vader hypothetically catch the Coronavirus?", "answer": false, "facts": ["The Coronavirus is transferred through infected droplets that can get into eyes, nose, or mouth.", "Darth Vader permanently wears an iron weave helmet that he needs to breathe."], "decomposition": ["How is the Coronavirus transferred?", "What does Darth Vader wear on his head?", "Can #1's get through #2?"], "evidence": [[[["Coronavirus disease 2019-13"]], [["Darth Vader-16"]], [["Coronavirus disease 2019-4"]]], [[["Coronavirus-21"]], [["Darth Vader-15"]], ["operation"]], [[["Coronavirus-21"]], [["Darth Vader-15"]], [["Coronavirus disease 2019-13"], "no_evidence"]]]}
{"qid": "7730e9a15ff9315c24fe", "term": "Spanish\u2013American War", "description": "Conflict in 1898 between Spain and the United States", "question": "Did US President during Spanish-American War suffer similar demise to Abraham Lincoln?", "answer": true, "facts": ["The Spanish-American War lasted from April 21, 1898 to August 13, 1898.", "William McKinley was President of the United States from March 4, 1897 to September 14, 1901.", "William McKinley died from gun related injuries after an assassination attempt.", "Abraham Lincoln died shortly after being shot by John Wilkes Booth."], "decomposition": ["What years were the Spanish\u2013American War?", "Who was the US President during #1?", "How was #2 killed?", "How was Abraham Lincoln killed?", "Is #3 the same as #4?"], "evidence": [[[["Spanish\u2013American War-1"]], [["Spanish\u2013American War-2"]], [["William McKinley-1"]], [["Abraham Lincoln-4"]], ["operation"]], [[["Spanish\u2013American War-1"]], [["Spanish\u2013American War-2"]], [["William McKinley-1"]], [["Maryland in the American Civil War-55"]], ["operation"]], [[["Spanish\u2013American War-1"]], [["William McKinley-1"]], [["Assassination of William McKinley-1"]], [["Assassination of Abraham Lincoln-2"]], ["operation"]]]}
{"qid": "798252398fa282fa38e6", "term": "Messiah (Handel)", "description": "Oratorio by Handel", "question": "Would Bruce Gandy be an odd choice for Messiah (Handel)?", "answer": true, "facts": ["Messiah (Handel) is a 1741 Oratorio by George Frideric Handel.", "Messiah (Handel) requires the following instruments: 2 trumpets; timpani; 2 oboes; 2 violins; and a viola.", "Bruce Gandy is a world renowned bagpipe player."], "decomposition": ["What instruments are used in Messiah (Handel)?", "What instrument is played by Bruce Gandy?", "Is #2 listed in #1?"], "evidence": [[[["Messiah (Handel)-3", "Orchestra-1"], "no_evidence"], [["Bruce Gandy-1"]], ["operation"]], [[["Structure of Handel's Messiah-9"], "no_evidence"], [["Bruce Gandy-1"]], ["operation"]], [[["Structure of Handel's Messiah-7"]], [["Bruce Gandy-5"]], ["operation"]]]}
{"qid": "02eb6aacd72d1b93a83a", "term": "Vulcan (mythology)", "description": "Ancient Roman god of fire, volcanoes, and metalworking", "question": "Does the Roman god Vulcan have a Greek equivalent?", "answer": true, "facts": ["Vulcan is the Roman god of fire and metalworking.", "Hephaestus is the Greek god of fire and metalworking.", "They are the same mythological figure, one of many characters the Romans borrowed from the Greeks and changed their names."], "decomposition": ["What is the Roman god Vulcan god of?", "Is there a god of #1 in Greek mythology?"], "evidence": [[[["Vulcan (mythology)-17"]], [["Helios-13"]]], [[["Vulcan (mythology)-1"]], [["Vulcan (mythology)-1"]]], [[["Vulcan (mythology)-17"]], [["Hephaestus-1"]]]]}
{"qid": "65455e361b1bc45132db", "term": "Coen brothers", "description": "American filmmakers", "question": "Did the Coen brothers ever collaborate with the Brothers Grimm?", "answer": false, "facts": ["The Coen brothers were born in 1954 and 1957.", "The Brothers Grimm died in 1859 and 1863."], "decomposition": ["In what century were the Coen brothers born?", "In what century did the Brothers Grimm die?", "Is #1 before #2?"], "evidence": [[[["Coen brothers-1"]], [["Brothers Grimm-1"]], ["operation"]], [[["Coen brothers-1"]], [["Brothers Grimm-1"]], ["operation"]], [[["20th century-2", "Coen brothers-1"]], [["19th century-1", "Brothers Grimm-1"]], ["operation"]]]}
{"qid": "c45743b824e24f745fcf", "term": "Wehrmacht", "description": "unified armed forces of Germany from 1935 to 1945", "question": "Did the Wehrmacht affect the outcome of the War to End All Wars?", "answer": false, "facts": ["The Wehrmacht was the unified military of Germany from 1935 to 1945", "The War to End All Wars is a nickname for World War I", "World War I ended in 1918"], "decomposition": ["What war was the War to End All Wars?", "When did #1 end?", "When was the Wehrmacht formed?", "Is #3 before #2?"], "evidence": [[[["The war to end war-1"]], [["World War I-1"]], [["Wehrmacht-1"]], ["operation"]], [[["The war to end war-1"]], [["The war to end war-1"]], [["Wehrmacht-1"]], ["operation"]], [[["World War I-1"]], [["Armistice of 11 November 1918-1"]], [["Wehrmacht-1"]], ["operation"]]]}
{"qid": "65d216ee031d7c2a376f", "term": "Chlorine", "description": "Chemical element with atomic number 17", "question": "Does chlorine inhibit photosynthesis?", "answer": true, "facts": ["Chlorine prevents algae from growing in pools", "Algae photosynthesize "], "decomposition": ["What does Chlorine prevent from growing in a pool?", "Does #1 do photosynthesis?"], "evidence": [[[["Swimming pool-67"]], [["Algae-1"], "operation"]], [[["Chlorine-66"]], [["Photosynthesis-6"]]], [[["Chlorine dioxide-25"]], [["Bacteria-3"], "operation"]]]}
{"qid": "557e389d7efe47c5bc4d", "term": "Blue", "description": "A primary colour between purple and green", "question": "Is the most expensive color in the world Blue?", "answer": true, "facts": ["Blue is a primary color.", "Blue is between violet and green on the visible light spectrum.", "Lapis Lazuli is used to make ultramarine. ", "Ultramarine is a pigment of Blue", "Processing Lapis Lazuli into Ultramarine is the most expensive of color processes."], "decomposition": ["What was the most expensive pigment used by Renaissance painters?", "Is #1 a shade of the color blue?"], "evidence": [[[["Ultramarine-2"]], [["Ultramarine-1"], "operation"]], [[["Blue-2"]], [["Ultramarine-2"], "operation"]], [[["Ultramarine-2"]], [["Ultramarine-2"]]]]}
{"qid": "38a3e1117891b029cd6b", "term": "Adrenaline", "description": "hormone, neurotransmitter and medication. Epinephrine is normally produced by both the adrenal glands and certain neurons", "question": "Can cancer cause excess adrenaline production?", "answer": true, "facts": ["Adrenaline is produced by the adrenal glands.", "Cancer is a disease characterized by the formation of tumors.", "Tumors on the adrenal glands can cause them to over-express."], "decomposition": ["What is cancer cause to grow?", "Can #1 grow on Adrenal glands?", "Does #2 cause excess adrenaline production?"], "evidence": [[[["Cancer cell-5"]], [["Adrenal tumor-9"]], [["Adrenal tumor-1"]]], [[["Cancer-1"]], [["Adrenal gland-3"]], [["Adrenal tumor-10"], "operation"]], [[["Causes of cancer-1"]], [["Adrenal tumor-5"]], [["Adrenal tumor-8"]]]]}
{"qid": "fabf020bf07e0445c50c", "term": "Sea shanty", "description": "work song sung to accompany labor on board large merchant sailing vessels", "question": "Does Jack Sparrow know any sea shantys?", "answer": true, "facts": ["Jack Sparrow is the main character of the popular 'Pirates of the Caribbean' movie franchise.", "Jack Sparrow is the captain of a pirate ship.", "Jack Sparrow sings many songs while on the sea."], "decomposition": ["Which movie is Jack Sparrow a main character in?", "Which activity is associated with singing of sea shantys?", "As portrayed in #1, is Jack Sparrow in a position to engage in #2?"], "evidence": [[[["Jack Sparrow-1"]], [["Sea shanty-1"]], ["operation"]], [[["Jack Sparrow-1"]], [["Sea shanty-119"]], [["Sea shanty-119"]]], [[["Jack Sparrow-1"]], [["Sea shanty-39", "Sea shanty-4"]], [["Jack Sparrow-1"]]]]}
{"qid": "ffd8a720264778c0fd6e", "term": "Toyota Hilux", "description": "Series of light commercial vehicles produced by the Japanese car-manufacturer Toyota.", "question": "Can the Toyota Hilux tip the scales against Mr. Ed?", "answer": true, "facts": ["The current generation of Toyota Hilux weighs at least 4,310 lbs", "Mr. Ed was portrayed by an adult horse", "The average adult horse weighs up to 2,000 lbs"], "decomposition": ["What does a Toyota Hilux weigh?", "What does an adult horse weigh?", "Is #1 greater than #2?"], "evidence": [[["no_evidence"], [["Horse-13"]], ["no_evidence", "operation"]], [["no_evidence"], [["Horse-13"]], ["operation"]], [[["Toyota Hilux-1"], "no_evidence"], [["Horse-12"]], ["operation"]]]}
{"qid": "ea3f5363f250cb9c9969", "term": "United Airlines", "description": "Airline in the United States", "question": "Does United Airlines have a perfect operation record?", "answer": false, "facts": ["An airline with a perfect operation record has no crashes or other damaging incidents.", "United Airlines has had over 30 crash incidents over several decades."], "decomposition": ["What must an airline avoid if they want a perfect operation record?", "Is United Airlines free of #1?"], "evidence": [[[["Freedoms of the air-3"], "no_evidence"], [["United Airlines-62"], "no_evidence"]], [["no_evidence"], [["United Airlines-62"], "no_evidence", "operation"]], [[["Incident management (ITSM)-1"], "no_evidence"], [["United Airlines-62"], "operation"]]]}
{"qid": "3871d7a05a729494ecd9", "term": "Guitarist", "description": "person who plays the guitar", "question": "Do guitarist's have fingers that can handle pain better than average?", "answer": true, "facts": ["Guitarists typically have calloused fingertips. ", "Callouses are formed of layers of dead skin and usually lack sensation."], "decomposition": ["What typically forms on a Guitarists' finger?", "Does #1 usually cause a lack of sensation?"], "evidence": [[[["Callus-3"]], [["Callus-12"], "no_evidence", "operation"]], [[["Callus-3"]], ["no_evidence", "operation"]], [[["Callus-3"]], [["Callus-13", "Callus-6"]]]]}
{"qid": "e9689243222e7afa28ad", "term": "Swan", "description": "large water bird", "question": "Would a Nike shoebox be too small to fit a swan in?", "answer": true, "facts": ["Nike Shoeboxes are usually 14\" x 10\" x 5\".", "An average swan is 4-5.6 ft in length."], "decomposition": ["What is the average size of a Nike Shoebox?", "What is the average length of a swan?", "Is #2 smaller than #1?"], "evidence": [[[["Shoe size-13", "Sneakers-16"], "no_evidence"], [["Swan-3"], "no_evidence"], ["operation"]], [[["Shoe-1"], "no_evidence"], [["Swan-3"]], ["operation"]], [["no_evidence"], [["Swan-3"]], ["no_evidence", "operation"]]]}
{"qid": "2251a4d6e090572a63d7", "term": "Bengal fox", "description": "species of mammal", "question": "Could Ryan Crouser throw a bengal fox with ease?", "answer": true, "facts": ["Ryan Crouser is a professional shot putter who won the gold medal at the 2016 Olympics.", "The men's shot weighs 16.01 pounds.", "The typical weight of a Bengal fox is between 5 to 9 pounds."], "decomposition": ["What sport is Ryan Crouser a professional in?", "How much does the equipment for #1 weigh?", "How much does a Bengal fox weigh?", "Is #2 greater than #3?"], "evidence": [[[["Ryan Crouser-1"]], [["Shot put-11"]], [["Bengal fox-2"]], ["operation"]], [[["Ryan Crouser-1"]], [["Shot put-11"]], [["Bengal fox-2"]], ["operation"]], [[["Ryan Crouser-1"]], [["Shot put-11"], "no_evidence"], [["Bengal fox-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "ba67c57c41ae212177c8", "term": "Eleventh grade", "description": "educational year", "question": "Is eleventh grade required to get a driver's licence?", "answer": false, "facts": ["Eleventh grade is an educational year in high school.", "Many high schools offer driver's education classes.", "Drivers education classes can be taken outside by other organizationsof high school.", "One must pass a driving test to obtain a drivers license."], "decomposition": ["What criteria must be met to obtain a driver's license in the US?", "Is passing the eleventh grade required to meet #1?"], "evidence": [[[["Driver's licenses in the United States-10"]], ["operation"]], [[["Driver's license-3"]], ["operation"]], [[["Driver's license-3"]], ["operation"]]]}
{"qid": "3e1f787a59396deeb88c", "term": "Southern United States", "description": "Cultural region of the United States", "question": "Can you hunt Iberian wolves in the Southern United States?", "answer": false, "facts": ["The Iberian wolf inhabits northern Portugal and northwestern Spain.", "Portugal and Spain are not located in the Southern United States."], "decomposition": ["What is the range of the Iberian wolf?", "Is #1 located in the Southern United States?"], "evidence": [[[["Iberian wolf-1"]], ["operation"]], [[["Iberian wolf-1"]], [["United States-1", "Western Europe-1"]]], [[["Iberian wolf-1"]], [["Iberian Peninsula-64", "United States-1"]]]]}
{"qid": "bea8de56cae6a9dc374c", "term": "Allosaurus", "description": "Genus of large theropod dinosaur", "question": "Is Oculudentavis more dangerous than Allosaurus?", "answer": false, "facts": ["Oculudentavis was a dinosaur that resembled a tiny bird with a half an inch skull.", "The Allosaurus was a carnivorous dinosaur with teeth described as saws."], "decomposition": ["What were the characteristics of the Oculudentavis?", "What were the characteristics of the Allosaurus?", "Are #1 more likely to cause harm than #2?"], "evidence": [[[["Oculudentavis-3"]], [["Allosaurus-2"]], ["operation"]], [[["Oculudentavis-1"]], [["Allosaurus-2"]], ["operation"]], [[["Oculudentavis-4"]], [["Allosaurus-3"]], ["operation"]]]}
{"qid": "0013d38e0568f48acdc0", "term": "Voyager 2", "description": "Space probe and the second-farthest man-made object from Earth", "question": "Could a Hwasong-15 missile hypothetically reach Voyager 2?", "answer": false, "facts": ["Voyager 2 was a probe that traveled to the interstellar medium of space.", "The interstellar medium is over 12,161,300,000 miles away from earth.", "The Hwasong-15 missile is a North Korean missile with a range of 8,000 miles."], "decomposition": ["How far away from Earth has Voyager 2 traveled?", "What is the range of a Hwasong-15 missile?", "Is #2 greater or equal to #1?"], "evidence": [[[["Voyager 2-3"]], [["Hwasong-15-3"]], ["operation"]], [[["Voyager 2-3"]], [["Hwasong-15-1"]], ["operation"]], [[["Voyager 2-3"]], [["Hwasong-15-3"]], ["operation"]]]}
{"qid": "80d50b4511767c25aa28", "term": "Unicode", "description": "Character encoding standard", "question": "Did Malcolm X use Unicode?", "answer": false, "facts": ["Malcolm X died in 1965. ", "Unicode did not become a standard until 1991. "], "decomposition": ["When did Malcolm X die?", "When was Unicode established?", "Is #2 before #1?"], "evidence": [[[["Malcolm X-96"]], [["Unicode-12"]], [["Malcolm X-96", "Unicode-12"], "operation"]], [[["Malcolm X-1"]], [["Unicode-18"]], ["operation"]], [[["Malcolm X-1"]], [["Unicode-12"]], ["operation"]]]}
{"qid": "01786fe2b099fd7fb504", "term": "Minor League Baseball", "description": "hierarchy of professional baseball leagues affiliated with Major League Baseball", "question": "Were weather phenomena avoided when naming minor league baseball teams?", "answer": false, "facts": ["Weather phenomena refers to types of weather caused conditions such as cyclones, storms, and tsunamis.", "Minor league baseball teams include the Brooklyn Cyclones and Lake Elsinore Storm."], "decomposition": ["What are some names of weather phenomena?", "What are the name of minor league baseball teams?", "Are any terms in #1 also present in #2?"], "evidence": [[[["Weather-5"], "no_evidence"], [["Omaha Storm Chasers-1"], "no_evidence"], ["operation"]], [[["Glossary of meteorology-1"], "no_evidence"], [["Minor League Baseball-40"], "no_evidence"], ["no_evidence", "operation"]], [[["Thunder-1"]], [["Trenton Thunder-1"]], ["operation"]]]}
{"qid": "dc3310bf2a61d1a9f2cf", "term": "Amtrak", "description": "Intercity rail operator in the United States", "question": "Does Amtrak run from NYC directly to the Moai location?", "answer": false, "facts": ["Amtrak is a series of railways that transport people to various locations.", "The Moai are ancient stone statue faces that are a popular tourist destination.", "The Moai are located on Easter Island, an island in the Pacific ocean, near Chile."], "decomposition": ["Which major regions does Amtrak's passenger railroad service cover?", "Where are the Moai located?", "Is #2 located within any of #1?"], "evidence": [[[["Amtrak-1"]], [["Moai-8"]], ["operation"]], [[["Amtrak-3"]], [["Rapa Nui people-9"]], ["operation"]], [[["Amtrak-1"]], [["Moai-1"]], [["Polynesia-1"]]]]}
{"qid": "66dd7cd84b014a6d1f60", "term": "Eggplant", "description": "plant species Solanum melongena", "question": "Is eggplant deadly to most atopic individuals? ", "answer": false, "facts": ["Atopic individuals have a genetic tendency to develop allergic reactions", "Eggplant allergies are usually not life-threatening "], "decomposition": ["What kind of reactions do atopic people have a tendency of getting?", "Are #1 caused by eggplant usually deadly in nature?"], "evidence": [[[["Atopy-4"]], [["Eggplant-53"], "operation"]], [[["Atopy-1"]], ["no_evidence", "operation"]], [[["Atopy-1", "Atopy-4", "Atopy-5"]], [["Atopy-6"], "no_evidence", "operation"]]]}
{"qid": "4589898e4852e5389728", "term": "YMCA", "description": "Worldwide organization founded in 1844 on principles of muscular Christianity", "question": "Can you get Raclette in YMCA headquarters city?", "answer": true, "facts": ["YMCA is headquartered in Geneva, Switzerland.", "Raclette is a melted cheese and potato dish.", "Raclette is one of several foods Geneva, Switzerland is famous for."], "decomposition": ["Where is the YMCA headquartered?", "What foods is #1 famous for?", "Is raclette in #2?"], "evidence": [[[["YMCA-1"]], [["Swiss Cheese Union-9"], "no_evidence"], [["Raclette-2"], "operation"]], [[["YMCA-1"]], [["Swiss cuisine-2"]], ["operation"]], [[["YMCA-53"]], [["Lincoln Park, Chicago-37"]], [["Raclette-1"], "operation"]]]}
{"qid": "7acebd6478d0935c7a3b", "term": "Pi", "description": "Ratio of the circumference of a circle to its diameter", "question": "Can every digit in Pi be memorized?", "answer": false, "facts": ["The digits of Pi are infinite. ", "The human mind cannot hold an infinite amount of information."], "decomposition": ["How many digits are in Pi?", "Can the human mind memorize #1 amount of information?"], "evidence": [[[["Pi-4"]], [["Memory-10", "Short-term memory-21"], "no_evidence"]], [[["Pi-16"]], ["operation"]], [[["Pi-3"]], [["Piphilology-65"], "operation"]]]}
{"qid": "8e073418da1eab499775", "term": "Islamophobia", "description": "Fear, hatred of, or prejudice against the Islamic religion or Muslims generally,", "question": "Is Islamophobia against Cyprus majority religion misdirected?", "answer": true, "facts": ["Islamophobia is prejudice and fear against Muslims.", "Cyprus is a country in the Middle East, which is a predominantly Muslim region.", "Cyprus is the only Christian majority country in the Middle East, with Christians forming between 76% and 78% of the country's total population, and most of them adhere to Eastern Orthodox Christianity."], "decomposition": ["What religion is targeted by Islamophobia?", "What is the most common religion in Cyprus?", "Is #1 different than #2?"], "evidence": [[[["Islamophobia-1"]], [["Cyprus-100"]], ["operation"]], [[["Islamophobia-54"], "no_evidence"], [["Religion in Cyprus-1"], "operation"], ["no_evidence"]], [[["Islamophobia-1"]], [["Religion in Cyprus-1"]], ["operation"]]]}
{"qid": "0628999cf77312e0f23a", "term": "Justin Bieber", "description": "Canadian singer-songwriter and actor", "question": "Did U.S. soldiers listen to Justin Bieber's Believe album during the Battle of Baghdad?", "answer": false, "facts": ["The Battle of Baghdad was the U.S. invasion of Baghdad in the year 2003.", "Justin Bieber's album Believe was released in 2012."], "decomposition": ["When did the Battle of Baghdad take place?", "When was the Justin Bieber album Believe released?", "Is #2 before #1?"], "evidence": [[[["Battle of Baghdad (2003)-1"]], [["Believe (Justin Bieber album)-1"]], ["operation"]], [[["Battle of Baghdad (2003)-1"]], [["Believe (Justin Bieber album)-1"]], ["operation"]], [[["Battle of Baghdad (2003)-1"]], [["Believe (Justin Bieber album)-1"]], ["operation"]]]}
{"qid": "0992c14cfd410f2d5c1e", "term": "Slot machine", "description": "Casino gambling machine", "question": "Do any video games about the end of civilization have slot machines?", "answer": true, "facts": ["Fallout New Vegas is a game that takes place after the apocalypse has ocurred. ", "In Fallout New Vegas, players can go to casinos and play on slot machines."], "decomposition": ["What video games take place in a post-apocalyptic world?", "Which video games have slot machines?", "Is at least one game in #1 found in #2?"], "evidence": [[[["Fallout (series)-2", "Fallout: New Vegas-1"]], [["Fallout: New Vegas-4"]], ["operation"]], [[["Fallout: New Vegas-1", "The Last of Us-1"], "no_evidence"], [["Fallout: New Vegas-4"], "no_evidence"], ["operation"]], [[["Fallout (series)-1"], "no_evidence"], [["Fallout: New Vegas-2", "Fallout: New Vegas-4"], "no_evidence"], ["operation"]]]}
{"qid": "55a0154c4a5dd692c046", "term": "Mercedes-Benz", "description": "automobile brand of Daimler AG", "question": "Was Mercedes-Benz associated with the Nazis?", "answer": true, "facts": ["During the 1930s, Mercedes-Benz produced the 770 model.", "The 770 was popular with Nazis, and Adolf Hitler used them as his personal vehicle."], "decomposition": ["Which Mercedes-Benz model was made during the 1930s?", "Was #1 popular among the Nazis?"], "evidence": [[[["Mercedes-Benz-6"]], ["operation"]], [[["Mercedes-Benz 770-1"]], [["Mercedes-Benz 770-1"]]], [[["Mercedes-Benz 770-6"]], [["Mercedes-Benz-6"], "operation"]]]}
{"qid": "e175b012fc9b5db8da3f", "term": "Pan (god)", "description": "Ancient Greek god of the wilds, shepherds, and flocks", "question": "Does the Boy Who Cried Wolf hypothetically have reason to pray to Pan?", "answer": true, "facts": ["Pan is the ancient Greek god of the wild, shepherds and flocks.", "The Boy Who Cried Wolf, from Aesop's Fables, was a shepherd boy."], "decomposition": ["What is the profession of The Boy Who Cried Wolf?", "What profession is Pan the god of?", "Is #1 the same as #2?"], "evidence": [[[["The Boy Who Cried Wolf-2"]], [["Pan (god)-1"]], ["operation"]], [[["The Boy Who Cried Wolf-2"]], [["Pan (god)-1"]], ["operation"]], [[["The Boy Who Cried Wolf-2"]], [["Pan (god)-1"]], ["operation"]]]}
{"qid": "78f2f99d04b9acd8bada", "term": "Alice's Adventures in Wonderland", "description": "book by Lewis Carroll", "question": "Would a Jehovah's witness approve of Alice's Adventures in Wonderland?", "answer": false, "facts": ["Jehovah's Witness is a religious group that strictly forbids tobacco and smoking.", "A prominent character in Alice's Adventures in Wonderland, the caterpillar, blows rings of smoke from a large pipe."], "decomposition": ["What are Jehovah's Witnesses?", "What items do #1's forbid?", "In Alice's Adventures in Wonderland, what is the caterpillar seen doing with a pipe?", "Is #2 different from #3?"], "evidence": [[[["Jehovah's Witnesses-1"]], [["Religious views on smoking-6"]], [["Caterpillar (Alice's Adventures in Wonderland)-6"]], ["operation"]], [[["Jehovah's Witnesses-1"]], [["Jehovah's Witnesses-36"]], [["Alice's Adventures in Wonderland-13"]], ["operation"]], [[["Jehovah's Witnesses-1"]], [["Jehovah's Witnesses practices-27"], "no_evidence"], [["Alice's Adventures in Wonderland-13"]], ["no_evidence", "operation"]]]}
{"qid": "8ab0f34f407608dbd2b3", "term": "Chicago \"L\"", "description": "rapid transit system in Chicago, Illinois, operated by the CTA", "question": "Would the fastest tortoise win a race against a Chicago \"L\"?", "answer": false, "facts": ["Top speed of  Chicago \"L\" is 55 mph (89 km/h).", "The Guinness Book of World Records maintains the record for fastest tortoise: the tortoise ran at an average speed of 0.63 miles per hour."], "decomposition": ["What is the top speed of a Chicago \"L\"?", "What is the top speed of a tortoise?", "Is #2 greater than #1?"], "evidence": [[[["Chicago \"L\"-37"], "no_evidence"], [["Turtle-5"], "no_evidence"], ["operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Chicago \"L\"-58"], "no_evidence"], [["Turtle racing-6"]], ["operation"]]]}
{"qid": "e8b311139f387c983996", "term": "Saltwater crocodile", "description": "species of reptile", "question": "Would you take a photo of a Saltwater crocodile in Memphis?", "answer": false, "facts": ["The saltwater crocodile is native to saltwater habitats and brackish wetlands from India's east coast across Southeast Asia and the Sundaic region to northern Australia and Micronesia.", "Memphis is a city in the United States."], "decomposition": ["Where can saltwater crocodiles be found?", "Is Memphis located in any of #1?"], "evidence": [[[["Saltwater crocodile-1"]], ["operation"]], [[["Saltwater crocodile-1"]], [["Memphis, Tennessee-1"]]], [[["Saltwater crocodile-20"]], ["operation"]]]}
{"qid": "132f21b2b388b637c22f", "term": "Disco", "description": "music genre", "question": "Did the Beatles write any music in the Disco genre?", "answer": false, "facts": ["The Beatles were active from 1960 until 1969.", "Disco began to appear around 1972."], "decomposition": ["When were the Beatles active as a full group?", "When did disco start?", "Is #2 before #1?"], "evidence": [[[["Break-up of the Beatles-1", "The Beatles-1"]], [["Disco-1"]], ["operation"]], [[["The Beatles-1"]], [["Disco-1"]], ["operation"]], [[["The Beatles-1", "The Beatles-3"]], [["Disco-1"]], ["operation"]]]}
{"qid": "89a19bd8f2bea335bca1", "term": "Doctor Strange", "description": "Superhero appearing in Marvel Comics publications and related media", "question": "Did Doctor Strange creators also make Batman?", "answer": false, "facts": ["Doctor Strange is a superhero created by Steve Ditko and Stan Lee.", "Batman is a DC comics superhero.", "Stan Lee worked for Marvel comics, the competitor of DC comics.", "Steve Ditko worked for DC late in his career and worked on Blue Beetle, the Question, the Creeper, Shade the Changing Man, and Hawk and Dove."], "decomposition": ["Who were the creators of the fictional character 'Doctor Strange'?", "Who were the creators of the fictional character 'Batman'?", "Are #1 the same as #2?"], "evidence": [[[["Doctor Strange-1"]], [["Batman-1"]], ["operation"]], [[["Doctor Strange-1"]], [["Batman-1"]], ["operation"]], [[["Doctor Strange-1"]], [["Batman-1"]], ["operation"]]]}
{"qid": "6b7feff09dde2f64fdd5", "term": "Ronda Rousey", "description": "American professional wrestler, actress, author, mixed martial artist and judoka", "question": "Will Ronda Rousey hypothetically defeat X-Men's Colossus in a fight?", "answer": false, "facts": ["Ronda Rousey is a mixed martial artist and wrestler.", "Ronda Rousey relies on striking moves and submission tactics to dominate her opponents.", "X-Men's Colossus has the ability to change his appearance.", "Colossus's mutation allows him to create an organic steel layer, that acts as an impenetrable external shell."], "decomposition": ["What type of profession is Ronda Rousey in?", "What moves do #1 use to beat their opponents?", "What special ability does X-men have?", "Can someone with #2 easily beat someone with #3?"], "evidence": [[[["Ronda Rousey-1"]], [["Ronda Rousey-43"]], [["X-Men-2"]], ["no_evidence"]], [[["Ronda Rousey-1"]], [["Professional wrestling-1"]], [["Colossus (comics)-55"]], ["operation"]], [[["Ronda Rousey-1"]], [["Grappling position-5"], "no_evidence"], [["Colossus (comics)-2"]], ["operation"]]]}
{"qid": "127e33dd84829d6283ef", "term": "Tenth Amendment to the United States Constitution", "description": "says powers not Constitutionally granted to the Federal Government belong to States or the People", "question": "Was the tenth Amendment to the Constitution written using Pitman shorthand?", "answer": false, "facts": ["Pitman shorthand was invented in 1837.", "The tenth Amendment to the Constitution was added in 1791."], "decomposition": ["When was Pitman shorthand invented?", "When was the  tenth Amendment to the Constitution added?", "Did #1 happen before #2?"], "evidence": [[[["Pitman shorthand-1"]], [["Tenth Amendment to the United States Constitution-1"]], ["operation"]], [[["Pitman shorthand-5"]], [["Tenth Amendment to the United States Constitution-1"]], ["operation"]], [[["Pitman shorthand-1"]], [["Tenth Amendment to the United States Constitution-1"]], ["operation"]]]}
{"qid": "f8e6087cd52c925fedad", "term": "Tony Bennett", "description": "American singer", "question": "Could ancient Tony Bennett have a baby in 2020?", "answer": true, "facts": ["Tony Bennett is a legendary singer who will turn 94 years old in August 2020.", "Ramjit Raghav, the oldest man to have a baby, had his first child at age 94.", "Ramjit Raghav had his second child at age 96."], "decomposition": ["How old was Tony Bennett in 2020?", "How old was the oldest man to father a child?", "Is #1 less than #2?"], "evidence": [[[["Tony Bennett-1"]], [["Ramjit Raghav-1"]], ["operation"]], [[["Tony Bennett-1"]], [["Ramjit Raghav-1"]], ["operation"]], [[["Tony Bennett-1"]], [["Ramjit Raghav-4"]], ["operation"]]]}
{"qid": "89a3281f33b15c7fba3f", "term": "The Hague", "description": "City and municipality in South Holland, Netherlands", "question": "Does Abdulqawi Yusuf go to the Hague on a typical work day?", "answer": true, "facts": ["Abdulqawi Yusuf is the current president of the International Court of Justice", "The International Court of Justice is headquartered in The Hague"], "decomposition": ["What organization does Abdulqawi Yusuf's work for?", "Where is #1 headquartered?"], "evidence": [[[["Abdulqawi Yusuf-1"]], [["International Court of Justice-3"], "operation"]], [[["Abdulqawi Yusuf-1"]], [["International Court of Justice-3"]]], [[["Abdulqawi Yusuf-1"]], [["United Nations-1"]]]]}
{"qid": "36edeeb054e722511fcd", "term": "Elizabeth II", "description": "Queen of the United Kingdom and the other Commonwealth realms", "question": "Was Elizabeth II the Queen during the Persian Gulf War?", "answer": true, "facts": ["Elizabeth II became Queen in 1952.", "The Persian Gulf War occurred 1990-1991."], "decomposition": ["When did Elizabeth II become the Queen?", "When was the Persian Gulf War?", "Was Elizabeth II alive in #2?", "Is #2 after #1?", "Are the answers to #3 and #4 both yes?"], "evidence": [[[["Elizabeth II-3"]], [["Persian Gulf-3"]], [["Elizabeth II-1"]], ["operation"], ["operation"]], [[["Head of the Commonwealth-8"]], [["Gulf War-1"]], [["Elizabeth II-41"]], ["operation"], ["operation"]], [[["Elizabeth II-3"]], [["Gulf War-1"]], [["Elizabeth II-42"]], ["operation"], ["operation"]]]}
{"qid": "4eef7889f6dc2815f41f", "term": "2010 United Kingdom general election", "description": "election of members to the House of Commons in 2010", "question": "Did John Kerry run in the 2010 United Kingdom general election?", "answer": false, "facts": ["John Kerry is an American citizen and politician", "Only citizens of the UK, Ireland or a Commonwealth nation are eligible to run in the United Kingdom general elections"], "decomposition": ["In order to run in the UK general election, a person must be a citizen of one of which countries? ", "John Kerry is a citizen of what country?", "Is #2 listed in #1?"], "evidence": [[[["Elections in the United Kingdom-7"]], [["John Kerry-1"]], ["operation"]], [[["Member of parliament-34"]], [["John Kerry-2"]], ["operation"]], [[["Citizenship-38"], "no_evidence"], [["John Kerry-5"], "no_evidence"], ["operation"]]]}
{"qid": "085b0b414514ce251e76", "term": "Kinetic energy", "description": "Energy in motion Or Object In Motion", "question": "Does taking ukemi halt kinetic energy?", "answer": false, "facts": ["\"Taking ukemi\" refers to the art of falling or receiving in martial arts", "Taking ukemi usually requires the person doing it to move their body in a way that minimizes injury, and so it uses kinetic energy"], "decomposition": ["What does the term 'taking ukemi' refer to?", "What state of an object indicates exertion of kinetic energy?", "Can #1 be executed while avoiding #2?"], "evidence": [[[["Uke (martial arts)-3"]], [["Kinetic energy-1"]], ["operation"]], [[["Uke (martial arts)-3"]], [["Kinetic energy-1"]], ["no_evidence"]], [[["Uke (martial arts)-3"]], [["Kinetic energy-1"]], [["Uke (martial arts)-4"], "operation"]]]}
{"qid": "9c0111d03557271a54fc", "term": "Reformation", "description": "Schism within the Christian Church in the 16th century", "question": "Would a tool used for Martin Luther's Reformation opening salvo aid in a crucifixion?", "answer": true, "facts": ["Martin Luther began the Reformation with the defiant act of nailing 95 grievances to the door of the Wittenberg church.", "Roman crucifixions required several tools including nails and wooden beams."], "decomposition": ["What did Martin Luther begin his Reformation with?", "What tools were used in #1?", "What are the tools required to preform Roman crucifixions?", "Is there any overlap between #2 and #3?"], "evidence": [[[["Ninety-five Theses-1"]], [["Wittenberg-7"]], [["Crucifixion of Jesus-44"]], ["operation"]], [[["Martin Luther-19"]], [["Nail (fastener)-1", "Nail (fastener)-2"]], [["Crucifixion-1"]], ["operation"]], [[["Martin Luther-19"]], [["Nail (fastener)-2"]], [["Crucifixion-1", "Nail (fastener)-2"]], ["operation"]]]}
{"qid": "94f996bf88b05741bb07", "term": "Kobe", "description": "Designated city in Kansai, Japan", "question": "Is Kobe's famous animal product used in a BLT?", "answer": false, "facts": ["Kobe's famous animal product is Kobe beef.", "The animal product used in a BLT is bacon.", "Beef is derived from cows.", "Bacon is derived from pigs."], "decomposition": ["What animal product is Kobe, Japan most famous for?", "What animal product comes is used in a BLT?", "What animal does #1 come from?", "What animal does #2 come from?", "Is #3 the same as #4?"], "evidence": [[[["Kobe beef-3"]], [["BLT-1"]], [["Beef-57"]], [["Bacon-39"]], ["operation"]], [[["Kobe-3"]], [["BLT-1"]], [["Bacon-7", "Pork belly-1"]], [["Beef-1", "Cattle-1"]], ["operation"]], [[["Kobe beef-1"]], [["BLT-1"]], [["Japanese Black-1"]], [["Bacon-1", "Pork-1"]], ["operation"]]]}
{"qid": "c6c7d980dd92cb870ca0", "term": "Presidency of Bill Clinton", "description": "1993\u20132001 U.S. presidential administration", "question": "Did the Presidency of Bill Clinton conclude with his impeachment?", "answer": false, "facts": ["Bill Clinton was impeached in 1998.", "Bill Clinton remained in office until 2001."], "decomposition": ["In what year was Bill Clinton impeached?", "In what year did Bill Clinton's presidency end?", "Is #1 the same as #2?"], "evidence": [[[["Bill Clinton-61"]], [["Bill Clinton-1", "Impeachment of Bill Clinton-29"]], ["operation"]], [[["Impeachment of Bill Clinton-16"]], [["Bill Clinton-1"]], ["operation"]], [[["Bill Clinton-61"]], [["Bill Clinton-61"]], ["operation"]]]}
{"qid": "184d0b1306899a9365ce", "term": "Forbidden City", "description": "Art museum, Imperial Palace, Historic site in Beijing, China", "question": "Is the Forbidden City host to a wooden rollercoaster?", "answer": false, "facts": ["Wooden rollercoasters are relatively modern.", "The Forbidden City is an ancient historic site."], "decomposition": ["When were wooden rollercoasters first built?", "What is the Forbidden City?", "When was #2 built?", "Did #3 come before #1?"], "evidence": [[[["Wooden roller coaster-3"]], [["Forbidden City-1"]], [["Forbidden City-2"]], ["operation"]], [[["Wooden roller coaster-3"]], [["Forbidden City-1"]], [["Forbidden City-2"]], ["operation"]], [[["History of the roller coaster-8"]], [["Forbidden City-1"]], [["Forbidden City-2"]], ["operation"]]]}
{"qid": "dda75d90553b54b13562", "term": "Snickers", "description": "brand name chocolate bar made by Mars, Incorporated", "question": "Is it wise to feed a Snickers bar to a poodle?", "answer": false, "facts": ["A Snickers bar contains chocolate.", "Chocolate is harmful or even toxic to dogs.", "Poodles are a breed of dog."], "decomposition": ["What are poodles a breed of?", "What substances are harmful to #1?", "What is a Snickers make out of?", "Is there no overlap between #2 and #3?"], "evidence": [[[["Poodle-1"], "no_evidence"], [["Dog food-60"], "no_evidence"], [["Snickers-1"], "no_evidence"], ["operation"]], [[["Poodle-1"]], [["Dog-19"]], [["Snickers-1"]], ["operation"]], [[["Poodle-18"], "operation"], ["no_evidence"], [["Snickers-3"], "operation"], ["no_evidence"]]]}
{"qid": "05e9cdc44f1b066badd7", "term": "Moustache", "description": "Facial hair grown on the upper lip", "question": "Is it common for women to have moustaches?", "answer": false, "facts": ["Facial hair doesn't normally grow on women like it does on men.", "A little bit of hair can grow between the upper lip and nose but it's a very small amount and generally not enough to be noticeable."], "decomposition": ["Which gender grows sizable moustaches more commonly?", "Is #1 the same as women?"], "evidence": [[[["Moustache-9"]], ["operation"]], [[["Beard-27"]], [["Beard-27"], "operation"]], [[["Facial hair-2"]], ["operation"]]]}
{"qid": "653e7f9907cc581803b6", "term": "Amtrak", "description": "Intercity rail operator in the United States", "question": "Would three newborn kittens fit on a standard Amtrak coach seat?", "answer": true, "facts": ["Newborn kittens are small enough to fit in an average human hand.", "The average human hand is 7 inches.", "An Amtrak coach seat is 39\" x 23\"."], "decomposition": ["What is the size of a newborn kitten?", "How big would #1 times three kittens be?", "How large is an Amtrak coach seat?", "Is #2 smaller than #3?"], "evidence": [[[["Cat-28"], "no_evidence"], ["operation"], [["Airline seat-29"], "no_evidence"], ["operation"]], [[["Kitten-4"], "no_evidence"], ["no_evidence"], [["Amtrak-43"], "no_evidence"], ["no_evidence", "operation"]], [[["Cat-28"], "no_evidence"], ["no_evidence", "operation"], [["Amtrak-48"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "cac049d9ec0b86a7f911", "term": "Starbucks", "description": "American multinational coffee company", "question": "Would menu at Chinese Starbucks be familiar to an American?", "answer": false, "facts": ["American Starbucks sells a number of coffee beverages like Lattes and Cappucino.", "The Chinese Starbucks menu focuses on teas such as Blackcurrant Raspberry Juiced Tea and Iced Shaken Mango Herbal Juiced Tea.", "Mooncakes, Chinese bakery products traditionally eaten during the Mid-Autumn Festival, are popular items at Chinese Starbucks."], "decomposition": ["What is on the typical American Starbucks' menu?", "What is on the typical Chinese Starbucks' menu?", "Are most things in #2 not found in #1?"], "evidence": [[[["Starbucks-16"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Starbucks-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Starbucks-1"]], [["Starbucks-27"], "no_evidence"], ["operation"]]]}
{"qid": "63b0be164dfd44bf1890", "term": "PlayStation 4", "description": "Sony's eighth-generation home video game console", "question": "Did Bill Gates help to develop the PlayStation 4?", "answer": false, "facts": ["The PlayStation 4 was developed by Sony Interactive Entertainment.", "Bill Gates works for Microsoft Corporation, which is a competitor of Sony."], "decomposition": ["Which organization does Bill Gate work for?", "Which organization developed PlayStation 4?", "Is #1 the same as #2?"], "evidence": [[[["Bill Gates-1"]], [["PlayStation 4-1"]], ["operation"]], [[["Bill Gates-1"]], [["PlayStation 4 system software-1"]], ["operation"]], [[["Bill Gates-1"]], [["PlayStation 4-1"]], ["operation"]]]}
{"qid": "54b08f028141c591badd", "term": "Intellectual disability", "description": "Generalized neurodevelopmental disorder", "question": "Is dyslexia the most common intellectual disability in US?", "answer": false, "facts": ["An intellectual disability is reflected in below-average IQ and a lack of skills needed for daily living.", "Learning disabilities are weaknesses in certain academic skills. usually, Reading, writing and math.", "Dyslexia is characterized by difficulties with accurate and/or fluent word recognition and by poor spelling and decoding abilities.", "Thomas Jefferson, George Washington, and John F. Kennedy were successful presidents while being dyslexic."], "decomposition": ["What are the practical effects of an intellectual disability?", "What are the practical effects of dyslexia?", "Is #2 within the scope of #1?"], "evidence": [[[["Intellectual disability-1"]], [["Dyslexia-1"]], [["Dyslexia-1", "Intellectual disability-1"]]], [[["Intellectual disability-1"]], [["Dyslexia-1"]], ["operation"]], [[["Intellectual disability-1"], "no_evidence"], [["Dyslexia-1"]], ["operation"]]]}
{"qid": "363e5889466d85bba2ca", "term": "Giraffe", "description": "Tall African ungulate", "question": "Do giraffes require special facilities at zoos?", "answer": true, "facts": ["Giraffes are much taller than other land animals.", "Giraffe shelters at zoos must be built larger than shelters for other animals to accommodate their height."], "decomposition": ["What is the most distinctive feature of a giraffe?", "Does #1 make it necessary for them to have different facilities from other animals at a zoo?"], "evidence": [[[["Giraffe-16"]], [["Giraffe-16"]]], [[["Giraffe-2"]], [["West African giraffe-4"], "no_evidence", "operation"]], [[["Giraffe-2"]], ["no_evidence", "operation"]]]}
{"qid": "a9238d2bba6ea325fb41", "term": "Cactus", "description": "Family of mostly succulent plants, adapted to dry environments", "question": " Is cactus fruit an important menu item for a restaurant based on Cuauht\u00e9moc?", "answer": true, "facts": ["The Aztecs cultivated cacti for the fruit", "Tenochtitlan was the capital of the Aztec empire", "Cuauht\u00e9moc was the last king of Tenochtitlan "], "decomposition": ["Where city was Cuauht\u00e9moc the king of?", "What empire was #1 the capital of?", "Did people in #2 eat cacti?"], "evidence": [[[["Cuauht\u00e9moc-1"]], [["Tenochtitlan-1"]], [["Aztec Empire-8"], "no_evidence"]], [[["Cuauht\u00e9moc-1"]], [["Tenochtitlan-1"]], [["Cactus-61"], "operation"]], [[["Cuauht\u00e9moc-1"]], [["Cuauht\u00e9moc-1"]], [["Aztec cuisine-4"]]]]}
{"qid": "c60ed53423d39fb996e2", "term": "U.S. Route 1", "description": "highway in the United States", "question": "Is US route 1 dominated by historically red states?", "answer": false, "facts": ["US route 1 is a highway in the US that spans 15 states.", "There are 5 historically red states along US Route 1.", "There are 10 historically blue states along US route 1."], "decomposition": ["What states does US Rte. 1 pass through?", "How many states in #1 are historically \"red states\"?", "How many states in #1 are historically \"blue states\"?", "Is #2 greater than #3?"], "evidence": [[[["U.S. Route 1-1"]], [["Red states and blue states-1"], "no_evidence"], [["Red states and blue states-17"], "no_evidence"], ["no_evidence", "operation"]], [[["U.S. Route 1-1"]], [["Red states and blue states-1"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["U.S. Route 1-1"]], [["Red states and blue states-29"], "no_evidence"], [["Red states and blue states-29"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "b7ee54ccf00c2de84abb", "term": "Koala", "description": "An arboreal herbivorous marsupial native to Australia.", "question": "Would a nickel fit inside a koala pouch?", "answer": true, "facts": ["Koala joeys (babies) enter their mother's pouch when they are about 2 to 3 centimeters long.", "An American nickel is 2.12 centimeters in diameter."], "decomposition": ["Who usually sits in a koala's pouch?", "What is the size of #1?", "How big is a nickel?", "Is #2 more than #3?"], "evidence": [[[["Koala-2"]], [["Koala-25", "Marsupial-26"]], [["Nickel (United States coin)-1"]], ["operation"]], [[["Koala-2"]], [["Koala-1"], "no_evidence"], [["Nickel (United States coin)-1"]], ["operation"]], [[["Koala-2"]], [["Koala-23", "Koala-24"]], [["Nickel (United States coin)-1"]], ["operation"]]]}
{"qid": "59978a3e99a498e5567b", "term": "Great Pyramid of Giza", "description": "Largest pyramid in the Giza Necropolis, Egypt", "question": "Is Great Pyramid of Giza the last wonder of its kind?", "answer": true, "facts": ["The Great Pyramid of Giza is classified as one of the Seven Wonders of the Ancient World.", "Five of the ancient wonders were destroyed, and a sixth (the Hanging Gardens of Babylon) may not have existed.", "The Great Pyramid of Giza is largely intact as of 2020."], "decomposition": ["What are the wonders of the ancient world that are either destroyed or non-existent?", "What is the wonder of the ancient world that is still intact?", "Has #2 survived a much longer time than #1?"], "evidence": [[[["Seven Wonders of the Ancient World-1"]], [["Great Pyramid of Giza-1"]], ["operation"]], [[["Seven Wonders of the Ancient World-1"]], [["Great Pyramid of Giza-1"]], ["operation"]], [[["Seven Wonders of the Ancient World-1"]], [["Great Pyramid of Giza-1"]], ["no_evidence", "operation"]]]}
{"qid": "b8de21dae500bfa66b7b", "term": "Viscosity", "description": "Resistance of a fluid to shear deformation", "question": "Does water have viscosity?", "answer": false, "facts": ["Viscosity is resistance of fluid to deformation.", "Water is not resistant to deformation."], "decomposition": ["What is viscosity?", "Is water #1?"], "evidence": [[[["Viscosity-1"]], ["operation"]], [[["Viscosity-1"], "operation"], ["no_evidence"]], [[["Viscosity-1"]], ["operation"]]]}
{"qid": "e5f13851532305d2f932", "term": "Cucumber", "description": "species of plant", "question": "Is growing seedless cucumber good for a gardener with entomophobia?", "answer": true, "facts": ["Seedless cucumber fruit does not require pollination", "Cucumber plants need insects to pollinate them", "Entomophobia is a fear of insects"], "decomposition": ["What are people with Entomophobia fearful of?", "How do #1's usually help in the process of gardening?", "Do seedless cucumbers not require #2?"], "evidence": [[[["Entomophobia-1"]], [["Pollination-4"]], [["Cucumber-3"], "operation"]], [[["Entomophobia-1"]], [["Pollination-1"], "no_evidence"], [["Cucumber-3"], "operation"]], [[["Entomophobia-1"]], [["Cucumber beetle-1"]], [["Cucumber-4"], "operation"]]]}
{"qid": "976710eb9fff4ed94fd8", "term": "Chuck Norris", "description": "American martial artist, actor, film producer and screenwriter", "question": "Will Chuck Norris be a nonagenarian by time next leap year after 2020 happens?", "answer": false, "facts": ["A nonagenarian is a person between 90 and 99 years of age.", "Chuck Norris is 80 years old in 2020.", "The next leap year after 2020 is 2024.", "Chuck Norris will be 84 in 2024."], "decomposition": ["When was Chuck Norris born?", "When is the next leap year after 2020?", "What is the difference between #1 and #2?", "How many years of age makes one a nonagenarian?", "Is #3 greater than or equal to #4?"], "evidence": [[[["Chuck Norris-1"]], [["Determination of the day of the week-14"]], ["operation"], [["Manuel Pinto da Fonseca-9"]], ["operation"]], [[["Chuck Norris-1"]], [["Leap year-6"], "no_evidence"], ["operation"], ["no_evidence"], ["operation"]], [[["Chuck Norris-4"]], [["2024-1"]], ["operation"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "d8649d55a6e1a22b92d9", "term": "Psychic", "description": "person who claims to use extrasensory perception to identify information hidden from the normal senses", "question": "Would a psychic who admits to hot reading be trustworthy?", "answer": false, "facts": ["Hot reading is a technique used by people presenting themselves as psychics to acquire information about a subject prior to the psychic session.", "Hot reading is considered deception in the psychic community."], "decomposition": ["What do people pretend to be in order to successfully carry out hot reading?", "Do the 'real' #1 consider hot reading to be genuine?"], "evidence": [[[["Hot reading-1", "Hot reading-2"]], ["operation"]], [[["Hot reading-1"]], [["Hot reading-1", "Hot reading-2"]]], [[["Hot reading-1"]], [["Psychic-1"], "no_evidence", "operation"]]]}
{"qid": "3b62e4e18ce9ec7015c0", "term": "Citrus", "description": "genus of fruit-bearing plants (source of fruit such as lemons and oranges)", "question": "Can citrus grow in Ulaanbaatar?", "answer": false, "facts": ["Citrus can withstand short periods down to as cold as \u221210 \u00b0C (14 \u00b0F), but realistically temperatures not falling below \u22122 \u00b0C (28 \u00b0F) are required for successful cultivation.", "Ulaanbaatar has an average annual temperature of \u22120.4 \u00b0C or 31.3 \u00b0F."], "decomposition": ["What climates are suitable for growing citrus?", "What is the climate of Ulaanbaatar?", "Is #2 similar to #1?"], "evidence": [[[["Citrus-34"]], [["Ulaanbaatar-39"]], [["Citrus-34"]]], [[["Citrus-26", "Citrus-31"]], [["Ulaanbaatar-39"]], ["operation"]], [[["Citrus-31"]], [["Ulaanbaatar-40"]], ["operation"]]]}
{"qid": "703db4629ff46d82a205", "term": "Kane (wrestler)", "description": "American professional wrestler, actor, businessman, and politician", "question": "Can Kane challenge Joe Biden in this year's primaries?", "answer": false, "facts": ["Kane is a member of the Republican Party", "Joe Biden is a member of the Democratic Party", "Primaries are conducted between members of the same political party"], "decomposition": ["Primaries are held within what?", "What #1 does Joe Biden belong to?", "What #1 does Kane belong to?", "Are #2 and #3 the same?"], "evidence": [[[["Primary election-1"]], [["Joe Biden-1"]], [["Kane (wrestler)-1"]], ["operation"]], [[["Primary election-5"]], [["Joe Biden-1"]], [["Kane (wrestler)-1"]], ["operation"]], [[["Primary election-1"]], [["Joe Biden-1"]], [["Kane (wrestler)-1"]], ["operation"]]]}
{"qid": "9d72d2a919f84ce9c597", "term": "Zoology", "description": "Study of the animal kingdom", "question": "Is zoology unconcerned with strigoi?", "answer": true, "facts": ["Zoology is the study of the behavior and classification of animals.", "Strigoi are spirits that can transform into animals in Romanian mythology.", "Zoology is based on science and fossils."], "decomposition": ["What does the study of zoology entail?", "What kind of creatures are the strigoi?", "Is #2 unrelated to #1"], "evidence": [[[["Zoology-3"]], [["Strigoi-5"]], [["Strigoi-5", "Zoology-3"], "operation"]], [[["Zoology-1"]], [["Strigoi-1"]], ["operation"]], [[["Zoology-1"]], [["Strigoi-1"]], ["operation"]]]}
{"qid": "3fc11f59d64ea3b65136", "term": "Thanksgiving (United States)", "description": "holiday celebrated in the United States on the fourth Thursday in November", "question": "Is Thanksgiving sometimes considered a day of mourning?", "answer": true, "facts": ["The Native American People in the United States were brutalized during the colonization period.", "Native Americans in the US often choose to mourn the genocide of their people on Thanksgiving."], "decomposition": ["When do Native Americans often choose to mourn the genocide of their people?", "Is Thanksgiving included in #1?"], "evidence": [[[["National Day of Mourning (United States protest)-1"]], [["National Day of Mourning (United States protest)-1"], "operation"]], [[["National Day of Mourning (United States protest)-1", "National Day of Mourning (United States protest)-17"]], ["operation"]], [[["National Day of Mourning (United States protest)-17"], "no_evidence"], ["operation"]]]}
{"qid": "28cd9041ad61b93e3b91", "term": "Cannabis (drug)", "description": "psychoactive drug from the Cannabis plant", "question": "Has cannabis been a big influence in rap music genre?", "answer": true, "facts": ["Rapper Dr. Dre named his 1992 album, The Chronic, a reference to marijuana.", "Cannabis is a flowering plant also known as marijuana.", "Rapper Canibus took his name from cannabis.", "Rapper Snoop Dogg's song OG has a line, \"Rolling up my Mary Jane,\" a reference to marijuana.", "Rap group Bone Thugs N Harmony's Weed Song is a reference to marijuana."], "decomposition": ["What is Rapper Dr. Dre's Album The Chronic a reference to?", "What did Rapper Canibus get his name from?", "Snoop Dogg's line \"Rolling up my Mary Jane\" from the song OG has reference to?", "Are all #1, #2, #3 the same as cannabis?"], "evidence": [[[["The Chronic-1"]], [["Canibus-4", "Cannabis sativa-1"]], [["Mary + Jane-1"]], ["operation"]], [[["The Chronic-1"]], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["The Chronic-1"]], [["Cannabis (drug)-1"]], [["Snoop Dogg-88"], "no_evidence"], ["operation"]]]}
{"qid": "b2c17613452eb229fa92", "term": "Phobos (moon)", "description": "natural satellite of Mars", "question": "Is Phobos (moon) name origin similar to Roman god Pavor?", "answer": true, "facts": ["Phobos (moon) derives its name from ancient Greek mythology.", "Phobos was the god of fear.", "In Roman mythology, Pavor or Terror is known as the personification of fear."], "decomposition": ["What was Phobos (moon) named after?", "What is #1 referred to in Roman mythology?", "Is #2 the same as Pavor or Terror?"], "evidence": [[[["Phobos (moon)-2"]], [["Phobos (mythology)-2"]], ["operation"]], [[["Phobos (moon)-6"]], [["Phobos (mythology)-2"]], ["operation"]], [[["Phobos (mythology)-1"]], [["Phobos (mythology)-2"]], ["operation"]]]}
{"qid": "6a756a5734139bfce297", "term": "Emu", "description": "Large flightless bird endemic to Australia", "question": "Can an emu chase a bogan?", "answer": true, "facts": ["Emus are endemic to the continent of Australia", "Bogan is a pejorative term for certain citizens of Australia"], "decomposition": ["Where are emus endemic to?", "Where is a \"bogan\" found?", "Do areas #1 and #2 overlap?"], "evidence": [[[["Emu-1"]], [["Bogan-2"]], ["operation"]], [[["Emu-1"]], [["Bogan-25"]], ["operation"]], [[["Emu-1"]], [["Bogan-1"]], ["operation"]]]}
{"qid": "3c106ba490a3706f3931", "term": "Water skiing", "description": "surface water sport", "question": "Is Morocco an ideal location for water skiing?", "answer": false, "facts": ["Water skiing is a sport that involves gliding over the surface of large bodies of water.", "Morocco is one of the leading countries plagued by drought."], "decomposition": ["What are the minimum requirements to engage in water skiing?", "Does Morocco have #1?"], "evidence": [[[["Water skiing-1"]], [["Morocco-1", "Morocco-39"], "no_evidence", "operation"]], [[["Water skiing-1"]], [["Morocco-41"], "operation"]], [[["Water skiing-5"]], [["Morocco-51"]]]]}
{"qid": "943cee73791171355fef", "term": "Elizabeth II", "description": "Queen of the United Kingdom and the other Commonwealth realms", "question": "Does Elizabeth II reign over the Balearic Islands?", "answer": false, "facts": ["Queen Elizabeth II is the monarch of the United Kingdom and its commonwealth", "The Balearic Islands are part of the country of Spain"], "decomposition": ["What are all the areas Queen Elizabeth II rules over?", "What country owns the Balearic Islands?", "Is #2 included in #1?"], "evidence": [[[["Monarchy of the United Kingdom-1"]], [["Balearic Islands-1"]], ["operation"]], [[["Commonwealth realm-1"]], [["Balearic Islands-3"]], ["operation"]], [[["Commonwealth realm-1"]], [["Balearic Islands-1"]], ["operation"]]]}
{"qid": "ea9b3204830068115fcb", "term": "John Muir", "description": "Scottish-born American naturalist and author", "question": "Would John Muir not likely have a vitamin D deficiency?", "answer": true, "facts": ["John Muir frequently spent time exploring various places in nature.", "Spending time in nature increases your exposure to sunlight.", "Skin exposure to sunlight increases vitamin D levels in the body."], "decomposition": ["What is the most common cause of vitamin D deficiency?", "What was the nature of John Muir's life's work?", "Does #2 ensure that he does not experience #1?"], "evidence": [[[["Vitamin D-17"]], [["John Muir-2"]], [["John Muir-2"], "operation"]], [[["Vitamin D-13"]], [["John Muir-52"]], ["operation"]], [[["Vitamin D deficiency-1"]], [["John Muir-1"]], ["operation"]]]}
{"qid": "d825d90c0c4d555b3bea", "term": "Black pepper", "description": "species of plant", "question": "Are ground bell peppers the main ingredient of black pepper?", "answer": false, "facts": ["Black pepper is made from black peppercorns.", "Black peppercorns grow on the Piper Nigrum plant.", "Bell peppers are from the capsicum annuum plant."], "decomposition": ["What is used to make black pepper?", "Is #1 the same thing as bell pepper?"], "evidence": [[[["Black pepper-1"]], [["Bell pepper-1"], "operation"]], [[["Black pepper-1"]], [["Bell pepper-1"], "operation"]], [[["Black pepper-1"]], [["Bell pepper-1"]]]]}
{"qid": "11f3a3f27f9029362aaf", "term": "Surgery", "description": "Medical specialty", "question": "Can surgery prevent an existential crisis?", "answer": false, "facts": ["Surgery is used to correct medical problems or make physical alterations to the body", "An existential crisis is a metaphysical affliction"], "decomposition": ["What is an existential crisis?", "What kinds of ailments can be treated with surgery?", "Is #1 included in #2?"], "evidence": [[[["Existential crisis-1"]], [["Surgery-1"], "no_evidence"], ["operation"]], [[["Existential crisis-1"]], [["Surgery-1"]], ["operation"]], [[["Existential crisis-1"]], [["Surgery-1"]], ["operation"]]]}
{"qid": "8f2f696e717fefb03d9e", "term": "The Dark Knight (film)", "description": "2008 film directed by Christopher Nolan", "question": "Would The Dark Knight be appropriate for a preschool class?", "answer": false, "facts": ["Preschoolers are between 3 and 5 years old.", "The Dark Knight is rated PG-13.", "PG-13 is a rating that means parents are strongly cautioned that the content of a film may not be appropriate for children under 13."], "decomposition": ["What is the average age of preschoolers?", "What is the Dark Knight rated?", "What is the minimum age to watch something rated #2?", "Is age #1 above #3?"], "evidence": [[[["Preschool-4"]], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Preschool-4"]], ["no_evidence"], ["no_evidence"], ["operation"]], [[["Preschool-4"]], ["no_evidence"], [["PG-13 (disambiguation)-1"]], ["operation"]]]}
{"qid": "93029b0b5b4f19ab150a", "term": "Skull", "description": "bony structure that forms the skeleton of head in most vertebrates", "question": "Can an adult human skull hypothetically pass through the birth canal?", "answer": true, "facts": ["The largest baby ever born was 22 pounds. ", "The average human skull weighs between 10 and 11 pounds."], "decomposition": ["How big is the average baby ever delivered vaginally?", "How big is the average adult skull?", "Is #1 greater than #2?"], "evidence": [[[["Childbirth-29"], "no_evidence"], [["Human head-18"]], [["Obstetrical dilemma-14"], "operation"]], [[["Infant-9"]], [["Human head-18"]], [["Human head-18", "Infant-9"]]], [[["Infant-5", "Infant-7"]], [["Skull-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "88675643c5f299344f36", "term": "Tomato", "description": "Edible berry of the tomato plant, originating in South America", "question": "Do you need both hot and cold water to peel a tomato?", "answer": true, "facts": ["The first step in removing the skin from at tomato is to quickly submerge it in boiling water.", "The second step in removing the skin from a tomato is to take the tomatoes out of the boiling water and put them into ice water."], "decomposition": ["What are the various steps involved in peeling tomatoes?", "Does any of #1 use hot water?", "Does any of #1 use cold water?", "Are #2 and #3 positive?"], "evidence": [[[["Blanching (cooking)-1", "Peel (fruit)-1"]], [["Blanching (cooking)-7"], "operation"], [["Blanching (cooking)-9"], "operation"], ["operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Tomato-89"], "no_evidence"], ["no_evidence", "operation"], ["no_evidence", "operation"], ["no_evidence", "operation"]]]}
{"qid": "6faf37c8d91482f1c025", "term": "Diarrhea", "description": "Loose or liquid bowel movements", "question": "Do people take laxatives because they enjoy diarrhea?", "answer": false, "facts": ["People take laxatives to relieve constipation and associated pain.", "People with eating disorders take laxatives to lose weight."], "decomposition": ["What is the primary reason for taking laxatives?", "Is #1 to induce diarrhea?"], "evidence": [[[["Laxative-1"]], ["operation"]], [[["Laxative-1"]], [["Laxative-1"], "operation"]], [[["Laxative-1"]], [["Laxative-2"], "operation"]]]}
{"qid": "2ea15e27e5d94fd82471", "term": "Van Morrison", "description": "Northern Irish singer-songwriter and musician", "question": "Does title of Van Morrison's most played song apply to a minority of women worldwide?", "answer": false, "facts": ["Van Morrison's most played song was the hit Brown Eyed Girl.", "Between 55 to 79 percent of people worldwide have brown eyes.", "Brown is the most common eye color."], "decomposition": ["What is Van Morrison's most played song?", "What percentage of women worldwide meet the description in #1?", "Is #2 less than 50%?"], "evidence": [[[["Van Morrison-1"]], [["Eye color-11"], "no_evidence"], ["no_evidence", "operation"]], [[["Brown Eyed Girl-7"]], [["Brown-20"], "no_evidence"], ["operation"]], [[["Brown Eyed Girl-7"]], [["Eye color-2"], "no_evidence"], ["no_evidence"]]]}
{"qid": "34d6c4937d1aa9a70ef5", "term": "Swiss Guard", "description": "Military of Vatican City", "question": "Would Swiss Guard defeat the Marines?", "answer": false, "facts": ["The Swiss Guard is the military of Vatican City and consists of 135 members.", "There are 186,000 active duty Marines as of 2017."], "decomposition": ["How many people are in the Swiss Guard?", "How many people are in the US Marine Corp?", "Is #1 greater than or equal to #2?"], "evidence": [[[["Swiss Guard-31"]], [["United States Marine Corps-3"]], ["operation"]], [[["Military in Vatican City-14"]], [["United States Marine Corps-3"]], ["operation"]], [[["Swiss Guards-18", "Swiss Guards-3"], "no_evidence"], [["United States Marine Corps-3"]], ["operation"]]]}
{"qid": "73cc8dadbae6bc0eb433", "term": "Bing (search engine)", "description": "Web search engine from Microsoft", "question": "Can I hold Bing in a basket?", "answer": false, "facts": ["Bing is a search engine, which is a digital object.", "A basket is a physical object.", "Physical objects cannot hold digital objects."], "decomposition": ["What is Bing?", "What kind of product is #1?", "What kind of object is a basket?", "Can #3 hold #2?"], "evidence": [[[["Bing (search engine)-1"]], [["Web search engine-1"]], [["Basket-1"]], ["operation"]], [[["Bing (search engine)-1"]], [["Web search engine-1"]], [["Basket-1"]], ["operation"]], [[["Bing (search engine)-1"]], [["Bing (search engine)-1"]], [["Basket-1"]], ["operation"]]]}
{"qid": "3996ee99b488820ea4fe", "term": "Eighth Amendment to the United States Constitution", "description": "prohibits cruel and unusual punishment and excessive bail", "question": "Does the Eighth Amendment to the United States Constitution protect freedom of speech?", "answer": false, "facts": ["The Eighth Amendment (Amendment VIII) of the United States Constitution prohibits the federal government from imposing excessive bail, excessive fines, or cruel and unusual punishments.", "The First Amendment (Amendment I) to the United States Constitution protects freedom of speech."], "decomposition": ["What changes were made by the Eighth Amendment to the United States Constitution?", "Is the protection of freedom of speech among #1?"], "evidence": [[[["Eighth Amendment to the United States Constitution-1"]], ["operation"]], [[["Eighth Amendment to the United States Constitution-1"]], ["operation"]], [[["Eighth Amendment to the United States Constitution-5"]], ["operation"]]]}
{"qid": "0e3b14f806bfea19faf2", "term": "Snow White", "description": "fairy tale", "question": "Can all of Snow White's dwarfs play a game of 7 Wonders simultaneously?", "answer": true, "facts": ["The fairy tale character Snow White was friends with seven dwarfs.", "The board game 7 Wonders is for 2 to 7 players."], "decomposition": ["How many players can participate in a game of 7 Wonders?", "How many dwarfs are in the story of Snow White?", "Is #2 less than or equal to #1?"], "evidence": [[[["7 Wonders (board game)-1"], "no_evidence"], [["Snow White and the Seven Dwarfs (1937 film)-1"]], ["no_evidence", "operation"]], [[["7 Wonders (board game)-14"], "no_evidence"], [["Snow White and the Seven Dwarfs (1937 film)-7"]], ["operation"]], [[["7 Wonders (board game)-21"]], [["Snow White-3"]], ["operation"]]]}
{"qid": "fe5428059eda37cc96c2", "term": "Mount Sharp", "description": "mountain on Mars", "question": "Are human footprints absent from Mount Sharp?", "answer": true, "facts": ["Mount Sharp is located on Mars.", "Human beings have not traveled to Mars.", "Human footprints could only be present if human feet touched down on Mount Sharp."], "decomposition": ["Where is Mount Sharp?", "What would produce a human footprint?", "Have #2 never traveled to #1?"], "evidence": [[[["Mount Sharp-1"]], [["Footprint-1"]], ["operation"]], [[["Mount Sharp-1"]], [["Footprint-1"]], [["Human mission to Mars-73"], "operation"]], [[["Mount Sharp-1"]], [["Footprint-1"]], [["Human mission to Mars-2"]]]]}
{"qid": "c144bc5e23d0944b4f1c", "term": "Mayor", "description": "head of municipal government such as a town or city", "question": "Are Mayors safe from harm from the federal government?", "answer": false, "facts": ["The Mayor of Portland is Ted Wheeler.", "Ted Wheeler was tear-gassed by federal troops sent to his state."], "decomposition": ["Who is the mayor of Portland?", "Has #1 been able to avoid harm when federal troops were sent to his state"], "evidence": [[[["Ted Wheeler-1"]], ["no_evidence", "operation"]], [[["Government of Portland, Oregon-3"], "no_evidence"], ["no_evidence"]], [[["Ted Wheeler-1"]], ["no_evidence"]]]}
{"qid": "be3458c61d6f0deee9d8", "term": "Pancake", "description": "Thin, round cake made of eggs, milk and flour", "question": "Are pancakes a bad snack for cats?", "answer": true, "facts": ["Pancakes contain the dairy product milk as one of the main ingredients.", "After 6 months cats lose the enzyme lactase that breaks down lactose, which makes them lactose intolerant.", "Cats that drink milk can suffer from upset stomach and vomiting."], "decomposition": ["What are the three major ingredients of pancake?", "Which substance do cats lose the ability to break down after six months?", "Does any of #1 contain #2?"], "evidence": [[[["Pancake-1"]], [["Cat-59"]], ["operation"]], [[["Pancake-64"]], [["Cat-59"]], [["Cat-59"], "operation"]], [[["Pancake-1"]], [["Cat-59"]], [["Cat-59"], "operation"]]]}
{"qid": "debac3970a4fc11774fd", "term": "Marco Rubio", "description": "United States Senator from Florida", "question": "Could Marco Rubio ride the Candymonium roller coaster at Hershey Park?", "answer": true, "facts": ["The Candymonium roller coaster is restricted to park visitors over 54\" tall (4'6\").", "Marco Rubio is 5'9\" tall."], "decomposition": ["What is the height limit for the Candymonium roller coaster?", "How tall is Marco Rubio?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Candymonium-6"], "no_evidence"], ["no_evidence"], ["operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Candymonium-1"], "no_evidence"], [["Marco Antonio Rubio-1", "Marco Rubio-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "99f1b07917c2df314619", "term": "Bumblebee", "description": "genus of insects", "question": "Are aggressive bumblebees suicidal?", "answer": false, "facts": ["Bees with barbed stingers lose the barb after attacking a victim and die soon afterwards", "Bumblebees do not have barbed stingers and can sting multiple times without dying"], "decomposition": ["Can bees with non-barbed stingers sting multiple times?", "Do bumblebees have non-barbed stingers?", "By #1 and #2 do bumblebees die after stinging just once?"], "evidence": [[[["Honey bee-61"]], [["Bumblebee-45"]], ["operation"]], [[["Bombus ternarius-23"]], [["Bumblebee-45"]], ["operation"]], [[["Bee sting-6"]], [["Bumblebee-45"]], ["operation"]]]}
{"qid": "3ea7edd8c6bf70af1f1b", "term": "Vice President of the United States", "description": "Second highest executive office in United States", "question": "Was the first Vice President of the United States an Ottoman descendant?", "answer": false, "facts": ["The first Vice President of the United States was John Adams.", "The Ottomans were a Turkic group that conquered Constantinople in 1453.", "John Adams was descended from English Puritans."], "decomposition": ["Who was the first Vice President of the United States?", "Which group of people was #1 a descendant of?", "Is #2 the same as Ottoman?"], "evidence": [[[["John Adams-1"]], [["John Adams-5"], "no_evidence"], [["Ottoman dynasty-1"], "operation"]], [[["Vice President of the United States-52"]], [["John Adams-6"], "no_evidence"], [["Christianity in the modern era-12"], "operation"]], [[["John Adams-1"]], [["John Adams-5"]], ["operation"]]]}
{"qid": "7d310e9ebc2025febdd6", "term": "Winter", "description": "one of the Earth's four temperate seasons, occurring between autumn and spring", "question": "Is winter solstice in Northern Hemisphere closer to July than in Southern Hemisphere? ", "answer": false, "facts": ["The winter solstice in the Northern Hemisphere happens in December.", "The winter solstice in the Southern Hemisphere happens in June."], "decomposition": ["When does the winter solstice occur in the Northern Hemisphere?", "When does the winter solstice occur in the Southern Hemisphere?", "How many days are in between #1 and July?", "How many days are between #2 and July?", "Is #4 greater than #3?"], "evidence": [[[["Winter solstice-2"]], [["Winter solstice-2"]], ["operation"], ["operation"], ["operation"]], [[["Winter solstice-2"]], [["Winter solstice-2"]], ["no_evidence", "operation"], ["no_evidence", "operation"], ["no_evidence", "operation"]], [[["Winter solstice-2"]], [["Winter solstice-2"]], ["no_evidence"], ["no_evidence"], ["operation"]]]}
{"qid": "ad9bf53d84f83ebc9822", "term": "Dragon Ball", "description": "Japanese media franchise", "question": "Does Dragon Ball shows and movies fall short of Friday 13th number of projects?", "answer": true, "facts": ["Dragon Ball has 6 TV series, 3 TV specials, and 2 direct to video spinoffs as of 2020.", "Friday the 13th has 12 movies in the franchise and 1 TV series as of 2020."], "decomposition": ["How many Dragon Ball series, TV specials and other features have been released?", "How many Friday the 13th franchise films and television series have been released?", "Is #2 greater than #1?"], "evidence": [[[["Dragon Ball-2"]], [["Friday the 13th (franchise)-1"]], ["operation"]], [[["Dragon Ball-2"]], [["Friday the 13th (franchise)-1", "Friday the 13th (franchise)-2"]], ["operation"]], [[["Dragon Ball-28", "Dragon Ball-33"], "no_evidence"], [["Friday the 13th (franchise)-3"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "d9e23006aef632b6d65f", "term": "Kane (wrestler)", "description": "American professional wrestler, actor, businessman, and politician", "question": "Have any murderers outlasted Kane's Royal Rumble record?", "answer": true, "facts": ["The longest Kane lasted in the Royal Rumble was 53:46 in 2001.", "Chris Benoit lasted over an hour in the 2004 Royal Rumble.", "Chris Benoit murdered his own wife and son in 2007."], "decomposition": ["What is Kane's Royal Rumble record?", "Which wrestlers have a Royal Rumble record longer than #1?", "Are any of the wrestlers listed in #2 a murderer?"], "evidence": [[[["Royal Rumble (2001)-13"], "no_evidence"], [["Royal Rumble (2004)-19"]], [["Chris Benoit-3"], "operation"]], [[["Royal Rumble (2014)-36"]], [["Royal Rumble match-30"]], [["Chris Benoit-3"]]], [[["Kane (wrestler)-3"]], [["Chris Benoit-2"], "no_evidence"], [["Chris Benoit-3"], "no_evidence", "operation"]]]}
{"qid": "665a7a698ff08a8aa399", "term": "Chick-fil-A", "description": "American fast food chain", "question": "Would a vegetarian be able to eat something at Chick-fil-A?", "answer": true, "facts": ["Most people who follow a vegetarian diet don't eat meat, fish or poultry. ", "While Chick-fil-A sells chicken, they also offer other items. ", "Items that are meat free include: hash browns, waffle fries, and superfood sides."], "decomposition": ["What foods must a vegetarian avoid?", "What foods are on the menu of Chick-fil-A?", "Are any items in #2 free of #1?"], "evidence": [[[["Vegetarianism-1"]], [["Chick-fil-A-39"]], [["Crinkle-cutting-4", "Potato-1"], "operation"]], [[["Vegetarianism-1"]], [["Chick-fil-A-39"]], ["operation"]], [[["Vegetarianism-1"]], [["Chick-fil-A-39"]], ["operation"]]]}
{"qid": "406d6897eb20e5740d3f", "term": "Brewing", "description": "production of beer", "question": "Should Peter Griffin be an expert at the craft of brewing?", "answer": true, "facts": ["Peter Griffin is an employee of a brewery in Quahog. ", "Peter has worked at the brewery for many years and is expected to be familiar with how beer is made."], "decomposition": ["Where does Peter Griffin work?", "Is #1 a brewery?"], "evidence": [[[["Peter Griffin-2"]], ["operation"]], [[["Jungle Love (Family Guy)-3"]], ["operation"]], [[["Peter Griffin-2"]], ["operation"]]]}
{"qid": "7a1c9d5ad2a66bf90240", "term": "Disco", "description": "music genre", "question": "Is ABBA's 1970's genre still relevant today?", "answer": true, "facts": ["ABBA was a 1970's music group that specialized in Disco music.", "Pop artist Dua Lipa's 2020 album, Future Nostalgia, was described by Rolling Stone as , \"The Disco Liberation We Need.\"", "Magnetic Magazine released an article in 2020 entitled, \"The Best Disco and Funk Tracks of 2020.\""], "decomposition": ["What genre of music did music group ABBA specialize in in the 1970's?", "Are #1 still relevant today?"], "evidence": [[[["ABBA-1"]], [["Mamma Mia! Here We Go Again-1", "Mamma Mia! Here We Go Again-21"]]], [[["ABBA-1"]], [["Popular music-1"], "operation"]], [[["ABBA-43"]], [["Disco-5"], "operation"]]]}
{"qid": "cf1365a8abd4e35c2f0b", "term": "Asiana Airlines", "description": "airline in South Korea", "question": "Can Harry Potter book a flight on Asiana Airlines?", "answer": false, "facts": ["Asiana Airlines is the second largest airline in South Korea", "Harry Potter is a fictional character"], "decomposition": ["Which universe does Harry Potter exist in?", "Does Asiana Airlines exist in #1?"], "evidence": [[[["Fiction-1", "Fictional universe of Harry Potter-1"]], [["Asiana Airlines-1", "Universe-8"], "operation"]], [[["Fictional universe of Harry Potter-1"]], [["Asiana Airlines-1"]]], [[["Harry Potter-1"]], [["Asiana Airlines-1"], "no_evidence", "operation"]]]}
{"qid": "a0ab5b0fc9bb188bcc99", "term": "Nickel", "description": "Chemical element with atomic number 28", "question": "Is nickel dominant material in US 2020 nickels?", "answer": false, "facts": ["Nickels have been made of various materials including silver in the 1940s.", "Nickels in 2020 are made from a mix of copper and nickel.", "2020 nickels are 25% nickel and 75% copper."], "decomposition": ["What is the composition of the US 2020 nickel?", "Of the elements listed in #1, do any of them make up more than 50% of the US 2020 Nickel?", "If #2 is yes, is that element nickel?"], "evidence": [[[["Jefferson nickel-14"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Nickel (United States coin)-1"], "no_evidence"], [["Nickel (United States coin)-1"]], ["operation"]], [[["Nickel-5"]], ["operation"], ["operation"]]]}
{"qid": "65557713351aed7519b8", "term": "Toyota Prius", "description": "Hybrid electric automobile", "question": "Could someone have arrived at Wrestlemania X in a Toyota Prius?", "answer": false, "facts": ["Wrestlemania X took place in 1994", "The Toyota Prius was first manufactured in 1997"], "decomposition": ["When did Wrestlemania X hold?", "When was the Toyota Prius first manufactured?", "Is #2 before #1?"], "evidence": [[[["WrestleMania X-1"]], [["Toyota Prius-1"]], ["operation"]], [[["WrestleMania X-1"]], [["Toyota Prius-1"]], ["operation"]], [[["WrestleMania X-1"]], [["Toyota Prius-1"]], ["operation"]]]}
{"qid": "25e1fe4b511b0194c8ac", "term": "Construction worker", "description": "tradesman, labourer, or professional employed in the physical construction of the built environment", "question": "Is a construction worker required to build a portfolio?", "answer": false, "facts": ["Construction workers build physical constructs, usually buildings or structures", "A portfolio is a collection of items of a similar type, including art, writing, or financial investments"], "decomposition": ["What is a portfolio?", "Who are people that builds #1?", "Is a construction worker among #2?"], "evidence": [[[["Career portfolio-1"]], [["Career portfolio-8"]], ["operation"]], [[["Artist's portfolio-1"]], [["Artist-1"]], [["Construction worker-1"]]], [[["Artist's portfolio-1", "Portfolio (finance)-1"]], [["Artist's portfolio-1", "Portfolio (finance)-2"]], ["operation"]]]}
{"qid": "8b982a46f1a78d5f295f", "term": "Spider wasp", "description": "family of insects", "question": "Do spider wasps have eight legs?", "answer": false, "facts": ["A spider wasp is a kind of wasp, which is an insect.", "Insects all have six legs."], "decomposition": ["What kind of animal is a spider wasp?", "Do #1's have eight legs?"], "evidence": [[[["Spider wasp-1"]], [["Spider wasp-5"]]], [[["Spider wasp-1", "Wasp-1"]], [["Insect-1"], "operation"]], [[["Spider wasp-1"]], ["no_evidence"]]]}
{"qid": "66a3c0af3141c7c7d215", "term": "QWERTY", "description": "keyboard layout where the first line is \"QWERTYUIOP\"", "question": "Can monkeys use QWERTY keyboards?", "answer": true, "facts": ["QWERTY keyboards are an alphabet key layout that were first used on typrwriters. ", "Monkeys can be trained to push buttons.", "Typewriter key's are buttons.", "Monkeys can press keys on keyboards."], "decomposition": ["What kind of keys are found on QWERTY keyboards?", "Can #1 be likened to buttons?", "Can monkeys be trained to push buttons?", "Are #2 and #3 positive?"], "evidence": [[[["QWERTY-17"]], ["operation"], ["no_evidence", "operation"], ["no_evidence", "operation"]], [[["QWERTY-12"]], [["Keyboard layout-3"]], [["Pet monkey-4"]], ["operation"]], [[["QWERTY-16", "QWERTY-17"]], [["Push-button-1"], "no_evidence"], [["Tool use by animals-21"], "no_evidence"], ["operation"]]]}
{"qid": "e3f5b70bb16f336cc7fc", "term": "Snowdon", "description": "highest mountain in Wales", "question": "Would Snowdon mountain be a piece of cake for Tenzing Norgay?", "answer": true, "facts": ["Tenzing Norgay was a mountaineer that climbed Mount Everest in 1953.", "Snowdon Mountain has a peak of 3,560 feet.", "Mount Everest has a peak of over 29,000 feet."], "decomposition": ["How high is Snowdon Mountain?", "What was the highest peak ever climbed by Tenzing Norgay", "How high is #2?", "Is #3 greater than #1?"], "evidence": [[[["Snowdon-1"]], [["Tenzing Norgay-1"]], [["Mount Everest-2"]], ["operation"]], [[["Snowdon-1"]], [["Mount Everest-1", "Tenzing Norgay-1"]], [["Mount Everest-2"]], ["operation"]], [[["Snowdon-1"], "no_evidence"], [["Tenzing Norgay-1"]], [["Mount Everest-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "e1f6fead3b0070fe2142", "term": "Intel", "description": "American semiconductor chip manufacturer", "question": "Would a silicon shortage be bad for Intel's sales?", "answer": true, "facts": ["Silicon is a key material for the production of semiconductor chips.", "A silicon shortage would mean fewer semiconductor chips could be produced.", "A business that produces fewer products than normal will receive lower than normal revenue."], "decomposition": ["What kind of products does Intel make?", "What are the key materials used in the production of #1?", "Is silicon in #2?"], "evidence": [[[["Intel-1"]], [["Integrated circuit-29"]], ["operation"]], [[["Intel-1"]], [["Integrated circuit-1"]], ["operation"]], [[["Intel-1"]], [["Integrated circuit-1"]], ["operation"]]]}
{"qid": "cac8e6300a98cf6128af", "term": "1800", "description": "Year", "question": "Is number of different US President's in 1800s a lucky number in Hong Kong?", "answer": false, "facts": ["There were 24 different US President's in the 1800s.", "4 is an unlucky number in Chinese numerology.", "Where East Asian and Western cultures blend, such as in Hong Kong, it is possible in some buildings that the thirteenth floor along with all the floors with 4s to be omitted. "], "decomposition": ["How many U.S. Presidents served during the 1800's?", "What number is unlucky in Chinese numerology?", "Does #1 end with a number other than #2?"], "evidence": [[[["John Adams-1", "William McKinley-1"]], [["Chinese numerology-7"]], ["operation"]], [[["John Adams-1", "William McKinley-1"]], [["Chinese numerology-1"]], ["operation"]], [[["USS President (1800)-31"], "no_evidence"], [["Chinese numerology-7"], "operation"], ["no_evidence"]]]}
{"qid": "bcc0ba30a471776d64a9", "term": "Snoop Dogg", "description": "American rapper", "question": "Was Snoop Dogg's debut studio album released on the weekend?", "answer": false, "facts": ["Snoop Dogg's debut studio album was Doggystyle.", "Doggystyle was released on November 23, 1993.", "November 23, 1993 was a Tuesday.", "In the USA, the weekend consists of Saturday and Sunday."], "decomposition": ["What was Snoop Dogg's first studio album?", "When was #1 released?", "What day of the week did #2 occur on?", "What days are considered the weekend?", "Is #3 one of the answers in #4?"], "evidence": [[[["Snoop Dogg-2"]], [["Doggystyle-1"]], ["no_evidence"], [["Workweek and weekend-1"]], ["operation"]], [[["Doggystyle-1"]], [["Doggystyle-1"]], ["no_evidence"], [["Workweek and weekend-1"]], ["no_evidence", "operation"]], [[["Snoop Dogg-2"]], [["Doggystyle-1"]], ["no_evidence"], [["Workweek and weekend-1"]], ["no_evidence", "operation"]]]}
{"qid": "1510637210330d817e74", "term": "Dual-energy X-ray absorptiometry", "description": "diagnostic test for bone mineral density testing", "question": "Would dual-energy X-ray absorptiometry be useful if performed on a crab?", "answer": false, "facts": ["Dual-energy X-ray absorptiometry is typically used to diagnose and follow osteoporosis.", "Osteoporosis is a disease in which bone weakening increases the risk of a broken bone.", "Crabs are invertebrates.", "Invertebrates do not have bones."], "decomposition": ["What condition is diagnosed with dual-energy X-ray absorptiometry?", "What body parts are affected by #1?", "Do crabs have #2?"], "evidence": [[[["Dual-energy X-ray absorptiometry-1"]], [["Dual-energy X-ray absorptiometry-2", "Osteoporosis-1"]], [["Crab-2"], "operation"]], [[["Dual-energy X-ray absorptiometry-2"]], [["Osteoporosis-1"]], [["Crab-1"]]], [[["Dual-energy X-ray absorptiometry-2"]], [["Osteoporosis-1"]], [["Crab-1", "Invertebrate-1"]]]]}
{"qid": "470c3051dc9996abc3a7", "term": "Abortion", "description": "Intentionally ending pregnancy", "question": "Is there any absolute way to prevent abortion?", "answer": false, "facts": ["In areas where professional medical abortions are illegal, women get unsafe illegal abortions from unlicensed practitioners. ", "Women have successfully aborted their own children through physical or chemical means for centuries."], "decomposition": ["In places where medical abortions are illegal, are women absolutely unable to get abortions?"], "evidence": [[[["Unsafe abortion-2"]]], [[["Abortion-41"]]], [[["Unsafe abortion-1", "Unsafe abortion-2"], "operation"]]]}
{"qid": "af64e22f2e17583b79cf", "term": "Byzantine calendar", "description": "The calendar used by the Eastern Orthodox Church from c. 691 to 1728", "question": "Did Ivan the Terrible use the Byzantine calendar?", "answer": true, "facts": ["Ivan the Terrible was the Tsar of Russia from 1530 to 1585. ", "The Byzantine calendar was the official calendar of the Russian government from 988 to 1700.", "The Tsar was the leader of the Russian government. "], "decomposition": ["What was Ivan the Terrible's role from 1530 to 1585?", "What country was Ivan the Terrible #1 of?", "Was the Byzantine calendar the official calendar of #2 from 1530 to 1585?"], "evidence": [[[["Ivan the Terrible-1"]], [["Ivan the Terrible-1"]], [["Byzantine calendar-1"], "operation"]], [[["Ivan the Terrible-1"]], [["Ivan the Terrible-1"]], [["Byzantine calendar-1"]]], [[["Ivan the Terrible-1"], "no_evidence"], [["Ivan the Terrible-2"]], [["Byzantine calendar-1"], "operation"]]]}
{"qid": "3428fcbe9ffdcd50d234", "term": "ABBA", "description": "Swedish pop group", "question": "Does ABBA have similar gender configuration to The Mamas & The Papas?", "answer": true, "facts": ["ABBA was a Swedish pop group composed of four members.", "The Mamas & The Papas was an American band composed of four members.", "The members of ABBA are Bj\u00f6rn Ulvaeus (male), Benny Andersson (male), Agnetha F\u00e4ltskog (female), and Anni-Frid Lyngstad (female)..", "The members of The Mamas & The Papas are John Phillips (male), Denny Doherty (male), Cass Elliot (female), and Michelle Phillips (female)."], "decomposition": ["How many men and women each make up the Mamas and the Papas?", "How many men and women each make up ABBA?", "Is #1 equal to #2?"], "evidence": [[[["The Mamas and the Papas-1"]], [["ABBA-1"]], ["operation"]], [[["The Mamas and the Papas-1"]], [["ABBA-1"]], ["operation"]], [[["The Mamas and the Papas-1"]], [["ABBA-1"]], ["operation"]]]}
{"qid": "e183f97699de5a056823", "term": "Hanging", "description": "execution or suicide method involving suspension of a person by a ligature", "question": "Do bodies movie during hanging?", "answer": true, "facts": ["Electrochemical nerve signals are fired after death that can cause a body to twitch.", "If death by hanging is accomplished due to asphyxia, the victim may attempt to free themselves or may appear to struggle."], "decomposition": ["What does death by hanging usually induce in victims?", "What processes could occur in the nervous system immediately after death?", "Do #1 or #2 result in body movement?"], "evidence": [[[["Hanging-25"]], [["Hanging-26"]], ["operation"]], [[["Hanging-19"]], ["no_evidence"], ["operation"]], [[["Hanging-1"]], [["Hanging-25"]], ["operation"]]]}
{"qid": "d0183768701c74f966c5", "term": "Holy Land", "description": "Term used by Jews, Christians, and Muslims to describe the Land of Israel and Palestine", "question": "Do worshipers of Shiva make a pilgrimage to the Holy Land?", "answer": false, "facts": ["The Holy Land is sacred to Judaism, Islam and Christianity", "Worshipers of Shiva are adherents of Hinduism"], "decomposition": ["Which group of religions have the Holy Land as a pilgrimage destination?", "Which religious group worships Shiva?", "Is #2 the same as any of #1?"], "evidence": [[[["Holy Land-1"]], [["Shiva-1"]], ["operation"]], [[["Pilgrimage-23"]], [["Shiva-10"]], ["operation"]], [[["Holy Land-4"], "no_evidence"], [["Shiva Puja-1"], "no_evidence"], ["operation"]]]}
{"qid": "c027d949f7b4a6af5869", "term": "Jujutsu", "description": "Japanese martial art", "question": "Could a Jujutsu expert hypothetically defeat a Janissary?", "answer": false, "facts": ["Jujutsu is a form of unarmed combat.", "Janissaries were the elite infantry of the Ottoman Empire.", "Janissaries wore chain mail and armor and wielded sharp swords."], "decomposition": ["What equipment does Jujutsu use?", "What equipment does Janissary use?", "Would someone with #1 likely defeat someone with #2?"], "evidence": [[[["Jujutsu-1"]], [["Janissaries-25"]], ["no_evidence"]], [[["Jujutsu-1"]], [["Janissaries-1", "Janissaries-12"]], ["operation"]], [[["Jujutsu-1"]], [["Janissaries-25"]], ["operation"]]]}
{"qid": "692119e8ebcbf634d224", "term": "Butter", "description": "dairy product", "question": "Would toast for a vegan have margarine instead of butter?", "answer": true, "facts": ["Margarine is typically made without the use of dairy ingredients.", "Vegans do not eat any animal products, including dairy and eggs."], "decomposition": ["Which products are avoided in vegan diet?", "Is margarine free of #1?"], "evidence": [[[["Veganism-1"]], [["Margarine-36"]]], [[["Veganism-1"]], [["Margarine-2"], "operation"]], [[["Veganism-1"]], [["Margarine-2"]]]]}
{"qid": "63830fb94ef200092420", "term": "Mental disorder", "description": "Distressing thought or behavior pattern", "question": "Are there mental disorders you can hide?", "answer": true, "facts": ["Many people do not notice depression in their friends or loved ones. ", "\"Masking\" is a phrase used to describe concealing the effects of one's personality, including mental disorder."], "decomposition": ["Do any mental disorders have symptoms/effects that can be hidden?"], "evidence": [[[["Mental disorder-39", "Mental disorder-4"], "no_evidence", "operation"]], [[["Major depressive disorder-2"]]], [[["Mental disorder-6"], "no_evidence"]]]}
{"qid": "0987df9ab860b01e3f17", "term": "Vietnamese people", "description": "ethnic group originally from northern Vietnam", "question": "Are the Vietnamese people a great untapped resource for NBA players?", "answer": false, "facts": ["Vietnam was ranked as one of the countries with the shortest people on average, in 2019.", "The average height of a Vietnamese man is 5 feet 4.74 inches.", "The average height of an NBA player in 2018 was 6 foot 7 inches tall."], "decomposition": ["What is the average height of NBA players?", "What is the average height of Vietnamese males?", "Is #2 close to being the same as #1?"], "evidence": [[[["Basketball-85"]], ["no_evidence"], ["operation"]], [[["Wilt Chamberlain-1"], "no_evidence"], [["Vietnamese people-7"], "no_evidence"], ["operation"]], [[["Basketball-85"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "3848c0621fc2a9d1c79f", "term": "Viscosity", "description": "Resistance of a fluid to shear deformation", "question": "Do people with swallowing disorders need high viscosity drinks?", "answer": true, "facts": ["Swallowing disorders can make thin liquids like water dangerous to drink.", "Liquid thickeners are marketed towards people with difficulty drinking."], "decomposition": ["If a person has a swallowing disorder, what types of liquids are dangerous for them to drink?", "Are high viscosity drinks the opposite of #1?"], "evidence": [[[["Thickened fluids-1"]], [["Viscosity-1"], "operation"]], [[["Dysphagia-2"], "no_evidence"], [["Viscosity-1"], "operation"]], [[["Oropharyngeal dysphagia-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "d1142162a82aab83611e", "term": "Television", "description": "Telecommunication medium for transmitting and receiving moving images", "question": "Did Gandhi watch the television show Bonanza?", "answer": false, "facts": ["Bonanza was a television show that aired from  September 12, 1959 until January 16, 1973.", "Gandhi was assassinated on January 30, 1948."], "decomposition": ["How long ago did Bonanza first air?", "How long ago did Gandhi die?", "Is #1 greater than #2?"], "evidence": [[[["Bonanza-1"]], [["Mahatma Gandhi-1"]], ["operation"]], [[["Bonanza-1"]], [["Family of Mahatma Gandhi-1"]], ["operation"]], [[["Bonanza-1"]], [["Mahatma Gandhi-90"]], ["operation"]]]}
{"qid": "e2608700f4055492cdc3", "term": "Gothenburg", "description": "City in V\u00e4sterg\u00f6tland and Bohusl\u00e4n, Sweden", "question": "Could the Toyota Stadium sit a tenth of the population of Gotheburg?", "answer": false, "facts": ["The Toyota Stadium seats 45,000 people", "Gothenburg has a population of over five hundred thousand"], "decomposition": ["How many people can the Toyota Stadium sit?", "What is the population of Gothenburg?", "Is #2 less than #1?"], "evidence": [[[["Toyota Stadium (Texas)-1", "Toyota Stadium-1"]], [["Gothenburg-1"]], ["operation"]], [[["Toyota Stadium-1"]], [["Gothenburg-17"]], ["operation"]], [[["Toyota Stadium-1"]], [["Gothenburg-1"]], ["operation"]]]}
{"qid": "18586794a7000980c6a8", "term": "Bing (search engine)", "description": "Web search engine from Microsoft", "question": "Do Bing (search engine) searches earn the searcher more than competitors do?", "answer": true, "facts": ["Bing (search engine) has a search rewards program that gives the user points, from conducting searches, to redeem for prizes.", "Bing (search engine) has several competitors such as Google, and DuckDuckGo.", "Google and DuckDuckGo do not have search rewards programs."], "decomposition": ["What does Bing give to people who use the search engine?", "Who are Bing's major competitors?", "What do the companies in #2 give people for using their service?", "Is #1 of greater value than #3?"], "evidence": [[[["Bing (search engine)-10", "Bing (search engine)-26"]], [["Bing (search engine)-52"]], ["no_evidence"], ["operation"]], [[["Bing (search engine)-57"]], [["Bing (search engine)-67"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Bing (search engine)-57"]], [["Bing (search engine)-54"]], ["no_evidence"], ["operation"]]]}
{"qid": "a649eb84fd37b11f9a01", "term": "Al Capone", "description": "American gangster and businessman", "question": "Did Al Capone carry a smartphone?", "answer": false, "facts": ["Al Capone died in 1947.", "Smartphones were invented in 1992."], "decomposition": ["In what year did Al Capone die?", "What year was the first smartphone invented?", "Is #1 after #2?"], "evidence": [[[["Al Capone-1", "Al Capone-34"]], [["Smartphone-16"]], ["operation"]], [[["Al Capone-1"]], [["Smartphone-5"]], ["operation"]], [[["Al Capone-34"]], [["Smartphone-6"]], ["operation"]]]}
{"qid": "6497da19a2bb3f0dfcbb", "term": "Swallow", "description": "family of birds", "question": "In a hypothetical race between a Swallow and an American Woodcock, would the Swallow win?", "answer": true, "facts": ["Swallow can fly about 30-40mph. ", "The American woodcock can fly approximately 5mph. "], "decomposition": ["How quickly can a swallow fly?", "How quickly can an American woodcock fly?", "Is #1 greater than #2?"], "evidence": [[[["Barn swallow-18"]], [["American woodcock-14"]], [["Barn swallow-18"]]], [["no_evidence"], [["American woodcock-14"]], ["no_evidence", "operation"]], [[["Swallow-16"], "no_evidence"], [["American woodcock-14"]], ["no_evidence", "operation"]]]}
{"qid": "cd1e50e79d07a0320120", "term": "Ancient Greece", "description": "Civilization belonging to an early period of Greek history", "question": "Did Polar Bears roam around in Ancient Greece?", "answer": false, "facts": ["Polar Bears live in the Arctic, with temperatures that can get as low as -35 degrees celsius.", "Ancient Greece had an average temperature of 24 degrees celsius."], "decomposition": ["Where do polar bears live?", "What is the average temperature of #1?", "What was the average temperature of Ancient Greece?", "Is #3 the same as #2?"], "evidence": [[[["Polar bear-9"]], [["Arctic Circle-12"]], [["Ancient Greece-42"], "no_evidence"], ["operation"]], [[["Polar bear-1"]], [["Climate of the Arctic-40"]], [["Climate of Greece-7"]], [["Climate of Greece-7"], "operation"]], [[["Polar bear-1"]], [["Arctic Circle-12"]], [["Greece-60"]], ["operation"]]]}
{"qid": "3a20f77eb5aaebb051c7", "term": "D", "description": "letter in the Latin alphabet", "question": "Is the letter D influenced by the shape of ancient doors?", "answer": true, "facts": ["D is the fourth letter of the Latin alphabet", "D is a descendent of the ancient Phoenician Dalet", "Dalet was represented by a glyph of a door"], "decomposition": ["Which ancient language did the letter 'D' descend from?", "What was used to represent 'D' in #1?", "Was #2 a symbol of a door?"], "evidence": [[[["D-2"]], [["Dalet-2"]], [["Dalet-2"]]], [[["D-2"]], [["D-2"]], ["operation"]], [[["D-2"]], [["D-2"]], [["D-2", "Logogram-1"]]]]}
{"qid": "8ed193332f45fe1b9def", "term": "Superhero fiction", "description": "Fiction genre", "question": "Was Superhero fiction invented in the digital format?", "answer": false, "facts": ["The Golden Age of comics occurred between the 1930's and the 1950's.", "Shatter was the first digitally drawn, commercially published comic."], "decomposition": ["In which format was superhero fiction first introduced?", "During which period were #1 first published and made popular?", "When was the first digitally drawn #1 published?", "Is #2 after #3?"], "evidence": [[[["Superhero fiction-21"]], [["Comic book-5"]], [["Shatter (digital comic)-2"]], ["operation"]], [[["Superhero fiction-21"]], [["Superhero fiction-21"]], [["Digital comic-4"]], ["operation"]], [[["Superhero-1"]], [["Superhero-1"]], ["no_evidence"], ["operation"]]]}
{"qid": "cea676f4afc9e1051166", "term": "United States Secretary of State", "description": "U.S. cabinet member and head of the U.S. State Department", "question": "Does the United States Secretary of State answer the phones for the White House?", "answer": false, "facts": ["The role of United States Secretary of State carries out the President's foreign policy.", "The White House has multiple phone lines managed by multiple people."], "decomposition": ["What are the duties of the US Secretary of State?", "Are answering phones part of #1?"], "evidence": [[[["United States Secretary of State-4"]], [["United States Secretary of State-4"]]], [[["United States Secretary of State-4"]], ["operation"]], [[["United States Secretary of State-4"]], [["United States Secretary of State-4"]]]]}
{"qid": "d4546cb00bd8a7f0e041", "term": "Wednesday", "description": "Day of the week", "question": "Does the anatomy of a camel lend itself to jokes on Wednesdays?", "answer": true, "facts": ["Wednesday is often referred to as 'hump day' as a joke.", "Camels are known for having a significant hump. "], "decomposition": ["As a joke, what is Wednesday otherwise known as?", "What are camels known for having?", "Is there overlap between #1 and #2?"], "evidence": [[[["Wednesday-25"]], [["Camel-1"]], ["operation"]], [[["Wednesday-25"]], [["Camel-1"]], ["operation"]], [[["Wednesday-25"]], [["Camel-1"]], ["operation"]]]}
{"qid": "29ee7da0020eb03888fb", "term": "Boolean algebra", "description": "Algebra involving variables containing only \"true\" and \"false\" (or 1 and 0) as values", "question": "Does coding rely on Boolean algebra characters?", "answer": true, "facts": ["Boolean algebra uses the characters of 1 and 0 to represent true and false.", "Binary code is an essential part of computer coding.", "Binary code consists of the characters 0 and 1 which represents strings of value."], "decomposition": ["What characters does Boolean algebra use?", "What characters does binary code use?", "Are #1 and #2 the same?"], "evidence": [[[["Boolean algebra-1"]], [["Binary code-1"]], ["operation"]], [[["Boolean algebra-1"]], [["Binary code-1"]], ["operation"]], [[["Boolean algebra-1"]], [["Binary code-1"]], ["operation"]]]}
{"qid": "5adc7e126ca3383da225", "term": "Farmer", "description": "person that works in agriculture", "question": "Do you need a farmer to make a circuit board?", "answer": false, "facts": ["Farmers cultivate and produce crops and/or livestock for sale or consumption", "Circuit boards contain various man made materials as well as metals", "Metals are produced from the earth by miners"], "decomposition": ["What do farmers produce?", "What are the things needed to make a circuit board?", "Is any of #1 part of #2?"], "evidence": [[[["Farmer-1"]], [["Printed circuit board-1"]], ["operation"]], [[["Farmer-9"]], [["Stamped circuit board-4"]], ["operation"]], [[["Farmer-1"]], [["Printed circuit board-1"]], ["operation"]]]}
{"qid": "c92281b901ba7765c2e2", "term": "French toast", "description": "bread soaked in beaten eggs and then fried", "question": "Can a goat be used for one of the ingredients in French toast?", "answer": true, "facts": ["French toast is made from bread, eggs, milk, and cinnamon.", "Goats are able to produce milk, similar to cows.", "Goats milk is used in a variety of cheeses and milks sold in super markets."], "decomposition": ["What common dairy product can be obtained from goats?", "What are the typical ingredients of French toast?", "Is #1 included in #2?"], "evidence": [[[["Goat-46"]], [["French toast-1"]], ["operation"]], [[["Goat-1"]], [["French toast-2"]], ["operation"]], [[["Goat-46"]], [["French toast-1"]], ["operation"]]]}
{"qid": "38ef97eb7cdd4200fd00", "term": "Latino", "description": "A group of people in the United States with ties to Latin America", "question": "Is blonde hair green eyed Sara Paxton considered a Latino?", "answer": true, "facts": ["Sara Paxton is an American actress.", "Latino's are people with ancestral ties to Latin America.", "Sara Paxton was born to an Irish/English father and a Mexican/Spanish/Chilean mother.", "Mexico is a country that is part of Latin America."], "decomposition": ["Latinos are people with which nationality?", "Which countries are Sara Paxton's parents from?", "Is any of #2 included in #1?"], "evidence": [[[["Latino (demonym)-1", "Latino (demonym)-2"]], [["Sara Paxton-3"]], ["operation"]], [[["Latin America-12", "Latino (demonym)-1", "Mexico-1"]], [["Sara Paxton-3"]], ["operation"]], [[["Latino (demonym)-18"]], [["Sara Paxton-3"]], ["operation"]]]}
{"qid": "4648058ffbc40905a042", "term": "Rupert Murdoch", "description": "Australian-born American media mogul", "question": "Does Rupert Murdoch's alma mater have more history than the USA?", "answer": true, "facts": ["Rupert Murdoch's alma mater is Worcester College.", "Worcester College was founded in 1714.", "The first documented use of the term the United States of America was in a January 2, 1776 letter."], "decomposition": ["What is Rupert Murdoch's alma mater?", "When was #1 founded?", "When was the United States founded?", "Is #2 prior to #3?"], "evidence": [[[["Rupert Murdoch-8"]], [["Worcester College, Oxford-1"]], [["United States Declaration of Independence-1"]], ["operation"]], [[["Rupert Murdoch-8"]], [["Worcester College, Oxford-1"]], [["United States Declaration of Independence-1"]], ["operation"]], [[["Rupert Murdoch-8"]], [["Worcester College, Oxford-1"]], [["United States-27"]], ["operation"]]]}
{"qid": "901156d5fcaf260eb4a7", "term": "Anchovy", "description": "Family of fishes", "question": "Do more anchovy live in colder temperature waters than warmer?", "answer": false, "facts": ["Anchovy are a type of small fish.", "Anchovy are concentrated in the temperate waters of the Atlantic, Indian, and Pacific Oceans.", "Anchovy are rarely found in colder waters."], "decomposition": ["Which oceans do Anchovy live in?", "Which seas do Anchovy live in?", "Are #1 and #2 cold waters?"], "evidence": [[[["Anchovy-5"]], [["Anchovy-6"]], [["Anchovy-6"], "no_evidence"]], [[["Anchovy-2"]], [["Anchovy-2"]], ["no_evidence", "operation"]], [[["Anchovy-5"]], [["Anchovy-5"]], ["operation"]]]}
{"qid": "29bf9aa61ed4124cd84c", "term": "Albany, Georgia", "description": "City in Georgia, United States", "question": "Will the Albany in Georgia reach a hundred thousand occupants before the one in New York?", "answer": false, "facts": ["Albany, GA has around 75,000 people", "Albany, NY has almost 100,000 people"], "decomposition": ["What is the population of Albany, Georgia?", "What is the population of Albany, New York?", "What is the difference between 100,000 and #1?", "What is the difference between 100,000 and #2?", "Is #3 smaller than #4?"], "evidence": [[[["Albany, Georgia-1"]], [["Albany, New York-2"]], ["operation"], ["operation"], ["operation"]], [[["Albany, Georgia-35"]], [["Albany, New York-2"]], ["operation"], ["operation"], ["operation"]], [[["Albany, Georgia-1"]], [["Albany, New York-2"]], ["operation"], ["operation"], ["operation"]]]}
{"qid": "5562e0c2c63d85105bab", "term": "Dr. Seuss", "description": "American children's writer and illustrator", "question": "Was Dr. Seuss a liar?", "answer": true, "facts": ["Dr. Seuss was a writer and illustrator of children's books", "Dr. Seuss first published a children's book under the name of Dr. Seuss in 1937", "Dr. Seuss did not actually have a doctorate or equivalent degree until 1956"], "decomposition": ["When did Dr. Seuss first use the title \"Dr.\"?", "When did he get his doctorate (or equivalent)?", "Is #1 before #2?"], "evidence": [[[["Dr. Seuss-2"]], [["Dr. Seuss-18"]], ["operation"]], [[["Dr. Seuss-8"]], [["Dr. Seuss-2"]], ["operation"]], [[["Dr. Seuss-2"]], [["Dr. Seuss-18"]], ["operation"]]]}
{"qid": "9608fbb33f01b799a816", "term": "Chlorophyll", "description": "group of chemical compounds", "question": "For Hostas to look their best, do they need lots of chlorophyll?", "answer": true, "facts": ["Hostas are characterized by large green striped leaves.", "The green color in plants is attributed to chlorophyll. "], "decomposition": ["What color is a visually appealing hosta?", "Do the get #1 from chlorophyll?"], "evidence": [[[["Hosta-2"]], [["Chlorophyll-2"], "operation"]], [[["Hosta-6"], "no_evidence"], [["Chloroplast-1", "Hosta-2"], "operation"]], [[["Hosta-2"]], [["Chlorophyll-2"], "operation"]]]}
{"qid": "e0400033f078e56faad2", "term": "Pride", "description": "inwardly directed emotion that carries two common meanings", "question": "Would a Catholic priest commend someone's pride?", "answer": false, "facts": ["Adherents to Catholicism subscribe to the notion of the '7 deadly sins'.", "Pride is one of the 7 deadly sins."], "decomposition": ["According to Catholic beliefs, what are the seven deadly sins?", "Is pride excluded from #1?"], "evidence": [[[["Seven deadly sins-1"]], ["operation"]], [[["Seven deadly sins-1"]], [["Seven deadly sins-1"], "operation"]], [[["Seven deadly sins-1"]], ["operation"]]]}
{"qid": "71691ae5050e621c9b4c", "term": "Breast cancer", "description": "cancer that originates in the mammary gland", "question": "Is someone more likely to survive having breast cancer in Japan than in Sweden?", "answer": false, "facts": ["84.70% of people in Japan with breast cancer survive", "86.20% of people in Sweden with breast cancer survive"], "decomposition": ["What percentage of people survive breast cancer in Japan?", "What percentage of people survive breast cancer in Sweden?", "Is #1 more than #2?"], "evidence": [[[["Breast cancer-4"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "4d880ab760e6a3094f01", "term": "Horror fiction", "description": "genre of fiction", "question": "Is Edgar Allan Poe obscure in the world of horror fiction?", "answer": false, "facts": ["Edgar Allan Poe's writing has endured for over 150 years. ", "Edgar Allan Poe's horror writing has been included in classroom curriculum for decades.  "], "decomposition": ["How long have Edgar Allan Poe's writings remained in common use?", "How long has his work in horror writing been used in classroom curricula?", "Is #1 or #2 less than a decade?"], "evidence": [[[["Edgar Allan Poe-1"], "no_evidence"], ["no_evidence"], ["operation"]], [[["Edgar Allan Poe-1", "Edgar Allan Poe-35"], "no_evidence"], [["The Masque of the Red Death (1964 film)-1", "The Pit and the Pendulum (1991 film)-1"], "no_evidence"], ["operation"]], [[["Edgar Allan Poe-3"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "3c4beb8b4c0728a34fef", "term": "Ancient Greece", "description": "Civilization belonging to an early period of Greek history", "question": "Were number of states in Ancient Greece underwhelming compared to US states in 1900?", "answer": false, "facts": ["In the year 1900 there were 42 US states.", "Ancient Greece had several hundred relatively independent city-states called poleis."], "decomposition": ["How many states were in the United States in 1900?", "How many city-states were there in Ancient Greece?", "Is #2 less than #1?"], "evidence": [[[["Oklahoma-2", "Utah-2"]], [["City-state-6"], "no_evidence"], ["operation"]], [[["Oklahoma-2", "Utah Territory-1"]], [["Ancient Greece-47"]], ["operation"]], [[["Oklahoma Territory-52", "Utah-2"]], [["Ancient Greece-22"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "b039b0d6e263ee8fb81a", "term": "Jumping spider", "description": "family of arachnids", "question": "Would a jumping spider need over half a dozen contact lenses?", "answer": true, "facts": ["Jumping spiders have eight eyes.", "Half a dozen objects is equal to six objects.", "One contact lens is worn per eye."], "decomposition": ["How many eyes do jumping spiders have?", "How much is half a dozen?", "Is #1 more than #2?"], "evidence": [[[["Jumping spider-3"]], [["Dozen-3"]], [["Jumping spider-3"]]], [[["Jumping spider-1"]], [["Dozen-1"], "operation"], ["operation"]], [[["Jumping spider-1"]], [["Dozen-3", "One half-1"]], ["operation"]]]}
{"qid": "b1c014fc0205f28e8101", "term": "Soy milk", "description": "Beverage made from soybeans", "question": "Would Cardi B. benefit from soy milk?", "answer": true, "facts": ["Cardi B became lactose intolerant in her early twenties.", "People who are lactose intolerant cannot have dairy.", "Soy milk is an alternative to dairy milk."], "decomposition": ["What food intolerance does Cardi B. suffer from?", "What must people with #1 avoid?", "Is soy milk free from #2?"], "evidence": [[["no_evidence"], [["Lactose intolerance-1"]], [["Soy milk-1"], "operation"]], [[["Cardi B-1"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence"]]]}
{"qid": "9527809204a14d94be67", "term": "Onion", "description": "vegetable", "question": "Can chemicals in onion help create a thermonuclear bomb?", "answer": true, "facts": ["A thermonuclear bomb, also called a hydrogen bomb, uses hydrogen under high temperatures to create an explosive reaction.", "While chopping onions, cells inside the onion are broken and the gas that comes out forms sulfenic acid.", "Sulfenic acid is composed of several elements including hydrogen."], "decomposition": ["What elements are used in a thermonuclear bomb?", "When onions are chopped what gas is released?", "What elements are found in #2?", "Is #1 a subset of #3?"], "evidence": [[[["Thermonuclear weapon-2"]], [["Onion-30"], "no_evidence"], [["Syn-Propanethial-S-oxide-1"], "no_evidence"], ["operation"]], [[["Thermonuclear weapon-1"], "no_evidence"], [["Onion-30"]], ["operation"], ["no_evidence", "operation"]], [[["Thermonuclear weapon-2"]], [["Onion-30"]], [["Syn-Propanethial-S-oxide-1"]], ["operation"]]]}
{"qid": "ec77d443ba555a906316", "term": "Taco Bell", "description": "American fast-food chain", "question": "Does the Taco Bell kitchen contain cinnamon?", "answer": true, "facts": ["Taco Bell serves churros.", "Cinnamon is an ingredient in churros."], "decomposition": ["What dough pastry based snack does Taco Bell serve?", "Does #1 contain Cinnamon?"], "evidence": [[[["Taco Bell-1"]], ["no_evidence", "operation"]], [[["Taco Bell-21"]], [["Cinnabon-3"]]], [[["Taco Bell-21"]], [["Cinnabon-3"], "no_evidence"]]]}
{"qid": "7f06a5428c7ddf781d7b", "term": "3D printing", "description": "Additive process used to make a three-dimensional object", "question": "Do you need a large room if you want to get into 3D printing?", "answer": false, "facts": ["Home 3D printers are sized to be able to sit on a desk or table.", "The accessories and materials needed for 3D Printers can be stored easily and efficiently in a box or tote."], "decomposition": ["What are the equipment needed for 3D printing?", "How were #1 designed to be accommodated?", "Would #2 require a larger-than-average sized room?"], "evidence": [[[["3D printing-47"], "no_evidence"], [["3D printing-47"], "no_evidence"], [["3D printing-47"], "no_evidence"]], [[["3D printing-47"]], ["no_evidence"], ["no_evidence", "operation"]], [[["3D printing processes-39"]], [["3D printing processes-39"]], ["operation"]]]}
{"qid": "33289d83688ed7080bd5", "term": "Cream", "description": "Dairy product", "question": "Does store bought milk have cream at the top?", "answer": false, "facts": ["When milk is non-homogenized, the cream will separate and rise to the top.", "Most store bought milk is homogenized. "], "decomposition": ["What processes does store-bought milk go through?", "What are the characteristics of milk that is treated with #1?", "Is \"cream on the top\" a characteristic listed in #2?"], "evidence": [[[["Pasteurization-1"]], [["Pasteurization-11"], "no_evidence"], ["operation"]], [[["Milk-55", "Milk-57", "Milk-59"]], [["Cream-1", "Milk-61"]], [["Cream-1"]]], [[["Milk-61"]], [["Milk-63"]], ["operation"]]]}
{"qid": "40a10c0c2ae965cd067d", "term": "Saddam Hussein", "description": "Iraqi politician and President", "question": "Did Saddam Hussein witness the inauguration of Donald Trump?", "answer": false, "facts": ["Saddam Hussein died on December 30th, 2006.", "Donald Trump was inaugurated as the President of the United States on January 20, 2017."], "decomposition": ["When did Saddam Hussein die?", "When was Donald Trump inaugurated as President?", "Is #2 before #1?"], "evidence": [[[["Saddam Hussein-101"]], [["Timeline of the Donald Trump presidency-1"]], ["operation"]], [[["Saddam Hussein-4"]], [["Inauguration of Donald Trump-1"]], ["operation"]], [[["Saddam Hussein-1"]], [["Inauguration of Donald Trump-1"]], ["operation"]]]}
{"qid": "50b58835d8ab6da72c32", "term": "Snow leopard", "description": "species of mammal", "question": "Can a snow leopard swim?", "answer": true, "facts": ["except for giraffes and apes, all four legged mammals can swim", "a snow leopard is a mammal", "snow leopards have four legs"], "decomposition": ["Is a snow leopard a four legged mammal?"], "evidence": [[[["Cat-1", "Snow leopard-1"], "no_evidence"]], [["no_evidence", "operation"]], [[["Felidae-1", "Quadrupedalism-1", "Snow leopard-1"]]]]}
{"qid": "2b776be964150651f4b3", "term": "Courage", "description": "quality of mind or spirit that enables a person to face difficulty, danger, or pain", "question": "Would an anxious person benefit from receiving courage from the Wizard of Oz?", "answer": false, "facts": ["An anxious person may benefit from medication or therapy.", "The Wizard of Oz cannot give courage to anyone."], "decomposition": ["What would an anxious person benefit from receiving?", "Can the Wizard of Oz provide #1?"], "evidence": [[[["Anxiety disorder-3", "Anxiety disorder-58"]], [["The Wizard of Oz (1939 film)-8"], "operation"]], [[["Anxiety-2", "Panic attack-47"], "no_evidence"], [["The Wonderful Wizard of Oz-10"], "no_evidence", "operation"]], [[["Anxiety-1", "Courage-1"]], [["The Wonderful Wizard of Oz-13"], "operation"]]]}
{"qid": "0aeb8bccd429c7dfe0da", "term": "Mickey Mouse", "description": "Disney cartoon character", "question": "Did Mickey Mouse appear in a cartoon with Bugs Bunny in 1930?", "answer": false, "facts": ["Bugs Bunny was created in the late 1930s.", "Mickey Mouse was created in 1928.", "Mickey Mouse appears in Disney cartoons.", "Bugs Bunny appears in Warner Bros. cartoons."], "decomposition": ["When was Bugs Bunny created?", "Is #1 before 1930?"], "evidence": [[[["Bugs Bunny-1"]], ["operation"]], [[["Bugs Bunny-1"]], ["operation"]], [[["Bugs Bunny-1"]], ["operation"]]]}
{"qid": "1ffe6c11a37f8e4e2542", "term": "Grey seal", "description": "species of seal", "question": "Can a grey seal swim in the same water as the subject of Moby Dick?", "answer": true, "facts": ["The range of gray seals is limited to parts of the northern hemisphere bordered by the Atlantic ocean", "The subject of Moby Dick was a sperm whale", "Sperm whales can be found in the north Atlantic, in addition to most other bodies of water on earth."], "decomposition": ["What kind of whale was Moby Dick?", "What is the range of #1?", "What is the range of gray seals?", "Is there an overlap between #2 and #3?"], "evidence": [[[["Moby-Dick-1"]], [["Sperm whale-2"], "no_evidence"], [["Grey seal-1"]], ["no_evidence", "operation"]], [[["Moby-Dick-1"]], [["Sperm whale-2"]], [["Grey seal-1"]], ["operation"]], [[["Moby-Dick-1"]], [["Sperm whale-2"]], [["Grey seal-7"]], ["operation"]]]}
{"qid": "dffa127553f4c2dc9993", "term": "Donatello", "description": "Italian painter and sculptor", "question": "Did Donatello use a smartphone?", "answer": false, "facts": ["Donatello died on December 13, 1466.", "The first smartphone did not come out until 1992."], "decomposition": ["What years was Donatello alive?", "When was the first smartphone released?", "Did #2 occur during #1?"], "evidence": [[[["Donatello-1"]], [["Smartphone-6"]], ["operation"]], [[["Donatello-1"]], [["Smartphone-16"]], ["operation"]], [[["Donatello-1"]], [["Smartphone-6"]], ["operation"]]]}
{"qid": "1e97ab50309873ca1789", "term": "Bengal cat", "description": "Breed of cat", "question": "Could a Bengal cat hypothetically best Javier Sotomayor's record?", "answer": true, "facts": ["Javier Sotomayor is an athlete that holds the men's high jump world record of slightly over 8 feet.", "The average cat can jump from 7.5 to 9 feet.", "Bengal cats have powerful hind legs which make them jump higher than other breeds."], "decomposition": ["How high is Javier Sotomayor's world record high jump?", "Which breed of cat can jump the highest?", "If the average cat can jump up to 9 feet, then #2 can jump higher than what number?", "Is #3 greater than #1?"], "evidence": [[[["Javier Sotomayor-1"]], [["Bengal cat-21"], "no_evidence"], ["operation"], ["operation"]], [[["High jump-3"]], [["Savannah cat-1", "Savannah cat-21"]], ["operation"], ["operation"]], [[["Javier Sotomayor-1"]], [["Caracal-2"], "no_evidence"], [["Bengal cat-21"], "no_evidence", "operation"], ["no_evidence", "operation"]]]}
{"qid": "6ced5b6cea1bf1d35435", "term": "Wednesday", "description": "Day of the week", "question": "Does New Year's Day always occur on a Wednesday?", "answer": false, "facts": ["New Year's Day occurs on January 1st each year.", "The day of the week any given date falls on rotates by one each year.", "If Leap Year wasn't breaking up the cycle, New Year's Day would be on a Wednesday every seventh year."], "decomposition": ["What is the date of New Year's Day?", "Does #1 occur on the same day each year?"], "evidence": [[[["New Year's Day-12"]], [["New Year's Day-12"]]], [[["New Year's Day-1"]], ["operation"]], [[["New Year's Day-1"]], [["New Year's Day-4"], "no_evidence", "operation"]]]}
{"qid": "fdeec181aeee06303113", "term": "Karachi", "description": "Megacity in Sindh, Pakistan", "question": "Are you likely to find a crucifix in Karachi?", "answer": false, "facts": ["The crucifix is a symbol of Christianity", "The vast majority of Pakistan's population is Muslim"], "decomposition": ["What religion does a crucifix symbolize?", "What is the main religion observed in Karachi, Pakistan?", "Is #1 the same as #2?"], "evidence": [[[["Crucifix-2"]], [["Karachi-66"]], ["operation"]], [[["Crucifix-2"]], [["Karachi-66", "Muslims-1"]], ["operation"]], [[["Christian cross-1"]], [["Religion in Karachi-6"]], ["operation"]]]}
{"qid": "725335996a1551cc953d", "term": "Leadership", "description": "ability of an individual or organization to guide other individuals, teams, or entire organizations", "question": "Is Steve Carell's character on The Office portrayed as one with tremendous leadership skills?", "answer": false, "facts": ["Steve Carell plays Michael Scott on The Office.", "Michael Scott is a clueless and naive character that is not meant to be seen as effective in his job as General Manager."], "decomposition": ["Who is Steve Carell's character on The Office?", "What are leadership skills?", "Does #1 possess #2?"], "evidence": [[[["Michael Scott (The Office)-1"]], [["Leadership-1"], "no_evidence"], [["Michael Scott (The Office)-20"], "operation"]], [[["Steve Carell-9"]], [["Skills management-7"]], [["Skills management-7"], "operation"]], [[["Steve Carell-9"]], [["Michael Scott (The Office)-12"]], ["operation"]]]}
{"qid": "955a55c2c64209b0ab7d", "term": "Call of Duty", "description": "First-person shooter video game franchise", "question": "Will Conan the Barbarian hypothetically last a short time inside of Call of Duty?", "answer": true, "facts": ["Conan the Barbarian is a comic book character.", "Conan the Barbarian is equipped with a sword and does not typically wear armor.", "Call of Duty is a modern warfare video game.", "Soldiers in Call of Duty are equipped with weapons like sniper rifles, shotguns, and machine guns."], "decomposition": ["What equipment for fighting does Conan the Barbarian use?", "What equipment for fighting does Call of Duty use?", "Are the items listed in #2 deadlier than those in #1?"], "evidence": [[[["Conan the Barbarian-1"]], [["Call of Duty-1"]], ["no_evidence", "operation"]], [[["Conan the Barbarian-20"]], [["Call of Duty-46"]], [["Sword-58"], "operation"]], [[["Conan the Barbarian-16"]], [["Call of Duty-4"]], ["operation"]]]}
{"qid": "d216d1e93117da3934e2", "term": "Tower of London", "description": "A historic castle on the north bank of the River Thames in central London", "question": "Would Robert Stack have been interested in Tower of London during 1400s for his 14 season show?", "answer": true, "facts": ["Robert Stack was an actor best known for Unsolved Mysteries which lasted for 14 seasons before being rebooted by Netflix.", "The Tower of London is a historic building in London.", "Unsolved Mysteries explored unexplained phenomenon and mysterious events.", "The heirs of Edward IV mysteriously vanished from the Tower of London in the 1400s and were presumed muredered."], "decomposition": ["What is the defining feature of Robert Stack's 14 season show?", "What events happened at the Tower of London in the 1400's?", "Do any of the events in #2 have the characteristic in #1?"], "evidence": [[[["Robert Stack-35"]], [["Tower of London-2", "Tower of London-3"]], ["operation"]], [[["Robert Stack-1"]], [["Tower of London-34"]], ["operation"]], [[["Unsolved Mysteries-1"]], [["Princes in the Tower-2"]], ["operation"]]]}
{"qid": "d7482b2dc4028be17b36", "term": "Pope Alexander VI", "description": "Pope of the Catholic Church 1492\u20131503", "question": "Were any of despised Pope Alexander VI's descendants canonized?", "answer": true, "facts": ["Pope Alexander the VI was a controversial pope born as Rodrigo Borgia.", "Rodrigo Borgia had several children including the despised Juan Borgia who was murdered in 1497.", "Juan Borgia's grandson, Francis Borgia, was a Jesuit priest and the third Superior General of the Society of Jesus.", "Canonization is the process by which the Catholic Church names someone a saint.", "Francis Borgia was named a Catholic saint in June 1670."], "decomposition": ["What dynastic house was Pope Alexander VI a member of?", "Were any members of #1 canonized?", "Was #2 a direct descendent of Alexander VI?"], "evidence": [[[["Pope Alexander VI-2"]], [["Francis Borgia, 4th Duke of Gand\u00eda-1"]], ["operation"]], [[["Pope Alexander VI-2"]], [["Francis Borgia, 4th Duke of Gand\u00eda-1"]], ["operation"]], [[["House of Borgia-2"]], [["Francis Borgia, 4th Duke of Gand\u00eda-1"]], [["House of Borgia-21"], "operation"]]]}
{"qid": "6a13b8cefb285c2b81cf", "term": "Mail carrier", "description": "employee of the post office or postal service, who delivers mail to residences and businesses", "question": "Is unanimously elected president's birthday a break for mail carriers?", "answer": true, "facts": ["The post office has several holidays including: New Year's Day, Washington's Birthday (President's Day), and Veterans Day.", "George Washington was the only US president elected unanimously."], "decomposition": ["Which US president was elected unanimously?", "When is #1's birthday?", "Is #2 a break or holiday for the post office?"], "evidence": [[[["1788\u201389 United States presidential election-6"]], [["George Washington-1"]], [["Washington's Birthday-1"]]], [[["George Washington-107"]], [["Washington's Birthday-1"]], [["Postal holiday-3"], "operation"]], [[["Living presidents of the United States-3"], "no_evidence"], [["Jimmy Carter-5"]], [["Public holidays in the United States-16"]]]]}
{"qid": "ea8bdd791571893e082d", "term": "Olive", "description": "Species of plant", "question": "Would you find olives at a heladeria?", "answer": false, "facts": ["Olives are fruits of the olive tree used in savory dishes and preparations like olive oil and tapenade", "A heladeria is an ice cream parlour"], "decomposition": ["What kinds of foods are served at a heladeria?", "Are olives a type of #1?"], "evidence": [[[["Lares Ice Cream Parlor-4"]], [["Olive-6"]]], [[["Helader\u00eda Coromoto-1"]], [["Olive-2"], "operation"]], [[["Helader\u00eda Coromoto-1"]], ["operation"]]]}
{"qid": "b6e0094f030a326e510a", "term": "Wool", "description": "Textile fibre from the hair of sheep or other mammals", "question": "Can a Sphynx cat be used for wool?", "answer": false, "facts": ["A Sphynx cat is a breed of cats that lacks hair.", "Wool is a soft smooth fabric derived from the hair of animals.", "Sphynx cats skin are covered in an oily sticky substance."], "decomposition": ["Which animals can wool be derived from?", "Is the Sphynx cat likely to be included in #1?"], "evidence": [[[["Wool-1"]], [["Sphynx cat-5"], "operation"]], [[["Wool-1"]], ["operation"]], [[["Wool-7"]], [["Sphynx cat-10"], "operation"]]]}
{"qid": "1f550df826ae448ff082", "term": "Subway (restaurant)", "description": "American fast food chain", "question": "Has the Subway restaurant franchise had any connections with child abusers?", "answer": true, "facts": ["Subway hired Jared Fogle as a spokesman for their sandwich shops.", "Jared Fogle was convicted for having sex with minors and for possessing child pornography. "], "decomposition": ["Was Jared Fogle a spokesman for Subway?", "Is Jared Fogle a sexual abuser of children?", "Are #1 and #2 the same?"], "evidence": [[[["Jared Fogle-2"]], [["Jared Fogle-40"]], ["operation"]], [[["Jared Fogle-2"]], [["Jared Fogle-15"]], ["operation"]], [[["Jared Fogle-1"]], [["Jared Fogle-3"]], ["operation"]]]}
{"qid": "55ce9ac27a4bd4e627dc", "term": "Rand Paul", "description": "American politician, ophthalmologist, and United States Senator from Kentucky", "question": "Can a New Yorker get their eyes checked by Rand Paul legally?", "answer": false, "facts": ["Rand Paul is a senator from Kentucky.", "Rand Paul was an ophthalmologist in Kentucky with ABO certification.", "The National Board of Ophthalmology does not recognize ABO certification.", "Kentucky does not require ophthalmologists to be certified.", "NY ophthalmologists must have approved application for licensure certifications."], "decomposition": ["What certifications does NY require of ophthalmologists?", "Does Rand Paul have #1?"], "evidence": [[[["Ophthalmology-42"], "no_evidence"], [["Rand Paul-12", "Rand Paul-13"], "operation"]], [[["Ophthalmology-1"]], [["Rand Paul-10"]]], [[["Ophthalmology-41"]], ["operation"]]]}
{"qid": "37505be3ab3ef4b7f2ab", "term": "Pan (god)", "description": "Ancient Greek god of the wilds, shepherds, and flocks", "question": "Is Pan a symbol of virtue and virginity in women?", "answer": false, "facts": ["Pan is famous for his sexual powers.", "Women who had had sexual relations with several men were referred to as \"Pan girls.\""], "decomposition": ["What was the nature of Pan's relation with women?", "Is #1 not sexual?"], "evidence": [[[["Pan (god)-17"]], [["Pan (god)-17", "Pan (god)-19"]]], [[["Pan (god)-17", "Pan (god)-18"]], ["operation"]], [[["Pan (god)-17", "Pan (god)-18"], "no_evidence"], [["Virginity-1"], "operation"]]]}
{"qid": "86f9275b46d101656634", "term": "Maritime pilot", "description": "mariner who manoeuvres ships through dangerous or congested waters", "question": "Can COVID-19 spread to maritime pilots?", "answer": true, "facts": ["Maritime pilots are human beings.", "COVID-19 can spread among human population. "], "decomposition": ["Which organisms are susceptible to COVID-19?", "Are maritime pilots one of #1?"], "evidence": [[[["Coronavirus disease 2019-1"], "no_evidence"], ["operation"]], [[["Coronavirus disease 2019-1"]], [["Maritime pilot-1"], "operation"]], [[["Coronavirus disease 2019-83"], "no_evidence"], ["operation"]]]}
{"qid": "b4414a29cba573a24c6c", "term": "Flag of the United States", "description": "National flag", "question": "Would someone with leukophobia enjoy looking at the Flag of the United States?", "answer": false, "facts": ["Leukophobia is a fear of the color white.", "The United States flag is colored red, white, and blue.", "People do not typically enjoy facing their fears."], "decomposition": ["What does someone suffering from leukophobia fear?", "What are the colors of the United States flag?", "Is #1 included in #2?"], "evidence": [[[["Chromophobia-8"]], [["Flag of the United States-1"]], ["operation"]], [[["Chromophobia-3"]], [["Flag of the United States-40"]], ["operation"]], [[["Chromophobia-3"]], [["Flag of the United States-1"]], ["operation"]]]}
{"qid": "7c60f63b6cd0d7aa13f4", "term": "Pottery", "description": "Craft of making objects from clay", "question": "Are all types of pottery safe to cook in?", "answer": false, "facts": ["Some types of pottery glaze are unsafe for contact with food meant for human consumption. ", "Antique pottery pieces may have hazardous levels of lead in them."], "decomposition": ["Are all antique or glazed pottery safe to cook in?"], "evidence": [[[["Pottery-35"], "no_evidence"]], [[["Pottery-4"], "no_evidence", "operation"]], [[["Pottery-62"], "no_evidence"]]]}
{"qid": "4bb58d0456bfea654c0f", "term": "Compact disc", "description": "Optical disc for storage and playback of digital audio", "question": "Did John Lennon listen to Compact discs?", "answer": false, "facts": ["The Compact disc was released in 1982 by Philips and Sony.", "John Lennon was killed on December 8, 1980."], "decomposition": ["When were Compact Discs first available for use?", "When did John Lennon die?", "Is #1 before #2?"], "evidence": [[[["Compact disc-1"]], [["John Lennon-1"]], ["operation"]], [[["Compact disc-1"]], [["John Lennon-1"]], ["operation"]], [[["Compact disc-1"]], [["John Lennon-36"]], ["operation"]]]}
{"qid": "268b7bf55b10eeab7a7e", "term": "USB", "description": "Industry standard", "question": "Is 500GB USB device enough to save 10 hours of Netflix shows a day?", "answer": false, "facts": ["5 hours of Netflix programming uses up approximately 1 TB of data.", "1 TB is equal to 1000 GB of data."], "decomposition": ["How many terabytes of data does 5 hours of Netflix use up?", "What is #1 multiplied by 2?", "How many GB are in a TB?", "What is #3 multiplied by #2?", "Is #4 less than 500?"], "evidence": [[["no_evidence"], ["no_evidence", "operation"], [["Terabyte-2"]], ["no_evidence", "operation"], ["no_evidence", "operation"]], [[["TiVo-46"], "no_evidence"], ["operation"], [["Terabyte-2"]], ["operation"], ["operation"]], [[["Streaming media-39"], "no_evidence", "operation"], ["no_evidence", "operation"], ["no_evidence", "operation"], ["no_evidence", "operation"], ["no_evidence", "operation"]]]}
{"qid": "e7ba17761073c7a1ec24", "term": "Secretary", "description": "occupation", "question": "Is the US Secretary of State similar to an administrative secretary of an office?", "answer": false, "facts": ["An administrative secretary of an office is hired to handle routine and calendar scheduling for a superior.", "The US Secretary of State is the head of the Department of State.", "The US Secretary of State is analogous to a foreign minister of other countries. ", "The US secretary of state can have administrative assistants. ", "Another name for administrative secretary is administrative assistant. "], "decomposition": ["What kind of duties are assigned to an administrative secretary?", "What are the duties and nature of the position of the US Secretary of State?", "Is #2 in accordance with #1?"], "evidence": [[[["Secretary-3"]], [["United States Secretary of State-4"]], ["operation"]], [[["Secretary-1", "Secretary-3"]], [["Secretary of state-14"]], ["operation"]], [[["Secretary-1"]], [["Secretary of state-14"]], ["operation"]]]}
{"qid": "6330413d518d44e68b94", "term": "Boolean algebra", "description": "Algebra involving variables containing only \"true\" and \"false\" (or 1 and 0) as values", "question": "Could boolean algebra be described as binary?", "answer": true, "facts": ["Binary options tend to have 2 instead of 10 as a base. ", "Binary directly describes something composed of 2 things. "], "decomposition": ["How many digits are used in boolean algebra?", "How many does 'binary' denote?", "Is #1 the same as #2?"], "evidence": [[[["Boolean algebra-1"]], [["Binary number-1"]], ["operation"]], [[["Boolean algebra-1"]], [["Binary number-1"]], ["operation"]], [[["Boolean algebra-1"]], [["Binary number-1"]], ["operation"]]]}
{"qid": "b113a9be03fa98305a1a", "term": "Eddie Murphy", "description": "American stand-up comedian and actor", "question": "Could Eddie Murphy dial 911 in a car as a young child?", "answer": false, "facts": ["Eddie Murphy was born in 1961.", "Car phones did not become commonplace in cars in America until 1984."], "decomposition": ["What year was Eddie Murphy born in?", "When did car phones become common in American cars?", "Is #1 after #2?"], "evidence": [[[["Eddie Murphy-1"]], [["Car phone-2"]], ["operation"]], [[["Eddie Murphy-1"]], [["Car phone-8"]], ["operation"]], [[["Eddie Murphy-1"]], [["Car phone-4", "Car phone-6"]], ["operation"]], [[["Eddie Murphy-1"]], [["Car phone-8"]], ["operation"]]]}
{"qid": "691c8df42c886d6db9d4", "term": "John the Baptist", "description": "1st-century Jewish preacher and later Christian saint", "question": "Would John the Baptist be invited to a hypothetical cephalophore reunion in heaven?", "answer": false, "facts": ["John the Baptist was a preacher that became a Catholic Saint.", "John the Baptist was beheaded by king Herod.", "A cephalophore is a Saint martyred by beheading, and is depicted in art as carrying their own head.", "Saint Denis was one of several beheaded saints that is said to have carried his own head and is depicted as such in art.", "John the Baptist did not carry his head, since it was on a plate owned by King Herod's stepdaughter."], "decomposition": ["What does one carry for one to be considered a cephalophore?", "Did John the Baptist carry #1?"], "evidence": [[[["Cephalophore-1"]], [["Cephalophore-4"], "operation"]], [[["Cephalophore-1"]], [["Cephalophore-5"], "operation"]], [[["Cephalophore-1"]], [["John the Baptist-188"], "no_evidence", "operation"]]]}
{"qid": "29a634ea52cba72c13e4", "term": "Brussels sprout", "description": "vegetable", "question": "Are Brussels sprout particularly good for adrenal fatigue?", "answer": true, "facts": ["Adenal fatigue is a disorder in which the body does not produce enough hormones and people get tired.", "Brussels sprout are foods rich in vitamin C.", "When stress levels rise, the adrenal glands require more Vitamin C and it is used very quickly."], "decomposition": ["What vitamins are found in abundance in Brussels sprouts?", "What vitamins do the adrenal glands require when a body is under stress?", "Is #2 found in #1?"], "evidence": [[[["Brussels sprout-12"]], [["Adrenaline-29"]], ["operation"]], [[["Brussels sprout-12"]], [["Adrenal gland-2"], "no_evidence"], ["no_evidence"]], [[["Brussels sprout-12"]], [["Adrenal fatigue-1", "Adrenal gland-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "526259cd504bffe7f888", "term": "Gladiator", "description": "combatant who entertained audiences in the Roman Republic and Roman Empire", "question": "Could a Gladiator's weapon crush a diamond?", "answer": false, "facts": ["Gladiators used a sword known as a Gladius.", "The Gladius was a short sword made from various elements of steel.", "Diamond is one the hardest known substances on earth.", "Only diamond can be used to cut another diamond."], "decomposition": ["What material were Gladiator weapons made from?", "Can #1 crush a diamond?"], "evidence": [[[["Gladius-16"]], [["Diamond-1", "Diamond-15"], "no_evidence", "operation"]], [[["Gladiator-36"]], [["Diamond-15"], "no_evidence"]], [[["Gladius-9"]], [["Diamond-15"], "operation"]]]}
{"qid": "1f9b1e6e299a9da962fe", "term": "March", "description": "third month in the Julian and Gregorian calendars", "question": "Does March begin on the same day of the week as February during leap years?", "answer": false, "facts": ["During normal years, February has exactly 28 days, so March begins on the same day of the week as February.", "However, on leap years, February has an extra day, so March begins the next day of the week from whichever day started February."], "decomposition": ["How many days are in February in a non-leap year?", "How many days are in February in a leap year?", "Does #1 mean that March will begin on the same day as February?", "Given that #3 is positive, will #2 make no difference to this outcome?"], "evidence": [[[["Leap year-2"]], [["Leap year-3"]], ["no_evidence"], ["operation"]], [[["February-10"]], [["Leap year-2"]], [["Determination of the day of the week-11"], "operation"], [["Determination of the day of the week-11"], "operation"]], [[["February-1"]], [["February-1"]], ["no_evidence", "operation"], ["no_evidence", "operation"]]]}
{"qid": "0467bce4b8304e2f5000", "term": "Fair trade", "description": "form of trade", "question": "Can you buy a fair trade laptop?", "answer": false, "facts": ["Fair trade is a term used with sustainable development focusing on agricultural production", "Laptops are consumer electronics"], "decomposition": ["What type of product is the fair trade label used with? ", "What type of product is a laptop?", "Is #2 the same as #1?"], "evidence": [[[["Fair trade-4"]], [["Laptop-1"]], ["operation"]], [[["Fair trade-1"]], [["Laptop-1"]], ["operation"]], [[["Fair trade-1"]], [["Laptop-1"]], ["operation"]]]}
{"qid": "3bd276ea5db4f37dc983", "term": "Middle Ages", "description": "Period of European history from the 5th to the 15th century", "question": "Did eggs need to be kept cold in the middle ages?", "answer": false, "facts": ["When eggs are freshly laid, they are covered in a film called a 'bloom.' ", "Eggs with their bloom intact are able to stay at room temperature for one month.", "Pasteurization destroys the bloom on eggs. ", "Pasteurization was introduced in the 1990's."], "decomposition": ["What naturally protects eggs from spoiling?", "What process removes #1 from eggs?", "Did #2 exist during the Middle Ages?"], "evidence": [[[["Egg as food-35"]], [["Egg as food-34"]], [["Middle Ages-1", "Refrigeration-6"], "operation"]], [[["Egg as food-34"], "no_evidence"], [["Egg as food-35"]], [["Refrigeration-9"], "operation"]], [[["Egg as food-35"], "no_evidence"], [["Egg as food-34"]], ["operation"]]]}
{"qid": "424ecb3dd6c64b6da4cc", "term": "Butler", "description": "male domestic worker in charge of all the male household staff", "question": "Do most middle class families have butlers?", "answer": false, "facts": ["Butlers make about $60,000 per year on average for their work.", "Middle class income is between $48,000 and $145,000."], "decomposition": ["What is a butler?", "How much does #1 make per year on average?", "How much is the average middle class income?", "Would #3 be enough to pay #2?"], "evidence": [[[["Butler-1"]], ["no_evidence"], [["Middle class-34"]], ["operation"]], [[["Butler-1"]], [["Butler-15"], "no_evidence"], [["Middle class-24"], "no_evidence"], ["operation"]], [[["Butler-1"]], [["Butler-20"], "no_evidence"], [["Middle class-37"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "49cd2c594e9715899734", "term": "Golden Gate Bridge", "description": "suspension bridge on the San Francisco Bay", "question": "Do depressed people travel to the Golden Gate Bridge often?", "answer": true, "facts": ["The Golden Gate Bridge is one of the most popular suicide spots in the USA.", "Suicide is often caused by severe depression."], "decomposition": ["What is the ultimate end that severe depression can lead to?", "Is the Golden Gate Bridge a place where #1 is known to often happen?"], "evidence": [[[["Major depressive disorder-22"]], [["Suicides at the Golden Gate Bridge-4"], "operation"]], [[["Suicide-7"]], [["Golden Gate Bridge-50"]]], [[["Suicide-1"]], [["Suicides at the Golden Gate Bridge-4"]]]]}
{"qid": "efde6ff2282415b9f2f6", "term": "Samsung Galaxy S4", "description": "Android smartphone", "question": "Would General Zod prefer an iPhone over a Samsung Galaxy S4?", "answer": false, "facts": ["General Zod is a villain.", "Apple does not allow moviemakers to give villains iPhones."], "decomposition": ["What movie is General Zod from?", "What is General Zod's role in #1?", "Does Apple allow moviemakers to give #2 iPhones?"], "evidence": [[[["General Zod-11"]], [["General Zod-1"]], ["no_evidence", "operation"]], [[["General Zod-11"]], [["General Zod-2"]], ["no_evidence"]], [[["Superman II-1"]], [["General Zod-1"]], ["no_evidence", "operation"]]]}
{"qid": "eb257b257001eb384cf3", "term": "Stone Cold Steve Austin", "description": "American professional wrestler", "question": "Did Stone Cold Steve Austin wrestle in three different centuries?", "answer": false, "facts": ["A century is a period of 100 years.", "Stone Cold Steve Austin made his wrestling debut on September 30, 1989.", "Stone Cold Steve Austin retired on March 30, 2003.", "The 20th (twentieth) century was a century that began on January 1, 1901 and ended on December 31, 2000.", "The 21st century began on January 1, 2001, and will end on December 31, 2100."], "decomposition": ["When did Stone Cold Steve Austin start wrestling?", "When did Stone Cold Steve Austin stop wrestling?", "In what century is #1?", "In what century is #2?", "Is #4 minus #3 greater than 1?"], "evidence": [[[["Stone Cold Steve Austin-6"]], [["Stone Cold Steve Austin-45"]], ["no_evidence"], ["no_evidence"], ["operation"]], [[["Stone Cold Steve Austin-6"]], [["Stone Cold Steve Austin-4"]], [["20th century-2"]], [["21st century-1"]], ["operation"]], [[["Stone Cold Steve Austin-6"]], [["Stone Cold Steve Austin-41"]], ["operation"], ["operation"], ["operation"]]]}
{"qid": "027a7b964c31a0540f9c", "term": "Baptism", "description": "Christian rite of admission and adoption, almost invariably with the use of water", "question": "Was Alexander the Great baptized?", "answer": false, "facts": ["Baptism is a symbolic Christian rite using water.", "Christianity started in the first century AD.", "Alexander the Great lived from 356 BC- 323 BC."], "decomposition": ["Baptism is a rite in which religion?", "When did #1 develop?", "When did Alexander the Great die?", "Is #2 before #3?"], "evidence": [[[["Baptism-1"]], [["Christianity in the 1st century-2"]], [["Alexander the Great-62"]], ["operation"]], [[["Baptism-1"]], [["Baptism-8"]], [["Alexander the Great-62"]], [["Alexander the Great-62", "Baptism-8"], "operation"]], [[["Baptism-1"]], [["Christianity-3"]], [["Alexander the Great-1"]], ["operation"]]]}
{"qid": "4013c96b17809c27699c", "term": "National Diet", "description": "legislature of Japan", "question": "Can Viper Room concert hypothetically be held at National Diet building?", "answer": true, "facts": ["The Viper Room has a capacity of 250 people.", "The National Diet building has two wings with over 700 seats."], "decomposition": ["What is the capacity of the The Viper Room?", "What is the capacity of the National Diet Building?", "Is #2 greater than or equal to #1?"], "evidence": [[[["The Viper Room-1"], "no_evidence"], [["National Diet Building-28"]], ["operation"]], [[["The Viper Room-1"], "no_evidence"], [["National Diet Building-11"], "no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], [["National Diet Building-28"]], [["National Diet Building-28"], "operation"]]]}
{"qid": "fa7b5c8e022bb8bec2d6", "term": "Diarrhea", "description": "Loose or liquid bowel movements", "question": "Can too many oranges cause diarrhea?", "answer": true, "facts": ["Oranges are very high in fiber and sugar.", "Too much fiber can cause diarrhea."], "decomposition": ["What high-level nutritional values do oranges have?", "Can excess of any of #1 cause diarrhea?"], "evidence": [[[["Mandarin orange-12"]], [["Vitamin C-21"], "operation"]], [[["Orange (fruit)-40", "Orange (fruit)-41"], "no_evidence"], ["no_evidence", "operation"]], [[["Orange (fruit)-20"]], [["Vitamin C-21"], "operation"]]]}
{"qid": "85a99480c6fb0177f4c7", "term": "Peach", "description": "species of fruit tree (for the fruit use Q13411121)", "question": "Will you see peach blossoms and Andromeda at the same time?", "answer": false, "facts": ["Peach trees bloom in the spring.", "Andromeda is visible in the fall."], "decomposition": ["When do peach trees bloom?", "When can you see Andromeda?", "Is #1 the same as #2?"], "evidence": [[[["Peach-18"]], [["Andromeda Galaxy-56"]], [["Andromeda Galaxy-56", "Peach-18"]]], [[["Peach-5"]], [["Andromeda (constellation)-3"], "no_evidence"], ["operation"]], [[["Peach-18"]], [["Andromeda (constellation)-1", "Andromeda (constellation)-3"], "no_evidence"], ["operation"]]]}
{"qid": "1feaaac968a53eac2a67", "term": "Goldfish", "description": "freshwater fish, common in aquariums", "question": "Are goldfish more difficult to care for than isopods?", "answer": true, "facts": ["Isopod care is compared to that of a houseplant.", "Goldfish are notorious for making their tanks dirty quite often."], "decomposition": ["What is isopod care comparable to?", "What challenges do Goldfish pose to keepers?", "Is #1 easier to deal with than #2?"], "evidence": [[[["Isopoda-14", "Isopoda-15"]], [["Goldfish-28"]], ["operation"]], [[["Isopoda-1", "Isopoda-13"]], [["Goldfish-15"], "no_evidence"], ["operation"]], [[["Isopoda-1"]], [["Goldfish-17", "Goldfish-21", "Goldfish-22"], "no_evidence"], ["operation"]]]}
{"qid": "03065f31c1a550a97107", "term": "Cookie Monster", "description": "character from the television series Sesame Street", "question": "Is Cookie Monster's diet Paleo friendly?", "answer": false, "facts": ["Cookie Monster is a Sesame Street character that eats copious amounts of chocolate chip cookies.", "The Paleo diet includes foods made from ingredients found during the Paleolithic area.", "Chocolate chip cookies contain soy lecithin and artificial grains.", "Lecithin is used in complex modern industrial processes."], "decomposition": ["What is the major component of the Cookie Monster's diet?", "What does Paleo diet consist of?", "Is #1 one of #2"], "evidence": [[[["Cookie Monster-1"]], [["Paleolithic diet-1", "Paleolithic diet-3"]], ["operation"]], [[["Cookie Monster-1"]], [["Paleolithic diet-3"]], ["operation"]], [[["Cookie Monster-1"]], [["Paleolithic diet-9"]], [["Paleolithic diet-9"]]]]}
{"qid": "59fdc8eaf72fdb34e744", "term": "Ahura Mazda", "description": "highest deity of Zoroastrianism", "question": "Does Ahura Mazda have a rivalry with Zeus?", "answer": false, "facts": ["Ahura Mazda is a deity of Zoroastrianism, a contemporary religion", "Zeus is a deity of Greek mythology"], "decomposition": ["What belief system is Ahura Mazda associated with?", "What belief system is Zeus associated with?", "Is #1 the same as #2?"], "evidence": [[[["Ahura Mazda-1"]], [["Zeus-1"]], ["operation"]], [[["Ahura Mazda-1"]], [["Zeus-1"]], ["operation"]], [[["Ahura Mazda-1"]], [["Zeus-1"]], ["operation"]]]}
{"qid": "a8bbf2e84d0649b1c52c", "term": "Monk", "description": "member of a monastic religious order", "question": "Are monks forbidden from engaging in warfare?", "answer": false, "facts": ["Monks are members of religious orders that usually take vows of poverty, chastity, and obedience.", "The Knights Templar were a religious order that fought during the Crusades and captured Jerusalem in 1099.", "Buddhist Shaolin monks developed very powerful martial arts skills, have defended temples during conquests."], "decomposition": ["What role did the Knights Templar play during the Crusades?", "What role have Shaolin monks played at temples during conquests?", "Did #1 or #2 not involve warfare?"], "evidence": [[[["Knights Templar-2"]], [["Shaolin Kung Fu-9"], "no_evidence"], ["operation"]], [[["Knights Templar-10"]], [["Shaolin Kung Fu-9"]], ["operation"]], [[["Knights Templar-2"]], [["Shaolin Monastery-11"]], ["no_evidence"]]]}
{"qid": "07bcc6301dae2a7b038f", "term": "Jujutsu", "description": "Japanese martial art", "question": "Are all limbs required for jujutsu?", "answer": false, "facts": ["Jujutsu is a Japanese martial art that uses unarmed combat to subdue opponents.", "Nick Newell, a congenital amputee, got his black belt after two straight submission wins.", "Fighter Aaron LaPointe has succeeded in martial arts with a fully paralyzed arm."], "decomposition": ["What kind of sport is jujutsu?", "Which sport did Nick Newell get a black belt in?", "Did Nick Newell have all limbs intact or is #2 not a form of #1?"], "evidence": [[[["Jujutsu-1"]], [["Nick Newell-1", "Nick Newell-2"], "no_evidence"], ["operation"]], [[["Jujutsu-1"]], [["Nick Newell-1"], "no_evidence"], [["Nick Newell-2"], "no_evidence", "operation"]], [[["Jujutsu-1"]], ["no_evidence"], [["Nick Newell-2"]]]]}
{"qid": "ae54adce616125cc6ddd", "term": "Hound", "description": "dog type", "question": "Was animal in You're a Good Sport, Charlie Brown, hypothetically a hound?", "answer": true, "facts": ["A hound is a type of hunting dog used to track prey.", "Hounds include Basenjis, Dachsunds, and Beagles, among others.", "Snoopy is the dog in the Charlie Brown movies and books.", "Snoopy is a Beagle."], "decomposition": ["What animals fall under the classification of \"hound\"?", "What kind of animal was Snoopy?", "What kind of #2 was Snoopy?", "Is #3 included in #1?"], "evidence": [[[["Hound-1", "Hound-3"]], [["Beagle-1"]], [["Snoopy-1"]], ["operation"]], [[["Hound-1"]], [["Snoopy-2"]], [["Snoopy-2"]], [["Beagle-1"]]], [[["Scent hound-2"]], [["Snoopy-7"]], [["Snoopy-1"]], [["Beagle-1"], "operation"]]]}
{"qid": "f318d0f8f873ce921ac9", "term": "Lie", "description": "intentionally false statement to a person or group made by another person or group who knows it is not wholly the truth", "question": "Is it okay to lie after taking an oath in a court of law?", "answer": false, "facts": ["In a court of law, lying under oath is considered perjury. ", "Perjury is considered a crime."], "decomposition": ["When you lie in court, what is that considered?", "Is #1 legal?"], "evidence": [[[["Perjury-1"]], [["Perjury-2"]]], [[["Perjury-1"]], ["operation"]], [[["Perjury-1"]], [["Perjury-2"]]]]}
{"qid": "d2e6dfad9db2e8eec4ed", "term": "Birdwatching", "description": "hobby", "question": "Would a birdwatcher pursue their hobby at a Philadelphia Eagles game?", "answer": false, "facts": ["Birdwatching is a recreational activity in which people observe and/or listen to the sounds of birds.", "Despite their name, the Philadelphia Eagles are a professional American Football team comprised of humans, not birds."], "decomposition": ["What is a birdwwatcher interested in watching?", "What kind of sport does the Philadelphia eagles play?", "Can #1 be found at #2?"], "evidence": [[[["Birdwatching-8"], "no_evidence"], [["Philadelphia Eagles-1"], "no_evidence"], ["operation"]], [[["Birdwatching-1"]], [["Philadelphia Eagles-1"]], [["American football-1"]]], [[["Birdwatching-1"]], [["Philadelphia Eagles-1"]], ["operation"]]]}
{"qid": "9d1e49ac4adff55b1b5c", "term": "Royal Observatory, Greenwich", "description": "observatory in Greenwich, London, UK", "question": "In geometry terms, is the Royal Observatory in Greenwich similar to a yield sign?", "answer": false, "facts": ["The main building of the Royal Observatory is the Octagon Room.", "A yield sign is shaped like a rounded triangle.", "Two figures are similar if they have the same shape but not necessarily the same size."], "decomposition": ["What is the shape of the Royal Observatory in Greenwich?", "What is the shape of a yield sign?", "Is #1 geometrically similar to #2?"], "evidence": [[[["Royal Observatory, Greenwich-31"]], [["Yield sign-3"]], ["operation"]], [[["Royal Observatory, Greenwich-1"], "no_evidence"], [["Yield sign-3"], "no_evidence"], ["no_evidence", "operation"]], [[["Royal Observatory, Greenwich-7"]], [["Yield sign-5"]], ["operation"]]]}
{"qid": "fd67eec2cbde837f5096", "term": "Brazilian jiu-jitsu", "description": "martial art focusing on grappling and ground fighting, originally based on Kodokan judo newaza taught by Japanese judoka, that developed independently in Brazil from experimentation and adaptation by Carlos and H\u00e9lio Gracie, Luiz Fran\u00e7a, et al.", "question": "Could a white belt defeat Jon Jones in a Brazilian jiu-jitsu match?", "answer": false, "facts": ["A white belt is the lowest ranking in Brazilian jiu-jitsu.", "Jon Jones has a purple belt in Brazilian jiu-jitsu under Roberto Alencar.", "A purple belt is the second highest ranking in Brazilian jiu-jitsu.", "Jon Jones is one of the greatest combat sports athletes to ever live."], "decomposition": ["What color belt does Jon Jones have in Brazilian jiu-jitsu?", "In belt color ranking in Brazilian jiu-jitsu, where is #1? ", "In belt color ranking in Brazilian jiu-jitsu, where is white belt?", "Is #2 higher than #3?"], "evidence": [[[["Jon Jones-2"], "no_evidence"], [["Brazilian jiu-jitsu-39"]], [["Brazilian jiu-jitsu-39"]], ["operation"]], [["no_evidence"], ["no_evidence"], [["Brazilian jiu-jitsu ranking system-5"]], ["no_evidence", "operation"]], [[["Jon Jones-1"], "no_evidence"], [["Black belt (martial arts)-9"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "2533aef219d77a6860ef", "term": "Cream", "description": "Dairy product", "question": "Would Kylee Jenner ask for no cream in her coffee?", "answer": true, "facts": ["Kylee Jenner is lactose intolerant.", "Lactose intolerance makes it uncomfortable for people to digest foods containing lactose.", "Cream is a dairy product and is rich in lactose."], "decomposition": ["What dietary condition does Kylee (Kylie) Jenner suffer from?", "What do people who have #1 have to avoid?", "Does cream have #2 in it?"], "evidence": [[["no_evidence"], [["Lactose intolerance-1"]], [["Cream-1"], "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence"]], [[["Kylie Jenner-1"]], [["Lactose intolerance-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "fb19a4a379ea2cb76568", "term": "Prime number", "description": "Integer greater than 1 that has no positive integer divisors other than itself and 1", "question": "Would an actuary be confused about what prime numbers are?", "answer": false, "facts": ["Actuaries must go through college and rigorous studies in mathematics to obtain their jobs.", "Prime numbers are introduced in basic high school mathematics. "], "decomposition": ["Which subjects do actuaries study in college before getting their jobs?", "Which subject are prime numbers taught in?", "Is #2 included in #1?"], "evidence": [[[["Actuary-4"], "no_evidence"], [["Prime number-2"]], ["no_evidence", "operation"]], [[["Actuary-1"], "no_evidence"], [["Prime number-2"]], ["operation"]], [[["Actuary-1"]], [["Prime number-24"]], ["operation"]]]}
{"qid": "0cc643196b24a6d37b46", "term": "United Nations Conference on Trade and Development", "description": "organization", "question": "Could Edward Snowden have visited the headquarters of United Nations Conference on Trade and Development?", "answer": true, "facts": ["The headquarters of the United Nations Conference on Trade and Development is in Geneva, Switzerland.", "Edward Snowden was stationed in Geneva in 2007 with the task of representing the US at the UN."], "decomposition": ["What city and country is the United Nations Conference on Trade and Development located in?", "In 2007, what was Edward Snowden's tasked with?", "Was Edward Snowden stationed in #1 in 2007 to accomplish #2? "], "evidence": [[[["United Nations Conference on Trade and Development-7"]], [["Edward Snowden-13"]], ["operation"]], [[["Palace of Nations-1"]], [["Edward Snowden-13"]], ["operation"]], [[["United Nations Conference on Trade and Development-3"]], [["Edward Snowden-13"]], ["operation"]]]}
{"qid": "cdd68b5d76364d35779f", "term": "United States Air Force", "description": "Air and space warfare branch of the United States Armed Forces", "question": "Would a member of the United States Air Force get a discount at Dunkin Donuts?", "answer": true, "facts": ["The United States Air Force is part of the military.", "Dunkin Donuts offers a military discount. "], "decomposition": ["What is the The United States Air Force a branch of?", "What groups of people get a discount at Dunkin Donuts?", "Is there any overlap between #1 and #2?"], "evidence": [[[["United States Air Force-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["United States Air Force-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["United States Air Force-1"]], [["Discounts and allowances-30"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "4c88f31810b240fd43a6", "term": "The Hobbit", "description": "Fantasy novel by J. R. R. Tolkien", "question": "Can The Hobbit be read in its entirety in four minutes?", "answer": true, "facts": ["The Hobbit is a 95,356 word book by J.R.R. Tolkien.", "Speed reader Howard Stephen Berg could read at the speed of 25,000 words per minute.", "Speed reader Maria Teresa Calderon from the Philippines claimed to be able to read 80,000 words per minute with 100% comprehension."], "decomposition": ["How many words are in the Hobbit?", "How many words per minute could Maria Teresa Calderon read?", "What is #2 multiplied by 4?", "Is #3 greater than or equal to #1?"], "evidence": [[[["The Hobbit-3"], "no_evidence"], [["Speed reading-19"], "no_evidence"], ["no_evidence", "operation"], ["no_evidence", "operation"]], [["no_evidence"], [["Speed reading-19"]], ["operation"], ["operation"]], [[["The Hobbit-1"], "no_evidence"], [["Speed reading-19"]], ["operation"], ["operation"]]]}
{"qid": "8ce466f6f1430a309edf", "term": "Yeti", "description": "Folkloric ape-like creature from Asia", "question": "Would a Yeti be likely to have prehensile limbs?", "answer": true, "facts": ["The animals that Yetis are said to look similar to are able to use their hands or toes to grasp items", "The ability to grasp with hands or other limbs is to be prehensile. "], "decomposition": ["What does it mean to be prehensile?", "What animals are Yetis said to look like?", "Would #2 be considered #1?"], "evidence": [[[["Prehensile feet-1"]], [["Yeti-28"]], ["operation"]], [[["Prehensile feet-1"]], [["Yeti-4"]], [["Yeti-4"]]], [[["Prehensility-1"]], [["Yeti-1"]], ["operation"]]]}
{"qid": "7cfc1003f0a479b3487c", "term": "Jack Black", "description": "American actor, comedian, musician, music producer and youtuber.", "question": "Is Jack Black unlikely to compete with Bear McCreary for an award?", "answer": true, "facts": ["Jack Black is a musician but not a composer", "Bear McCreary is a composer", "Their interests are similar but their skills not overlap in awards categories"], "decomposition": ["What music-related occupation does Bear McCreary have?", "What types of awards are won by notable figures who work as #1? ", "What music-related occupation does Jack Black have?", "What types of awards have been won by notable figures who work as #3?", "Are #2 and #4 separate categories of awards?"], "evidence": [[[["Bear McCreary-1"]], [["American Society of Composers, Authors and Publishers-18"]], [["The Pick of Destiny-8"]], [["Jack Black-24"]], [["American Society of Composers, Authors and Publishers-18", "Jack Black-24"]]], [[["Bear McCreary-1"]], [["American Society of Composers, Authors and Publishers-18", "International Film Music Critics Association-1"], "no_evidence"], [["Jack Black-1"]], [["Grammy Award-1", "Grammy Award-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Bear McCreary-1"]], [["Bear McCreary-2"]], [["Jack Black-16"]], [["Grammy Award for Best Hard Rock Performance-1"]], ["operation"]]]}
{"qid": "b0ee9781a2840b582d9d", "term": "Nicole Kidman", "description": "Australian-American actress and film producer", "question": "Is Nicole Kidman ideal choice to play Psylocke based on height and weight?", "answer": true, "facts": ["Psylocke is a Marvel super hero whose real name is Betsy Braddock.", "Betsy Braddock is 5'11 and 155 lbs.", "Actress Nicole Kidman is 5'11 and weighs 137 lbs.", "Actresses gain weight all the time for roles, such as Charlize Theron who gained 30 pounds for the movie Monster."], "decomposition": ["What is Psylocke's height?", "What is Psylocke's wieght?", "Does Nicole Kidman have similar attributes as #1 and #2?"], "evidence": [[[["Psylocke-2"], "no_evidence"], ["no_evidence"], [["Nicole Kidman-1"], "no_evidence", "operation"]], [[["Psylocke-2"], "no_evidence"], [["Psylocke-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Psylocke-4"], "no_evidence"], [["Psylocke-4"], "no_evidence"], [["Model (person)-19", "Model (person)-20", "Nicole Kidman-1"], "no_evidence", "operation"]]]}
{"qid": "29d785535d6462d9e711", "term": "Red Sea", "description": "Arm of the Indian Ocean between Arabia and Africa", "question": "Does the Red Sea have biblical significance? ", "answer": true, "facts": ["During the biblical Exodus, the Israelite had to cross the Red Sea.", "Moses parted the Red Sea to allow the Israelite group to escape from the Egyptians. "], "decomposition": ["What bodies of water are important to Biblical stories?", "Is the Red Sea among #1?"], "evidence": [[[["Red Sea-8"]], [["Red Sea-8"], "operation"]], [[["Jordan River-2", "Mediterranean Sea-11", "Red Sea-8", "Sea of Galilee-4"]], ["operation"]], [[["Crossing the Red Sea-1"]], ["operation"]]]}
{"qid": "4ce7336b43da9f13fbd1", "term": "Argon", "description": "Chemical element with atomic number 18", "question": "Can you chew argon?", "answer": false, "facts": ["Chewing is the act of breaking down solid objects with your teeth", "Under normal conditions, argon exists as a gas"], "decomposition": ["What kind of substance is argon?", "Do humans usually chew #1?"], "evidence": [[[["Argon-1"]], [["Chewing-1"], "operation"]], [[["Argon-1"]], [["Chewing-1"]]], [[["Argon-1"]], ["operation"]]]}
{"qid": "43422a156aa28bf24d7c", "term": "History of art", "description": "history of human creation of works for aesthetic, communicative, or expressive purposes", "question": "Can the history of art be learned by an amoeba?", "answer": false, "facts": ["The history of art is the academic study of the development of human artistic expression over time", "Academic study requires human-level intelligence", "An amoeba is a single-celled organism "], "decomposition": ["What intellectual ability is necessary to study the history of art?", "Does an amoeba possess #1?"], "evidence": [[[["Human brain-66", "Human brain-67"]], [["Amoeba-1", "Cell (biology)-1", "Cell (biology)-16"], "operation"]], [[["Learning-1"], "no_evidence"], [["Amoeba-1"], "no_evidence", "operation"]], [[["Art history-6"]], [["Amoeba-25"]]]]}
{"qid": "6f6cc7ad88e1a4bd1880", "term": "Charlemagne", "description": "King of the Franks, King of Italy, and Holy Roman Emperor", "question": "Would Temujin hypothetically be jealous of Charlemagne's conquests?", "answer": false, "facts": ["Temujin was the birth name of Genghis Khan.", "Genghis Khan founded the Mongol Empire which was the largest land empire in world history.", "Charlemagne, King of the Franks, conquered most of Western Europe.", "At its peak, the Mongol Empire had 110 million people.", "Charlemagne's empire had around 20 million people at its height."], "decomposition": ["Temujin was the name of which leader?", "How many people did #1's empire have at its peak?", "How many people did Charlemagne's empire have at its peak?", "Is #3 greater than #2?"], "evidence": [[[["Genghis Khan-1"]], ["no_evidence"], [["Carolingian Empire-1", "Carolingian Empire-3"]], ["no_evidence", "operation"]], [[["Genghis Khan-1"]], [["Mongol Empire-1"], "no_evidence"], [["Carolingian Empire-3", "Charlemagne-1"]], ["no_evidence", "operation"]], [[["Genghis Khan-1"]], [["Mongol Empire-109"], "no_evidence"], [["Carolingian Empire-1", "Carolingian Empire-3"]], ["operation"]]]}
{"qid": "01c3faf4915a44133f60", "term": "Iggy Pop", "description": "American rock singer-songwriter, musician, and actor", "question": "Was Iggy Pop named after his father?", "answer": true, "facts": ["Iggy Pop's birth name was James Newell Osterberg Jr.", "The father of Iggy Pop was James Newell Osterberg Sr."], "decomposition": ["What is Iggy Pop's real name?", "What is Iggy Pop's father's name?", "Is #1 the same as #2?"], "evidence": [[[["Iggy Pop-1"]], [["Iggy Pop-5"]], ["operation"]], [[["Iggy Pop-1"]], [["Iggy Pop-5"]], ["operation"]], [[["Iggy Pop-1"]], [["Iggy Pop-5"]], ["operation"]]]}
{"qid": "3210c34ec2b8fcda4cae", "term": "German Shepherd", "description": "Dog breed", "question": "Would Robert Wadlow tower over a German Shepherd?", "answer": true, "facts": ["German Shepherds have a height between 22 and 26 inches.", "Robert Wadlow was the tallest man ever, reaching a height of 8 ft 11.1 inches at his death."], "decomposition": ["What is the typical height range of German Shepherds?", "How tall was Robert Wadlow?", "Is #2 greater than #1?"], "evidence": [[[["German Shepherd-3"]], [["Robert Wadlow-2"]], ["operation"]], [[["German Shepherd-3"]], [["Robert Wadlow-2"]], ["operation"]], [[["German Shepherd-3"], "no_evidence"], [["Robert Wadlow-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "f7d66ea2a1fcc7473f48", "term": "Bengal cat", "description": "Breed of cat", "question": "Can a Bengal cat survive eating only pancakes?", "answer": false, "facts": ["Bengal cats are carnivores.", "Pancakes contain no meat.", "Carnivores eat only meat to survive. "], "decomposition": ["What type of diet does a Bengal cats follow?", "What do #1 mainly eat?", "Do pancakes contain #2?"], "evidence": [[[["Bengal cat-1"]], [["Cat food-9"]], ["operation"]], [[["Bengal cat-1", "Cat-1"]], [["Carnivore-1"]], [["Pancake-1"], "operation"]], [[["Bengal cat-1", "Carnivore-7"]], [["Carnivore-7"]], [["Pancake-1"]]]]}
{"qid": "42b892d5dd158c0fd26a", "term": "Swastika", "description": "a geometrical figure and an ancient religious icon in the cultures of Eurasia and 20th-century symbol of Nazism", "question": "Are swastikas used in the most common religion in India?", "answer": true, "facts": ["The swastika is a religious symbol that is used in Hinduism, Buddhism, and Jainism.", "Almost 80% of people in India practice Hinduism."], "decomposition": ["Which religions use the swastika as a symbol?", "What is the most common religion in India?", "Is #2 included in #1?"], "evidence": [[[["Swastika-1"]], [["Hinduism in India-1"]], ["operation"]], [[["Swastika-1"]], [["Hinduism-1"]], ["operation"]], [[["Swastika-1"]], [["Religion in India-1"]], ["operation"]]]}
{"qid": "57cace65de55cbb6b8d4", "term": "Colitis", "description": "inflammation of the colon or the large intestine", "question": "Is it best to avoid kola nuts with colitis?", "answer": true, "facts": ["Colitis is a disease in which the colon becomes inflamed.", "Many things can trigger colitis, including dairy, alcohol, and caffeine.", "The kola nut is the fruit of the tropical cola tree that contains caffeine inside."], "decomposition": ["What triggers colitis? ", "Are any of the triggers in #1 present in the kola nut?"], "evidence": [[[["Colitis-17"], "no_evidence"], [["Kola nut-2"], "operation"]], [[["Colitis-10"], "no_evidence"], [["Kola nut-1"], "no_evidence"]], [[["Colitis-3"], "no_evidence"], [["Kola nut-1"], "no_evidence", "operation"]]]}
{"qid": "08271060e7c75ea1e8b8", "term": "Lorem ipsum", "description": "Placeholder text used in publishing and graphic design", "question": "Should a finished website have lorem ipsum paragraphs?", "answer": false, "facts": ["Lorem Ipsum paragraphs are meant to be temporary.", "Web designers always remove lorem ipsum paragraphs before launch."], "decomposition": ["What is a lorem ipsum paragraph? ", "Is #1 good to have on a website?"], "evidence": [[[["Lorem ipsum-1"]], [["Lorem ipsum-1", "Lorem ipsum-2"]]], [[["Lorem ipsum-1"]], ["operation"]], [[["Lorem ipsum-1"]], ["operation"]]]}
{"qid": "19c069cf9329b5dc7764", "term": "Snake", "description": "limbless, scaly, elongate reptile", "question": "Can a snake swallow an M60 Patton?", "answer": false, "facts": ["An M60 Patton is an army tank that weighs several tons.", "One of the largest animals a snake ate was an impala that weighed 130 pounds."], "decomposition": ["What is the largest animal that a snack has ever swallowed?", "How much does #1 weigh?", "How much does a M60 Patton weigh?", "Is #3 less than #2?"], "evidence": [[[["Reticulated python-26", "Reticulated python-27"]], [["Reticulated python-22"]], [["M60 tank-64"]], ["operation"]], [[["African rock python-2"], "no_evidence"], [["Antelope-12", "Crocodile-9"], "no_evidence"], [["M60 tank-64"]], ["operation"]], [[["Snake-1"], "no_evidence"], ["no_evidence"], [["M60 tank-64"]], ["operation"]]]}
{"qid": "fa472b6db8dcec9abcff", "term": "Torso", "description": "the central part of the living body", "question": "Will the torso be safe from blows to the largest and smallest bones in body?", "answer": true, "facts": ["The three smallest bone in the body are malleus, incus, and stapes.", "Malleus, incus, and stapes are located in the ear.", "The femur is the largest bone in the body.", "The femur is located in the leg.", "The torso is located in the center of the body."], "decomposition": ["Which part of the human body is the torso?", "Which is the largest and smallest bone in the human body?", "Where are #2 located?", "Is any of #3 part of #1?"], "evidence": [[[["Torso-1"]], [["Femur-1", "Stapes-1"]], [["Human leg-1", "Stapes-1"]], [["Abdomen-1", "Perineum-1", "Thorax-1"], "operation"]], [[["Torso-1"]], [["Bone-3"]], [["Femur-7"]], [["Femur-7"], "operation"]], [[["Torso-1"]], [["Bone-3"]], [["Thigh-1"]], ["operation"]]]}
{"qid": "2127e3455127e099982b", "term": "Scottish people", "description": "ethnic inhabitants of Scotland", "question": "Does the Pixar film Brave feature Scottish people?", "answer": true, "facts": ["The movie Brave is set in the Scottish highlands.", "Merida, the main character of Brave, is a Princess of Medieval Scotland "], "decomposition": ["Who are the main characters of the Pixar film Brave?", "Are any of #1 from Scotland?"], "evidence": [[[["Brave (2012 film)-4"]], ["operation"]], [[["Brave (2012 film)-4"]], [["Brave (2012 film)-4"], "operation"]], [[["Brave (2012 film)-1", "Brave (2012 film)-4"]], ["operation"]]]}
{"qid": "48cac3b98391f6da285f", "term": "Wednesday", "description": "Day of the week", "question": "Will Communion be denied to Wednesday name origin followers?", "answer": true, "facts": ["Communion is the body and blood of Christ given out during mass.", "Communion is only given to believers baptized in the Christian Church.", "Wednesday comes from Old English Wodnesdaeg referring to Woden, also called Odin.", "Odin was the pagan god of Norse mythology.", "Vikings, believers in Norse mythology, clashed with Christians in Wessex and Northumbria for hundreds of years."], "decomposition": ["Which deity is related to the origin of the name 'Wednesday'?", "Who are the worshipers of #1?", "Which group of people are allowed to take the Communion?", "Are #2 included in #3?"], "evidence": [[[["Odin-2"]], [["Odin-2"], "no_evidence"], [["Eucharist-1"]], ["operation"]], [[["Wednesday-1"]], [["Odin-2"]], [["First Communion-1"]], ["operation"]], [[["Wednesday-1"]], [["Anglo-Saxon paganism-1"]], [["Eucharist-1"]], ["operation"]]]}
{"qid": "b39a840f37ef3d97d498", "term": "Goofy", "description": "Disney cartoon character", "question": "Would Goofy hypothetically enjoy Nylabone?", "answer": true, "facts": ["Goofy is a popular Disney cartoon character that is a dog.", "Nylabone is a popular dog bone brand.", "Dogs chew bones for the taste, and to exercise the muscles of the jaw."], "decomposition": ["What kind of animal does Goofy portray?", "What kind of animal are Nylabones made for?", "Are #1 and #2 both dog?"], "evidence": [[[["Goofy-1"]], [["Dog toy-7"]], ["operation"]], [[["Goofy-1"]], [["Dog toy-7"]], ["operation"]], [[["Goofy-1"]], [["Dog toy-7"]], ["operation"]]]}
{"qid": "913c1014198f2e584dc7", "term": "Ice", "description": "water frozen into the solid state", "question": "Is there a popular Disney character made from living ice?", "answer": true, "facts": ["Olaf is a popular character in Disney's Frozen series.", "Olaf is a snowman, accidentally enchanted to life by Elsa while she magically builds her ice tower."], "decomposition": ["Which popular Disney character did Elsa accidentally enchant to life while building her ice tower?", "Was #1 made of snow/ice?"], "evidence": [[[["Frozen (2013 film)-7"]], [["Snowman-4"], "operation"]], [[["Olaf (Frozen)-1"]], [["Snowman-1"]]], [[["Olaf (Frozen)-5"]], [["Olaf (Frozen)-1"], "operation"]]]}
{"qid": "7f5bde421ffbd43d7cdd", "term": "Sirius", "description": "Brightest star in the night sky", "question": "Is Sirius part of a constellation of an animal?", "answer": true, "facts": ["Sirius is the brightest star in the constellation Canis Major.", "Canis Major represents a large dog."], "decomposition": ["What constellation is Sirius a part of?", "What does #1 represent?", "Is #2 an animal?"], "evidence": [[[["Canis Major-2"]], [["Canis Major-1"]], ["operation"]], [[["Sirius-4"]], [["Canis Major-1"]], ["operation"]], [[["Sirius-4"]], [["Canis Major-4"]], [["Animal-4"]]]]}
{"qid": "fabdc0199bd6444eb78c", "term": "Mongoose", "description": "family of mammals", "question": "Did mongoose come from later period than rhinos?", "answer": true, "facts": ["The mongoose originated  in the Neogene geological period.", "Rhinos are from the Paleogene geological period.", "The Paleogene period spans 43 million years from the end of the Cretaceous Period 66 million years ago to the beginning of the Neogene Period."], "decomposition": ["During which period did the mongoose originate?", "Which period did Rhinos originate from?", "Is #2 before #1?"], "evidence": [[[["Mongoose-2"]], [["Rhinoceros-5"]], [["Mongoose-2", "Rhinoceros-5"], "operation"]], [[["Mongoose-1", "Mongoose-2"]], [["Rhinoceros-5"]], ["operation"]], [[["Mongoose-2"]], [["Rhinoceros-5"]], ["operation"]]]}
{"qid": "fd5f22b8ed969a08eea5", "term": "Rick and Morty", "description": "Animated sitcom", "question": "Could Rich and Morty be triggered for children of alcoholics?", "answer": true, "facts": ["Rick, one of the titular characters of Rick and Morty, is often seen drunk and speaking abusively to Morty.", "Morty's mother Beth is depicted multiple times neglecting her children while getting drunk on wine. ", "Trauma triggers can occur when someone is exposed to something that reminds them of a traumatic situation. "], "decomposition": ["What depictions are common triggers for children of alcoholics?", "Do any of the characters from Rick and Morty exhibit the characteristics in #1?"], "evidence": [[[["Alcoholism-13"], "no_evidence"], [["Rick and Morty-5"], "operation"]], [[["Alcoholism-13"], "no_evidence"], [["Rick and Morty-5"], "no_evidence", "operation"]], [[["Adult Children of Alcoholics-4"]], [["Adult Children of Alcoholics-4", "Rick and Morty-4", "Rick and Morty-5"]]]]}
{"qid": "1be5f9fda680e4e07f7c", "term": "Durian", "description": "genus of plants", "question": "Would Columbus have discovered Durian trees during his 1492 expedition?", "answer": false, "facts": ["Columbus ended up in the Americas", "Durian only exists in Southeast Asia"], "decomposition": ["Which country did Columbus discover on his 1492 experdition?", "Which countries could you find Durian on?", "Is there any overlap between #1 and #2?"], "evidence": [[[["Voyages of Christopher Columbus-1"]], [["Durian-1"]], ["operation"]], [[["Voyages of Christopher Columbus-1"]], [["Durian-1"]], [["Borneo-1", "Voyages of Christopher Columbus-27"], "operation"]], [[["Christopher Columbus-2"]], [["Borneo-2", "Durian-21", "Durian-22", "Durian-23"]], ["operation"]]]}
{"qid": "90e003dc429517ba3ebc", "term": "Lionel Richie", "description": "American singer-songwriter, musician, record producer and actor", "question": "Does  Lionel Richie believe in holistic medicine?", "answer": true, "facts": ["Lionel Richie suffered prolonged throat problems and had surgery four times in four years before being told by conventional doctors that he could lose his singing career. ", "Lionel Richie finally turned to a holistic doctor who said that the problem was simply acid reflux caused by foods he was eating before going to bed."], "decomposition": ["Which doctor diagnosed Lionel Richie satisfactorily after he had surgeries for a prolonged throat problem?", "Is #1 a holistic doctor?"], "evidence": [[["no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], ["operation"]], [["no_evidence"], ["operation"]]]}
{"qid": "af531b69039676567cb9", "term": "Menthol", "description": "chemical compound", "question": "Is Menthol associated with Thanksgiving?", "answer": false, "facts": ["Menthol is the main component of peppermint oil and is responsible for the noticeable cooling sensation. ", "During Thanksgiving, turkey, potatoes, gravy, and pie are common dishes. None of which have menthol in it."], "decomposition": ["What are some common dishes served during Thanksgiving?", "Does any of #1 contain menthol?"], "evidence": [[[["Thanksgiving (United States)-1"]], ["operation"]], [[["Thanksgiving-6"]], [["Menthol-1"]]], [[["Thanksgiving dinner-10", "Thanksgiving dinner-16"]], [["Menthol-23", "Thanksgiving dinner-10", "Thanksgiving dinner-16"]]]]}
{"qid": "3f7daff5574045d7b737", "term": "Olive", "description": "Species of plant", "question": "Would Bugs Bunny harm an olive tree in the real world?", "answer": true, "facts": ["Bugs Bunny is an anthropomorphic gray and white rabbit.", "Rabbits eat the bark of olive trees and can do considerable damage, especially to young trees."], "decomposition": ["What kind of animal is Bugs Bunny?", "Do #1 eat and damage the bark of olive trees?"], "evidence": [[[["Bugs Bunny-2"]], [["Olive-73"]]], [[["Bugs Bunny-2"]], [["Olive-73"], "operation"]], [[["Bugs Bunny-2"]], [["Olive-73"]]]]}
{"qid": "5ab66b27a0caee886970", "term": "Miami", "description": "City in Florida, United States", "question": "Would it be common to find a penguin in Miami?", "answer": false, "facts": ["Penguins are native to the deep, very cold parts of the southern hemisphere.", "Miami is located in the northern hemisphere and has a very warm climate."], "decomposition": ["Where is a typical penguin's natural habitat?", "What conditions make #1 suitable for penguins?", "Are all of #2 present in Miami?"], "evidence": [[[["Penguin-2", "Penguin-48", "Penguin-50"]], [["Penguin-48"]], [["Miami-20"], "operation"]], [[["Chinstrap penguin-5", "Penguin-48"]], [["Penguin-48"]], [["Miami-20", "Miami-22"]]], [[["Penguin-1"]], [["Penguin-2"]], [["Miami-20"], "operation"]]]}
{"qid": "c406445894101a7f4d71", "term": "Days of Our Lives", "description": "American daytime soap opera", "question": "Is a thousand dollars per Days of Our Lives episodes preferred to other soaps?", "answer": false, "facts": ["Days of Our Lives has aired around 13,900 episodes as of 2020.", "General Hospital aired their 14,000th episode on February 23, 2018."], "decomposition": ["How many episodes of 'Days of Our Lives' are there as of 2020?", "How many episodes of 'General Hospital' have been aired as of 2020?", "Is #1 greater than #2?"], "evidence": [[[["Days of Our Lives-3"], "no_evidence"], [["General Hospital-1", "General Hospital-3"], "no_evidence"], ["operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Days of Our Lives-3"], "no_evidence"], [["General Hospital-10"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "517614ab4adf946dbe20", "term": "Eve", "description": "Biblical figure", "question": "Was Eve involved in an incestuous relationship?", "answer": true, "facts": ["God made Eve from a bone he removed from Adam.", "Since Eve was made from Adam, they would have had similar DNA and been considered twins or at least siblings.", "As the only humans at the time, they ended up starting a family together."], "decomposition": ["Who did Eve have intercourse with?", "How was Eve related to #1?", "Can it be concluded that they are family based on #2?"], "evidence": [[[["Incest-18"]], [["Incest-18"]], ["operation"]], [[["Eve-13"]], [["Eve-2"]], ["operation"]], [[["Adam and Eve-2"]], [["Adam and Eve-2"]], [["Adam and Eve-2"]]]]}
{"qid": "df0429c062ac5aaa9b99", "term": "Bugs Bunny", "description": "Warner Bros. cartoon character", "question": "Can you find Bugs Bunny at Space Mountain?", "answer": false, "facts": ["Space Mountain is an attraction at Disney theme parks", "Bugs Bunny is a Warner Bros. character", "Warner Bros. characters appear at Six Flags theme parks"], "decomposition": ["Where is Space Mountain located?", "Which animation studio created Bugs Bunny?", "Which entertainment company is #1 related to?", "Is #2 part of #3?"], "evidence": [[[["Space Mountain-1"]], [["Bugs Bunny-1"]], [["Space Mountain (Disneyland)-1"]], ["operation"]], [[["Space Mountain-1"]], [["Bugs Bunny-1"]], [["Disney Parks, Experiences and Products-1"]], ["operation"]], [[["Space Mountain (Disneyland)-1"]], [["Bugs Bunny-1"]], [["Disneyland-1"]], ["operation"]]]}
{"qid": "3ed6c807bfa51e5577d1", "term": "Daytona 500", "description": "Auto race held in Daytona, Florida, United States", "question": "Can E6000 cure before a hoverboard finishes the Daytona 500? ", "answer": true, "facts": ["The Daytona 500 is 500 miles", "A hoverboard can move at six to eight miles per hour", "E6000 fully cures in 24 to 72 hours"], "decomposition": ["How long is the Daytona 500?", "How fast can a hoverboard move in hours?", "What is #1 divided by #2?", "How many hours does it take for a E6000 to cure?", "Is #4 more less than #3?"], "evidence": [[[["Daytona 500-1"]], [["Franky Zapata-12"], "no_evidence"], ["operation"], [["Conroe (microprocessor)-8"], "no_evidence"], ["operation"]], [[["Daytona 500-1"]], [["Self-balancing scooter-9"]], ["operation"], [["Adhesive-28"], "no_evidence"], ["operation"]], [[["Daytona 500-1"]], [["Hoverboard-18"]], ["operation"], [["Adhesive-42"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "2c6955a5381253c1067c", "term": "Linus Torvalds", "description": "Creator and lead developer of Linux kernel", "question": "Does Linus Torvalds make money off of DirectX?", "answer": false, "facts": ["DirectX is a proprietary technology owned by Microsoft", "Linus Torvalds is the creator and lead developer for the open-source Linux kernel", "The Linux kernel is used in operating systems that are competitors of Microsoft Windows"], "decomposition": ["Which company owns the DirectX technology?", "Which operating system does #1 develop?", "Linus Torvalds develops which operating system?", "Is #2 the same as #3?"], "evidence": [[[["DirectX-1"]], [["Microsoft Windows-1"]], [["Linus Torvalds-1"]], ["operation"]], [[["DirectX-1"]], [["DirectX-1"]], [["Linus Torvalds-1"]], ["operation"]], [[["DirectX-1"]], [["Microsoft Windows-1"]], [["Linus Torvalds-1"]], ["operation"]]]}
{"qid": "192bea4bc6d8b65a513a", "term": "QWERTY", "description": "keyboard layout where the first line is \"QWERTYUIOP\"", "question": "Can the majority of vowels be typed on the first line of a QWERTY keyboard?", "answer": true, "facts": ["In English the vowels consist of A, E, I, O, U, and sometimes Y.", "The first line of the QWERTY keyboard contains the vowels E, I, O, U, and Y.", "A majority means more than half of the total."], "decomposition": ["What letters are vowels in the English language?", "What are the letters on the first line of a Qwerty keyboard?", "Is more than half of the letters listed in #1 also listed in #2?"], "evidence": [[[["English alphabet-20"]], [["QWERTY-1", "Ray Tomlinson-5"], "no_evidence"], ["operation"]], [[["Vowel-49"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Vowel-49"]], [["QWERTY-1"], "no_evidence"], ["operation"]]]}
{"qid": "1127f625b634b9371ee1", "term": "Sloth", "description": "tree dwelling animal noted for slowness", "question": "Do moths that live on sloths have family dinners?", "answer": false, "facts": ["Algae grows on sloths", "Sloth moths feed on algae that grows on sloths", "Sloth moth caterpillars feed on sloth dung ", "Sloths defecate far from their ususl abode"], "decomposition": ["What do sloth moths enjoy eating from the body of sloths?", "Where is #1 found on the sloth?", "What do baby or caterpillar sloth moths enjoy eating from the body of sloths?", "Where is #3 found relative to the sloth?", "Is #2 found in the same location as #4?"], "evidence": [[[["Sloth moth-2"], "no_evidence"], [["Sloth moth-3"], "no_evidence"], ["no_evidence"], ["no_evidence"], ["operation"]], [[["Sloth moth-4"]], [["Sloth moth-1"]], [["Sloth moth-2"]], [["Arthropods associated with sloths-12"]], ["operation"]], [[["Sloth moth-1", "Sloth moth-4"]], [["Sloth-2"]], [["Sloth moth-2"], "no_evidence"], ["no_evidence", "operation"], ["operation"]]]}
{"qid": "f353cbd3286ea1e452aa", "term": "Telescope", "description": "Optical instrument that makes distant objects appear magnified", "question": "Can telescopes hear noise?", "answer": false, "facts": ["Telescopes are used to view things far away.", "Telescopes are an optical instrument. "], "decomposition": ["What are the uses of a telescope?", "Does #1 include detecting noise?"], "evidence": [[[["Telescope-1"]], ["operation"]], [[["Telescope-5"]], [["Telescope-5"]]], [[["Telescope-1"]], [["Telescope-1"], "operation"]]]}
{"qid": "1534ef2130cb48d6abb4", "term": "Heart", "description": "organ for the circulation of blood in animal circulatory systems", "question": "Is a jellyfish safe from atherosclerosis?", "answer": true, "facts": ["Atherosclerosis is a condition in which the arteries to the heart are blocked.", "Jellyfish use their guts to circulate nutrients because they do not have hearts."], "decomposition": ["What structures are affected by atherosclerosis?", "What bodily system does #1 contribute to?", "What structures are found in the jellyfish #2?", "Are there structures in common in both #1 and #3?"], "evidence": [[[["Atherosclerosis-1"]], [["Circulatory system-1"]], [["Jellyfish-18"]], ["operation"]], [[["Atherosclerosis-1"]], [["Artery-2"]], [["Jellyfish-18"]], ["operation"]], [[["Atherosclerosis-1"]], [["Artery-2"]], [["Jellyfish-18"]], ["operation"]]]}
{"qid": "826cdebd34c07f92fca5", "term": "Tsar", "description": "title given to a male monarch in Russia, Bulgaria and Serbia", "question": "Would a duke hypothetically be subservient to a Tsar?", "answer": true, "facts": ["The Tsar was the highest ruler in several eastern countries.", "A duke was a title given to important european nobles.", "Dukes ranked below princes, kings, and queens.", "Tsars were the equivalents of English Kings."], "decomposition": ["What is the equivalent of a Tsar in English hierarchy/royalty?", "Do dukes rank below #1?"], "evidence": [[[["Tsar-1"]], [["Duke-1"]]], [[["Tsar-1"]], [["Duke-1"], "operation"]], [[["Tsar-6"]], [["Duke-1"], "operation"]]]}
{"qid": "cf95bbecccc040a95dbb", "term": "Acetylene", "description": "chemical compound", "question": "Does welding with acetylene simulate the temperature of a star?", "answer": true, "facts": ["Acetylene is used for oxyacetylene welding ", "An acetylene/oxygen flame burns at about 3,773 K ", "The star Betelgeuse has a surface temperature of 3,500 K"], "decomposition": ["What temperature is reached when welding with acetylene?", "What temperature can stars reach?", "Are #1 and #2 similar in magnitude?"], "evidence": [[[["Acetylene-14"]], [["Star-91"]], ["operation"]], [[["Acetylene-8"], "no_evidence"], [["Star-91"]], ["operation"]], [[["Acetylene-14"]], [["Star-91"]], ["operation"]]]}
{"qid": "2bfe7f37f939ee456600", "term": "Pig Latin", "description": "secret language game", "question": "Is it impossible for pigs to use pig latin?", "answer": true, "facts": ["Pig latin is a language game played by rearranging parts of words to disguise them", "Pigs are ungulates and incapable of speech using human languages"], "decomposition": ["What is referred to as pig latin?", "Which species are capable of using #1?", "Are pigs excluded from #2?"], "evidence": [[[["Pig Latin-1"]], [["English language-1", "Human-1", "Language-15"]], ["operation"]], [[["Pig Latin-1"]], [["Language-1"]], ["operation"]], [[["Pig Latin-1"]], [["Great ape language-1", "Language-1"], "no_evidence"], ["operation"]]]}
{"qid": "aefa59c255bf15e90f58", "term": "Naruto", "description": "Japanese manga and anime series", "question": "Would the historic Hattori Hanz\u014d admire Naruto?", "answer": false, "facts": ["Naruto is a ninja", "Ninja tactics were considered dishonorable by samurai", "Hattori Hanz\u014d is a famous historical samurai "], "decomposition": ["What was Naruto's profession?", "What was Hattori Hanz\u014d's profession? ", "Did #2 respect the actions of #1?"], "evidence": [[[["Naruto-1"]], [["Hattori Hanz\u014d-1"]], [["Hattori Hanz\u014d-6"], "no_evidence", "operation"]], [[["Naruto-1"]], [["Hattori Hanz\u014d-1"]], [["Ninja-1"], "operation"]], [[["Naruto-7"], "no_evidence"], [["Hattori Hanz\u014d-10"], "operation"], ["no_evidence"]]]}
{"qid": "01e796e851a77dae22bc", "term": "Joker (character)", "description": "Fictional character in the DC Universe", "question": "Was the Joker an enemy of the Avengers?", "answer": false, "facts": ["The Joker is a DC Comics villain.", "The Avengers are a group of heroes from Marvel Comics.", "Being from different publishers, they do not meet."], "decomposition": ["Which world does the Joker exist in?", "The Avengers are from which universe?", "Is #1 the same as #2?"], "evidence": [[[["Joker (2019 film)-46"]], [["The Avengers (2012 film)-37"]], [["The Avengers (2012 film)-45"], "operation"]], [[["Joker (character)-1"]], [["Avengers (comics)-1"]], ["operation"]], [[["Joker (character)-1"]], [["Avengers (comics)-1"]], ["operation"]]]}
{"qid": "fcc9fc36ed71bd5d5723", "term": "Lil Wayne", "description": "American rapper, record executive and actor from Louisiana", "question": "Lil Wayne similar real name rapper has over quadruple Wayne's Grammy awards?", "answer": true, "facts": ["Lil Wayne was born Dwayne Michael Carter.", "Jay-Z was born Shawn Corey Carter.", "Lil Wayne has won 5 Grammy awards.", "Jay-Z has won 22 Grammy awards."], "decomposition": ["What is Lil Wayne's real name?", "What rapper has a real name that is similar to #1?", "How many Grammy awards does Lil Wayne have?", "How many Grammy awards does #2 have?", "Is #4 divided by #3 greater than 4?"], "evidence": [[[["Lil Wayne-1"]], [["Jay-Z-1"]], [["Lil Wayne-4"]], [["Jay-Z-4"]], ["operation"]], [[["Lil Wayne-1"]], [["Jay-Z-1"]], [["Lil Wayne-4"]], [["Jay-Z-4"]], ["operation"]], [[["Lil Wayne-1"]], [["Jay-Z-1"]], [["Lil Wayne-4"]], [["Jay-Z-4"]], ["operation"]]]}
{"qid": "e51ea4cf89bc91a77f3c", "term": "Portuguese Colonial War", "description": "1961\u20131974 armed conflicts in Africa between Portugal and independence movements", "question": "Did any country in Portuguese Colonial War share Switzerlands role in WWII?", "answer": true, "facts": ["The Portuguese Colonial War was between Portugal and several groups including People's Movement for Liberation of Angola.", "Switzerland remained neutral in World War II and did not get involved.", "Portugal stayed out of world affairs during World War II."], "decomposition": ["What was Switzerland's position in World War II?", "Which countries were involved in the Portuguese Colonial War?", "Did any of #2 maintain a #1 position through World War II?"], "evidence": [[[["Switzerland-33"]], [["Portuguese Colonial War-2"]], [["The Two Faces of War-11"]]], [[["Switzerland during the World Wars-20"]], [["Liberal Wars-1"]], [["Neutral powers during World War II-6"], "operation"]], [[["Switzerland during the World Wars-1"]], [["Portuguese Colonial War-1"]], ["operation"]]]}
{"qid": "527a89feb66ade5f0908", "term": "Ashland, Oregon", "description": "City in Oregon, United States", "question": "Is 2018 Ashland, Oregon population inadequate to be a hypothetical military division?", "answer": false, "facts": ["The 2018 population of Ashland Oregon was 21,263 people.", "The number of soldiers in a military division is between 10,000 and 25,000 people."], "decomposition": ["What was the population of Ashland, Oregon in 2018?", "How many soldiers are in a military division?", "Is #1 less than the minimum in #2?"], "evidence": [[[["Ashland, Oregon-1"], "no_evidence"], [["Division (military)-16"], "no_evidence"], ["no_evidence"]], [[["Ashland, Oregon-1"]], [["Division (military)-1"]], ["operation"]], [[["Ashland, Oregon-1"]], [["Division (military)-1"]], ["operation"]]]}
{"qid": "f6c3094dbf7cb1f21b2a", "term": "Petroleum", "description": "Naturally occurring hydrocarbon liquid found underground", "question": "Can petroleum jelly be used as fuel in a car?", "answer": false, "facts": ["Petroleum is a highly reactive liquid used to power cars.", "Petroleum jelly is a solid substance used as an ointment on cuts and scrapes to promote healing.", "Petroleum jelly does not oxidize on exposure to the air and is not readily acted on by chemical reagents."], "decomposition": ["What is petroleum jelly used for?", "Does #1 include fueling cars?"], "evidence": [[[["Petroleum jelly-8"]], [["Petroleum jelly-8"]]], [[["Petroleum jelly-2"]], [["Gasoline-1"], "operation"]], [[["Petroleum jelly-15", "Petroleum jelly-23", "Petroleum jelly-24", "Petroleum jelly-26", "Petroleum jelly-8"]], ["operation"]]]}
{"qid": "a73446e82b72b4a99e5b", "term": "Glutamic acid", "description": "amino acid", "question": "Does Masaharu Morimoto rely on glutamic acid?", "answer": true, "facts": ["Masaharu Morimoto is a Japanese chef", "Japanese cuisine relies on several forms of seaweed as ingredients and flavorings for broth like kombu dashi", "Glutamic acid has been identified as the flavoring component in kombu seaweed"], "decomposition": ["What is Masaharu Morimoto's profession?", "What cuisine does #1 make?", "What is a main ingredient in #2?", "Is glutamic acid a flavoring component in #3?"], "evidence": [[[["Masaharu Morimoto-1"]], [["Masaharu Morimoto-2"]], [["Monosodium glutamate-2"]], [["Glutamic acid-3"]]], [[["Masaharu Morimoto-1"]], [["Masaharu Morimoto-1"]], [["Rice-8"]], ["no_evidence"]], [[["Masaharu Morimoto-1"]], [["Masaharu Morimoto-1"]], [["Japanese cuisine-2", "Soy sauce-6"], "no_evidence"], [["Glutamic acid-22"], "operation"]]]}
{"qid": "adf00eea72beb009ff3e", "term": "Portuguese Empire", "description": "Global empire centered in Portugal", "question": "Did Columbus obtain his funding from the rulers of the Portugese Empire?", "answer": false, "facts": [" King Ferdinand and Queen Isabella funded Columbus' voyage to the New World.", "King Ferdinand of Argon and Queen Isabella of Castille were the joint rulers of kingdoms of the Iberian Peninsula, which included modern-day Spain but excludes Portugal. ", "King John II of Portugal rejected Columbus' request for funding. "], "decomposition": ["Which major voyage did Columbus require funding to embark upon?", "Who funded #1?", "Which kingdoms did #2 rule over?", "Is the Portuguese Empire included in #3?"], "evidence": [[[["Voyages of Christopher Columbus-62"]], [["Voyages of Christopher Columbus-6"]], [["The empire on which the sun never sets-12"]], ["operation"]], [[["Christopher Columbus-1"]], [["Christopher Columbus-2"]], [["Isabella I of Castile-1"]], ["operation"]], [[["Voyages of Christopher Columbus-7"]], [["Voyages of Christopher Columbus-12"]], [["Voyages of Christopher Columbus-9"]], [["Portuguese Empire-4"], "operation"]]]}
{"qid": "cc266a3e29a3b8442b14", "term": "Billionaire", "description": "person who has a net worth of at least one billion (1,000,000,000) units of a given currency", "question": "Would a 900,000 pound net worth person be an American billionaire if they exchange currency June 2020?", "answer": true, "facts": ["The exchange rate in June of 2020 between dollars and pounds is 1 Euro= 1.23 dollar.", "900000 pounds is equal to about 1,107,000.00"], "decomposition": ["What is the minimum amount one must have to be called a billionaire?", "As of  June 2020, how many dollars make a pound?", "Is #2 times 900000 at least equal to #1?"], "evidence": [[[["Billionaire-1"]], [["Pound sterling-62"], "no_evidence"], ["operation"]], [[["Billionaire-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Billionaire-1"]], [["Pound sterling-62"]], ["operation"]]]}
{"qid": "75bcf0203ee31aeeddd5", "term": "United States Capitol", "description": "seat of the United States Congress", "question": "Is the United States Capitol located near the White House?", "answer": true, "facts": ["The Capitol building is located at one end of the National Mall in downtown Washington DC.", "The White House is located next to the Washington Monument a short way down from the Mall."], "decomposition": ["What city is the United States Capitol located in?", "What city is the White House located in?", "Is #1 the same as #2?"], "evidence": [[[["United States Capitol-1"]], [["White House-1"]], ["operation"]], [[["United States-1"]], [["White House-1"]], ["operation"]], [[["United States Capitol-1"]], [["White House-1"]], ["operation"]]]}
{"qid": "e0a9f1ef5fae44427b26", "term": "Pear", "description": "genus of plants", "question": "Would a pear sink in water?", "answer": false, "facts": ["The density of a raw pear is about 0.59 g/cm^3.", "The density of water is about 1 g/cm^3.", "Objects only sink if they are denser than the surrounding fluid."], "decomposition": ["What is the density of a pear?", "What is the density of water?", "Is #1 greater than #2?"], "evidence": [[[["Density-12", "Pear-8"]], [["Density-12", "Density-5"]], ["operation"]], [["no_evidence"], [["Water-7"]], ["no_evidence", "operation"]], [["no_evidence"], [["Properties of water-14"]], ["operation"]]]}
{"qid": "87c07cc6b730abde6d76", "term": "Sweet potato", "description": "species of plant", "question": "Do Sweet Potatoes prevent other plants from growing in their place?", "answer": true, "facts": ["When sweet potato plants decompose, they release a chemical that prevents germination in their soil.", "Farmers will work to ensure that all parts of a sweet potato plant are out of the field before trying to grow in it again."], "decomposition": ["What chemical is released when sweet potatoes decompose?", "Where is #1 released into?", "Does #1 prevent other plants from growing in #2?"], "evidence": [[[["Sweet potato-19"], "no_evidence"], [["Sweet potato-19"], "no_evidence"], ["no_evidence"]], [[["Sweet potato-19"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Sweet potato storage-10"], "no_evidence"], ["no_evidence"], ["no_evidence"]]]}
{"qid": "d15a33b8f88dc5ce32b0", "term": "Drummer", "description": "percussionist who creates and accompanies music using drums", "question": "Do drummers need spare strings?", "answer": false, "facts": ["Drummers usually work with guitarists or other stringed instrumentalists.", "However, drum sets do not contain strings.", "Musicians usually change their own strings as necessary, so it is their band mates, not the drummer, who carries the spare strings."], "decomposition": ["What instruments require strings in order to be played?", "What instrument do drummers play?", "Is there any overlap between #2 and #1?"], "evidence": [[[["String instrument-1"]], [["Drum-1"]], ["operation"]], [[["String instrument-4"]], [["Drum-1"]], [["Drum-1"], "operation"]], [[["String instrument-4"]], [["Drummer-2"]], ["operation"]]]}
{"qid": "a4526fcfad49a21eed15", "term": "Louvre", "description": "Art museum and Historic site in Paris, France", "question": "Can nitric acid break the Louvre?", "answer": true, "facts": ["Parts of the Louvre are built of limestone.", "Nitric acid dissolves limestone."], "decomposition": ["What materials were used to build the Louvre?", "Can any of #1 be destroyed by nitric acid?"], "evidence": [[[["Louvre Pyramid-2"]], [["Nitric acid-18"], "no_evidence", "operation"]], [[["Louvre-21"], "no_evidence"], ["no_evidence"]], [[["Louvre-1"], "no_evidence"], [["Nitric acid-25"], "no_evidence", "operation"]]]}
{"qid": "bfb0f6c573076a1a0634", "term": "Solomon", "description": "king of Israel and the son of David", "question": "Did Solomon make up bigger percentage of Islamic prophets than Kings of Judah?", "answer": false, "facts": ["According to The Quran, Solomon was one of 25 prophets.", "According to some Islamic hadiths, there have been as many as 124,000 prophets.", "Solomon was one of 20 Kings of Judah."], "decomposition": ["According to the Quran, how many prophets were there?", "How many Kings of Judah were there?", "What is 1 divided by #1?", "What is 1 divided by #2?", "Is #3 greater than #4?"], "evidence": [[[["Prophet-23"]], [["Kings of Judah-14"]], ["operation"], ["operation"], ["operation"]], [[["Prophet-23"]], [["David-1", "Zedekiah-1"], "no_evidence"], ["operation"], ["operation"], ["operation"]], [[["Quran-47"], "no_evidence"], [["Kingdom of Judah-1"]], ["no_evidence", "operation"], ["no_evidence", "operation"], ["no_evidence", "operation"]]]}
{"qid": "52e67de035f5274e26f3", "term": "Israelis", "description": "Ethnic group", "question": "Have the Israelis played the Hammerstein Ballroom?", "answer": false, "facts": ["The Israelis are an ethnic group", "The Hammerstein Ballroom is a venue for concerts and musical performances"], "decomposition": ["What kind of groups play in the Hammerstein Ballroom?", "What kind of a group is the Israelis?", "Is #2 included in #1?"], "evidence": [[[["Hammerstein Ballroom-1", "Hammerstein Ballroom-4"]], [["Israelis-1"]], ["operation"]], [[["Hammerstein Ballroom-4"]], [["Israelis-4"]], ["operation"]], [[["Hammerstein Ballroom-1"]], [["Israelis-1"]], ["operation"]]]}
{"qid": "c06605d435462122d1de", "term": "Walt Disney", "description": "American entrepreneur, animator, voice actor and film producer", "question": "Walt Disney dominated his amusement park peers at Academy Awards?", "answer": true, "facts": ["Walt Disney won a total of 26 Academy Awards.", "The founder of Six Flags, Angus G Wynne, had 0 academy awards.", "The founder of Knott's Berry Farm, Walter Knott, had 0 academy awards."], "decomposition": ["At the Academy Awards, how many awards did Walt Disney win?", "At the Academy Awards, how many awards did Angus G Wynne win?", "At the Academy Awards, how many awards did Walter Knott win?", "Is #1 more than #2 and #3?"], "evidence": [[[["Walt Disney-1"]], [["Angus G. Wynne-1"], "no_evidence"], [["Walter Knott-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Walt Disney-1"]], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Walt Disney-1"]], [["Angus G. Wynne-1"]], [["Walter Knott-1"]], ["operation"]]]}
{"qid": "de287a3a87a5ac5197ff", "term": "Toronto Star", "description": "Newspaper in Toronto, Ontario, Canada", "question": "Can someone sell their time through the Toronto Star?", "answer": true, "facts": ["The Toronto Star has a classifieds section", "Readers can advertise their own labor or services and thus their time "], "decomposition": ["What section of the Toronto Star lists things for sale?", "Can someone's services or labor be sold in #1?"], "evidence": [[[["Toronto Star-31"]], [["Classified advertising-1"]]], [[["Toronto Star-31"]], [["Classified advertising-1"], "operation"]], [[["Toronto Star-31"]], ["operation"]]]}
{"qid": "38b57970d1b2ba8279b8", "term": "Christopher Columbus", "description": "Italian explorer, navigator, and colonizer", "question": "Did Christopher Columbus sail representing a different country than his original home?", "answer": true, "facts": ["Columbus was originally from Genoa in what is now Italy.", "His expeditions were funded by the Spanish monarchy."], "decomposition": ["What country was Christopher Columbus born in?", "What country did Christopher Columbus sail for?", "Is #1 different than #2?"], "evidence": [[[["Christopher Columbus-5"]], [["Christopher Columbus-80"]], [["Christopher Columbus-80"]]], [[["Christopher Columbus-5"]], [["Christopher Columbus-1"]], ["operation"]], [[["Christopher Columbus-5"]], [["Christopher Columbus-30"]], ["operation"]]]}
{"qid": "102db3a12d5a45bf7a2a", "term": "RoboCop", "description": "1987 science fiction film directed by Paul Verhoeven", "question": "Is RoboCop director from same country as Gaite Jansen?", "answer": true, "facts": ["Robocop was directed by Paul Verhoeven.", "Paul Verhoeven was born in Amsterdam, Netherlands.", "Gaite Jansen is an actress known for Jett and Peaky Blinders and was born in Rotterdam, Netherlands."], "decomposition": ["Who is the director of the movie RoboCop?", "Where was #1 born?", "Where was Gaite Jansen born?", "Are #2 and #3 the same?"], "evidence": [[[["RoboCop-1"]], [["Paul Verhoeven-1", "Paul Verhoeven-4"]], [["Gaite Jansen-1"]], ["operation"]], [[["RoboCop-1"]], [["Paul Verhoeven-4"]], [["Gaite Jansen-1"]], ["operation"]], [[["RoboCop-13"]], [["Paul Verhoeven-4"]], [["Gaite Jansen-1"]], ["operation"]]]}
{"qid": "8cab175fdcffeba3ec52", "term": "Eurovision Song Contest", "description": "Annual song competition held among the member countries of the European Broadcasting Union", "question": "Can actress Dafne Keen win the Eurovision Song Contest finals in 2020?", "answer": false, "facts": ["Contestants must be at least 16 years of age to compete in the finals of Eurovision Song Contest.", "Dafne Keen is 15 years old in 2020."], "decomposition": ["What is the minimum age for constests on  \"Eurovision Song Contest\"?", "How old is Dafne Keen?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Eurovision Song Contest-68"], "no_evidence"], [["Dafne Keen-1"], "no_evidence"], ["operation"]], [[["Rules of the Eurovision Song Contest-11"]], [["Dafne Keen-1"]], ["operation"]], [[["Eurovision Song Contest-68"]], [["Dafne Keen-1"]], ["operation"]]]}
{"qid": "1647d6f49307d7678d18", "term": "Anorexia nervosa", "description": "Eating disorder characterized by refusal to maintain a healthy body weight, and fear of gaining weight due to a distorted self image", "question": "Would a person with Anorexia nervosa be more likely to break a bone than a regular person?", "answer": true, "facts": ["People with Anorexia Nervosa restrict food and as a result lack essential nutrients.", "Many people with Anorexia Nervosa, are at high risk for osteoporosis(and to a lesser extent bulimia nervosa) will have low bone density and consequently reduced bone strength.", "People with Anorexia Nervosa, are at high risk for osteoporosis. "], "decomposition": ["What kind of eating behavior do people with anorexia nervosa exhibit?", "Does #1 lead to reduced bone strength?"], "evidence": [[[["Anorexia nervosa-1"]], [["Osteoporosis-1"], "operation"]], [[["Anorexia nervosa-1"]], [["Anorexia nervosa-54"]]], [[["Anorexia nervosa-4"]], [["Malnutrition-3"]]]]}
{"qid": "e1cce18241839245a516", "term": "Agnosticism", "description": "view that the existence of any deity is unknown or unknowable", "question": "Does Billy Graham support agnosticism?", "answer": false, "facts": ["Bill Graham was a prominent American evangelical leader.", "In Christianity, evangelism is the commitment to or act of publicly preaching (ministry) of the Gospel with the intention to share the message and teachings of Jesus Christ. ", "Agnosticism is the belief that humanity is unsure if God exists.", "Evangelical Christians share the belief that God exists."], "decomposition": ["What religion does Billy Graham subscribe to?", "Does #1 allow for the uncertainty of God's existence?"], "evidence": [[[["Billy Graham-1"]], [["Evangelicalism-1"], "no_evidence", "operation"]], [[["Billy Graham-1"]], [["Evangelicalism-1"], "operation"]], [[["Billy Graham-1"]], [["Evangelicalism-1"]]]]}
{"qid": "a16ec88f41867d97f60a", "term": "Charles Manson", "description": "American criminal, cult leader", "question": "Has Don King killed more people than Charles Manson did with his own hands in 1971?", "answer": true, "facts": ["Charles Manson is famous for a series of murders in 1971.", "Charles Manson's cult was responsible for seven deaths in 1971 but he was not present during the murders.", "Boxing promoter Don King has been charged with killing two people in incidents 13 years apart and settled out of court.."], "decomposition": ["How many people did Charles Manson actually kill?", "Don King has been charged with killing how many people?", "Is #2 larger than #1?"], "evidence": [[[["Charles Manson-1"]], [["Don King (boxing promoter)-3"]], [["Charles Manson-1", "Don King (boxing promoter)-3"], "operation"]], [[["Charles Manson-1"]], [["Don King (boxing promoter)-1"]], ["operation"]], [[["Charles Manson-1"], "no_evidence"], [["Don King (boxing promoter)-3"]], ["operation"]]]}
{"qid": "25a088d9d2ce674e639a", "term": "Grapefruit", "description": "citrus fruit", "question": "Can eating grapefruit kill besides allergies or choking?", "answer": true, "facts": ["Grapefruit is a citrus fruit consumed mostly during the summer months.", "Chemicals in grapefruit can interact with medications such as statins.", "Grapefruit can lead to too much absorption of statin medicine.", "Too much statins can cause severe muscle pain, liver damage, kidney failure and death. "], "decomposition": ["What health risks associated with eating grapefruit could lead to death?", "Is #1 more than just allergy and choking?"], "evidence": [[[["Grapefruit-16"]], [["Grapefruit-16"]]], [[["Grapefruit-18"]], [["Drug overdose-1"]]], [[["Grapefruit\u2013drug interactions-3"]], ["operation"]]]}
{"qid": "ba04b5ebc2edd682c4dd", "term": "The Matrix", "description": "1999 science fiction action film directed by the Wachowskis", "question": "Is the Matrix a standalone movie?", "answer": false, "facts": ["The Matrix ends in a cliffhanger.", "The story is then resolved in two sequels, making a trilogy.", "There are also supplemental works adding to the story, such as a video game and the Animatrix."], "decomposition": ["How many movies are in The Matrix franchise?", "Is #1 equal to one?"], "evidence": [[[["The Matrix (franchise)-9"]], [["The Matrix (franchise)-9"], "operation"]], [[["The Matrix (franchise)-1"]], ["operation"]], [[["The Matrix-49"]], ["operation"]]]}
{"qid": "3d55b2ce338f4e2cdcf4", "term": "Augustus", "description": "First emperor of the Roman Empire", "question": "Was Augustus his real name?", "answer": false, "facts": ["Augustus was given the name Gaius Octavius at birth.", "After he was adopted by his uncle Julius Caesar, he took the name Gaius Iulius Caesar.", "He took the name Augustus upon the breaking of the ruling Triumvirate and becoming Emperor."], "decomposition": ["What name did Augustus have when he was born?", "Is #1 identical to Augustus?"], "evidence": [[[["Augustus-2"]], ["operation"]], [[["Augustus-2"]], ["operation"]], [[["Augustus-2"]], ["operation"]]]}
{"qid": "6bed2a566da292a36593", "term": "Rice pudding", "description": "Dish made from rice mixed with water or milk", "question": "Would Cyndi Lauper use milk substitute in her rice pudding?", "answer": true, "facts": ["Cyndi Lauper wrote a song about lactose intolerance.", "Lactose intolerance leads to gastrointestinal discomfort upon eating dairy."], "decomposition": ["What conditions lead people to using milk substitutes?", "Does Cyndi Lauper suffer from any conditions listed in #1?"], "evidence": [[[["Lactose intolerance-1", "Veganism-1"]], [["Cyndi Lauper-1"], "no_evidence", "operation"]], [[["Milk allergy-9"]], [["Cyndi Lauper-76"], "no_evidence"]], [[["Milk substitute-17"]], ["no_evidence"]]]}
{"qid": "5c27625de0e7c35be856", "term": "Tony Bennett", "description": "American singer", "question": "Is Tony Bennett's middle name shared by a former UFC champion?", "answer": true, "facts": ["Tony Bennett's full name is Anthony Dominick Benedetto.", "Dominick Cruz is a two-time UFC Bantamweight Champion."], "decomposition": ["What is Tony Bennett's middle name?", "What are the names of the former UFC champions?", "Is #1 found in #2?"], "evidence": [[[["Tony Bennett-1"]], [["Dominick Cruz-1"]], ["operation"]], [[["Tony Bennett-1"]], [["Dominick Cruz-1"]], ["operation"]], [[["Tony Bennett-1"]], [["Dominick Reyes-1"], "no_evidence"], ["operation"]]]}
{"qid": "7419826e4373eb1e83ff", "term": "Grey seal", "description": "species of seal", "question": "Would a dog respond to bell before Grey seal?", "answer": true, "facts": ["Grey seals have no ear flaps and their ears canals are filled with wax.", "Grey seals hear better underwater when their ears open like a valve.", "Dogs have sensitive ears that can hear as far as a quarter of a mile away."], "decomposition": ["How sensitive is a grey seal's hearing on land?", "How sensitive is a dog's hearing on land?", "Is #2 better than #1?"], "evidence": [[[["Pinniped-24"]], [["Hearing range-11", "Hertz-5"]], ["operation"]], [[["Grey seal-1"], "no_evidence"], [["Dog-54"], "no_evidence"], ["no_evidence", "operation"]], [[["Grey seal-1"], "no_evidence"], [["Dog anatomy-114"]], ["operation"]]]}
{"qid": "9467c294f175d06473c3", "term": "Judo", "description": "modern martial art, combat and Olympic sport", "question": "Does the judo rank system reach the triple digits?", "answer": false, "facts": ["A triple digit number would be equal to at least 100.", "The judo dan-rank system was capped at 10th dan after the death of judo's founder, Kan\u014d Jigor\u014d."], "decomposition": ["Was is the lowest three digit number?", "What is the highest rank a person can reach in Judo?", "Is #2 a higher number than #1?"], "evidence": [[[["100-1", "Numerical digit-1"]], [["Judo-55"]], ["operation"]], [[["Numerical digit-1"], "no_evidence"], [["Rank in Judo-6"]], ["operation"]], [[["100-1"]], [["Judo-55"]], ["operation"]]]}
{"qid": "01844485471f396ee9ef", "term": "Edward Snowden", "description": "American whistleblower and former National Security Agency contractor", "question": "Is Edward Snowden in hiding from the United States?", "answer": false, "facts": ["Edward Snowden has an active twitter account and has been on political commentary shows.", "Edward Snowden's country of residence is listed on his Wikipedia."], "decomposition": ["Where does Edward Snowden live?", "Is the location of #1 kept secret?"], "evidence": [[[["Edward Snowden-77"]], [["Edward Snowden-77"], "operation"]], [[["Edward Snowden-78"]], [["Edward Snowden-78"], "no_evidence"]], [[["Edward Snowden-78"]], ["operation"]]]}
{"qid": "f1895e4df6287a560a08", "term": "Binary number", "description": "system that represents numeric values using two symbols; 0 and 1", "question": "Can binary numbers and standard alphabet satisfy criteria for a strong password?", "answer": false, "facts": ["The criteria for a strong password according to cybersecurity company Avast is: at least 15 characters. uppercase letters. lowercase letters. numbers. and symbols.", "The standard alphabet contains twenty six letters but no special characters.", "Binary numbers only contain 0 and 1."], "decomposition": ["Which characters make up binary numbers?", "Which characters make up the standard English alphabet", "Does #1 or #2 include special characters or symbols?"], "evidence": [[[["English alphabet-1"], "no_evidence"], [["Binary number-1"]], ["operation"]], [[["Binary number-1"]], [["Alphabet-1"]], [["Password strength-13"], "operation"]], [[["Binary number-1"]], [["English alphabet-1"]], ["no_evidence"]]]}
{"qid": "b6d02dc46dfc49f32984", "term": "Whole genome sequencing", "description": "A process that determines the complete DNA sequence of an organism's genome at a single time", "question": "Can whole genome sequencing be used for COVID-19?", "answer": false, "facts": ["Whole genome sequencing is used to analyze DNA", "RNA viruses do not have DNA", "COVID-19 is an RNA virus."], "decomposition": ["What does the whole genome sequencing process determine?", "Which virus is responsible for COVID-19?", "Does #2 have #1?"], "evidence": [[[["Whole genome sequencing-6"]], [["Coronavirus-1"]], [["Coronavirus-1"], "operation"]], [[["Whole genome sequencing-1"]], [["Coronavirus-1"]], [["RNA virus-1", "RNA virus-2"], "operation"]], [[["Whole genome sequencing-1"]], [["Coronavirus disease-8"]], [["Positive-sense single-stranded RNA virus-1"]]]]}
{"qid": "979b4b0fa0a8606bfcae", "term": "Lecturer", "description": "tenure-track or tenured position at a university or similar institution", "question": "Would Quiet from Metal Gear be a poor hypothetical choice for lecturer at Haub?", "answer": true, "facts": ["Quiet is an assassin from the Metal Gear video game series that does not speak.", "Haub is a school at Pace University that has annual lectures.", "Haub is a law school that has annual lectures on topics in the law field."], "decomposition": ["Who is Quiet?", "What is #1 unable to do?", "How does one convey information as a lecturer?", "Is #2 the same as #3?"], "evidence": [[[["Quiet (Metal Gear)-1"]], [["Quiet (Metal Gear)-5"]], [["Lecture-1"]], ["operation"]], [[["Quiet (Metal Gear)-1"]], [["Quiet (Metal Gear)-7"]], [["Lecture-1"]], ["operation"]], [[["Quiet (Metal Gear)-1"]], [["Quiet (Metal Gear)-7"]], [["Lecture-1"]], ["operation"]]]}
{"qid": "45ff478a039792001dbc", "term": "Harvey Milk", "description": "American politician who became a martyr in the gay community", "question": "Would Harvey Milk have approved of Obama?", "answer": true, "facts": ["Obama awarded Harvey Milk a posthumous Medal of Freedom. ", "Obama was known for supporting marriage equality and LGBT rights. "], "decomposition": ["What was Harvey Milk known for?", "Did Obama support #1?", "Is #1 the same as #2?"], "evidence": [[[["Harvey Milk-1"]], [["Barack Obama-4"]], ["operation"]], [[["Harvey Milk-1"]], [["Barack Obama-4"]], ["operation"]], [[["Harvey Milk-4"]], [["Stuart Milk-4"]], ["operation"]]]}
{"qid": "dfe89f86d25ea26ab85d", "term": "Monty Python's Flying Circus", "description": "British sketch comedy television series", "question": "Did Monty Python write the Who's on First sketch?", "answer": false, "facts": ["Who's on First debuted in 1945.", "Monty Python's first show was in 1969."], "decomposition": ["When was the Who's on First sketch first performed?", "When was the debut of the Monty Python show?", "Is #2 before #1?"], "evidence": [[[["Who's on First?-2"]], [["Monty Python-1"]], ["operation"]], [[["Abbott and Costello-25", "Who's on First?-3"]], [["Monty Python's Flying Circus-16"]], ["operation"]], [[["Who's on First?-2", "Who's on First?-3"]], [["Monty Python-1"]], ["operation"]]]}
{"qid": "858feef04ea972946401", "term": "Family Guy", "description": "American animated sitcom", "question": "Does Family Guy take place on the American West Coast?", "answer": false, "facts": ["Family Guy takes place in the fictional town of Quahog, Rhode Island.", "Rhode Island is a state on the American East Coast."], "decomposition": ["Where is Family Guy set?", "Is #1 on the American West Coast?"], "evidence": [[[["Family Guy-1"]], [["Rhode Island-1"]]], [[["Rhode Island-89"]], [["West Coast of the United States-1"]]], [[["Family Guy-9"]], [["Rhode Island-34"], "operation"]]]}
{"qid": "bc429593abdbd062e8d2", "term": "Toyota Hilux", "description": "Series of light commercial vehicles produced by the Japanese car-manufacturer Toyota.", "question": "Can a 2019 Toyota Hilux hypothetically support weight of thirty Big John Studd clones?", "answer": false, "facts": ["The 2019 Toyota Hilux has a maximum carry load of 3500kg or, around 7,700 pounds.", "Big John Studd was a professional wrestler that weighed 364 pounds."], "decomposition": ["What is the maximum carry load weight of a Toyota Hilux?", "How much did Big John Studd weigh?", "What is #2 multiplied by 30?", "Is #1 greater than or equal to #3?"], "evidence": [[["no_evidence"], ["no_evidence"], ["no_evidence", "operation"], ["no_evidence", "operation"]], [[["Toyota Hilux-1"], "no_evidence"], [["Big John Studd-14"], "no_evidence"], ["operation"], ["operation"]], [[["Toyota Hilux-1"], "no_evidence"], [["Big John Studd-1", "NWA Mid-Atlantic Heavyweight Championship-4"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "2b69557b4f4f87193f1c", "term": "Nine Inch Nails", "description": "American industrial rock band", "question": "Is Nine Inch Nails's lead singer associated with David Lynch?", "answer": true, "facts": ["David Lynch is a director that created the television show Twin Peaks.", "Trent Reznor is the lead singer of Nine Inch Nails.", "Trent Reznor appeared on Twin Peaks: The Return in 2017.", "David Lynch directed the music video for Nine Inch Nail's Came Back Haunted."], "decomposition": ["Who is the lead singer of Nine Inch Nails?", "What works has #1 appeared in?", "What are the works of David Lynch?", "Is there overlap between #2 and #3?"], "evidence": [[[["Trent Reznor-1"]], [["Trent Reznor-29"]], [["Trent Reznor-29"]], ["operation"]], [[["Trent Reznor-1"]], [["Trent Reznor-29"], "no_evidence"], [["David Lynch-1"], "no_evidence"], ["operation"]], [[["Nine Inch Nails-1"]], [["Part 8 (Twin Peaks)-13", "Trent Reznor-3"], "no_evidence"], [["David Lynch-1"], "no_evidence"], ["operation"]]]}
{"qid": "361f7e0cd93f9826b7f6", "term": "Myocardial infarction", "description": "Interruption of blood supply to a part of the heart", "question": "Is myocardial infarction a brain problem?", "answer": false, "facts": ["Myocardial infarction is a problem in the heart.", "The equivalent in the brain would be similar to a stroke."], "decomposition": ["Which organ in the body does myocardial infarction affect?", "Is #1 the same as the brain?"], "evidence": [[[["Myocardial infarction-1"]], ["operation"]], [[["Myocardial infarction-1"]], [["Brain-1"], "operation"]], [[["Myocardial infarction-1"]], ["operation"]]]}
{"qid": "6a01b523e0140f21c426", "term": "Mediterranean Sea", "description": "Sea connected to the Atlantic Ocean between Europe, Africa and Asia", "question": "Did a Mediterranean Sea creature kill Steve Irwin?", "answer": true, "facts": ["Steve Irwin was killed by a Stingray animal.", "Batoids are sea ray animals that live in the Mediterranean Sea.", "Batoids and stingrays are related by sharing a scientific class of Chondrichthyes."], "decomposition": ["Which animal killed Steve Irwin?", "Is #1 a sea creature"], "evidence": [[[["Steve Irwin-35"]], [["Stingray-2"]]], [[["Steve Irwin-35"]], [["Broad stingray-4", "Great Barrier Reef-7"]]], [[["Steve Irwin-35"]], [["Stingray-1"]]]]}
{"qid": "d22a8c50ff6a652dd49e", "term": "Heracles", "description": "divine hero in Greek mythology, son of Zeus and Alcmene", "question": "Were all of Heracles's children present for his funeral pyre?", "answer": false, "facts": ["Heracles killed his children by his first wife Megara.", "They were not returned to life prior to his death."], "decomposition": ["What did Heracles do to his children by his first wife?", "Are people who have been #1 able to come back to life?"], "evidence": [[[["Heracles-21"], "no_evidence"], [["Death-11"], "operation"]], [[["Megara (mythology)-4"]], [["Death (disambiguation)-1"], "operation"]], [[["Megara (mythology)-4"]], ["operation"]]]}
{"qid": "122724772ba385a713a6", "term": "Johns Hopkins University", "description": "Private research university in Baltimore, Maryland", "question": "Could the endowment of Johns Hopkins University pay off the MBTA debt?", "answer": false, "facts": ["Johns Hopkins University had an endowment of $6.28 billion in 2019.", "The MBTA is in debt for approximately $9 billion."], "decomposition": ["How much was Johns Hopkins University endowment in 2019?", "How much is the MBTA debt?", "Is #1 greater than #2?"], "evidence": [[["no_evidence"], [["Massachusetts Bay Transportation Authority-91"]], ["operation"]], [[["Johns Hopkins University-11"], "no_evidence"], [["Massachusetts Bay Transportation Authority-90", "Massachusetts Bay Transportation Authority-91"], "no_evidence"], ["operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "fc60a290ab2e9a467f1c", "term": "Spinach", "description": "species of plant", "question": "For bone growth, is kale more beneficial than spinach?", "answer": true, "facts": ["Calcium is an important nutrient for bone health.", "Kale has more calcium per serving than spinach."], "decomposition": ["What nutrient is critical for bone growth?", "How much #1 does kale contain?", "How much #1 does spinach contain?", "Is #2 greater than #3?"], "evidence": [[[["Bone growth factor-3"]], [["Kale-11"]], [["Spinach-7"]], ["operation"]], [[["Calcium-36"]], [["Kale-11"]], [["Spinach-7"]], ["operation"]], [[["Calcium-3"]], [["Kale-11"], "no_evidence"], [["Spinach-7"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "a895b73bdfb2397b2e27", "term": "Friday", "description": "day of the week", "question": "Does 2015 have more unlucky Friday's than usual?", "answer": true, "facts": ["Friday the 13th is known as an unlucky Friday because of the number 13.", "A year can have as many as three Friday the 13ths.", "One Friday the 13th is the average per year.", "There were 3 Friday the 13ths in 2015."], "decomposition": ["How many Friday the 13ths were in 2015?", "What is the usual number of Friday the 13ths per year?", "Is #1 more than #2?"], "evidence": [[[["Friday the 13th-1"]], [["Friday the 13th-1"]], ["operation"]], [[["Friday the 13th-1"]], [["Friday the 13th-1"]], ["operation"]], [[["Friday the 13th-25"]], [["Friday the 13th-1"]], ["operation"]]]}
{"qid": "c664e847b957da434f15", "term": "Hair", "description": "protein filament that grows from follicles found in the dermis, or skin", "question": "Is it safe to eat hair?", "answer": true, "facts": ["Hair is made of keratin.", "Food manufacturers use L-cysteine as a food additive.", "L-cysteine is made from keratin."], "decomposition": ["What is hair made of?", "What else is made from #1?", "Are any of #2 used in food production?"], "evidence": [[[["Hair-2"]], [["Alpha-keratin-1"]], ["no_evidence", "operation"]], [[["Hair-6"]], [["Hair-6"]], [["Food-1"]]], [[["Hair-1"]], [["Beef-1"]], [["Hamburger-1"], "operation"]]]}
{"qid": "5b0a4c75f55575ae7e83", "term": "Lieutenant", "description": "junior commissioned officer in many nations' armed forces", "question": "Would Gomer Pyle salute a lieutenant?", "answer": true, "facts": ["Gomer Pyle was a character on a television sitcom", "Pyle was in the US Marine Corp", "Lieutenants are junior commissioned officers in the USMC", "Marine custom dictates that officers are to be saluted by other Marines"], "decomposition": ["Which arm of the US Armed Forces did Gomer Pyle join?", "What was his rank in the #1?", "According to #1 tradition. would a #2 salute a lieutenant?"], "evidence": [[[["Gomer Pyle-4"]], [["Private first class-8"]], [["Lieutenant-1"], "operation"]], [[["Gomer Pyle, U.S.M.C.-2"]], [["Gomer Pyle, U.S.M.C.-12"]], [["Private (rank)-1"]]], [[["Gomer Pyle-7"]], [["Gomer Pyle-8"]], [["Lieutenant-12", "Salute-57"], "no_evidence"]]]}
{"qid": "99b23da6c0f8ad0fc0ea", "term": "Crustacean", "description": "subphylum of arthropods", "question": "Can the largest crustacean stretch out completely on a king-sized mattress?", "answer": false, "facts": ["The largest crustacean is the Japanese spider crab ", "The largest Japanese spider crabs have a leg span of just over 12 feet ", "The longer edge of a king-sized mattress is six feet, eight inches"], "decomposition": ["What is the largest crustacean?", "How long is the largest #1?", "How long is a king-sized matress?", "Is #2 smaller than #3?"], "evidence": [[[["Japanese spider crab-1"]], [["Japanese spider crab-2"]], [["Bed size-6"], "no_evidence"], ["operation"]], [[["Crustacean-15"]], [["Crustacean-15"]], [["Mattress-8"], "no_evidence"], ["operation"]], [[["Japanese spider crab-1"]], [["Crustacean-15"]], [["Bed size-17"]], ["operation"]]]}
{"qid": "24fc2cfc65f5230e2cd4", "term": "Morphine", "description": "Pain medication of the opiate family", "question": "Could morphine cure HIV?", "answer": false, "facts": ["Morphine is an opioid that is used to treat pain.", "HIV is a virus that has no known cure, but can be treated with anti-retroviral drugs."], "decomposition": ["What is morphine used to treat?", "What type of system is affected by contraction of HIV?", "Will treatment of #1 cure HIV-infected #2?"], "evidence": [[[["Morphine-1"]], [["HIV-2"]], [["HIV-49"], "operation"]], [[["Morphine-1"]], [["HIV-1"]], ["operation"]], [[["Morphine-1"]], [["HIV-2"]], [["HIV-49"], "operation"]]]}
{"qid": "b24d019c3f205bafdea5", "term": "Euphoria", "description": "mental and emotional condition in which a person experiences intense feelings of well-being, elation, happiness and excitement", "question": "Did Rumi spend his time in a state of euphoria?", "answer": true, "facts": ["Euphoria is a state in which people experience intense feelings that overwhelm their body.", "Rumi was a 13th century Persian poet that was also a dervish.", "Dervishes participated in ceremonies in which they experienced religious ecstasy.", "Religious ecstasy is an altered state of consciousness characterized by visions and emotional (and sometimes physical) euphoria."], "decomposition": ["What religious practices did Rumi engage in?", "What emotional experiences are associated with #1?", "Is euphoria among #2?"], "evidence": [[[["Rumi-1", "Sufi whirling-1"]], [["Sufi whirling-5"]], ["operation"]], [[["Rumi-1"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Rumi-1"]], [["Sufism-75"]], [["Ecstasy (emotion)-8"], "operation"]]]}
{"qid": "9e78c01675a198781cca", "term": "Michael Bloomberg", "description": "American billionaire businessman and politician, former mayor of New York City", "question": "Can Michael Bloomberg fund the debt of Micronesia for a decade?", "answer": true, "facts": ["Michael Bloomberg is worth an estimated 60 billion dollars as of 2020.", "Micronesia has annual expenses of nearly 200 million dollars."], "decomposition": ["What is Micheal Bloomberg's worth?", "What is the annual expense for Micronesia?", "Is #1 greater than #2?"], "evidence": [[[["Michael Bloomberg-2"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Michael Bloomberg-2"]], [["Micronesia-31"], "no_evidence"], ["no_evidence", "operation"]], [[["Michael Bloomberg-2"]], [["Economy of the Federated States of Micronesia-7"]], ["operation"]]]}
{"qid": "acb372237880dc80c4a1", "term": "Post Malone", "description": "American singer, rapper, songwriter, and record producer", "question": "Does Post Malone have a fear of needles?", "answer": false, "facts": ["Post Malone's body is covered with many tattoos.", "The most common method of tattooing in modern times is the electric tattoo machine, which inserts ink into the skin via a single needle or a group of needles that are soldered onto a bar, which is attached to an oscillating unit."], "decomposition": ["What is Post Malone known for having on his body and face?", "Does getting #1 not involve the use of needles?"], "evidence": [[[["Post Malone-27"]], [["Tattoo-49"]]], [[["Post Malone-27"]], [["Tattoo-51"], "operation"]], [[["Post Malone-27"]], [["Tattoo-51"]]]]}
{"qid": "8b9f3835041b7bbc30a3", "term": "Crucifixion", "description": "Method of capital punishment in which the victim is tied or nailed to a large wooden beam and left to hang until eventual death", "question": "If it socially acceptable to wear an icon depicting crucifixion? ", "answer": true, "facts": ["The crucifixion of Jesus is a common sign used by Catholics and Christian denominations. ", "Many jewelry stores offer necklaces with the Crucifixion of Jesus Christ."], "decomposition": ["Which common symbol is used by Catholics to depict crucifixion?", "Is #1 commonly found in jewelry stores?"], "evidence": [[[["Christian symbolism-6"], "no_evidence"], [["Christian cross variants-3"], "operation"]], [[["Crucifix-2"]], [["Crucifix-12"], "no_evidence", "operation"]], [[["Crucifixion-2"]], ["no_evidence"]]]}
{"qid": "811081ee6a24ee0f7177", "term": "Arithmetic", "description": "Elementary branch of mathematics", "question": "Did Neanderthals use arithmetic?", "answer": false, "facts": ["The earliest written records indicate the Egyptians and Babylonians used all the elementary arithmetic operations as early as 2000 BC.", "Neanderthals are an extinct species or subspecies of archaic humans who lived in Eurasia until about 40,000 years ago."], "decomposition": ["The earliest records of arithmetic use date back to when?", "When did the Neanderthals become extinct?", "Is #1 before #2?"], "evidence": [[[["Arithmetic-2"]], [["Neanderthal-1"]], ["operation"]], [[["Arithmetic-2"]], [["Neanderthal-2"]], [["Neanderthal-2"], "operation"]], [[["History of mathematics-10"]], [["Neanderthal extinction-1"]], ["operation"]]]}
{"qid": "84235f18202b0fe962f2", "term": "Bonanza", "description": "1959-1973 American western/cowboy television series", "question": "Would Bonanza marathon end before WWE Heat marathon?", "answer": false, "facts": ["Bonanza had a total of 431 episodes.", "WWE Heat had a total of 513 episodes.", "The average run time of WWE Heat was 45 minutes.", "The average run time of Bonanza was 49 minutes."], "decomposition": ["How many episodes exist of Bonanza?", "How many episodes exist of WWE Heat?", "How long is each episode of Bonanza?", "How long is each episode of WWE Heat?", "Is #1 times #3 less than #2 times #4?"], "evidence": [[[["Bonanza-30"]], [["WWE Heat-11"]], ["no_evidence"], ["no_evidence"], ["operation"]], [[["Bonanza-30"]], [["WWE Heat-3"]], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Bonanza-1"]], [["WWE Heat-11"]], [["Bonanza-19", "Bonanza-33"], "no_evidence"], [["WWE Heat-4"]], ["operation"]]]}
{"qid": "2c774c2108bfaef1032c", "term": "Internet slang", "description": "Slang languages used by different people on the Internet", "question": "Did Alfred Hitchcock include internet slang in his films?", "answer": false, "facts": ["Alfred Hitchcock died in 1908.", "The internet began developing slang in the 1990's."], "decomposition": ["What year did Alfred Hitchcock die?", "When did internet become available for people?", "Is #1 after #2?"], "evidence": [[[["Alfred Hitchcock-1"]], [["History of the World Wide Web-11"]], ["operation"]], [[["Alfred Hitchcock-1"]], [["World Wide Web-2"]], ["operation"]], [[["Alfred Hitchcock-70"]], [["Internet-10"]], ["operation"]]]}
{"qid": "3ba4e4cd6db5e42e06b0", "term": "Ham", "description": "Pork from a leg cut that has been preserved by wet or dry curing, with or without smoking", "question": "Did Malcolm X avoid eating ham?", "answer": true, "facts": ["Malcolm X was a practicing Muslim", "Muslims are prohibited from eating foods derived from pigs"], "decomposition": ["What religion did Malcolm X practice?", "Does #1 forbid its believers eating pig products?"], "evidence": [[[["Malcolm X-1"]], ["operation"]], [[["Malcolm X-1"]], [["Islamic culture-45"]]], [[["Malcolm X-50"]], [["Islamic culture-45"]]]]}
{"qid": "48648780e56f136fdae5", "term": "Pandora", "description": "Mythological figure", "question": "Were items released from Pandora's box at least two of the names of Four Horsemen?", "answer": true, "facts": ["Pandora was a mythical figure that opened a box and released several ills on the world including famine, sickness, and death.", "The Four Horsemen of the Apocalypse are: Pestilence, War, Famine, and Death."], "decomposition": ["What items were released from Pandora's box?", "What were the names of the Four Horsemen", "Is there any overlap between #1 and #2?"], "evidence": [[[["Pandora's box-2"]], [["Four Horsemen of the Apocalypse-3"]], [["Four Horsemen of the Apocalypse-3", "Pandora's box-2"]]], [[["Pandora's box-2", "Pandora's box-31"]], [["Four Horsemen of the Apocalypse-5", "Horsemen of Apocalypse-7"], "no_evidence"], ["no_evidence", "operation"]], [[["Pandora's box-2"]], [["Four Horsemen of the Apocalypse-3"]], ["operation"]]]}
{"qid": "5f267b7c20090236a2fb", "term": "Beauty and the Beast", "description": "traditional fairy tale", "question": "Were Beauty and the Beast adaptations devoid of Kurt Sutter collaborators?", "answer": false, "facts": ["Beauty and the Beast is a fairy tale adapted into several movie and TV shows.", "Kurt Sutter created the TV series Sons of Anarchy and The Shield.", "Charlie Hunnam and Ron Perlman starred in Sons of Anarchy.", "Ron Perlman starred in the TV series Beauty and the Beast which aired from 1987-1990."], "decomposition": ["Which characters were featured in Kurt Sutter's Sons of Anarchy and The Shield?", "Which characters were featured in TV series Beauty and the Beast?", "Is there no character common to #1 and #2?"], "evidence": [[[["Clay Morrow-1", "The Shield-1"], "no_evidence"], [["Beauty and the Beast (1987 TV series)-13"]], [["Ron Perlman-1"], "operation"]], [[["Clay Morrow-1"], "no_evidence"], [["Ron Perlman-5"], "no_evidence"], ["operation"]], [[["Ron Perlman-1", "The Shield-1"]], [["Beauty and the Beast (1987 TV series)-1"]], ["operation"]]]}
{"qid": "deea92d9c38f95fef4a8", "term": "Swallow", "description": "family of birds", "question": "Can an ostrich fit into the nest of a swallow?", "answer": false, "facts": ["Swallows weigh less than an ounce.", "An ostrich can weigh over 200 pounds."], "decomposition": ["How much does a swallow weigh?", "How much does an ostrich weigh?", "Is #2 within 20% of #1?"], "evidence": [[[["Swallow-7"]], [["Common ostrich-5"]], ["operation"]], [[["Swallow-7"]], [["Common ostrich-5"]], ["operation"]], [[["Swallow-7"]], [["Common ostrich-5"]], ["operation"]]]}
{"qid": "8b41a17e65ef7f6e22b5", "term": "Advertising", "description": "Form of communication for marketing, typically paid for", "question": "During the pandemic, is door to door advertising considered inconsiderate?", "answer": true, "facts": ["Door to door advertising involves someone going to several homes in a residential area to make sales and leave informational packets.", "During the COVID-19 pandemic, the CDC recommends that people limit their travel to essential needs only.", "During the COVID-19 pandemic, citizens are advised to stay home and to limit their interaction with others.", "During the COVID-19 pandemic, people are encouraged to remain six feet away from each other at all times.", "The more people that someone interacts with, the higher the likelihood of them becoming a vector for the COVID-19 virus."], "decomposition": ["What does door to door advertising involve a person to do?", "During the COVID-19 pandemic, what does the CDC advise people to do in terms of traveling?", "During the COVID-19 pandemic, what does the CDC advise people to do in terms of interaction with others?", "Does doing #1 go against #2 and #3?"], "evidence": [[[["Door-to-door-1"]], [["Cloth face mask-12"]], ["no_evidence"], ["operation"]], [[["Door-to-door-1"]], [["Coronavirus recession-13"]], [["Social distancing-30"]], ["operation"]], [[["Door-to-door-1"]], [["Stay-at-home order-18"], "no_evidence"], [["Social distancing-1"]], ["operation"]]]}
{"qid": "58860d3595c8eb1f4690", "term": "Skull", "description": "bony structure that forms the skeleton of head in most vertebrates", "question": "Is the skull formed as one whole bone?", "answer": false, "facts": ["The skull forms inwards from the outside.", "There are fission lines where the multiple pieces of bone came together to form a skull. "], "decomposition": ["How many bones are found in the skull?", "Is #1 equal to one?"], "evidence": [[[["Skull-10"]], ["operation"]], [[["Skull-1"]], ["operation"]], [[["Skull-10"]], ["operation"]]]}
{"qid": "373634846d34dafefcff", "term": "Phobos (moon)", "description": "natural satellite of Mars", "question": "Is Phobos part of the Andromeda galaxy?", "answer": false, "facts": ["Phobos orbits around Mars.", "Mars is a planet in Earth's solar system.", "The solar system is in the Milky Way galaxy."], "decomposition": ["What planet does Phobos orbit around?", "What solar system is #1 part of?", "What galaxy is #2 part of?", "Is #3 the same as the Andromeda galaxy?"], "evidence": [[[["Phobos (moon)-1"]], [["Mars-1"]], [["Milky Way-1"]], [["Andromeda Galaxy-1"]]], [[["Phobos (moon)-1"]], [["Solar System-2"]], [["Milky Way-1"]], ["operation"]], [[["Phobos (moon)-16"]], [["Solar System-37"]], [["Solar System-73"]], ["operation"]]]}
{"qid": "bdb553a709a06b79ed91", "term": "Snoopy", "description": "cartoon dog", "question": "Could Snoopy transmit rabies?", "answer": false, "facts": ["Snoopy is a fictional dog.", "Fictional animals cannot transmit diseases to real people."], "decomposition": ["What can transmit rabies?", "What is Snoopy?", "Is #2 included in #1?"], "evidence": [[[["Rabies-3"]], [["Snoopy-2"]], ["operation"]], [[["Rabies-2"]], [["Snoopy-1"]], ["operation"]], [[["Rabies-15"]], [["Snoopy-1"]], ["operation"]]]}
{"qid": "00e13b8d03d35929c049", "term": "Retail", "description": "Sale of goods and services from individuals or businesses to the end-user", "question": "Is SnapCap an example of a retail store?", "answer": false, "facts": ["SnapCap specializes in small business loans.", "Retail stores sell products to individual consumers. ", "Small businesses are not individual consumers."], "decomposition": ["What does SnapCap specialize in?", "Who do #1's sell their products to?", "Who do retail stores sell their products to?", "Is #2 the same as #3?"], "evidence": [[[["LendingTree-8"], "no_evidence"], ["no_evidence"], [["Retail-6"]], ["operation"]], [[["LendingTree-8"], "no_evidence"], [["LendingTree-1"], "no_evidence"], [["Retail-1"]], ["operation"]], [[["Payday loan-1"], "no_evidence"], [["Payday loan-1"]], [["Retail-1"], "no_evidence"], ["operation"]]]}
{"qid": "557b6230413fc65f6a16", "term": "Ocean sunfish", "description": "species of fish", "question": "Would it be impossible to keep an ocean sunfish and a goldfish in the same tank?", "answer": true, "facts": ["Ocean sunfish live in salt water environments.", "Goldfish live in fresh water environments.", "Putting a fish into the wrong water type can cause them to die."], "decomposition": ["What kind of water habitat does the ocean sunfish live in?", "What kind of water habitat do goldfish live in?", "Is #1 interchangeable with #2"], "evidence": [[[["Ocean sunfish-21", "Ocean-2"]], [["Goldfish-1"]], ["operation"]], [[["Ocean sunfish-1"]], [["Goldfish-1"]], ["operation"]], [[["Ocean-11", "Saltwater fish-3"]], [["Freshwater fish-3", "Goldfish-1"]], [["Freshwater fish-3", "Saltwater fish-3"]]]]}
{"qid": "7b75cf06f6fe3cdf08b4", "term": "Hamster", "description": "subfamily of mammals", "question": "Could a hamster experience two leap years?", "answer": false, "facts": ["Pet hamsters typically have a maximum lifespan of three years.", "Leap years are typically separated by four years."], "decomposition": ["How long is the lifespan of a hamster?", "How many years are between two leap years?", "Is #1 longer than #2?"], "evidence": [[[["Hamster-27"]], [["Leap year-16"]], ["operation"]], [[["Hamster-27"]], [["Leap year-16"]], ["operation"]], [[["Hamster-27"]], [["Leap year-6"]], ["operation"]]]}
{"qid": "4f286910705ee9e8aceb", "term": "Hypothermia", "description": "A human body core temperature below 35.0\u00b0C", "question": "Would hypothermia be a concern for a human wearing zoot suit on Triton?", "answer": true, "facts": ["A zoot suit was a man's suit of an exaggerated style popular in the 1940s.", "Triton is one of the coldest planets in the solar system.", "Triton is located about 2.8 billion miles from the warmth of the sun.", "Triton has an average temperature of -235.0\u00b0C", "A zoot suit is made of thin material such as cloth."], "decomposition": ["What is the average temperature on Triton?", "What material are zoot suits made of?", "Below which body temperature will hypothermia set in?", "Would clothes made of #2 be unable to keep body temperature above #3 in ambient temperature of #1?"], "evidence": [[[["Triton (moon)-3"]], [["Zoot Suit Riots-2"]], [["Hypothermia-1"]], ["operation"]], [[["Triton (moon)-3"]], [["Zoot Suit Riots-12", "Zoot Suit Riots-2"]], [["Human body temperature-30"]], ["operation"]], [[["Triton (moon)-3"]], [["Zoot suit-15"], "no_evidence"], [["Hypothermia-1"]], ["operation"]]]}
{"qid": "d258695ba910ec875522", "term": "Johnny Carson", "description": "American talk show host and comedian", "question": "Did Johnny Carson win enough Emmy's to fill a carton if Emmy's were eggs?", "answer": false, "facts": ["There are 12 eggs in a carton.", "Johnny Carson won 6 Emmys.", "6 is less than 12."], "decomposition": ["How many eggs can fit in a standard egg carton?", "How many Emmy Awards did Johnny Carson win?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Egg carton-8"]], [["Johnny Carson-1"]], ["operation"]], [[["Egg carton-8"]], [["Johnny Carson-1"]], ["operation"]], [[["Egg as food-11"]], [["Johnny Carson-1"]], ["operation"]]]}
{"qid": "43c636907c6b92d251d5", "term": "Silicon", "description": "Chemical element with atomic number 14", "question": "Is silicon important in California?", "answer": true, "facts": ["There is a region in California called the Silicon Valley.", "Silicon Valley is home to a large number of technology corporations.", "Silicon Valley was originally named after the large number of corporations there that manufactured silicon-based circuit chips."], "decomposition": ["Which industrial area in California is named after silicon?", "What kind of companies are prevalent in #1?", "What kind of products do #2 make?", "Is silicon an important raw material for #3?"], "evidence": [[[["Silicon Valley-1"]], [["Silicon Valley-38"]], [["Silicon Valley-29"]], [["Silicon Valley-2"]]], [[["Silicon Valley-1"]], [["Silicon Valley-2"]], [["Silicon Valley-2"]], [["Integrated circuit-1", "Transistor-48"]]], [[["Silicon Valley-1"]], [["Silicon Valley-2"]], [["Transistor-48"]], [["Semiconductor-1"], "operation"]]]}
{"qid": "3a61dcbed7e358b3aee8", "term": "Great Pyramid of Giza", "description": "Largest pyramid in the Giza Necropolis, Egypt", "question": "Can 200 men end to end cover Great Pyramid of Giza's base?", "answer": true, "facts": ["The base of the Great Pyramid of Giza is 756 feet long.", "The average height of a man is 5 foot 9."], "decomposition": ["What is the height in inches of the average man?", "What is length in inches of the base of The Great Pyramid of Giza?", "What is 200 times #1?", "Is #3 more than #2?"], "evidence": [[[["Dinka people-3"], "no_evidence"], [["Great Pyramid of Giza-4"]], ["operation"], ["operation"]], [[["Dinka people-3"], "no_evidence"], [["Great Pyramid of Giza-4"], "no_evidence"], ["no_evidence", "operation"], ["no_evidence", "operation"]], [[["Human height-46"]], [["Great Pyramid of Giza-4"]], [["Foot (unit)-1"], "operation"], ["operation"]]]}
{"qid": "f8bf74ed2a1f4005a37f", "term": "Clouded leopard", "description": "species of mammal found from the Himalayan foothills through mainland Southeast Asia into China", "question": "Would a clouded leopard encounter an awake pangolin?", "answer": true, "facts": ["Pangolins and clouded leopards have an overlap of ranges", "Pangolins are nocturnal", "Clouded leopards are nocturnal"], "decomposition": ["What is the range of the clouded leopard?", "What time of day is the clouded leopard active?", "What is the range of the pangolin?", "What time of day is the pangolin active?", "Do #1 and #3 overlap while #2 and #4 overlap?"], "evidence": [[[["Clouded leopard-1"]], [["Clouded leopard-24"]], [["Pangolin-1"]], [["Pangolin-2"]], [["Clouded leopard-1", "Clouded leopard-24", "Pangolin-1", "Pangolin-2"]]], [[["Clouded leopard-1"]], [["Clouded leopard-24"]], [["Pangolin-1"], "no_evidence"], [["Pangolin-2"]], ["no_evidence", "operation"]], [[["Clouded leopard-1"]], [["Clouded leopard-24"]], [["Pangolin-1"]], [["Pangolin-2"]], ["operation"]]]}
{"qid": "47ed3fe19be0eea3ffaa", "term": "Oscar Wilde", "description": "19th-century Irish poet, playwright and aesthete", "question": "Was Oscar Wilde's treatment under the law be considered fair in the US now?", "answer": false, "facts": ["Oscar Wilde was imprisoned for sexual indecency that amounted to having sexual relations with another man.", "In the United States, being gay is not a punishable offense. "], "decomposition": ["Why was Oscar Wilde imprisioned?", "is #1 considered a punishable offense in the US today?"], "evidence": [[[["Oscar Wilde-4"]], ["no_evidence"]], [[["Oscar Wilde-68"]], [["Same-sex marriage in the United States-1"], "operation"]], [[["Oscar Wilde-75"]], [["Sodomy laws in the United States-2"], "operation"]]]}
{"qid": "b8677742616fef051f00", "term": "Genghis Khan", "description": "founder and first Great Khan of the Mongol Empire", "question": "Are more people today related to Genghis Khan than Julius Caesar?", "answer": true, "facts": ["Julius Caesar had three children.", "Genghis Khan had sixteen children.", "Modern geneticists have determined that  out of every 200 men today has DNA that can be traced to Genghis Khan."], "decomposition": ["How many kids did Julius Caesar have?", "How many kids did Genghis Khan have?", "Is #2 greater than #1?"], "evidence": [[[["Caesarion-2", "Julia (daughter of Caesar)-1"]], [["Alakhai Bekhi-1", "Tolui-1"], "no_evidence"], ["operation"]], [[["Julius Caesar-75"]], [["Genghis Khan-17"]], ["operation"]], [[["Gaius Julius Caesar-7"]], [["Genghis Khan-15"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "22955a0a82aacacd37eb", "term": "Methane", "description": "Simplest organic molecule with one carbon atom and four hydrogen", "question": "Can methane be seen by the naked eye?", "answer": false, "facts": ["Methane is a gas.", "Methane is colorless.", "Methane is odorless."], "decomposition": ["What is the color of methane?", "Can #1 gases be seen by the naked eye?"], "evidence": [[[["Methane-4"]], ["operation"]], [[["Methane-4"]], ["operation"]], [[["Methane-4"]], ["operation"]]]}
{"qid": "f41b809dcfb764234ce8", "term": "Reddit", "description": "Online news aggregator", "question": "Are the majority of Reddit users familiar with the Pledge of Allegiance?", "answer": true, "facts": ["55% of the Reddit user base comes from the United States.", "Congressional sessions open with the recital of the Pledge, as do many government meetings at local levels, and meetings held by many private organizations.", "All states except California, Hawaii, Iowa, Vermont, and Wyoming require a regularly scheduled recitation of the pledge in public schools."], "decomposition": ["What country do most Reddit users come from?", "What country is the Pledge of Allegiance associated with?", "Is #1 the same as #2?"], "evidence": [[[["Reddit-2"]], [["Pledge of Allegiance-1"]], ["operation"]], [[["Reddit-2"]], [["Pledge of Allegiance-1"]], ["operation"]], [[["Reddit-2"]], [["Pledge of Allegiance-1"]], ["operation"]]]}
{"qid": "16e41c83724a949fb983", "term": "Stone Cold Steve Austin", "description": "American professional wrestler", "question": "Coud every wife of Stone Cold Steve Austin fit in Audi TT?", "answer": true, "facts": ["Stone Cold Steve Austin has been married to 4 different women.", "The Audi TT is a sports car with 4 seats."], "decomposition": ["How many wives has Stone Cold Steve Austin had?", "How many people can sit in an Audi TT", "Is #2 at least #1?"], "evidence": [[[["Stone Cold Steve Austin-67"]], [["Audi TT-2"]], ["operation"]], [[["Stone Cold Steve Austin-67"]], [["2+2 (car body style)-1", "Audi TT-2"]], ["operation"]], [[["Stone Cold Steve Austin-67"]], [["Audi TT-1"]], ["operation"]]]}
{"qid": "a3acf1afdbeea87948d7", "term": "Elijah Cummings", "description": "U.S. Representative from Maryland", "question": "Will Elijah Cummings vote for Joe Biden in the next presidential elections?", "answer": false, "facts": ["The next presidential elections will take place in November of 2020", "Elijah Cummings passed away in October of 2019"], "decomposition": ["When will the next presidential election be held?", "When did Elijah Cummings pass away?", "Is #2 after #1?"], "evidence": [[[["2020 United States presidential election-1"]], [["Elijah Cummings-1"]], ["operation"]], [[["2020 United States presidential election-1"]], [["Elijah Cummings-1"]], ["operation"]], [[["2020 United States presidential election-1"]], [["Elijah Cummings-1"]], ["operation"]]]}
{"qid": "acb7edac010554509519", "term": "Chlorophyll", "description": "group of chemical compounds", "question": "Would human race go extinct without chlorophyll?", "answer": true, "facts": ["Chlorophyll is a pigment in plants responsible for photosynthesis.", "Photosynthesis is the process by which plants release oxygen into the atmosphere.", "Humans need oxygen to live."], "decomposition": ["What is Chlorophyll responsible for in plants?", "What does #1 release into the air?", "Do humans need #2 in order to survive?"], "evidence": [[[["Chlorophyll-1"]], [["Photosynthesis-1"]], ["operation"]], [[["Chlorophyll-6"]], [["Photosynthesis-1"]], [["Breathing-2"]]], [[["Chlorophyll-1"]], [["Photosynthesis-1"]], [["Breathing-2"]]]]}
{"qid": "4649ef4a279369c83a9f", "term": "Alan Rickman", "description": "British actor", "question": "Do many fans of J.K Rowling know who Alan Rickman is?", "answer": true, "facts": ["J.K Rowling wrote the Harry Potter series.", "Alan Rickman performed the role of Severus Snape throughout all 8 Harry Potter films."], "decomposition": ["What is JK Rowling most famous for?", "What characters has actor Alan Rickman played?", "What characters appear in #1?", "Is at least one character from #2 also listed in #3?"], "evidence": [[[["J. K. Rowling-1"]], [["Alan Rickman-2"]], [["Harry Potter (film series)-30"], "no_evidence"], ["operation"]], [[["J. K. Rowling-1"]], [["Alan Rickman-2"]], [["Severus Snape-3"]], ["operation"]], [[["J. K. Rowling-1"]], [["Alan Rickman-15"]], [["Severus Snape-47"]], ["operation"]]]}
{"qid": "cf8c0f4ee24b30530377", "term": "Mercury (element)", "description": "Chemical element with atomic number 80", "question": "Does Mercury make for good Slip N Slide material?", "answer": false, "facts": ["The Slip N Slide was an outdoor water slide toy.", "Mercury is a thick liquid at room temperature.", "Mercury is poisonous and used to kill hatters that lined their hats with the substance."], "decomposition": ["Who are Slip N Slides made for?", "Is Mercury safe for #1 to be around?"], "evidence": [[[["Slip 'N Slide-4"]], [["Mercury poisoning-27"]]], [[["Slip 'N Slide-4"]], [["Mercury poisoning-1", "Mercury poisoning-27"]]], [[["Slip 'N Slide-2"]], [["Mercury (element)-3", "Mercury (element)-5"], "operation"]]]}
{"qid": "867d95acb802575522dc", "term": "Aldi", "description": "Germany-based supermarket chain", "question": "Are all United States Aldi locations owned by the same company?", "answer": false, "facts": ["Aldi is actually two German-based supermarket chains, Aldi Nord and Aldi Sud.", "Both companies operate internationally, but the United States is the only country other than Germany where both Aldi chains operate."], "decomposition": ["Which country is Aldi based in?", "How many chains of Aldi operate in #1?", "Are each of #2 owned by different organizations?", "How many chains of Aldi operate in the US?", "Is #3 negative or #4 different than #2?"], "evidence": [[[["Aldi-1"]], [["Aldi-2"]], [["Aldi-13"]], [["Aldi-2"]], ["operation"]], [[["Aldi-1"]], [["Aldi-1"]], ["no_evidence", "operation"], [["Aldi-2"]], ["operation"]], [[["Aldi-1"]], [["Aldi-1"]], [["Aldi-1"]], [["Aldi-17", "Aldi-2"]], ["operation"]]]}
{"qid": "72277c0ba2a0bcdaf739", "term": "Scottish independence", "description": "political aim for Scotland to be independent from the UK", "question": "Is Alistair Darling in favor of Scottish independence?", "answer": false, "facts": ["Alistair Darling was the chair of the Better Together Campaign.", "Better Together was the principal campaign for a No vote in the 2014 Scottish independence referendum, advocating Scotland continuing to be part of the United Kingdom. "], "decomposition": ["What was the main purpose of the Better Together Campaign?", "Was #1 against independence of Scotland?", "Was Alistair Darling the chair of the campaign?", "Is #2 or #3 negative?"], "evidence": [[[["Better Together (campaign)-1"]], [["Better Together (campaign)-2"]], [["Better Together (campaign)-2"]], ["operation"]], [[["Better Together (campaign)-1"]], ["operation"], [["Alistair Darling-3"]], ["operation"]], [[["Better Together (campaign)-1"]], ["operation"], [["Better Together (campaign)-2"]], ["operation"]]]}
{"qid": "c47897304b87477d7622", "term": "Second Coming", "description": "Christian and Islamic belief regarding the future (or past) return of Jesus after his ascension", "question": "Does Woody Allen await the Second Coming?", "answer": false, "facts": ["The Second Coming refers to Jesus Christ returning to earth", "Christians and Muslims believe in Jesus Christ", "Woody Allen is Jewish"], "decomposition": ["Which religious groups believe in the second coming?", "Does Woody Allen belong to any of #1?"], "evidence": [[[["Second Coming-1"]], [["Woody Allen-4"], "operation"]], [[["Second Coming-1"]], ["no_evidence", "operation"]], [[["Second Coming-1"]], [["Woody Allen-4"]]]]}
{"qid": "0e2302c5416dbec922e6", "term": "Al-Farabi", "description": "Philosopher in 10th century Central Asia", "question": "Would ISIS agree with Al-Farabi's religious sect?", "answer": false, "facts": ["The philosopher Al-Farabi was believed to be a Shia Muslim.", "ISIS is an extremist Sunni Muslim group.", "The Sunni and Shia are constantly at war\u2014Sunni often use car bombs, while Shia favor death squads."], "decomposition": ["What religious sect did Al-Farabi belong to?", "What religious sect does ISIS belong to?", "Do #1 and #2 avoid conflict with each other?"], "evidence": [[[["Al-Farabi-11"]], [["Islamic State of Iraq and the Levant-1"]], ["no_evidence", "operation"]], [[["Al-Farabi-11"]], [["Islamic State of Iraq and the Levant-1"]], [["Shia\u2013Sunni relations-4"]]], [[["Al-Farabi-11"], "no_evidence"], [["Islamic State of Iraq and the Levant-64"]], [["Shia\u2013Sunni relations-1"], "operation"]]]}
{"qid": "9fe0a73c0db0f034f859", "term": "Pope John Paul I", "description": "263rd Pope of the Catholic Church", "question": "Phileas Fogg's around the world would be difficult to achieve during Pope John Paul I's reign?", "answer": true, "facts": ["Phileas Fogg is a character in Jules Verne's Around the World in Eighty Days.", "Phileas Fogg attempts to circumnavigate the globe in 80 days.", "Pope John Paul I reigned for only 33 days."], "decomposition": ["How long did it take Phileas Fogg to go around the world?", "How long did Pope John Paul I reign?", "Is #1 longer than #2?"], "evidence": [[[["Phileas Fogg-1"]], [["Pope John Paul I-1"]], ["operation"]], [[["Around the World in Eighty Days-1"]], [["Pope John Paul I-1"]], ["operation"]], [[["Phileas Fogg-2"]], [["Pope John Paul I-1"]], ["operation"]]]}
{"qid": "50bf347c2a05b645a0f9", "term": "Supreme Court of the United States", "description": "Highest court in the United States", "question": "Is Supreme Court of the United States analogous to High Courts of Justice of Spain?", "answer": false, "facts": ["The Supreme Court of the United States is the final court ad has final say in judicial matters.", "The High Courts of Justice in Spain rule over single communities.", "The Supreme Court of Spain is the highest court in Spain and can overrule lesser courts."], "decomposition": ["What is the extent of the jurisdiction of The Supreme Court of the United States?", "Do the High courts of justice (Spain) have the same jurisdiction as #1?"], "evidence": [[[["Supreme Court of the United States-1"]], [["High Courts of Justice of Spain-1", "Judiciary of Spain-7"]]], [[["Supreme Court of the United States-1"]], [["High Courts of Justice of Spain-1"], "operation"]], [[["Supreme Court of the United States-60"]], ["operation"]]]}
{"qid": "54128d7439105554c9e3", "term": "ABBA", "description": "Swedish pop group", "question": "Is calling ABBA the Swedish Beatles a preposterous claim?", "answer": true, "facts": ["ABBA was a Swedish band that had 1 Billboard number 1 hit and 4 top 10 hits.", "The Beatles had 20 Billboard number 1 hits and 34 top 10 hits."], "decomposition": ["How many Billboard number ones did ABBA have?", "How many Billboard number ones did the Beatles have?", "Is #1 lower than #2?"], "evidence": [[[["ABBA-38"]], [["Billboard 200-25"]], ["operation"]], [[["ABBA-120"]], [["The Beatles-111", "The Beatles-4"], "no_evidence"], ["operation"]], [[["ABBA-121"]], [["Billboard 200-26"]], [["Billboard 200-26"], "operation"]]]}
{"qid": "089b0eb6cdf0fe53a863", "term": "Scottish people", "description": "ethnic inhabitants of Scotland", "question": "Are Scottish people descended from Mary, Queen of Scots part French?", "answer": true, "facts": ["Mary, Queen of Scots was Queen of Scotland in the 1500s.", "Mary, Queen of Scots was the daughter of Mary of Guise.", "Mary of Guise was born to a French nobleman, and her mother was French as well."], "decomposition": ["Who was the mother of Mary, Queen of Scots?", "Who were the parents of #1?", "Were #2 French?"], "evidence": [[[["Mary of Guise-1"]], [["Antoinette de Bourbon-1", "Claude, Duke of Guise-1"]], ["operation"]], [[["Mary, Queen of Scots-5"]], [["Mary of Guise-2"]], [["Claude, Duke of Guise-1"], "operation"]], [[["Mary, Queen of Scots-5"]], [["Mary of Guise-2"]], [["Antoinette de Bourbon-1", "Claude, Duke of Guise-1"]]]]}
{"qid": "384f2454d749208556d8", "term": "Telescope", "description": "Optical instrument that makes distant objects appear magnified", "question": "Would stargazers prefer binoculars over a telescope?", "answer": false, "facts": ["Depending on a stargazer's goal, the scope of view necessary can change. ", "Companies produce both telescopes and binoculars for stargazing. "], "decomposition": ["How does the scope of a stargazer's observation vary?", "Does #1 stay the same?"], "evidence": [[[["Telescope-1"]], [["Binoculars-1"]]], [[["Observational astronomy-1"], "no_evidence"], [["Binoculars-1"], "operation"]], [[["Amateur astronomy-1"]], ["operation"]]]}
{"qid": "86791c3eb5f380b56439", "term": "Bulk carrier", "description": "merchant ship specially designed to transport unpackaged bulk cargo", "question": "Would eliminating competition in the Japanese bulk carrier market be profitable for a steel company?", "answer": true, "facts": ["62% of bulk carriers are built in Japan", "Bulk carrier hulls are made of steel"], "decomposition": ["Where are most bulk carriers built?", "What materials would #1 use in making bulk carriers?", "Is steel a major component of #2?"], "evidence": [[[["Bulk carrier-2"]], [["Bulk carrier-48"]], [["Bulk carrier-48"]]], [[["Bulk carrier-20", "Bulk carrier-22"], "no_evidence"], [["Shipbuilding-45"]], ["operation"]], [[["Malaysian Bulk Carriers-1"], "no_evidence"], ["no_evidence"], ["operation"]]]}
{"qid": "0aad1627ee2984c8c147", "term": "1980 United States presidential election", "description": "49th quadrennial presidential election in the United States", "question": "Was the 1980 presidential election won by a member of the Grand Old Party?", "answer": true, "facts": ["The Republican party is nicknamed the Grand Old Party.", "The 1980 election was won by Ronald Reagan.", "Reagan was a Republican."], "decomposition": ["Which political party is also known as the Grand Old Party?", "Who won the 1980 presidential election?", "What political party did #2 belong to?", "Is #3 the same as #1?"], "evidence": [[[["Republican Party (United States)-1"]], [["1980 United States presidential election-1"]], [["Ronald Reagan-3"]], ["operation"]], [[["Republican Party (United States)-1"]], [["1980 United States presidential election-1"]], [["Ronald Reagan-3"]], ["operation"]], [[["Republican Party (United States)-1"]], [["1980 United States presidential election-1"]], [["Ronald Reagan-3"]], ["operation"]]]}
{"qid": "283e6170947e33043c1b", "term": "Sugar Ray Robinson", "description": "American boxer", "question": "Did Sugar Ray Robinson win a fight against Canelo Alvarez?", "answer": false, "facts": ["Sugar Ray Robinson died in 1989", "Canelo Alvarez was born in 1990"], "decomposition": ["In what year did Sugar Ray Robinson die?", "In what year was Canelo Alvarez born?", "Is #2 before #1?"], "evidence": [[[["Sugar Ray Robinson-28"]], [["Canelo \u00c1lvarez-1"]], ["operation"]], [[["Sugar Ray Robinson-1"]], [["Canelo \u00c1lvarez-1"]], ["operation"]], [[["Sugar Ray Robinson-1"]], [["Canelo \u00c1lvarez-1"]], ["operation"]]]}
{"qid": "a6bf045651f7b6b64035", "term": "Macaque", "description": "genus of Old World monkeys", "question": "Could an elephant easily defeat a male macaque?", "answer": true, "facts": ["Male macaques range from 16 to 28 inches tall with a weight between 12.13 to 39.7 pounds.", "Elephants are between 7 to 11 feet tall and weigh several thousand pounds.", "Elephants contain large, sharp tusks that can injure or kill other animals."], "decomposition": ["How much does a male macaques weigh?", "How much can an elephant weigh?", "How tall is a male macaque?", "How tall is an elephant?", "Is #2 more than #1 and is #4 more than #3?"], "evidence": [[[["Macaque-4"]], [["Elephant-14"]], [["Macaque-4"]], [["Elephant-12"]], ["operation"]], [[["Macaque-4"]], [["Elephant-15"]], [["Macaque-4"]], [["Elephant-15"]], ["operation"]], [[["Macaque-4"]], [["Elephant-15", "Elephantidae-1"], "no_evidence"], [["Macaque-4"]], [["Elephant-15"]], ["operation"]]]}
{"qid": "3e9e3ccc9fc4d44a3eb4", "term": "Astronaut", "description": "Person who commands, pilots, or serves as a crew member of a spacecraft", "question": "Can actress Danica McKellar skip astronaut education requirements?", "answer": true, "facts": ["Astronaut's are required to have a bachelor's degree in engineering, biological science, physical science, computer science, or mathematics.", "Actress Danica McKellar graduated summa cum laude from UCLA with a degree in Mathematics."], "decomposition": ["Astronauts can have any one of which degrees?", "What degree does Danica McKellar have?", "Is #2 included in #1?"], "evidence": [[[["NASA Astronaut Corps-10"]], [["Danica McKellar-5"]], ["operation"]], [[["NASA Astronaut Corps-10"]], [["Danica McKellar-5"]], ["operation"]], [[["NASA Astronaut Corps-10"]], [["Danica McKellar-5"]], ["operation"]]]}
{"qid": "ac641c5074e03e422221", "term": "Kane (wrestler)", "description": "American professional wrestler, actor, businessman, and politician", "question": "Was Kane (wrestler) banned from WCW  headquarters city?", "answer": false, "facts": ["Kane (wrestler is a professional wrestler most known for his WWE tenure.", "Kane wrestled one match in WCW as Bruiser Mastino.", "WWE main rival WCW was headquartered in Atlanta, Georgia.", "Kane competed in an eight-man tag match at Wrestlemania XXVII in the Georgia Dome.", "The Georgia Dome was a stadium in Atlanta Georgia."], "decomposition": ["Where were the headquarters of the WCW?", "Did Kane never perform in #1?"], "evidence": [[[["World Championship Wrestling-4"]], [["Royal Rumble (2002)-1", "Royal Rumble (2002)-15"], "operation"]], [[["World Championship Wrestling-4"]], [["Kane (wrestler)-1"], "no_evidence", "operation"]], [[["World Championship Wrestling-4"]], [["Royal Rumble (2002)-1", "Royal Rumble (2002)-15"]]]]}
{"qid": "e91ba24305ae9f8850ed", "term": "Hulk", "description": "Superhero appearing in Marvel Comics publications and related media", "question": "Can Hulk's alter ego explain atomic events?", "answer": true, "facts": ["Hulk's alter ego is Dr. Robert Bruce Banner", "Dr. Robert Bruce Banner is a nuclear physicist. ", "Nuclear physics is the field of physics that studies atomic nuclei and their constituents and interactions. "], "decomposition": ["Who is the Hulk's alter ego?", "What is the profession of #1?", "What do people in #2 have a knowledge of?", "Is atomic events included in #3?"], "evidence": [[[["Hulk-1"]], [["Hulk-45"]], [["Physicist-1"]], [["Elementary event-1"]]], [[["Hulk-9"]], [["Hulk-1"]], [["Scientist-1"]], [["Atomic Age (design)-1"], "operation"]], [[["Hulk-1"]], [["Hulk-57"]], ["operation"], ["operation"]]]}
{"qid": "76821a3d4561f872b607", "term": "Futurama", "description": "American animated sitcom for the Fox Broadcasting Company and Comedy Central", "question": "Has the creator of Futurama lived in multiple centuries?", "answer": true, "facts": ["The creator of Futurama is Matt Groening.", "Matt Groening was born in 1954.", "The 20th (twentieth) century was a century that began on January 1, 1901 and ended on December 31, 2000.", "The 21st (twenty-first) century began on January 1, 2001, and will end on December 31, 2100."], "decomposition": ["Who is the creator of Futurama?", "How old is #1?", "What is 2020 minus #2?", "When did the most recent new century begin?", "Is #4 between #3 and 2020?"], "evidence": [[[["Futurama-1"]], [["Matt Groening-1"]], ["operation"], [["2000-1"]], ["operation"]], [[["Futurama-1"]], [["Matt Groening-1"]], ["operation"], [["21st century-1"]], ["operation"]], [[["Futurama-1"]], [["Matt Groening-1"]], ["operation"], [["21st century-1"]], ["operation"]]]}
{"qid": "e6d3973ed3feb8a42928", "term": "Bee", "description": "Clade of insects", "question": "Can Africanized bees be considered multicultural?", "answer": true, "facts": ["Multicultural refers to a blend of several cultures within one organism.", "Africanized bees, also killer bees are a result of crossbreeding.", "Africanized bees are a mix of East African lowland honey bees and European honey bee subspecies such as the Italian honey bee and the Iberian honey bee. "], "decomposition": ["What is the definition of multicultural?", "What are Africanized bees a result of?", "What types of bees were part of #2?", "Is #3 an example of #1?"], "evidence": [[[["Multiculturalism-1"]], [["Africanized bee-1"]], [["Africanized bee-1"]], [["Africanized bee-1", "Multiculturalism-1"]]], [[["Multiracial people-1"]], [["Honey bee-21"]], [["Africanized bee-1"]], ["operation"]], [[["Multiculturalism-1"]], [["Africanized bee-1"]], [["African bee-1", "Western honey bee-1"]], ["operation"]]]}
{"qid": "064d8faaa8f164b55270", "term": "Apollo 15", "description": "Fourth crewed mission to land on the Moon", "question": "Would the crew of Apollo 15 have difficulty riding a unicycle?", "answer": true, "facts": ["There were 3 astronauts in the crew of the Apollo 15 mission.", "A unicycle only contains one saddle, and is typically only operated by a single person."], "decomposition": ["What is the maximum number of people that can ride a typical unicycle?", "How many people were on the Apollo 15 crew?", "Is #2 greater than #1?"], "evidence": [[[["Unicycle-1"]], [["Apollo 15-1"]], ["operation"]], [[["Unicycle-1"], "no_evidence"], [["Apollo 15-6"]], ["operation"]], [[["Unicycle-25"]], [["Apollo 15-6"]], ["operation"]]]}
{"qid": "f3e238989015dd72bfda", "term": "Queen Elizabeth The Queen Mother", "description": "Queen consort of King George VI, mother of Queen Elizabeth II", "question": "Did Queen Elizabeth The Queen Mother and her daughter share name with Tudor queen?", "answer": true, "facts": ["Queen Elizabeth the Queen Mother gave birth to Queen Elizabeth II in 1926.", "The Tudor dynasty had a number of Queens including: Mary I of England, Elizabeth I of England, and Margaret Tudor, Queen of Scots."], "decomposition": ["Which name did the Queen Mother and Queen Elizabeth have in common?", "What are the names of some queens from the Tudor dynasty?", "Is #1 included in any of #2?"], "evidence": [[[["Elizabeth II-1", "Queen Elizabeth The Queen Mother-1"]], [["House of Tudor-1"]], ["operation"]], [[["Queen Elizabeth The Queen Mother-1"]], [["Elizabeth I of England-1", "Mary I of England-1"]], ["operation"]], [[["Queen Elizabeth The Queen Mother-1"]], [["House of Tudor-1"]], ["operation"]]]}
{"qid": "bc8bcfe04e4b026e9c96", "term": "Louvre", "description": "Art museum and Historic site in Paris, France", "question": "Is the Louvre's pyramid known for being unbreakable? ", "answer": false, "facts": ["The Pyramid at the Louvre is made of glass and metal.", "The Louvre Pyramid glass is 10mm thick.", "10mm thick glass is not unbreakable."], "decomposition": ["What materials is the Louvre made of?", "Are all the materials in listed in #1 unbreakable?"], "evidence": [[[["Louvre Pyramid-1"]], [["Glass-19"]]], [[["Louvre Pyramid-1"]], [["Glass-2"], "operation"]], [[["Louvre Pyramid-3"]], [["Mohs scale of mineral hardness-4", "Strength of glass-5"], "no_evidence"]]]}
{"qid": "17fc5cdda68b55351597", "term": "Amy Winehouse", "description": "English singer and songwriter", "question": "Would Amy Winehouse's death have been prevented with Narcan?", "answer": false, "facts": ["Narcan is a medication that save the life of someone overdosing on opiates.", "Amy Winehouse died from alcohol poisoning.", "Narcan cannot work on alcohol overdoses."], "decomposition": ["What was the cause of Amy Winehouse's death?", "What are the indications/symptoms that can be treated with Narcan?", "Is #1 included in #2?"], "evidence": [[[["Amy Winehouse-4"]], [["Naloxone-1"]], ["operation"]], [[["Amy Winehouse-92"]], [["Naloxone-4", "Naloxone-7"]], ["operation"]], [[["Amy Winehouse-92"]], [["Naloxone-1"]], ["operation"]]]}
{"qid": "2be83f11f8b6602afe87", "term": "Psychotherapy", "description": "clinically applied psychology for desired behavior modification", "question": "Do some psychotherapy patients have no mental illness?", "answer": true, "facts": ["Psychotherapy is useful for couples navigating relationship issues.", "Grief is a common reason that people seek psychotherapy. "], "decomposition": ["What are some common issues that make people seek psychotherapy?", "Does #1 not always involve mental illness?"], "evidence": [[[["Psychotherapy-1"]], ["operation"]], [[["Psychotherapy-1"]], [["Psychotherapy-4"], "operation"]], [[["Psychotherapy-1"]], [["Psychotherapy-32"], "operation"]]]}
{"qid": "7459eacff621fe539afc", "term": "Los Angeles Memorial Sports Arena", "description": "Former arena in California, United States", "question": "Was Los Angeles Memorial Sports Arena hypothetically inadequate for hosting Coachella?", "answer": true, "facts": ["The Los Angeles Memorial Sports Arena had a capacity of 16,740 people.", "Coachella has had attendance numbers in excess of 99.000 people.", "Coachella relies on an outdoor set up to accommodate the massive crowds."], "decomposition": ["How many people can the Los Angeles Memorial Sports Arena hold?", "How many people usually attend Coachella?", "Is #2 greater than #1?"], "evidence": [[[["Los Angeles Memorial Sports Arena-15"]], [["Coachella Valley Music and Arts Festival-3"]], [["Coachella Valley Music and Arts Festival-3", "Los Angeles Memorial Sports Arena-15"], "operation"]], [[["Los Angeles Memorial Sports Arena-15"]], [["Coachella Valley Music and Arts Festival-3"]], ["operation"]], [[["Los Angeles Memorial Sports Arena-15"]], [["Coachella Valley Music and Arts Festival-20"]], [["Coachella Valley Music and Arts Festival-20"], "operation"]]]}
{"qid": "df538a945f0d1c012cd2", "term": "Super Mario", "description": "platform video game series from Nintendo's Mario franchise", "question": "Does Super Mario require electricity to play?", "answer": true, "facts": ["Super Mario is a video game.", "Video games are played on electronic devices.", "Electronic devices require electricity to function."], "decomposition": ["What is Super Mario?", "Where are #1 played?", "Do #2 require electricity?"], "evidence": [[[["Super Mario-1"]], [["Nintendo video game consoles-1"]], [["Nintendo video game consoles-1"]]], [[["Super Mario-1"]], [["Nintendo Entertainment System-2"]], [["Nintendo Entertainment System-12"], "operation"]], [[["Super Mario-1"]], [["Super Mario-1", "Video game console-3"]], [["Video game console-3"]]]]}
{"qid": "b172aea303690917153e", "term": "Constitution of the Philippines", "description": "Supreme law of the Republic of the Philippines", "question": "Does the Constitution of the Philippines copy text from the British constitution?", "answer": false, "facts": ["The Constitution of the Philippines is a document ratified in 1987", "The British constitution is not an actual document, but a collection of legal statutes, precedent, political custom and social convention"], "decomposition": ["What was the British Constitution?", "What kind of document was the Constitution of the Philippines?", "Can #1 copy something from #2"], "evidence": [[[["Constitution of the United Kingdom-1"]], [["Constitution of the Philippines-1"]], ["operation"]], [[["Constitution of the United Kingdom-1"]], [["Constitution of the Philippines-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Constitution of the United Kingdom-5"]], [["Constitution of the Philippines-1"]], ["no_evidence"]]]}
{"qid": "46b3927a42ca343d71c3", "term": "Suicide", "description": "Intentional act of causing one's own death", "question": "Would Modafinil be effective in completing a suicide?", "answer": false, "facts": ["Modafinil is a powerful wakefulness drug, typically prescribed at 100mg or 200mg per day doses.", "Suicide attempts with up to 5,000mg of Modafinil have been unsuccessful. "], "decomposition": ["What is Modafinil?", "What are the effects of taking too much #1?", "Would someone who wanted to commit suicide want to #2?"], "evidence": [[[["Modafinil-1"]], [["Modafinil-12"]], ["operation"]], [[["Modafinil-1"]], [["Modafinil-19"]], ["operation"]], [[["Modafinil-1"]], [["Modafinil-19"]], ["no_evidence", "operation"]]]}
{"qid": "4f8054d068f6d12cd1ad", "term": "Stroke", "description": "Medical condition where poor blood flow to the brain causes cell death", "question": "Did Dale Jr.'s father crash his car due to a stroke?", "answer": false, "facts": ["Dale Earnhardt Jr. is his late father's namesake.", "Dale Earnhardt died in a crash during a NASCAR race. ", "Dale Earnhardt's car spun out of control after it tapped the car of another driver.", "Dale Earnhardt's death was a Basilar skull fracture."], "decomposition": ["Who was Dale Jr's father?", "What was the cause of the car crash that killed #1?", "Is #2 a stroke?"], "evidence": [[[["Dale Earnhardt Jr.-4"]], [["Dale Earnhardt-23"]], [["Dale Earnhardt-23"], "operation"]], [[["Dale Earnhardt Jr.-1"]], [["Dale Earnhardt-23"]], ["operation"]], [[["Dale Earnhardt Jr.-4"]], [["Dale Earnhardt-23"]], ["operation"]]]}
{"qid": "57e6b3d22162e254f7f0", "term": "United Airlines", "description": "Airline in the United States", "question": "Is Glycol something United Airlines would buy?", "answer": true, "facts": ["Glycol is a commonly used de-icing fluid for commercial planes.", "American Airlines flies all year round, including throughout the winter."], "decomposition": ["What is Glycol commonly used for?", "What cold season does American Airlines fly its planes?", "Would #1 be helpful in #2?"], "evidence": [[[["Diol-2", "Diol-4"]], [["American Airlines-1"], "no_evidence"], ["operation"]], [[["Ethylene glycol-1"]], [["Winter-1"]], [["Ethylene glycol-16"]]], [[["Diol-2", "Ethylene glycol-1"]], [["Winter-1"], "no_evidence"], ["operation"]]]}
{"qid": "bdc60c16ac8d47491464", "term": "Spider-Man", "description": "Fictional Marvel superhero", "question": "Did Spiderman fight against Falcon in the MCU?", "answer": true, "facts": ["In Captain America: Civil War, Iron Man and Captain America became enemies following a disagreement.", "Iron Man summoned Spiderman to fight with his team of still-loyal Avengers.", "Falcon was one of Captain America's best friends and supported the Captain in the conflict.", "Therefore, Spiderman and Falcon were on opposite teams during the inter-Avenger battle in the movie."], "decomposition": ["In the marvel movie Captain America: Civil War, which factions were the avengers divided into?", "Were Spiderman and Falcon on opposing sides of #1?"], "evidence": [[[["Captain America: Civil War-1"]], ["no_evidence"]], [[["Captain America: The Winter Soldier-1"]], [["Peter Parker (Marvel Cinematic Universe)-7", "The Falcon and the Winter Soldier-5"], "operation"]], [[["Captain America: Civil War-1"]], [["Falcon (comics)-38", "Spider-Man-27"]]]]}
{"qid": "a946324a5ad6d3528da9", "term": "Publishing", "description": "Process of production and dissemination of literature, music, or information", "question": "Does Buddy The Elf know anyone who works in publishing?", "answer": true, "facts": ["Buddy The Elf is a character from the movie Elf.", "Buddy The Elf's father works in a Manhattan publishing firm."], "decomposition": ["Which people are known to the movie character Buddy The Elf?", "Does any of #1 work in publishing?"], "evidence": [[[["Elf (film)-5", "Elf (film)-9"]], [["Elf (film)-6"], "no_evidence"]], [[["Elf (film)-10"]], ["operation"]], [[["Elf (film)-3"]], ["operation"]]]}
{"qid": "bea6df46c8f218b4b5fb", "term": "Game engine", "description": "Software-development environment designed for building video games", "question": "Does Adobe Suite have video game engine coding?", "answer": true, "facts": ["Adobe applications runs on the C++ framework.", "Many video games are run on Unity game engine.", "The Unity game engine is a C++ coded engine."], "decomposition": ["What framework does Adobe Suite run on?", "What game engine do most video games run on?", "What type of engine is #2?", "Is the framework for #1 the same as the engine for #3?"], "evidence": [[[["Adobe Creative Suite-1", "Starling Framework-2"]], [["Starling Framework-1"], "no_evidence"], [["Starling Framework-3"], "no_evidence"], ["operation"]], [[["Adobe Creative Suite-1"], "no_evidence"], [["Game engine-27"], "no_evidence"], [["Game engine-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Adobe Creative Suite-1", "C++-2"], "no_evidence"], [["Unreal Engine-1"]], [["Unreal Engine-1"]], ["operation"]]]}
{"qid": "a60e5f73700b47a5f34a", "term": "Boat", "description": "vessel for transport by water", "question": "Does rock star Keith Richards play a captain of a boat in a movie?", "answer": true, "facts": ["Keith Richards has a cameo appearance in two of the Pirates of the Caribbean movies.", "He plays Captain Teague, the elderly father of famous pirate Captain Jack Sparrow.", "In At World's End, he is the member of the council of Pirate Lords who is responsible for keeping the Pirate Code, and there is a brief shot of him and his crew aboard their ship during the sequence where the pirates are raising their banners in preparation to fight."], "decomposition": ["What role did Keith Richards play in the Pirates of the Caribbean movies?", "Can #1 be considered a captain of a boat?"], "evidence": [[[["Keith Richards-47"]], [["Captain-1"], "operation"]], [[["Keith Richards-47"]], [["Captain-1"]]], [[["Keith Richards-47"]], ["operation"]]]}
{"qid": "cf0a1e2e39a6af9a79a9", "term": "Durian", "description": "genus of plants", "question": "Could Durian cause someone's stomach to feel unwell?", "answer": true, "facts": ["Durian has a pungent odor that many people describe as being similar to feet and onions.", "Unpleasant smells can make people feel nauseous. "], "decomposition": ["What would some people describe durian's smell as?", "Would #1  cause some people to feel unwell?"], "evidence": [[[["Durian-3"]], [["Durian-50"]]], [[["Durian-3"]], ["operation"]], [[["Durian-29"]], [["Durian-50"]]]]}
{"qid": "3b0c98640caf02aa66e8", "term": "Beaver", "description": "Genus of mammals", "question": "Does the land in close proximity to beaver dams suffer?", "answer": true, "facts": ["Beaver dams often lead to flooding in the areas around them.", "Flooding can lead to loosening of the soil.", "Loosened soil can cause trees to fall over. ", "Flooding can lead to soil erosion."], "decomposition": ["What are the effects of beaver dams on surrounding lands?", "Are any of #1 significantly negative?"], "evidence": [[[["Beaver eradication in Tierra del Fuego-4", "North American beaver-9"]], ["operation"]], [[["Beaver dam-11"]], [["Beaver dam-26"]]], [[["Beaver dam-26"]], ["no_evidence"]]]}
{"qid": "603f33161fb1500bb73d", "term": "Great Depression", "description": "20th-century worldwide economic depression", "question": "Can a person be diagnosed with a Great Depression?", "answer": false, "facts": ["The Great Depression was a severe worldwide economic depression that took place mostly during the 1930s, beginning in the United States.", "Major depressive disorder (MDD), also known simply as depression, is a mental disorder characterized by at least two weeks of low mood that is present across most situations."], "decomposition": ["What was the Great Depression?", "What is depression that people suffer from?", "Are #1 and #2 the same?"], "evidence": [[[["Great Depression-1"]], [["Minor depressive disorder-2"]], [["Great Depression-1", "Minor depressive disorder-2"], "operation"]], [[["Great Depression-1"]], [["Depression (mood)-1"]], ["operation"]], [[["Great Depression-1"]], [["Depression (mood)-8", "Major depressive disorder-30"]], ["operation"]]]}
{"qid": "4c72798de7aca9e0954e", "term": "Metallica", "description": "American heavy metal band", "question": "Is Metallica protective over their music?", "answer": true, "facts": ["Napster was a P2P music sharing service.", "Metallica sued Napster in order to remove their songs from the program, as they were not getting profit from it."], "decomposition": ["What did Metallica do in response to Napster hosting their songs?", "Did #1 involve legal action?"], "evidence": [[[["Metallica v. Napster, Inc.-1"]], [["Lawsuit-1"], "operation"]], [[["Metallica-3"]], ["operation"]], [[["Metallica-3"]], [["Metallica-29"]]]]}
{"qid": "b88ba16883b786c8469b", "term": "Silk", "description": "fine, lustrous, natural fiber produced by the larvae of various silk moths, especially the species Bombyx mori", "question": "Does Bombyx mori have a monopoly over silk production?", "answer": false, "facts": ["A monopoly refers to the exclusive supply of a good.", "The Bombyx mori is a moth famous for its silk production.", "Spiders, beetles, caterpillars, and fleas produce silk.", "Wild silk produced by caterpillars has been used in China, Europe, and South Asia since antiquity."], "decomposition": ["In a monopoly, how many different entities supply goods?", "What insects produce silk?", "How many things are listed in #2?", "Is #3 equal to #1?"], "evidence": [[[["Monopoly-1"]], [["Bombyx mori-1", "Silk-2"]], ["operation"], ["operation"]], [[["Monopoly-1"]], [["Silk-2"]], [["Silk-2"]], ["operation"]], [[["Monopoly-2"]], [["Silk-2"]], ["operation"], ["operation"]]]}
{"qid": "8d06b619a7045ed02f51", "term": "Diamond", "description": "Allotrope of carbon often used as a gemstone and an abrasive", "question": "Is the title of Shirley Bassey's 1971 diamond song a true statement?", "answer": false, "facts": ["Shirley Bassey recorded the song Diamonds are Forever in 1971,", "Over time, diamonds degrade and turn into graphite.", "Graphite is the same chemical composition found in pencils."], "decomposition": ["What is the title to Shirley Bassey's 1971 diamond song?", "Do diamonds last for the time span in #1?"], "evidence": [[[["Diamonds Are Forever (soundtrack)-2"]], [["Material properties of diamond-8"], "no_evidence", "operation"]], [[["Shirley Bassey-1"]], [["Material properties of diamond-31"], "operation"]], [[["Shirley Bassey-1"], "no_evidence"], [["Diamond-48"], "no_evidence"]]]}
{"qid": "2b0900c25deff445e6b1", "term": "Salmon", "description": "Family of fish related to trout", "question": "Do salmon mate in the Caspian Sea?", "answer": false, "facts": ["Salmon reproduce in freshwater", "The Caspian Sea is a saltwater lake"], "decomposition": ["What kind of water do salmon reproduce in?", "Is the Caspian Sea salt or freshwater?", "Is #1 the same as #2?"], "evidence": [[[["Salmon-2"]], [["Caspian Sea-54"]], ["operation"]], [[["Salmon-2"]], [["Caspian Sea-1"]], ["operation"]], [[["Salmon-2"]], [["Caspian Sea-2"]], ["operation"]]]}
{"qid": "ed421aaf019e01f38a84", "term": "Landscape architect", "description": "person involved in the planning, design and sometimes direction of a landscape, garden, or distinct space", "question": "Would Persephone be a good consultant to a landscape architect?", "answer": true, "facts": ["Persephone is a vegetation goddess. ", "A vegetation deity is a nature deity whose disappearance and reappearance, or life, death and rebirth, embodies the growth cycle of plants.", "Landscape architects deal with planning and laying out gardens and other plant life."], "decomposition": ["Over what domains does Persephone preside?", "Do landscape architects work with any of #1?"], "evidence": [[[["Persephone-1", "Persephone-2"]], [["Landscape architect-1"], "operation"]], [[["Persephone-1"]], [["Landscaping-5"]]], [[["Persephone-1"]], ["operation"]]]}
{"qid": "11f0ae8346b66bc1d948", "term": "Secretary", "description": "occupation", "question": "Is Tange Sazen hypothetically an ideal choice for a secretary job?", "answer": false, "facts": ["Secretaries are required to type and also read copious amounts of notes.", "Tange Sazen is a one-eyed, one-armed swordsman in Japanese literature."], "decomposition": ["What physical characteristics is Tange Sazen known to have?", "What type of skill is secretary supposed to have?", "Would it be easy to do #2 when having #1?"], "evidence": [[[["Tange Sazen-1"]], [["Secretary-3"]], [["Secretary-3", "Tange Sazen-1"]]], [[["Tange Sazen-1"]], [["Secretary-3"]], ["operation"]], [[["Tange Sazen-1"]], [["Secretary-13"]], ["operation"]]]}
{"qid": "99e34b51538c03fcd8bb", "term": "Fiat Chrysler Automobiles", "description": "Multinational automotive manufacturing conglomerate", "question": "Is Fiat Chrysler gaining a new overall corporate identity?", "answer": true, "facts": ["The company is renaming itself Stellantis following the completion of its merger.", "There are 14 automobile brands owned by the company, which will be keeping their names and logos."], "decomposition": ["What plans are underway as regards naming after the completion of the Fiat Chrysler merger?", "Does #1 involve a change of the collective corporate identity?"], "evidence": [[[["Fiat Chrysler Automobiles-37"], "no_evidence"], [["Corporate identity-2"], "operation"]], [[["Fiat Chrysler Automobiles-1"]], [["Fiat Chrysler Automobiles-1"], "no_evidence"]], [[["Groupe PSA-23"]], ["operation"]]]}
{"qid": "b3c8f537cfb900ba92e5", "term": "Salsa (sauce)", "description": "Sauce", "question": "Would the chef at La Grenouille find salsa to be a strange request?", "answer": true, "facts": ["La Grenouille is a classic French cuisine restaurant in NYC.", "Salsa is a staple food in Mexican cuisine."], "decomposition": ["What type of cuisine does La Grenouille serve?", "Would you typically find salsa in #1?"], "evidence": [[[["La Grenouille (restaurant)-3"], "operation"], ["no_evidence"]], [[["La Grenouille (restaurant)-1"]], [["Mexican cuisine-28"]]], [[["La Grenouille (restaurant)-3"]], [["La Grenouille (restaurant)-1", "Salsa-1"]]]]}
{"qid": "1a50ff1647077d670841", "term": "Snakebite", "description": "Injury caused by a bite from a snake", "question": "Would a snakebite hypothetically be a threat to T-1000?", "answer": false, "facts": ["Snakebites are dangerous because they inject venom into blood streams.", "The T-1000 is an android from the movie series Terminator.", "Androids are machines made of wires and computer parts."], "decomposition": ["Where does the injurous action of a snakebite happen?", "What kind of entity is a T-1000?", "Does a #2 have a #1?"], "evidence": [[[["Snakebite-32"], "no_evidence"], [["T-1000-2"]], [["T-1000-7"], "no_evidence", "operation"]], [[["Skin-1"]], [["T-1000-10"]], ["operation"]], [[["Venomous snake-1"]], [["T-1000-2"]], ["operation"]]]}
{"qid": "088e22a7b1b40fd2d95b", "term": "Moscow Kremlin", "description": "fortified complex in Moscow, Russia", "question": "Can the Moscow Kremlin fit inside Disney Land?", "answer": true, "facts": ["The Moscow Kremlin is a fortified complex in the middle of Moscow Russia.", "The Kremlin takes up sixty eight acres.", "Disney Land is an amusement park in California. ", "Disney Land occupies eighty five acres."], "decomposition": ["What is the area of Moscow Kremlin?", "What is the size of Disney Land?", "Is #1 smaller than #2?"], "evidence": [[["no_evidence"], [["Disneyland-22"]], ["no_evidence", "operation"]], [[["Moscow Kremlin-1"], "no_evidence"], [["Disneyland-2"], "no_evidence"], ["operation"]], [[["Moscow Kremlin-18"]], [["Disneyland-22"]], ["operation"]]]}
{"qid": "fa6c3c6b8471d6489f43", "term": "Napoleonic Wars", "description": "Series of early 19th century European wars", "question": "Did earth complete at least one orbit around the sun during the Napoleonic Wars?", "answer": true, "facts": ["Earth orbits around the Sun in 365 days.", "Napoleonic Wars lasted 12 years, 5 months and 4 weeks."], "decomposition": ["How long is the orbit of the earth around the sun?", "How long were the Napoleonic Wars?", "Is #2 greater than #1?"], "evidence": [[[["Year-1"]], [["Napoleonic Wars-1"]], ["operation"]], [[["Earth's orbit-1"]], [["Napoleonic Wars-1"]], ["operation"]], [[["Earth's orbit-1"]], [["Napoleonic Wars-1"]], ["operation"]]]}
{"qid": "a59367577ae81ab33531", "term": "Lettuce", "description": "Species of annual plant of the daisy family, most often grown as a leaf vegetable", "question": "Can lettuce result in spontaneous abortion?", "answer": true, "facts": ["Food-borne pathogens that can survive on lettuce include Listeria monocytogenes, ", "Listeria monocytogenes is the causative agent of listeriosis.", "The manifestations of listeriosis include intrauterine or cervical infections in pregnant women, which may result in spontaneous abortion."], "decomposition": ["What diseases can be caused by contaminated lettuce?", "Can any of #1 cause intrauterine or cervical infections?"], "evidence": [[[["Lettuce-4"]], [["Cervix-30", "Escherichia coli-1", "Salmonella-1"], "no_evidence", "operation"]], [[["Lettuce-4"]], [["Salmonella-22"], "no_evidence", "operation"]], [[["Lettuce-4"]], ["no_evidence"]]]}
{"qid": "5fd0dc99fdf46de79b6a", "term": "Citrus", "description": "genus of fruit-bearing plants (source of fruit such as lemons and oranges)", "question": "Would someone on antidepressants need to be cautious of some citrus fruits?", "answer": true, "facts": ["Grapefruit is a citrus fruit.", "Grapefruit can cause some medications to reach unintentionally high levels in the body. ", "SSRI's are a medication type that can be affected by grapefruit."], "decomposition": ["Which fruits can affect antidepressant medications?", "Is #1 a citrus fruit?"], "evidence": [[["no_evidence"], ["no_evidence"]], [[["Antidepressant-30"]], ["no_evidence", "operation"]], [[["Grapefruit\u2013drug interactions-1", "Grapefruit\u2013drug interactions-2"]], [["Grapefruit\u2013drug interactions-2"]]]]}
{"qid": "b257b34db67a10038f18", "term": "Human overpopulation", "description": "The condition where human numbers exceed the short or long-term carrying capacity of the environment", "question": "Does Rusev have to worry about human overpopulation in his homeland?", "answer": false, "facts": ["Human overpopulation results from the birthrate exceeding the death rate in a country.", "Rusev is a professional wrestler who was born in Bulgaria.", "The population of Bulgaria decreased by .7% in 2018."], "decomposition": ["Who is Rusev?", "What is the homeland of #1?", "Is #2 overpopulated?"], "evidence": [[[["Rusev (wrestler)-1"]], [["Rusev (wrestler)-3"]], [["Population decline-50"], "operation"]], [[["Rusev (wrestler)-2"]], [["Rusev (wrestler)-3"]], [["Plovdiv-42"]]], [[["Rusev (wrestler)-1"]], [["Rusev (wrestler)-3"]], [["Demographics of Bulgaria-4"]]]]}
{"qid": "1515242f123df1362ad7", "term": "Elk", "description": "Large antlered species of deer from North America and east Asia", "question": "Would a body builder prefer an elk burger over a beef burger?", "answer": true, "facts": ["Bodybuilders want to build muscle and keep fat low", "Elk meat is leaner than beef", "Elk meat has higher protein than beef", "Protein helps build muscle"], "decomposition": ["Which nutrients are more important for a body builder's diet?", "How is an elk burger different from a beef burger in terms of nutrients?", "Considering #1 and #2 would an elk burger be a better source of #1?"], "evidence": [[[["Bodybuilding-31", "Bodybuilding-41"]], [["Elk-3"]], [["Bodybuilding-31", "Elk-3"]]], [[["Bodybuilding-41"]], [["Elk-3"]], ["operation"]], [[["Bodybuilding-39"]], [["Elk-3"]], [["Elk-3"], "operation"]]]}
{"qid": "da76a093d3b1cc47c6f2", "term": "Traffic collision", "description": "occurs when a vehicle collides with another vehicle, pedestrian, animal, road debris, or other stationary obstruction, such as a tree, pole or building or drives off the road", "question": "Can a traffic collision make someone a millionaire?", "answer": true, "facts": ["Traffic collisions sometimes result in extremely expensive physical damage.", "Physical damage is compensated by insurance companies in the form of monetary payment.", "Million dollar verdicts are sometimes awarded for traffic collisions that result in major damage. "], "decomposition": ["What can kind of damage can traffic collisions cause?", "If #1 occurs, how would insurance companies react?", "Can #2 sometimes occur in a million dollar verdict?"], "evidence": [[[["Personal injury-1"], "no_evidence"], [["Personal injury-26"], "no_evidence"], [["Pain and suffering-5"], "no_evidence", "operation"]], [[["Traffic collision-1"]], [["Vehicle insurance in the United States-1"]], [["Traffic collision-84"]]], [[["Traffic collision-1"]], [["Vehicle insurance-1"]], ["no_evidence"]]]}
{"qid": "b77d2efee37741e44c32", "term": "Space Race", "description": "Competition between the USSR and the USA to explore space", "question": "Did the Space Race use relay batons?", "answer": false, "facts": ["The Space Race was a competition between the USA and USSR regarding spaceflight and exploration", "Relay batons are used in relay races", "Relay races are athletic track and field events"], "decomposition": ["What was the Space Race?", "What are relay batons used for?", "Is #1 the same as #2?"], "evidence": [[[["Space Race-1"]], [["Relay race-11"]], [["Relay race-11", "Space Race-1"], "operation"]], [[["Space Race-1"]], [["Relay race-1"]], ["operation"]], [[["Space Race-1"]], [["Relay race-1"]], ["operation"]]]}
{"qid": "24b3b5e476a4c7b4824e", "term": "Aldi", "description": "Germany-based supermarket chain", "question": "Would you spend less on your food at Aldi than at Whole Foods?", "answer": true, "facts": ["Whole Foods is known for costing 10-20% more than other stores.", "Aldi is known for having deeply discounted food and home supplies."], "decomposition": ["What is Aldi mainly known for?", "Compared to other stores, how do Whole Foods prices compare?", "Would #1 have goods that cost less than #2?"], "evidence": [[[["Aldi-1"]], [["Whole Foods Market-2"], "no_evidence"], ["no_evidence", "operation"]], [[["Aldi-1"]], [["Whole Foods Market-1", "Whole Foods Market-24"], "no_evidence"], [["Discount store-1"], "operation"]], [[["Aldi-1"]], [["Wild Oats Markets-11"]], ["operation"]]]}
{"qid": "f5e5ec91462ee970cf86", "term": "Statue of Freedom", "description": "19th-century statue by Thomas Crawford on top of the US Capitol", "question": "Can you see the Statue of Freedom from the Statue of Liberty?", "answer": false, "facts": ["The Statue of Freedom is in Washington, D.C. on the Capitol Building", "The Statue of Liberty is in New York City"], "decomposition": ["Where is the Statue of Freedom located?", "Where is the Statue of Liberty located?", "Is #1 within reasonable range of visibility from #2?"], "evidence": [[[["Statue of Freedom-2"]], [["Statue of Liberty-1"]], [["Statue of Freedom-2"]]], [[["Statue of Freedom-1"]], [["Statue of Liberty-1"]], ["operation"]], [[["Statue of Freedom-1"]], [["Statue of Liberty-1"]], ["operation"]]]}
{"qid": "d8eaf52f02c5cfb98bce", "term": "Sacrum", "description": "Triangular-shaped bone at the bottom of the spine", "question": "Do human sacrums have more fused vertebrae than an Alaskan Malamute?", "answer": true, "facts": ["The human sacrum consists of five fused vertebrae.", "An Alaskan Malamute is a large domestic dog breed.", "Dogs have three fused vertebrae attached to their sacrums."], "decomposition": ["How many vertebrae are found in the human sacrum?", "What species of animal is an Alaskan Malamute?", "How many vertebrae are found in a #2's sacrum?", "Is #1 greater than #3?"], "evidence": [[[["Sacrum-1"]], [["Alaskan Malamute-1"]], [["Dog anatomy-54", "Nuchal ligament-10"], "no_evidence"], ["no_evidence", "operation"]], [[["Sacrum-1"]], [["Alaskan Malamute-1"]], [["Sacrum-4"]], ["operation"]], [[["Sacrum-1"]], [["Alaskan Malamute-1"]], [["Sacrum-4"]], ["operation"]]]}
{"qid": "80aa769f55b14c1e4d8d", "term": "Sable", "description": "Species of marten", "question": "Are sables related to wolverines?", "answer": true, "facts": ["The sable is a species of marten, which make up the genus Martes.", "Wolverines are from the genus Gulo.", "Both the Martes and the Gulo are from the family Mustelidae."], "decomposition": ["What species is a sable?", "What genus is #1 from?", "What genus are wolverines from?", "Are #2 and #3 from the same family?"], "evidence": [[[["Sable-1"]], [["Marten-1"]], [["Gulo-1"]], [["Gulo-1", "Marten-1"]]], [[["Sable-1"]], [["Marten-1"]], [["Gulo-1", "Wolverine-1"]], ["operation"]], [[["Sable-1"]], [["Marten-1"]], [["Gulo-1"]], ["operation"]]]}
{"qid": "8f936e225ee1fe225f66", "term": "Shaggy (musician)", "description": "Reggae singer and former U.S. Marine", "question": "Would Shaggy and Redenbacher popcorn founder both raise hand during first name roll call?", "answer": true, "facts": ["Roll call is when teachers call the names of students and they raise their hand to show they are present.", "The founder of Redenbacher popcorn was Orville Redenbacher.", "Reggae musician Shaggy was born Orville Richard Burrell."], "decomposition": ["What is the first name of the person who founded Redenbacher popcorn?", "What is the first name of Reggae musician Shaggy?", "Is #1 the same as #2?"], "evidence": [[[["Orville Redenbacher-1"]], [["Shaggy (musician)-1"]], ["operation"]], [[["Orville Redenbacher-1"]], [["Shaggy (musician)-1"]], ["operation"]], [[["Orville Redenbacher-1"]], [["Shaggy (musician)-1"]], ["operation"]]]}
{"qid": "643a517d0d0f0d2944a3", "term": "Prime number", "description": "Integer greater than 1 that has no positive integer divisors other than itself and 1", "question": "Are Brian Cranston and Saoirse Ronan's combined Emmy Awards a prime number?", "answer": false, "facts": ["Brian Cranston has won 6 Emmy Awards.", "Saoirse Ronan has won 0 Emmy awards.", "6 is divisible by the following numbers: 1,2,3, and 6."], "decomposition": ["How many Emmy Awards has Brian Cranston won?", "How many Emmy Awards has Saoirse Ronan won?", "What is #1 plus #2?", "Is #3 not evenly divisible by any other number than 1 and #3?"], "evidence": [[[["Bryan Cranston-2"]], [["Saoirse Ronan-1"]], ["operation"], [["Composite number-4"], "operation"]], [[["Bryan Cranston-27"]], [["Saoirse Ronan-1"]], ["operation"], ["operation"]], [[["Bryan Cranston-12"]], [["Saoirse Ronan-1"], "no_evidence"], ["operation"], ["operation"]]]}
{"qid": "7ce5f72988455dfb63da", "term": "Samsung Galaxy", "description": "series of Android mobile computing devices", "question": "Would the operating system of a Samsung Galaxy 1 sound edible?", "answer": true, "facts": ["The first Samsung Galaxy device ran a version of Android from 2009.", "In 2009, the Android edition was called \"cupcake.\" "], "decomposition": ["What are the operating systems of a Samsung Galaxy 1?", "Does #1 sound like something that is edible?"], "evidence": [[[["Samsung Galaxy S-22"]], ["operation"]], [[["Android Cupcake-1", "Samsung Galaxy (original)-1"]], [["Cupcake-1"], "operation"]], [[["Samsung Galaxy S-26"], "no_evidence"], ["operation"]]]}
{"qid": "a202af46315d9970d768", "term": "University of Pittsburgh", "description": "American state-related research university located in Pittsburgh, Pennsylvania", "question": "Did University of Pittsburgh founder have great deal in common with Judith Sheindlin?", "answer": true, "facts": ["Hugh Henry Brackenridge founded University of Pittsburgh in 1787.", "Judith Sheindlin is a judge, lawyer, and author.", "Hugh Henry Brackenridge was a writer, lawyer, judge, and Justice of the Supreme Court of Pennsylvania."], "decomposition": ["Who was the founder of University of Pittsburgh?", "What are the major things #1 is known for?", "What are the major things Judith Sheindlin is known for?", "Is there an overlap between #2 and #3?"], "evidence": [[[["History of the University of Pittsburgh-2"]], [["Hugh Henry Brackenridge-4"]], [["Judy Sheindlin-1"]], [["Judge-5"], "operation"]], [[["University of Pittsburgh-1"]], [["Hugh Henry Brackenridge-1"]], [["Judy Sheindlin-1"]], ["operation"]], [[["History of the University of Pittsburgh-2"]], [["Hugh Henry Brackenridge-1"]], [["Judy Sheindlin-1"]], ["operation"]]]}
{"qid": "ae25e990129848141330", "term": "Florence", "description": "Capital and most populous city of the Italian region of Tuscany", "question": "Is there a Harry Potter character named after Florence?", "answer": true, "facts": ["Firenze is the native Italian form of the name Florence.", "There is a centaur who appars as a minor character in the Harry Potter series named Firenze.", "Firenze appears in three of the Harry Potter books but only one movie."], "decomposition": ["What is the native Italian form for the name Florence?", "What is the name of the centaur who appears  in the Harry Potter series?", "Is #1 the same as #2?"], "evidence": [[[["Florence (given name)-5"]], [["Magical creatures in Harry Potter-65"]], [["Florence (given name)-5", "Magical creatures in Harry Potter-65"], "operation"]], [[["Florence-1"]], [["Magical creatures in Harry Potter-65"]], ["operation"]], [[["Florence-1"]], [["Magical creatures in Harry Potter-65"]], ["operation"]]]}
{"qid": "363a55b705110a878be1", "term": "Goofy", "description": "Disney cartoon character", "question": "If Goofy were a pet, would he need heartworm prevention?", "answer": true, "facts": ["Goofy is an anthropomorphic dog character. ", "Dogs require regular heartworm prevention. "], "decomposition": ["What kind of animal is Goofy?", "Does a #1 require regular heartworm prevention?"], "evidence": [[[["Goofy-1"]], [["Dog-18"]]], [[["Goofy-1"]], [["Dog health-50"]]], [[["Goofy-1"]], ["operation"]]]}
{"qid": "2e508efbf0b72f1af2c2", "term": "Quartz", "description": "mineral composed of silicon and oxygen atoms in a continuous framework of SiO\u2084 silicon\u2013oxygen tetrahedra, with each oxygen being shared between two tetrahedra, giving an overall chemical formula of SiO\u2082", "question": "Could Quartz be useful to humans if plants died off and there was no oxygen?", "answer": true, "facts": ["Plants produce oxygen which is needed by humans to survive.", "Quartz is a hard mineral substance made of several elements.", "Quartz is composed of silicon and oxygen.", "Quartz can be melted at high temperatures."], "decomposition": ["What are the constituents elements of quartz?", "Is oxygen included in #1?"], "evidence": [[[["Quartz-1"]], ["operation"]], [[["Quartz-1"]], ["operation"]], [[["Quartz-1"]], [["Oxygen-1"]]]]}
{"qid": "8c599ce83178d5c0f480", "term": "Prime Minister of the United Kingdom", "description": "Head of UK Government", "question": "Does highest US Court have enough seats for every Prime Minister of the United Kingdom since 1952?", "answer": false, "facts": ["The highest court in the US is the Supreme Court.", "There are nine seats on the Supreme Court.", "There have been fifteen Prime Ministers of the United Kingdom since 1952."], "decomposition": ["What is the highest United States court?", "How many positions  are there in #1?", "How many United Kingdom Prime Ministers have there been since 1952?", "Is #2 equal to or greater than #3?"], "evidence": [[[["Supreme Court of the United States-1"]], [["Supreme Court of the United States-20"]], [["Anthony Eden-1", "Boris Johnson-1"], "no_evidence"], ["operation"]], [[["Supreme Court of the United States-1"]], [["Supreme Court of the United States-20"]], [["Alec Douglas-Home-1", "Anthony Eden-1", "Boris Johnson-1", "David Cameron-1", "Edward Heath-1", "Gordon Brown-1", "Harold Macmillan-1", "Harold Wilson-1", "James Callaghan-1", "John Major-1", "Margaret Thatcher-1", "Theresa May-1", "Tony Blair-1", "Winston Churchill-1"]], ["operation"]], [[["Supreme Court of the United States-1"]], [["Supreme Court of the United States-20"]], ["no_evidence"], ["no_evidence"]]]}
{"qid": "f9fcf86196d1847b2f0b", "term": "2008 Summer Olympics", "description": "Games of the XXIX Olympiad, held in Beijing in 2008", "question": "Could you drive a Rowe 550 to the 2008 Summer Olympics?", "answer": true, "facts": ["The Rowe 550 was a car produced by the Chinese SAIC motor company.", "The Rowe 550 debuted at the 2007 Shanghai Auto Show.", "The 2008 Beijing Summer Olympics happened in the Capital of the People's Republic of China."], "decomposition": ["When was the Roewe 550 launched?", "Did the 2008 Summer Olympics hold before or during #1?"], "evidence": [[[["Roewe 550-1"]], [["2008 Summer Olympics-1"], "operation"]], [[["Roewe 550-1"]], [["2008 Summer Olympics-1"], "operation"]], [[["Roewe 550-2"]], ["operation"]]]}
{"qid": "037acdd213ada618830f", "term": "Sesame", "description": "species of plant", "question": "Would a sesame seed be mistaken for a wood frog egg?", "answer": false, "facts": ["A sesame seed is a flat 3 to 4 mm size seed.", "Wood frog eggs are globe looking masses about 2 to 5 inches in diameter."], "decomposition": ["What shape and size is a sesame seed?", "What is the shape and size of a wood frog egg?", "Are #1 and #2 the same?"], "evidence": [[[["Sesame-11"]], [["Wood frog-14"]], [["Sesame-11", "Wood frog-14"]]], [[["Sesame-11"]], [["Wood frog-14"], "no_evidence"], ["operation"]], [[["Sesame-11"]], [["Wood frog-14", "Wood frog-3"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "e705505f353721ac0b59", "term": "PlayStation 4", "description": "Sony's eighth-generation home video game console", "question": "Did Tom Bosley enjoy video games on the PlayStation 4?", "answer": false, "facts": ["The PlayStation 4 was launched in 2013.", "Tom Bosley died in 2010."], "decomposition": ["What year did Tom Bosley die?", "What year was the PlayStation 4 Launched?", "Is #2 before #1?"], "evidence": [[[["Tom Bosley-13"]], [["PlayStation 4-1"]], ["operation"]], [[["Tom Bosley-13"]], [["PlayStation 4-1"]], ["operation"]], [[["Tom Bosley-1"]], [["PlayStation 4-1"]], ["operation"]]]}
{"qid": "0b577826d5e7b6a50aad", "term": "Alice's Adventures in Wonderland", "description": "book by Lewis Carroll", "question": "Is tobacco use made to seem enjoyable in Alice's Adventures in Wonderland?", "answer": true, "facts": ["In Alice's Adventures in Wonderland, one of the characters is a caterpillar that smokes hookah.", "Hookah is a water pipe used to smoke tobacco products.", "The caterpillar speaks to Alice while making letters out of the smoke he blows."], "decomposition": ["In Alice's Adventures in Wonderland, what is a caterpillar seen smoking?", "What do you use #1 to do?", "Does it seem like the caterpillar enjoys #2?"], "evidence": [[[["Alice's Adventures in Wonderland-13"]], [["Hookah-1"]], ["no_evidence"]], [[["Alice's Adventures in Wonderland-13"]], [["Hookah-1"]], ["no_evidence", "operation"]], [[["Alice's Adventures in Wonderland-13"]], [["Hookah-1"]], ["no_evidence", "operation"]]]}
{"qid": "250d2ecf5f5bc889a863", "term": "Hammer and sickle", "description": "Communist symbol", "question": "Did the Nazis use the Hammer and sickle flag?", "answer": false, "facts": ["Hammer and sickle is a communist symbol used on flags", "The Nazi flag had a large symbol of a swastika. ", "The hammer and sickle was used as a anti Nazi symbol during World War II."], "decomposition": ["Which symbol is featured in the Nazi flag?", "Is #1 a hammer and sickle symbol?"], "evidence": [[[["Flag of Nazi Germany-1"]], [["Hammer and sickle (disambiguation)-1"]]], [[["Flag of Nazi Germany-4"]], ["operation"]], [[["Flag of Nazi Germany-1"]], [["Swastika-1"]]]]}
{"qid": "d19a209a6cddeca38a94", "term": "National Hockey League", "description": "North American professional ice hockey league", "question": "Do American teams in National Hockey League outnumber Canadian teams?", "answer": true, "facts": ["The National Hockey League is the premiere North American hockey league.", "The National Hockey League has 7 Canadian teams.", "The National Hockey League has 24 teams from the United States."], "decomposition": ["How many Canadian teams are in the The National Hockey League?", "How many American teams are in the The National Hockey League?", "Is #2 greater than #1?"], "evidence": [[[["National Hockey League-1"]], [["National Hockey League-1"]], ["operation"]], [[["Ice hockey in the United States-5"]], [["Ice hockey in the United States-5"]], ["operation"]], [[["National Hockey League-1"]], [["National Hockey League-1"]], ["operation"]]]}
{"qid": "56434ca634c4ef6e0741", "term": "Eid al-Fitr", "description": "Islamic holiday that marks the end of Ramadan", "question": "Could  jockey win Triple Crown between Eid al-Fitr endpoints?", "answer": false, "facts": ["The Triple Crown is an accomplishment in which a jockey wins three specific races.", "The three Triple Crown races are: Preakness, Kentucky Derby, and Belmont Stakes.", "The three Triple Crown races take place weeks apart.", "Eid al-Fitr is a Muslim holiday that lasts for three consecutive days."], "decomposition": ["How long does Eid al-Fitr last?", "How long is it between the first and last races of the Triple Crown?", "Is #1 longer than #2?"], "evidence": [[[["Eid al-Fitr-4"]], [["Belmont Stakes-1"]], [["Week-1"], "operation"]], [[["Eid al-Fitr-1"]], [["Triple Crown of Thoroughbred Racing (United States)-1"], "no_evidence"], ["operation"]], [[["Eid al-Fitr-1"]], [["Belmont Stakes-1", "Kentucky Derby-1", "Triple Crown of Thoroughbred Racing (United States)-1"]], ["operation"]]]}
{"qid": "115dd3102b245bdbc737", "term": "Dr. Seuss", "description": "American children's writer and illustrator", "question": "Did Dr. Seuss live a tragedy free life?", "answer": false, "facts": ["Dr. Seuss's wife committed suicide.", "In his later years, Dr. Seuss was diagnosed with cancer."], "decomposition": ["Was Dr. Seuss' life free of tragic occurrences?"], "evidence": [[[["Dr. Seuss-20"]]], [[["Dr. Seuss-20"]]], [[["Dr. Seuss-22"], "no_evidence"]]]}
{"qid": "441d83eccca7714ba2a7", "term": "Harlem Renaissance", "description": "African-American cultural movement in New York City in the 1920s", "question": "Could Al Capone have read works from the Harlem Renaissance?", "answer": true, "facts": ["The Harlem Renaissance occurred during the 1920s.", "Al Capone lived through the 1920s."], "decomposition": ["When was the Harlem Renaissance?", "Was Al Capone able to read during #1?"], "evidence": [[[["Harlem Renaissance-1"]], [["Al Capone-1"], "operation"]], [[["Harlem Renaissance-1"]], [["Al Capone-1"], "operation"]], [[["Harlem Renaissance-41"], "no_evidence"], [["Al Capone-3"], "no_evidence"]]]}
{"qid": "bcfeb6bb99d969f74e48", "term": "Popular science", "description": "Interpretation of science intended for a general audience", "question": "Is \"A Tale of Two Cities\" a popular science novel?", "answer": false, "facts": ["\"A Tale of Two Cities\" is a historical fiction novel.", "Popular science books focus on scientific facts presented to a mainstream audience.", "Fiction is not fact."], "decomposition": ["What genre is the novel 'A Tale of Two Cities' classified as?", "Is #1 based on scientific facts?"], "evidence": [[[["A Tale of Two Cities-1"]], ["operation"]], [[["A Tale of Two Cities-1"]], ["operation"]], [[["A Tale of Two Cities-1"]], [["Historical fiction-3"]]]]}
{"qid": "784d37fe54b0ad49c49a", "term": "Jukebox musical", "description": "stage or film musical compiled from pre-existing songs", "question": "Is there a jukebox musical about a sweet transvestite from Transexual, Transylvania?", "answer": false, "facts": ["Jukebox musicals feature songs that have already been released.", "Rocky Horror Picture Show is about a sweet transvestite from Transexual, Transylvania", "Rocky Horror Picture Show contains songs written specifically for itself"], "decomposition": ["What is characteristic of songs in a jukebox musical?", "What musical is about a sweet transvestite from Transexual, Transylvania?", "Does #2 contain #1?"], "evidence": [[[["Jukebox musical-6"]], [["The Rocky Horror Picture Show-5"]], ["operation"]], [[["Jukebox musical-1"]], [["The Rocky Horror Show-1"]], ["operation"]], [[["Jukebox musical-1"]], [["The Rocky Horror Picture Show-5"]], [["The Rocky Horror Picture Show-31"], "no_evidence", "operation"]]]}
{"qid": "86a79365b44b937959f7", "term": "B\u00f6rek", "description": "Stuffed phyllo pastry", "question": "Would Recep Tayyip Erdo\u011fan be unfamiliar with b\u00f6rek?", "answer": false, "facts": ["Turkey enjoys a wide variety of regional variations of b\u00f6rek among the different cultures and ethnicities composing it.", "B\u00f6rek is very popular in the cuisines of the former Ottoman Empire, especially in North Africa and throughout the Balkans.", "Recep Tayyip Erdo\u011fan is the current president of Turkey and he was born and raised there."], "decomposition": ["Where was Recep Tayyip Erdo\u011fan born?", "In which regions is b\u00f6rek part of the normal cuisine?", "Is #1 not part of #2?"], "evidence": [[[["Istanbul-1", "Recep Tayyip Erdo\u011fan-7"]], [["B\u00f6rek-1"]], ["operation"]], [[["Recep Tayyip Erdo\u011fan-7"]], [["B\u00f6rek-9"]], ["operation"]], [[["Istanbul-1", "Recep Tayyip Erdo\u011fan-7"]], [["B\u00f6rek-1"]], [["Turkey-1"], "operation"]]]}
{"qid": "9e18fca673458935cbe8", "term": "Carnation Revolution", "description": "revolution", "question": "Was the Carnation Revolution the deadliest revolution in Europe?", "answer": false, "facts": ["The Carnation Revolution was initially a 25 April 1974 military coup in Lisbon which overthrew the authoritarian Estado Novo regime.", "Its name arose from the fact that almost no shots were fired, and Celeste Caeiro offered carnations to the soldiers when the population took to the streets to celebrate the end of the dictatorship; other demonstrators followed suit, and carnations were placed in the muzzles of guns and on the soldiers' uniforms.", "Portugal is a country located mostly on the Iberian Peninsula, in southwestern Europe."], "decomposition": ["Why was the Carnation Revolution so named?", "Does #1 imply that no lives were lost?", "Did the Revolution take place in Europe?", "Is #2 or #3 negative?"], "evidence": [[[["Carnation Revolution-2"]], [["Carnation Revolution-7"]], [["Carnation Revolution-1", "Portugal-1"]], ["operation"]], [[["Carnation Revolution-2"]], ["operation"], [["Carnation Revolution-1", "Lisbon-1"]], ["operation"]], [[["Carnation Revolution-2"]], ["operation"], [["Carnation Revolution-1"]], ["operation"]]]}
{"qid": "748b072c995cf5147ac9", "term": "Music", "description": "form of art using sound and silence", "question": "Are deaf people left out of enjoying music?", "answer": false, "facts": ["Deafness exists on a spectrum of total hearing loss to partial hearing loss.", "Individuals with total hearing loss can still enjoy the bass and beat of music through vibration.", "Deaf people with cochlear implants can hear music, albeit in a different way than hearing people."], "decomposition": ["In what different ways can music be perceived?", "Does partial or total hearing loss make one unable to detect any of #1?"], "evidence": [[[["Hearing loss-38"], "no_evidence"], [["Vibration-4"], "no_evidence", "operation"]], [[["Music-1"], "no_evidence"], [["Dance-1"], "no_evidence", "operation"]], [[["Sound-6"]], [["Deaf hearing-2"], "operation"]]]}
{"qid": "2a7eeadb1e045fda4550", "term": "Spinach", "description": "species of plant", "question": "Was the amount of spinach Popeye ate unhealthy?", "answer": true, "facts": ["Popeye was a cartoon character that ate whole cans of spinach to maintain his fighting strength.", "Spinach is high in oxalates which can lead to kidney stones.", "Too much spinach can lead to bloating, gas, fever, and diarrhea."], "decomposition": ["What is spinach high in?", "What does eating too much of #1 do to a body?", "Are #2's bad for a body?"], "evidence": [[[["Spinach-1"]], [["Oxalate-10"]], [["Kidney stone disease-1", "Oxalate-10"]]], [[["Spinach-7"]], [["Oxalate-10"]], ["operation"]], [[["Spinach-7"]], [["Vitamin A-13"]], [["Vitamin A-16"]]]]}
{"qid": "f61fa68d73eb81ede181", "term": "Gorillaz", "description": "British virtual band", "question": "Does it seem like the Gorillaz is composed of more members than they have?", "answer": true, "facts": ["In music videos for Gorillaz songs, there are four animated bandmates playing.", "Gorillaz is a collaboration of 3 band members."], "decomposition": ["How many band members are in Gorillaz?", "How many animated band members are in Gorillaz videos?", "Is #2 more than #1?"], "evidence": [[[["Gorillaz-1"]], [["Gorillaz-1"]], ["operation"]], [[["Gorillaz-1"]], [["Gorillaz-1"]], ["operation"]], [[["Gorillaz-1"]], [["Gorillaz-1"]], ["operation"]]]}
{"qid": "5633fa480c01d39119ee", "term": "B", "description": "letter in the Latin alphabet", "question": "Is B's place in alphabet same as Prince Harry's birth order?", "answer": true, "facts": ["B is the second letter of the alphabet.", "Prince Harry was the second son of Charles, Prince of Wales and Diana, Princess of Wales."], "decomposition": ["What position in the alphabet does \"B\" hold?", "What is the nominal number associated with #1?", "Does Prince Harry have exactly #2 minus 1 older siblings?"], "evidence": [[[["B-1"]], [["Nominal number-1", "Nominal number-2"], "operation"], [["Prince Harry, Duke of Sussex-1", "Prince Harry, Duke of Sussex-2"], "operation"]], [[["B-1"]], [["Ordinal numeral-9"]], [["Prince Harry, Duke of Sussex-4"]]], [[["B-1"]], ["operation"], [["Prince Harry, Duke of Sussex-4"], "operation"]]]}
{"qid": "8cfde6ee28d059a5aff6", "term": "Very Large Telescope", "description": "telescope in the Atacama Desert, Chile", "question": "Is it possible to get killed walking to the Very Large Telescope?", "answer": true, "facts": ["The Very Large Telescope is in the Atacama Desert", "The Atacama Desert is the driest hot desert in the world."], "decomposition": ["Where is the Very Large Telescope?", "How hot is it in #1?", "Is it possible to die from being somewhere that is #2?"], "evidence": [[[["Very Large Telescope-1"]], [["Atacama Desert-7"]], [["Desert-4"]]], [[["Very Large Telescope-1"]], [["Arabian Desert-8"]], [["Heat stroke-1"], "operation"]], [[["Very Large Telescope-1"]], [["Atacama Desert-23"], "no_evidence"], [["Evan Tanner-27", "Evan Tanner-29"], "operation"]]]}
{"qid": "e374088f76c6618c3459", "term": "Portuguese Colonial War", "description": "1961\u20131974 armed conflicts in Africa between Portugal and independence movements", "question": "Do all of the African regions that participated in the Portugese Colonial War share an official language?", "answer": true, "facts": [" The current African nations of Angola, Guinea-Bissau and Mozambique participated in the the Portugese Colonial War.", "The Portugese Colonial War was a decisive struggle in Lusophone Africa.", "Lusaphone countries are those that include Portugese as an official language."], "decomposition": ["Which African nations participated in the Portuguese Colonial War?", "Which African region did all of #1 belong to?", "Do all nations in #2 share official language?"], "evidence": [[[["Portuguese Colonial War-1"], "no_evidence"], [["Portuguese Colonial War-1"]], [["Lusophone-1"]]], [[["Portuguese Colonial War-24"]], [["Southern Africa-2"]], [["Swahili language-1"]]], [[["Portuguese Colonial War-2"]], [["Sub-Saharan Africa-1"], "no_evidence"], [["Portuguese Angola-36", "Portuguese Guinea-4", "Portuguese Mozambique-55"], "no_evidence", "operation"]]]}
{"qid": "05e69c19a536222d90db", "term": "Anorexia nervosa", "description": "Eating disorder characterized by refusal to maintain a healthy body weight, and fear of gaining weight due to a distorted self image", "question": "Did Jon Brower Minnoch suffer from anorexia nervosa?", "answer": false, "facts": ["Jon Brower Minnoch was an American man who, at his peak weight, was the heaviest human being ever recorded, weighing 1,400 lb.", "Anorexia nervosa,Anorexia nervosa is an eating disorder, characterized by low weight, food restriction, fear of gaining weight, and a strong desire to be thin. Many people with anorexia see themselves as overweight even though they are, in fact, underweight."], "decomposition": ["What are characteristics of anorexia nervosa?", "How much did Jon Brower Minnoch weigh?", "Is #2 a weight that would be considered #1?"], "evidence": [[[["Anorexia nervosa-1"]], [["Jon Brower Minnoch-1"]], [["Anorexia nervosa-2", "Jon Brower Minnoch-5"]]], [[["Anorexia nervosa-1"]], [["Jon Brower Minnoch-1"]], ["operation"]], [[["Anorexia nervosa-4"]], [["Jon Brower Minnoch-1"]], [["Jon Brower Minnoch-1"], "operation"]]]}
{"qid": "2c71f90e9c5656eb8edc", "term": "Black Sea", "description": "Marginal sea of the Atlantic Ocean between Europe and Asia", "question": "Could the moon fit inside the Black Sea?", "answer": false, "facts": ["The volume of the Black Sea is 547,000 cubic kilometers.", "The volume of the moon is 21.9 billion cubic kilometers."], "decomposition": ["What is the volume of the Black Sea?", "What is the volume of the moon?", "Is #1 higher than #2?"], "evidence": [[[["Black Sea-2"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Black Sea-2"]], [["Moon-48"], "no_evidence"], ["operation"]], [[["Black Sea-28"], "no_evidence"], [["Earth-85"], "no_evidence"], ["operation"]]]}
{"qid": "669b3c6a48f494a5d74e", "term": "Kurt Cobain", "description": "American singer, composer, and musician", "question": "Was Kurt Cobain's death indirectly caused by Daniel LeFever?", "answer": true, "facts": ["Kurt Cobain committed suicide with a shotgun.", "Daniel LeFever was the inventor of the American hammerless shotgun."], "decomposition": ["What object caused the death of Kurt Cobain?", "Was #1 invented by Daniel LeFever?"], "evidence": [[[["Suicide of Kurt Cobain-1"]], ["operation"]], [[["Kurt Cobain-3"]], [["Daniel Myron LeFever-1"]]], [[["Kurt Cobain-55"]], [["Shotgun-38"]]]]}
{"qid": "e39243fb96d47aba82a2", "term": "Jackson Pollock", "description": "American painter", "question": "Was Jackson Pollock trained by Leonardo da Vinci?", "answer": false, "facts": ["Leonardo lived during the Italian Renaissance in the 17th century.", "Jackson Pollock lived during the 20th century."], "decomposition": ["When did Leonardo da Vinci die?", "When was Jackson Pollock born?", "Is #2 before #1?"], "evidence": [[[["Leonardo da Vinci-1"]], [["Jackson Pollock-1"]], ["operation"]], [[["Leonardo da Vinci-1"]], [["Jackson Pollock-1"]], ["operation"]], [[["Leonardo da Vinci-27"], "no_evidence"], [["Jackson Pollock-4"], "operation"], ["no_evidence"]]]}
{"qid": "4496d5cac14132b6e7ea", "term": "San Antonio", "description": "City in Texas, United States", "question": "Did any citizen of San Antonio vote for Boris Johnson?", "answer": false, "facts": ["San Antonio is a city in Texas in the United States of America", "Boris Johnson is the Prime Minister of the UK", "Only UK and commonwealth citizens may vote in UK elections"], "decomposition": ["Is San Antonio a city in the UK?", "Is Boris Johnson the Prime Minister of the UK?", "Are American citizens allowed to vote in the UK elections?", "Are #1 and #3 the same answer as #2?"], "evidence": [[[["San Antonio-18"]], [["Boris Johnson-100"]], ["no_evidence"], ["operation"]], [[["San Antonio-41"]], [["Boris Johnson-100"]], [["Elections in the United Kingdom-7"]], ["operation"]], [[["San Antonio-1"]], [["Boris Johnson-1"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "3c95fe5ad91a9c38bc15", "term": "Arnold Schwarzenegger", "description": "Austrian-American actor, businessman, bodybuilder and politician", "question": "Can Arnold Schwarzenegger deadlift an adult Black rhinoceros?", "answer": false, "facts": ["Arnold Schwarzenegger deadlifted 710 pounds in a competition.", "The world deadlift record is 1,104 pounds, set by Game of Thrones actor Hafthor Bjornsson.", "The weight of an adult Black rhinoceros is between 1,800 \u2013 3,100 pounds."], "decomposition": ["How much can Arnold Schwarzenegger deadlift?", "How much does an adult Black rhino weigh?", "Is #1 greater than #2?"], "evidence": [[[["Arnold Schwarzenegger-24"]], [["Black rhinoceros-8"]], ["operation"]], [[["Arnold Schwarzenegger-24"]], [["Black rhinoceros-8"]], ["operation"]], [[["Arnold Schwarzenegger-24"]], [["Black rhinoceros-8"]], ["operation"]]]}
{"qid": "30b5a9505949caa3c4cd", "term": "President of India", "description": "Ceremonial head of state of India", "question": "Is it more expensive to run for President of India than to buy a new iPhone 11?", "answer": false, "facts": ["Candidates for the presidency of India must pay a deposit of Rs 15,000", "A brand new iPhone 11 costs Rs 67,300"], "decomposition": ["How much must a candidate pay to run for president in India?", "How much does a new iPhone 11 cost?", "Is #1 more than #2?"], "evidence": [[[["President of India-63"], "no_evidence"], [["IPhone-10"], "no_evidence"], ["operation"]], [[["President of India-2"], "no_evidence"], [["IPhone 11-1"], "no_evidence"], ["no_evidence", "operation"]], [[["President of India-57"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "261863cb4eeef4df279d", "term": "Surveying", "description": "The technique, profession, and science of determining the positions of points and the distances and angles between them", "question": "Would you hire someone with dyscalculia to do surveying work?", "answer": false, "facts": ["Dyscalculia is a learning disability in math. People with dyscalculia have trouble with math at many levels. ", "Surveyors work with elements of geometry, trigonometry, regression analysis, physics, engineering, metrology, programming languages, and the law. ", "Geometry and trigonometry are types of advanced mathematics."], "decomposition": ["What do people with dyscalculia struggle with?", "What skills are necessary to be a competent surveyor?", "Is #1 not listed in #2?"], "evidence": [[[["Dyscalculia-1"]], [["Surveying-2"]], ["operation"]], [[["Dyscalculia-1"]], [["Surveying-2"]], ["operation"]], [[["Dyscalculia-1"]], [["Surveying-2"]], ["operation"]]]}
{"qid": "b418ba4e11aee26faabc", "term": "Jason", "description": "Greek mythological hero", "question": "Does Jason have anything in common with Dr. Disrespect?", "answer": true, "facts": ["Jason cheated on Medea with Creusa", "Dr. Disrespect cheated on his wife with another woman"], "decomposition": ["Was Jason faithful or unfaithful?", "Was Dr. Disrespect faithful or unfaithful?", "Are #1 and #2 the same?"], "evidence": [[[["Medea-10"], "no_evidence"], [["Dr DisRespect-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Jason-3"]], ["no_evidence"], ["operation"]], [[["Jason-18"]], [["Dr DisRespect-5"]], ["operation"]]]}
{"qid": "cc072feedd07aee23d2a", "term": "Samsung Galaxy", "description": "series of Android mobile computing devices", "question": "Does Iphone have more iterations than Samsung Galaxy?", "answer": false, "facts": ["As of 2020 the latest Iphone is Iphone 11.", "As of 2020 the latest Samsung Galaxy phone is the Samsung Galaxy S20."], "decomposition": ["How many models of the iPhone have been released as of 2020?", "How many models of the Samsung Galaxy have been released as of 2020?", "Is #1 greater than #2?"], "evidence": [[[["IPhone-178"]], [["Samsung Galaxy-1"], "no_evidence"], ["operation"]], [[["IPhone-178"]], [["Samsung Galaxy-1"], "no_evidence"], ["no_evidence", "operation"]], [[["IPhone SE (2nd generation)-1"]], [["Samsung Galaxy S20-1"]], ["operation"]]]}
{"qid": "668a4e03534608476faf", "term": "Ringo Starr", "description": "British musician, drummer of the Beatles", "question": "Would Ringo Starr avoid the pot roast at a restaurant?", "answer": true, "facts": ["Ringo Starr is a vegetarian.", "Vegetarianism is the practice of abstaining from the consumption of meat.", "Pot roast is a braised beef dish made by browning a roast-sized piece of beef before slow cooking the meat in a covered dish, sometimes with vegetables, in or over liquid."], "decomposition": ["What dietary system does Ringo Starr follow?", "What type of foods are not allowed to be eaten by someone following #1?", "What is pot roast made of?", "Is #3 part of #2?"], "evidence": [[[["Ringo Starr-71"]], [["Vegetarianism-1"]], [["Pot roast-1"]], ["operation"]], [[["Ringo Starr-71"]], [["Vegetarianism-1"]], [["Pot roast-1"]], [["Beef-1"], "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence"], ["no_evidence"]]]}
{"qid": "b5cdf7f8a6b440cdd451", "term": "Carl Friedrich Gauss", "description": "German mathematician and physicist", "question": "Could Carl Friedrich Gauss speak to someone 100 miles away?", "answer": false, "facts": ["Carl Friedrich Gauss was born in 1777.", "Speaking to someone 100 miles away requires a telephone.", "The telephone was invented in 1876."], "decomposition": ["What device allows people to speak to each other even if they are 100 miles apart?", "When was #1 invented?", "When did Carl Friedrich Gauss die?", "Is #2 before #3?"], "evidence": [[[["Telephone-1"]], [["Telephone-19"]], [["Carl Friedrich Gauss-13"]], ["operation"]], [[["Telephone-1"]], [["Telephone-22"]], [["Carl Friedrich Gauss-13"]], ["operation"]], [[["Telephone-1"]], [["Alexander Graham Bell-31"]], [["Carl Friedrich Gauss-1"]], ["operation"]]]}
{"qid": "b3522ea1e8d0a95dd0b3", "term": "Cooking", "description": "Preparing food for consumption with the use of heat", "question": "If your electric stove has a glass top, should you use cast iron skillets?", "answer": false, "facts": ["Cast iron skillets can scratch or crack flat top stoves.", "Glass top stoves are considered 'flat tops'."], "decomposition": ["What would cast iron skillets do to flat top serves?", "What kind of stove are glass top stoves?", "Would someone want their #2 to be #1?"], "evidence": [[[["Cooktop-8"], "no_evidence"], [["Cooktop-5"]], ["operation"]], [[["Cast-iron cookware-1"], "no_evidence"], [["Kitchen stove-1"], "no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], [["Electric stove-13"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "d57b4438cf31f3ca05fe", "term": "Roman numerals", "description": "Numbers in the Roman numeral system", "question": "Is MIX a word and a roman numeral?", "answer": true, "facts": ["\"Mix\" means to combine in english.", "M equals one thousand in roman numerals", "I equals one in roman numerals ", "I before X in roman numerals equals nine.", "MIX equals one thousand nine in roman numerals. "], "decomposition": ["What does Mix mean in english language?", "Is Mix a number in Roman numerals?", "Based on #1 and #2, is mix both a word and a roman numeral?"], "evidence": [[[["Audio mixing (recorded music)-1"]], [["Roman numerals-5"]], [["Audio mixing (recorded music)-1", "Roman numerals-5"]]], [[["Mix (magazine)-1", "Mixing (process engineering)-38"], "no_evidence"], [["1009-1", "Roman numerals-1"]], ["operation"]], [[["DJ mix-1"]], [["Roman numerals-5"]], ["operation"]]]}
{"qid": "07ba78b177df5d2a30c3", "term": "Whole genome sequencing", "description": "A process that determines the complete DNA sequence of an organism's genome at a single time", "question": "Did Rosalind Franklin contribute to work that led to Whole Genome Sequencing?", "answer": true, "facts": ["Rosalind Franklin used specialized photography to capture the first photos of the double helix.", "The double helix is the form that DNA takes.", "Without understanding the structure of DNA, genome sequencing would be impossible."], "decomposition": ["Rosalind Franklin capture the first photo of what?", "What takes the form of #1?", "Is understanding #2 essential to genome sequencing?"], "evidence": [[[["Rosalind Franklin-19"]], [["DNA-1"]], [["Whole genome sequencing-1"], "operation"]], [[["Rosalind Franklin-3"]], [["Rosalind Franklin-3"]], [["Whole genome sequencing-1"], "operation"]], [[["Rosalind Franklin-3"]], [["Rosalind Franklin-3"]], [["Rosalind Franklin-3", "Whole genome sequencing-3"]]]]}
{"qid": "697789a9ee6a5b2f4e0f", "term": "Michael", "description": "male given name", "question": "Is Michael an unpopular name in the United States?", "answer": false, "facts": ["More boys were named Michael in the United States than any other name between 1954 and 1998.", "Michael and its foreign variants were within the top 20 names in Canada, Australia, UK, and Europe in the 2010s."], "decomposition": ["What are the most popular names in the USA?", "Is Michael absent from #1?"], "evidence": [[["no_evidence"], ["no_evidence", "operation"]], [[["Michael-5"], "no_evidence"], ["operation"]], [[["John (given name)-2", "Michael-5", "Richard-2", "Robert-3"]], ["operation"]]]}
{"qid": "71ca1a8a75c5c582ab3f", "term": "Head coach", "description": "Senior coach or manager of a sports team", "question": "Do most high school head coaches make as much as the Head Coach at NCSU?", "answer": false, "facts": ["The average high school makes about $41,000.", "The head coach for NCSU makes about $1.8 million dollars."], "decomposition": ["What is the average salary for a high school head coach?", "What is the salary of the head football coach at NCSU?", "Is #1 within 5% of #2?"], "evidence": [[["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Head coach-4"], "no_evidence"], [["NC State Wolfpack-1"], "no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], [["NC State Wolfpack football-34"]], ["no_evidence", "operation"]]]}
{"qid": "9cba30635f5cfd2ce0d4", "term": "Student", "description": "learner, or someone who attends an educational institution", "question": "Do Elementary School students typically need graphing calculators?", "answer": false, "facts": ["Elementary schools typically teach K-5th grade.", "5th Graders are reaching a point in their education where they are just beginning to understand decimals and fractions.", "Graphing calculators are used for higher level math work including complex equations and functions.", "Students are usually introduced to functions in late middle or high school math."], "decomposition": ["What grades are part of elementary schools?", "Out of all the grades in #1, what do students in the highest grade learn in math?", "What topics in math require students to use graphing calculators?", "Is #2 the same s #3?"], "evidence": [[[["Primary school-1"]], [["Arithmetic-54"]], [["Graphing calculator-10"]], ["operation"]], [[["Primary school-17"]], [["Primary education-2"], "no_evidence"], [["Graphing calculator-10"]], ["operation"]], [[["Primary school-17"]], [["Mathematics education-15"], "no_evidence"], [["Graphing calculator-10"], "no_evidence"], ["operation"]]]}
{"qid": "e6391d901dcc8a269c79", "term": "Fairy", "description": "mythical being or legendary creature", "question": "Did King James I despise fairy beings?", "answer": true, "facts": ["King James I wrote Daemonologie in which he stated that a fairy was a being that could act as a familiar.", "A familiar was an animal or spirit that conspired with The Devil.", "King James I presided over the execution of Agnes Sampson.", "Agnes Sampson was accused of conspiring with familiars and was burned at the stake."], "decomposition": ["What did King James I claim that fairies could act as in his book 'Daemonologie'", "Which beings did he execute Agnes Sampson for allegedly conspiring with?", "Is #1 the same as #2?"], "evidence": [[[["Daemonologie-8"], "no_evidence"], [["Agnes Sampson-9"], "no_evidence"], ["operation"]], [[["Daemonologie-15"]], [["Agnes Sampson-7"], "no_evidence"], ["operation"]], [[["Daemonologie-6"], "no_evidence"], [["Agnes Sampson-10", "Agnes Sampson-5", "Agnes Sampson-9"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "8e35a948ae9e0bf019f4", "term": "Curling", "description": "Team sport played on ice", "question": "Is a curling iron necessary in curling?", "answer": false, "facts": ["A curling iron is a tool used to make the hair curly using heat.", "The sport of curling requires curling brooms, stones (rocks), and curling shoes.", "Changing the structure of your hair has no practical benefit to the sport of curling."], "decomposition": ["What equipment is used in the sport of curling?", "Is a curling iron included in #1?"], "evidence": [[[["Curling-31"]], ["operation"]], [[["Curling-1"]], [["Hair iron-1"], "operation"]], [[["Curling-15", "Curling-21", "Curling-28", "Curling-32"]], ["operation"]]]}
{"qid": "acbc6f68c37f4f9dc601", "term": "Caracal", "description": "Small wild cat", "question": "Would a caracal be defeated by Javier Sotomayor in a high jump competition?", "answer": false, "facts": ["The caracal can leap higher than 12 feet in the air.", "Javier Sotomayor is the current men's high jump record holder with a jump of 2.45 m (8 ft 1\u20444 in)."], "decomposition": ["How high was Javier Sotomayor's highest jump?", "How high are caracals known to jump?", "Is #1 greater than #2?"], "evidence": [[[["Javier Sotomayor-11"]], [["Caracal-24"]], ["operation"]], [[["Javier Sotomayor-1"]], [["Caracal-2"]], ["operation"]], [[["Javier Sotomayor-1"]], [["Caracal-2"]], ["operation"]]]}
{"qid": "0d22526961c82ad6ef4a", "term": "Fairy", "description": "mythical being or legendary creature", "question": "Is a fairy more prevalent in world myths than a valkyrie?", "answer": true, "facts": ["Valkyries are female figures that choose heroes to bring to Valhalla.", "Valkyries are exclusive to Norse mythology.", "A fairy is a mystical magical being that can be found in Celtic, Slavic, German, English, and French folklore."], "decomposition": ["In what myths do the Valkyries appear?", "Do fairies appear in more myths than #1?"], "evidence": [[[["Valkyrie-1"]], [["Fairy-12"]]], [[["Valkyrie-2"], "no_evidence"], [["Fairy-2"], "no_evidence", "operation"]], [[["Valkyrie-1"]], [["Fairyland-1", "Fairyland-3"]]]]}
{"qid": "076f905ae36408b5ee69", "term": "Rainbow", "description": "meteorological phenomenon", "question": "Is lunch on the beach a good activity to spot the full circle of a rainbow?", "answer": false, "facts": ["The full circle of a rainbow cannot usually be seen from ground level", "Sometimes the full circle of a rainbow can be seen from a high building or aircraft", "You can see more of a rainbow the closer to the horizon the sun is", "Lunch occurs at midday when the sun is likely high in the sky"], "decomposition": ["At what point in the sky is the sun most likely to create a full circle rainbow?", "At what altitudes are full rainbows more likely to be seen?", "Is lunchtime at the beach relatively close to conditions #1 and #2?"], "evidence": [[[["Halo (optical phenomenon)-1"]], [["Halo (optical phenomenon)-2"]], [["Atmospheric optics-17", "Beach-16"]]], [[["Rainbow-2"], "no_evidence"], [["Rainbow-11"]], ["operation"]], [["no_evidence"], [["Rainbow-11"], "no_evidence"], [["Sea level-1"], "no_evidence", "operation"]]]}
{"qid": "959fb200fccf056f00d7", "term": "Naruto", "description": "Japanese manga and anime series", "question": "Did Naruto escape the Temple of Doom?", "answer": false, "facts": ["Naruto is a character in a Japanese anime and manga about ninjas", "The Temple of Doom is a setting from an Indiana Jones movie"], "decomposition": ["Which country was the movie Indiana Jones and the Temple of Doom set in?", "What is the setting of manga that features Naruto?", "Are #1 and #2 the same?"], "evidence": [[[["Indiana Jones and the Temple of Doom-4"]], [["Manga-1"]], ["operation"]], [[["Indiana Jones and the Temple of Doom-4"]], [["Naruto-1"]], ["operation"]], [[["Indiana Jones-8"]], [["Naruto-16"]], ["operation"]]]}
{"qid": "b995e9731d1488cc1241", "term": "Cancer", "description": "group of diseases", "question": "Do all cancer patients get disability?", "answer": false, "facts": ["All forms of cancer qualify as diagnoses that can result in disability.", "Disability is not determined by diagnosis, but by degree of impairment.", "Some cancer patients do not experience major impairment."], "decomposition": ["What is disability determined by?", "Do all patients of cancer have the same degree of #1?"], "evidence": [[[["Disability-1"]], [["Disability-4"]]], [[["Disability-2"], "no_evidence"], [["Cancer-99"], "no_evidence", "operation"]], [[["Disability Determination Services-18"]], [["Cancer rehabilitation-3"], "operation"]]]}
{"qid": "bd3caa68cb957d27b0e2", "term": "Lighthouse of Alexandria", "description": "Ancient lighthouse in Egypt", "question": "Were Greeks essential to crafting Egyptian Lighthouse of Alexandria?", "answer": true, "facts": ["The Lighthouse of Alexandria was an impressive monument in Egypt.", "The Lighthouse of Alexandria was built by pharaoh Ptolemy II.", "Ptolemy II was the son of Ptolemy I Soter.", "Ptolemy I Soter was a Greek bodyguard of Alexander the Great and became pharaoh of Egypt."], "decomposition": ["Who built the Lighthouse of Alexandria?", "Who was #1's father?", "Was #2 Greek?"], "evidence": [[[["Lighthouse of Alexandria-7", "Sostratus of Cnidus-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Lighthouse of Alexandria-6"]], [["Ptolemy I Soter-2"]], [["Philip II of Macedon-1"], "operation"]], [[["Lighthouse of Alexandria-6"]], [["Ptolemy I Soter-1"]], ["operation"]]]}
{"qid": "a18c59e77cc176f748b2", "term": "Blue", "description": "A primary colour between purple and green", "question": "Do some home remedies result in your skin color turning blue?", "answer": true, "facts": ["Colloidal silver is a popular alternative treatment/home remedy that is used by some people.", "Ingestion of colloidal silver in high amounts can tint the skin blue."], "decomposition": ["What can cause skin color to change?", "Of #1, what changes can be caused by ingestion of something?", "Of #2, what causes skin color to become blue?", "Is #3 used in home remedies?"], "evidence": [[[["Argyria-1", "Argyria-6", "Carrot juice-3", "Drug-induced pigmentation-2"]], [["Carrot juice-3", "Drug-induced pigmentation-2", "Medical uses of silver-21"]], [["Argyria-1"]], [["Argyria-5"], "operation"]], [[["Human skin color-41", "Human skin color-56"], "no_evidence"], ["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Cyanosis-1"]], [["Methemoglobinemia-2"]], [["Methemoglobinemia-6"]], [["Benzocaine-5"], "no_evidence"]]]}
{"qid": "dac61f77d13b59a9631e", "term": "Euro", "description": "European currency", "question": "Would someone pay for a coffee in NYC with Euros?", "answer": false, "facts": ["New York City is located within the United States.", "The currency used in the United States is the United States dollar, not the Euro."], "decomposition": ["In what country is New York City?", "What is the currency for #1?", "Is #2 the Euro?"], "evidence": [[[["New York City-1"]], [["United States dollar-1"]], ["operation"]], [[["New York City-1"]], [["United States dollar-1"]], ["operation"]], [[["New York City-1"]], [["United States dollar-1"]], ["operation"]]]}
{"qid": "4a99bfb0539856dbf1a4", "term": "Newcastle, New South Wales", "description": "City in New South Wales, Australia", "question": "Was the MLB World Series held in Newcastle, New South Wales?", "answer": false, "facts": ["The MLB World Series is held annually in a stadium belonging to one of its teams", "MLB teams are located in the United States and Canada", "New South Wales is a state in Australia"], "decomposition": ["In which countries are MLB World Series held?", "Is Australia one of #1?"], "evidence": [[[["MLB International-1"]], ["operation"]], [[["World Series-1"]], ["operation"]], [[["World Series-1"], "no_evidence"], ["operation"]]]}
{"qid": "e32529b0074a1b857a85", "term": "DC Comics", "description": "U.S. comic book publisher", "question": "Would Avengers Comics be out of place in a DC Comics store?", "answer": true, "facts": ["The Avengers are a comic produced by Marvel.", "Marvel and DC are rival companies, each having their own line of products and merchandise. "], "decomposition": ["Who produces the Avengers Comics?", "Are #1 and DC Comics rival companies?"], "evidence": [[[["Marvel Avengers Alliance-15"]], [["DC vs. Marvel-7"]]], [[["Avengers (comics)-1"]], [["DC Comics-18", "Marvel Comics-17"], "operation"]], [[["Avengers (comics)-1"]], [["Marvel Comics-25"]]]]}
{"qid": "47ba45019129dd07cb55", "term": "Stephen King", "description": "American author", "question": "Could Stephen King join the NASA Astronaut Corps?", "answer": false, "facts": ["NASA Astronaut Corps candidates must have a master's degree from an accredited institution in engineering, biological science, physical science or mathematics.", "Stephen King studied at the University of Maine, graduating in 1970 with a Bachelor of Arts in English."], "decomposition": ["What degrees are acceptable to meet the minimum requirement for admittance to the NASA Astronaut Corps?", "What degrees does Stephen King hold?", "Is #2 also in #1?"], "evidence": [[[["NASA Astronaut Corps-10"]], [["Stephen King-6"]], ["operation"]], [[["NASA Astronaut Corps-10"]], [["Stephen King-6"]], ["operation"]], [[["NASA Astronaut Corps-10"]], [["Stephen King-6"]], ["operation"]]]}
{"qid": "05ab64dd540d095d9c62", "term": "Mood disorder", "description": "(psychology) Any of various disorders characterised by disturbance in an individual's mood", "question": "Do people with mood disorders need permanent institutionalization?", "answer": false, "facts": ["Most mood disorders can be treated in the outpatient setting.", "Many people with mood disorders do not get diagnosed at all."], "decomposition": ["Do most mood disorders need the patient to leave their homes to get treatment?"], "evidence": [[[["Mood disorder-21"], "operation"]], [[["Mood disorder-21"], "no_evidence"]], [[["Bipolar disorder-44", "Mood (psychology)-17"], "no_evidence"]]]}
{"qid": "e201b35fd4c6f00aa5ae", "term": "Peach", "description": "species of fruit tree (for the fruit use Q13411121)", "question": "Does Princess Peach's dress resemble a peach fruit?", "answer": false, "facts": ["Peaches have fuzzy red, orange, and yellow skin.", "Princess Peach is a character in the Nintendo Mario Universe.", "Princess Peach's dress is pink and floor length."], "decomposition": ["What color is a peach?", "What color is Princess Peach normally seen in?", "What shape is a peach?", "What shape is princess peach?", "Is #1 the same as #2 or is #3 the same as #4?"], "evidence": [[[["Peach (fruit)-5"], "no_evidence"], [["Princess Peach-3"]], ["no_evidence"], ["no_evidence"], ["operation"]], [[["Peach (fruit)-3"]], [["Princess Peach-3"]], [["Peach (fruit)-3"], "no_evidence"], [["Princess Peach-3"]], ["operation"]], [[["Peach-23"]], [["Princess Peach-3"]], [["Peach-9"], "no_evidence"], [["Princess Peach-3"]], ["operation"]]]}
{"qid": "2bec732d14cf2b289435", "term": "Santa Claus", "description": "Folkloric figure, said to deliver gifts to children on Christmas Eve", "question": "Are most mall Santa Claus actors white?", "answer": true, "facts": ["In 2016, a black man playing Santa Claus at the Mall of America made national headlines.", "There are map websites dedicated to locating black Santa Claus mall actors."], "decomposition": ["What is the ethnicity of the man who made headlines for playing Santa Claus at the Mall of America in 2016?", "Does #1 imply that black Santas are a rare occurrence?"], "evidence": [[["no_evidence"], ["no_evidence"]], [[["Santa Claus-2"], "no_evidence"], ["operation"]], [["no_evidence"], [["Santa Claus-50"], "no_evidence", "operation"]]]}
{"qid": "b3c5d591c696cda63e48", "term": "Hyena", "description": "family of mammal", "question": "Do hyenas appear in a Broadway musical?", "answer": true, "facts": ["Scar is the evil lion in Disney's Lion King.", "Scar's minions are a group of hyenas.", "There is a Broadway stage version of Lion King."], "decomposition": ["Who is the main antagonist in Disney's Lion King?", "Which animals were #1's minions?", "Has the Lion King been adapted into a Broadway musical and are #2 hyenas?"], "evidence": [[[["Scar (The Lion King)-1"]], [["Scar (The Lion King)-17"]], [["The Lion King (musical)-2"], "operation"]], [[["Scar (The Lion King)-1"]], [["Scar (The Lion King)-1"]], [["The Lion King (musical)-1"], "operation"]], [[["Scar (The Lion King)-1"]], [["Scar (The Lion King)-3"]], [["Scar (The Lion King)-3", "The Lion King (musical)-2"]]]]}
{"qid": "56b31f6fe1e5163d2382", "term": "Liberty Bell", "description": "bell that serves as a symbol of American independence and liberty", "question": "Will a Holstein cow and the Liberty Bell balance out a giant scale?", "answer": false, "facts": ["The Liberty Bell weighs 2,080 pounds.", "A mature Holstein cow weighs around 1,500 pounds."], "decomposition": ["What is the average weight of a mature Holstein cow?", "What is the weight of the Liberty Bell?", "Is #1 closely the same as #2?"], "evidence": [[[["Holstein Friesian cattle-7"]], [["Liberty Bell-27"]], ["operation"]], [[["Holstein Friesian cattle-7"]], [["Liberty Bell-27"], "no_evidence"], ["operation"]], [[["Holstein Friesian cattle-7"]], [["Liberty Bell-36"]], ["operation"]]]}
{"qid": "b135f5ff283e5f7329a9", "term": "United States Army Rangers", "description": "Elite military formation of the United States Army", "question": "Would Michael J Fox qualify for the Army Rangers?", "answer": false, "facts": ["Michael J Fox has Parkinson's disease. ", "Parkinson's disease is a brain disorder that leads to shaking, stiffness, and difficulty with walking, balance, and coordination.", "To qualify for the Army Rangers,  you must complete a 12-mile march with a 35-pound rucksack and weapon in less than three hours."], "decomposition": ["What must you do to qualify for the Army Rangers?", "What condition does Michael J Fox have?", "What are some symptoms of #2?", "Could someone experiencing #3 complete #1?"], "evidence": [[[["Ranger School-17"]], [["Michael J. Fox-2"]], [["Parkinson's disease-1"]], ["operation"]], [[["75th Ranger Regiment-63"]], [["Michael J. Fox-2"]], [["Parkinson's disease-1"]], ["operation"]], [[["75th Ranger Regiment-76", "United States Army Rangers-48"], "no_evidence"], [["Michael J. Fox-2"]], [["Parkinson's disease-1"]], [["Parkinson's disease-20"], "operation"]]]}
{"qid": "07e2a845709bbcb30b65", "term": "JPMorgan Chase", "description": "American multinational banking and financial services holding company", "question": "Could every citizen of Samoa send a letter to a unique JPMorgan Chase employee?", "answer": true, "facts": ["JPMorgan Chase had a total of 256,981 employees in the fourth quarter of 2019.", "The estimated population of Samoa as of July 1st, 2019 is 200,874."], "decomposition": ["How many employees does JPMorgan Chase have?", "What is the population of Samoa?", "Is #2 less than or equal to #1?"], "evidence": [[["no_evidence"], [["Samoa-64"]], ["operation"]], [[["JPMorgan Chase-83"]], [["Vatia, American Samoa-17"]], ["operation"]], [["no_evidence"], [["Samoa-64"]], ["no_evidence", "operation"]]]}
{"qid": "7571100f05bc56919c78", "term": "Funeral", "description": "ceremony for a person who has died", "question": "Is it unusual to play Happy hardcore music at a funeral?", "answer": true, "facts": ["Happy hardcore is a music genre of hard dance.", "Happy hardcore emerged both from the UK breakbeat hardcore rave scene, and Belgian, German and Dutch hardcore techno scenes.", "A funeral is traditionally a somber event.", "Funerals typically do not involve dancing.", "Raves are typically energetic and upbeat places and are not somber like a funeral."], "decomposition": ["What type of music is usually played at funerals?", "What are the characteristics of Happy Hardcore music?", "Do any of #1 have the characteristics of #2?"], "evidence": [[[["Funeral-8"]], [["Happy hardcore-1"]], ["operation"]], [[["Dirge-1"]], [["Happy hardcore-1", "Happy hardcore-7"], "no_evidence"], ["no_evidence", "operation"]], [[["Funeral march-1"]], [["Happy hardcore-2"]], [["Funeral march-1"]]]]}
{"qid": "b9d5010aaef9115f77e7", "term": "Tom Cruise", "description": "American actor and producer", "question": "Could Tom Cruise explain mental auditing?", "answer": true, "facts": ["Mental auditing is a practice within the church of Scientology.", "Tom Cruise is a long standing member of the church of Scientology and is high in the ranks."], "decomposition": ["What church practices mental auditing?", "Is Tom Cruise a member of #1?"], "evidence": [[[["Auditing (Scientology)-1", "Auditing (Scientology)-2"]], ["no_evidence", "operation"]], [[["Scientology beliefs and practices-1"]], [["Tom Cruise-36"]]], [[["Auditing (Scientology)-1"]], [["Tom Cruise-4"]]]]}
{"qid": "a593481c1ddb91e9f96b", "term": "Asian black bear", "description": "species of mammal", "question": "Is the Asian black bear multicolored?", "answer": true, "facts": ["The Asian black bear is an animal that lives in habitats with trees.", "Multicolored refers to anything that is composed of more than one color.", "The Sian black bear has a black coat with a white V-shaped patch."], "decomposition": ["How many colors of fur does the asian black bear have?", "Is #1 greater than 1?"], "evidence": [[[["Asian black bear-2"]], ["operation"]], [[["Asian black bear-2"]], ["operation"]], [[["Asian black bear-2"]], ["operation"]]]}
{"qid": "fc3a305f513090432212", "term": "Rash", "description": "skin condition", "question": "Is CAS number 8009-03-8 harmful for a rash?", "answer": false, "facts": ["Some common substances that help rashes are creams, oils, and petroleum based products.", "CAS number 8009-03-8 is the identifier number for petroleum jelly."], "decomposition": ["What is CAS number 8009-03-8 the identifier number for?", "Is #1 harmful to put on a rash?"], "evidence": [[[["Petroleum jelly-1"]], [["Petroleum jelly-2"]]], [[["Petroleum jelly-1"]], [["Petroleum jelly-2"], "operation"]], [[["Petroleum jelly-1"]], [["Petroleum jelly-2"]]]]}
{"qid": "43a26c2f067095e1992b", "term": "Guitar Hero", "description": "video game series", "question": "Is Guitar Hero Beatles inappropriate for a US third grader?", "answer": false, "facts": ["The average age of a US third grader is 8.", "Guitar Hero is recommended for ages 7 and up.", "The Beatles were a British rock band with a plethora of radio friendly hits."], "decomposition": ["How old is the average US third grader?", "What is the recommended age to play Guitar Hero?", "Is #1 higher than #2?"], "evidence": [[[["Third grade-1"]], ["no_evidence"], ["operation"]], [[["Third grade-1"]], ["no_evidence"], ["operation"]], [[["Third grade-1"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "e03ec826db49319eb034", "term": "J. K. Rowling", "description": "English novelist", "question": "Did Helen Keller ever read a novel by J. K. Rowling?", "answer": false, "facts": ["Helen Keller died in 1968.", "J. K. Rowling's first novel was published in 1997."], "decomposition": ["When was J. K. Rowling's first novel published?", "When did Helen Keller die?", "Is #1 before #2?"], "evidence": [[[["J. K. Rowling-15"]], [["Helen Keller-1"]], ["operation"]], [[["Harry Potter and the Philosopher's Stone-2"]], [["Helen Keller-1"]], ["operation"]], [[["J. K. Rowling-2"], "no_evidence"], [["Helen Keller-45"]], ["operation"]]]}
{"qid": "425683ababbbc31c733c", "term": "Islamophobia", "description": "Fear, hatred of, or prejudice against the Islamic religion or Muslims generally,", "question": "Was  Godfrey of Bouillon an Islamaphobe?", "answer": true, "facts": [" Godfrey of Bouillon lead troops during the Prince's Crusade.", "The Prince's Crusade was an attempt by Europeans to \"take back\" the city of Jerusalem from Islamic hands."], "decomposition": ["Islamaphobe indicates fear of what?", "What kind of interactions did Godfrey of Bouillon majorly have with Muslims?", "Is #2 an indication of #1?"], "evidence": [[[["Islamophobia-1"]], [["Godfrey of Bouillon-14"]], ["operation"]], [["no_evidence"], [["Godfrey of Bouillon-14"], "operation"], ["no_evidence"]], [[["Islamophobia-1"]], [["Godfrey of Bouillon-10"]], ["operation"]]]}
{"qid": "ecd7594494e88099aeac", "term": "Goblin shark", "description": "Deep-sea shark", "question": "Would a goblin shark eat at Crossroads Kitchen?", "answer": false, "facts": ["Goblin sharks are carnivores that subsist on other fish, cephalopods and crustaceans", "Crossroads Kitchen is a vegan restaurant in Los Angeles", "Vegans do not consume any animal products"], "decomposition": ["What is the goblin shark's diet-based classification?", "What kind of food is served at Crossroads Kitchen?", "Would a #1 typically consume #2?"], "evidence": [[[["Goblin shark-12"]], [["Crossroads Kitchen-1"]], ["operation"]], [[["Goblin shark-12"]], [["Crossroads Kitchen-6"]], [["Goblin shark-12"], "operation"]], [[["Goblin shark-12"]], [["Crossroads Kitchen-1"]], ["operation"]]]}
{"qid": "d912709b7341dd86ba39", "term": "Mile", "description": "Unit of length", "question": "Would an Olympic athlete be tired out after running a mile?", "answer": false, "facts": ["The Olympic standard for men in running one mile is 4 minutes, 19 seconds. ", "The Olympic standard for women in running one mile is at least 4 minutes and 40 seconds. "], "decomposition": ["What is the Olympic standard time in running one mile for men?", "What is the Olympic standard time in running one mile for women?", "Is #1 or #2 a very long period of time?"], "evidence": [[[["Mile run-4"], "no_evidence"], [["Mile run-4"], "no_evidence"], ["operation"]], [[["Mile run world record progression-1"], "no_evidence"], [["Mile run world record progression-1"], "no_evidence"], ["operation"]], [[["Mile run-4"], "no_evidence"], [["Mile run-4"], "no_evidence"], ["operation"]]]}
{"qid": "5090f573b09ac3050824", "term": "Eagle", "description": "large carnivore bird", "question": "Are eagles and young bears both used as labels for skills-training youth groups?", "answer": true, "facts": ["A young bear is a cub.", "Boy Scouts is a skill-training youth group that includes divisions such as Cub Scouts and Eagle Scouts"], "decomposition": ["What is the name of a young bear?", "What is a popular skill training group for boys? ", "Are #1 and eagles names for groups in #2?"], "evidence": [[[["Bear-27"]], [["Boy Scouts of America-2"]], [["Boy Scouts of America-22", "Boy Scouts of America-26"], "operation"]], [[["Bear-37"]], [["Boy Scouts of America-1", "Scouting-1"]], [["Cub Scout-1", "Eagle Scout (Boy Scouts of America)-1"]]], [[["Bear-27"]], [["Scout (Scouting)-1"]], [["Eagle Scout (Boy Scouts of America)-1", "Scout (Scouting)-5"], "operation"]]]}
{"qid": "06b9ed3f803e3d5796ed", "term": "The Powerpuff Girls", "description": "American animated television series", "question": "Could the Powepuff Girls make the background to the Azerbaijani flag?", "answer": true, "facts": ["The national flag of the Republic of Azerbaijan is a horizontal tricolour featuring three equally sized fesses of blue, red, and green", "Each of the Powerpuff Girls creates a trail of a different color when she flies: Bubbles makes blue, Blossom makes red, and Buttercup makes green."], "decomposition": ["What colors are present on the Azerbaijani flag?", "What colors are the Powerpuff Girls?", "Is #1 the same as #2?"], "evidence": [[[["Flag of Azerbaijan-1"]], [["The Powerpuff Girls-5"]], ["operation"]], [[["Flag of Azerbaijan-1"]], [["The Powerpuff Girls-9"]], ["operation"]], [[["Flag of Azerbaijan-1"]], [["The Powerpuff Girls-5"]], ["operation"]]]}
{"qid": "427fe3968e32005479b9", "term": "Tibia", "description": "larger of the two bones of the leg below the knee for vertebrates", "question": "Is the tibia necessary to win the Stanley Cup?", "answer": true, "facts": ["The Stanley Cup is the championship trophy of the National Hockey League", "Ice hockey is a game played by individuals wearing ice skates to move around a frozen playing field", "The tibia is a leg bone", "Legs are required in order to use ice skates"], "decomposition": ["Which achievement leads to the award of the Stanley Cup?", "Which sport does #1 involve?", "Which body parts are actively involved in playing #2", "Which part of the body is the tibia found in?", "Is #4 included in #3?"], "evidence": [[[["Stanley Cup-1"]], [["Ice hockey-1"]], [["Ice hockey-55"]], [["Tibia-1"]], ["operation"]], [[["Stanley Cup-1"]], [["Ice hockey-1"]], [["Ice skate-1"]], [["Tibia-1"]], ["operation"]], [[["Stanley Cup-1"]], [["Stanley Cup-1"]], [["Ice hockey-43"], "no_evidence"], [["Tibia-1"]], ["operation"]]]}
{"qid": "7a0e419ffb6009156828", "term": "Apollo 13", "description": "A failed crewed mission to land on the Moon", "question": "Was ship that recovered Apollo 13 named after a World War II battle?", "answer": true, "facts": ["Apollo 13 was recovered by the USS Iwo Jima.", "Iwo Jima was captured from the Imperial Japanese Army during World War II by the US in a conflict called the Battle of Iwo Jima."], "decomposition": ["Which ship recovered Apollo 13 crew?", "What was #1 named for?", "Did #2 occur during World War II?"], "evidence": [[[["USS Iwo Jima (LPH-2)-13"]], [["USS Iwo Jima (LPH-2)-1"]], [["Battle of Iwo Jima-1"]]], [[["Apollo 13-55"]], [["USS Iwo Jima (LPH-2)-1"]], ["operation"]], [[["Apollo 13-55"]], [["Iwo Jima-3"]], [["Iwo Jima-19"]]]]}
{"qid": "61f96e271bbedf0148c0", "term": "Paulo Coelho", "description": "Brazilian lyricist and novelist", "question": "Does Paulo Coelho's wife make a living through speech?", "answer": false, "facts": ["Paulo Coelho's wife is Christina Oiticica.", "Christina Oiticica is a Brazilian artist.", "Artists make a living through drawing things, which is done by their hands.", "Speech is typically performed with one's mouth."], "decomposition": ["Who is Paulo Coelho's wife?", "What does #1 do for a living?", "What body part does she use to do #2?", "What body part do singers use to produce their craft?", "Is #3 the same as #4?"], "evidence": [[[["Paulo Coelho-6"]], [["Christina Oiticica-2"]], [["Christina Oiticica-3"]], [["Origin of speech-14"]], ["operation"]], [[["Paulo Coelho-6"]], [["Christina Oiticica-1"]], [["Painting-1"]], [["Singing-1"]], ["operation"]], [[["Paulo Coelho-6"]], [["Christina Oiticica-4"]], [["Christina Oiticica-3"]], [["Singing-4"]], ["operation"]]]}
{"qid": "11e20bbf1f44625b8349", "term": "Family Guy", "description": "American animated sitcom", "question": "Does the art from Family Guy look a lot like the art in American Dad?", "answer": true, "facts": ["Family Guy and American Dad are both Fox Animated Sitcoms animated by Seth MacFarlane.", "Family Guy and American Dad characters all share common facial features and movement styles."], "decomposition": ["Who is the animator for Family Guy?", "Who is the animator for American Dad?", "Is #1 the same as #2?"], "evidence": [[[["Seth MacFarlane-14"]], [["Seth MacFarlane-21"]], ["operation"]], [[["Family Guy-1"]], [["American Dad!-1"]], ["operation"]], [[["Family Guy-2"]], [["American Dad!-14"]], ["operation"]]]}
{"qid": "15ea72669f16beecac5a", "term": "Confederate States Army", "description": "Southern army in American Civil War", "question": "Did Confederate States Army influence West Point fashion?", "answer": true, "facts": ["The Confederate States Army was clad in cadet gray uniforms.", "West Point uniforms are cadet gray and white.", "Confederate States Army uniforms contained Generally, the uniform jacket of the Confederate soldier was single breasted, made of gray or brown fabric, with a six to nine button front and hat.", " West Point uniforms contain a standing collar, white trousers, and black shakos (known as a \"tarbucket hat\" in U.S. Army nomenclature)."], "decomposition": ["What were the main features of the Confederate States Army uniforms?", "What are the most notable features of West Point uniforms?", "Is there a significant overlap between #1 and #2?"], "evidence": [[[["Uniforms of the Confederate States Armed Forces-17"]], [["United States Military Academy-62"], "no_evidence"], ["operation"]], [[["Confederate States Army-49"], "no_evidence"], [["United States Military Academy-74"], "no_evidence"], ["no_evidence", "operation"]], [[["Uniforms of the Confederate States Armed Forces-12"]], ["no_evidence"], ["operation"]]]}
{"qid": "d697f6246a7d06e195ee", "term": "Deciduous", "description": "Trees or shrubs that lose their leaves seasonally", "question": "Are Christmas trees dissimilar to deciduous trees?", "answer": true, "facts": ["Christmas trees are usually pine trees.", "Pine trees keep their needles all year round."], "decomposition": ["Which kind of trees are commonly used as Christmas trees?", "Are #1 dissimilar to deciduous trees?"], "evidence": [[[["Christmas tree-1"]], [["Deciduous-1"], "operation"]], [[["Christmas tree-56"]], [["Fir-1"], "operation"]], [[["Christmas tree-1"]], [["Deciduous-1"]]]]}
{"qid": "8036e79e6e6d26a45b28", "term": "Al-Farabi", "description": "Philosopher in 10th century Central Asia", "question": "Was Al-Farabi a student of the Great Sheikh?", "answer": false, "facts": ["The Great Sheikh was the name for Avicenna", "Avicenna was born in 980", "Al Farabi died around 950 "], "decomposition": ["What other name was the Great Sheikh known by?", "When was #1 born?", "When did Al-Farabi die?", "Is #3 more recent than #2?"], "evidence": [[[["Zayed bin Sultan Al Nahyan-2"]], [["Zayed bin Sultan Al Nahyan-1"]], [["Al-Farabi-10"]], ["operation"]], [[["Zayed bin Khalifa Al Nahyan-1"], "no_evidence"], [["Zayed bin Khalifa Al Nahyan-1"], "no_evidence"], [["Al-Farabi-1"]], ["operation"]], [[["Zayed bin Khalifa Al Nahyan-1"]], [["Zayed bin Khalifa Al Nahyan-1"]], [["Al-Farabi-1"]], ["operation"]]]}
{"qid": "da8b34432133127c4a97", "term": "P. G. Wodehouse", "description": "English author", "question": "Did P. G. Wodehouse like the internet as a child?", "answer": false, "facts": ["P. G. Wodehouse was born in 1881.", "The internet was not conceived of until 1965. "], "decomposition": ["When was P. G. Wodehouse born?", "When was the internet invented?", "Did #1 come before or during #2?"], "evidence": [[[["P. G. Wodehouse-1"]], [["Internet-2"]], ["operation"]], [[["P. G. Wodehouse-5"], "operation"], [["When Radio Was-6"], "no_evidence"], ["no_evidence"]], [[["P. G. Wodehouse-5"], "operation"], [["Internet-13"], "operation"], ["operation"]]]}
{"qid": "e12fef0504a959e49b23", "term": "New England", "description": "Region in the northeastern United States", "question": "Can someone from New England profit by growing coffee?", "answer": false, "facts": ["Coffee can only be grown in subtropical and equatorial climates", "New England is located in a humid continental climate"], "decomposition": ["What climates does coffee grow in?", "What kind of climate does New England have?", "Is #1 the same as #2?"], "evidence": [[[["Coffee-30"]], [["Climate of New England-2"]], ["operation"]], [[["Coffee-28"]], [["Climate of New England-4"]], ["operation"]], [[["Coffee bean-9"]], [["England-43"]], ["operation"]]]}
{"qid": "2ed50522610a3683933f", "term": "Jalape\u00f1o", "description": "Hot pepper", "question": "Is jalapeno heat outclassed by Bhut jolokia?", "answer": true, "facts": ["The Scoville scale measures how hot peppers are.", "The jalapeno pepper has a Scoville scale rating of between 3,500 and 3,600 SHU (Scoville Heat Units).", "The Bhut jolokia (ghost pepper) has a Scoville scale rating of 1 million SHU (Scoville Heat Units)."], "decomposition": ["How many Scoville units does a Jalapeno have?", "How many Scoville units does a  Bhut jolokia have?", "Is #2 greater than #1?"], "evidence": [[[["Jalape\u00f1o-16"]], [["Bhut jolokia-4"]], ["operation"]], [[["Jalape\u00f1o-1"]], [["Bhut jolokia-2"]], ["operation"]], [[["Jalape\u00f1o-16"]], [["Race to grow the hottest pepper-1"]], ["operation"]]]}
{"qid": "7e552e58565771a2008c", "term": "Noah's Ark", "description": "the vessel in the Genesis flood narrative", "question": "Were there eight humans on Noah's Ark?", "answer": true, "facts": ["Noah only took his family aboard the Ark.", "Noah brought his wife, three sons, and his sons' wives.", "Four couples lived on the Ark, eight total people."], "decomposition": ["How many people entered Noah's Ark?", "Is #1 greater than or equal to eight?"], "evidence": [[[["Wives aboard Noah's Ark-6"]], [["Wives aboard Noah's Ark-6"]]], [[["Wives aboard Noah's Ark-6"]], ["operation"]], [[["Wives aboard Noah's Ark-1"]], ["operation"]]]}
{"qid": "78754ccf05c5f541050c", "term": "Oceanography", "description": "The study of the physical and biological aspects of the ocean", "question": "Does a person suffering from Thalassophobia enjoy oceanography?", "answer": false, "facts": ["Thalassophobia is a deep and persistent fear of the sea.", "Oceanography is the study of bodies of water.", "Oceanographers frequently observe and interact with bodies of water such as lakes, seas, and oceans."], "decomposition": ["What do people that have thalassophobia fear?", "Oceanography is the study of what?", "Is #1 excluded from #2?"], "evidence": [[[["Thalassophobia-1"]], [["Oceanography-1"]], ["operation"]], [[["Thalassophobia-1"]], [["Oceanography-1"]], ["operation"]], [[["Thalassophobia-1"]], [["Oceanography-1"]], ["operation"]]]}
{"qid": "589eb85285b438a0c59f", "term": "Astrology", "description": "Pseudoscience claiming celestial objects influence human affairs", "question": "Would Elon Musk be more likely to know about astrology than physics?", "answer": false, "facts": ["Elon Musk is a businessman and engineer with a bachelor's degree and unfinished Ph.D. in physics", "Engineering is based on principles of applied physics", "Astrology is not a form of science or applied science"], "decomposition": ["Which field(s) of study did Elon Musk specialize in?", "Is Astrology closely related to (any of) #1?"], "evidence": [[[["Elon Musk-10"]], [["Astrology-34", "Physics-2"], "operation"]], [[["Elon Musk-2"]], [["Astrology-1"]]], [[["Elon Musk-10"]], [["Astrology-1"], "operation"]]]}
{"qid": "b3234ad7249fde05a126", "term": "Groundhog Day", "description": "Traditional method of weather prediction", "question": "Is groundhog day used as a global season indicator? ", "answer": false, "facts": ["Groundhog Day is an American tradition that occurs on February 2nd. ", "Groundhog Day derives from a superstition that if a groundhog sees it's shadow it will mean there are six more weeks of winter.", "People living in the southern hemisphere of the world experience summer while the people in the north experience winter.", "Different global cultures define the dates of seasons differently."], "decomposition": ["Where is Groundhog Day celebrated?", "Is #1 in both the northern and southern hemisphere?"], "evidence": [[[["Groundhog Day-1"]], [["Southern Hemisphere-1"], "operation"]], [[["Groundhog Day-1"]], [["North America-1", "North America-10", "North America-11"]]], [[["Groundhog Day-1"]], [["Winter-1"], "operation"]]]}
{"qid": "9390df61207ef77f8ba0", "term": "Swan", "description": "large water bird", "question": "Would WWF be angrier if you killed koala instead of black swan?", "answer": true, "facts": ["The WWF is an international organization that works for the preservation of animals.", "Black swans are designated as least concern species meaning they are not close to being endangered.", "Koalas are designated as  vulnerable to extinction\u2014just a step above endangered."], "decomposition": ["What is the black swan's listing on the IUCN red list?", "How is the Koala listed on the IUCN red list?", "What does WWF represent?", "Considering #3, is #2 in more dire straits than #1?"], "evidence": [[[["Black swan-24"]], [["Koala-3"]], [["World Wide Fund for Nature-1"]], ["operation"]], [[["Black swan-24"]], [["Koala-44"]], [["World Wide Fund for Nature-10"]], ["operation"]], [[["Black swan-13", "IUCN Red List-1"]], [["Koala-50", "Vulnerable species-1"], "no_evidence"], [["World Wide Fund for Nature-1"]], ["operation"]]]}
{"qid": "53271c927076992cfb21", "term": "Suicide", "description": "Intentional act of causing one's own death", "question": "Is slitting your wrists an unreliable suicide method?", "answer": true, "facts": ["Wrist slitting has only a 6% mortality rate.", "Many people cannot complete the action of slitting their wrists due to pain or shock."], "decomposition": ["How often do people survive attempts to commit suicide by wrist-slitting?", "Does #1 indicate a high chance of survival?"], "evidence": [[["no_evidence"], ["no_evidence"]], [["no_evidence"], ["no_evidence"]], [[["Suicide methods-5"], "no_evidence"], ["operation"]]]}
{"qid": "6d2b70f4dd9eec8ef932", "term": "Doctorate", "description": "academic or professional degree", "question": "Should you be skeptical of a 21 year old claiming to have a doctorate?", "answer": true, "facts": ["The average age that someone gets their doctorate at is 33. ", "A doctorate takes an average of 8.5 years."], "decomposition": ["What is the average age at which people get their doctorate?", "Is 21 very much less than #1 ?"], "evidence": [[[["Graduate science education in the United States-6"]], ["operation"]], [[["Doctorate-1", "Graduate science education in the United States-6"], "no_evidence"], ["operation"]], [[["Doctorate-1", "Doctorate-18"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "ec71dcb7d6ace3e73ef9", "term": "Soup", "description": "primarily liquid food", "question": "Is shoe soup innocuous?", "answer": true, "facts": ["Soup is a primarily liquid food containing various meats and beans.", "Director Werner Herzog lost a bet and cooked his shoe into a soup and ate it in 1980.", "Werner Herzog turned 77 in 2019 and had a role in the hit TV series the Mandalorian."], "decomposition": ["What film director ate shoe soup in the year 1980?", "Is #1 still alive?"], "evidence": [[[["Werner Herzog Eats His Shoe-1"]], [["Werner Herzog-1"], "operation"]], [[["Werner Herzog-12"]], [["Werner Herzog-30"], "operation"]], [[["Werner Herzog Eats His Shoe-1"]], [["Werner Herzog-1"]]]]}
{"qid": "a1dabe439511af470303", "term": "Lil Wayne", "description": "American rapper, record executive and actor from Louisiana", "question": "Will AC/DC album sales buy more B-52 bombers than Lil Wayne's?", "answer": true, "facts": ["The B-52 bomber plane cost 60 million dollars in 2018.", "AC/DC has sold over 200 million albums.", "Lil Wayne has sold 120 million records worldwide."], "decomposition": ["How much does one B-52 bomber cost?", "How much is AC/DC worth due to the sales of their albums?", "Lil Wayne has made how much from his album sales?", "Is #2 more than both #1 and #3?"], "evidence": [[[["Boeing B-52 Stratofortress-6"], "no_evidence"], [["AC/DC-5"], "no_evidence"], [["Lil Wayne-4"], "no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], [["AC/DC-5"], "no_evidence"], ["no_evidence"], ["operation"]], [[["Bomber B-5"], "no_evidence"], [["AC/DC-2"], "no_evidence"], [["Lil Wayne-3"], "operation"], ["no_evidence"]]]}
{"qid": "ac543a4e99396d4f8132", "term": "Mona Lisa", "description": "Painting by Leonardo da Vinci", "question": "Is the Mona Lisa based on a real person?", "answer": true, "facts": ["There are two main theories about the origin of the Mona Lisa.", "The first is that a wealthy noblewoman, the wife of one of Leonardo's friends, sat as the model.", "Another popular theory is that Leonardo painted her as a cross-gendered self portrait."], "decomposition": ["Who was the Mona Lisa painting based on?", "Is #1 a real person?"], "evidence": [[[["Mona Lisa-2"]], [["Lisa del Giocondo-1"]]], [[["Mona Lisa-2"]], [["Lisa del Giocondo-1"], "operation"]], [[["Mona Lisa-12"]], [["Isabella of Aragon, Queen of Germany-1"]]]]}
{"qid": "1660a6bd9b0e309aef9b", "term": "Asian black bear", "description": "species of mammal", "question": "Can an Asian black bear use chopsticks?", "answer": false, "facts": ["Asian black bear are a species of bear found in asia. ", "Asian black bear don't have opposable thumbs", "Chopsticks are eating utensils use requires opposable thumbs."], "decomposition": ["In order to use chopsticks, what body part does one need?", "Do Asian black bears have #1?"], "evidence": [[[["Chopsticks-18"]], [["Bear-1"]]], [[["Finger-2"], "no_evidence"], [["Asian black bear-6"], "no_evidence"]], [[["Chopsticks-18"]], [["Asian black bear-41"], "operation"]]]}
{"qid": "b94f96243e515dba1dac", "term": "Stoning", "description": "execution method", "question": "Will a celibate cleric likely suffer a stoning in Somalia?", "answer": false, "facts": ["A cleric is the term for a Muslim priest.", "Celibate people remain chaste and do not engage in relations with others.", "Stoning is a penalty in Somalia used to punish adulterers.", "Many Islamic militants have been in control of various parts of Somalia."], "decomposition": ["Which crime is punishable by stoning in Somalia?", "What relationship must a person guilty of #1 be in in order to be deemed guilty?", "Would a celibate cleric be involved in #2?"], "evidence": [[[["Sharia-16", "Sharia-4", "Somalia-158"]], [["Adultery-1"]], [["Celibacy-1"], "operation"]], [[["Stoning-65"]], [["Adultery-1"]], [["Celibacy-1"], "operation"]], [[["Stoning-83"]], [["Stoning-83"]], [["Stoning-83"]]]]}
{"qid": "0b3c9c9aea94adef6e3a", "term": "Bitcoin", "description": "decentralized cryptocurrency", "question": "Was the Louisiana Purchase made with bitcoin?", "answer": false, "facts": ["Bitcoin was launched as a currency in 2009.", "The Louisiana Purchase was in 1803."], "decomposition": ["When was Bitcoin launched?", "When did the Louisiana Purchase take place?", "Is #1 prior to #2?"], "evidence": [[[["Bitcoin-2"]], [["Louisiana Purchase-1"]], ["operation"]], [[["Bitcoin-2"]], [["Louisiana Purchase-1"]], ["operation"]], [[["Bitcoin-4"]], [["Louisiana Purchase-1"]], ["operation"]]]}
{"qid": "d7886984475ee7c616a2", "term": "Haiku", "description": "very short form of Japanese poetry", "question": "Is Lines on the Antiquity of Microbes briefer than any haiku?", "answer": true, "facts": ["A haiku is a short Japanese poem that follows a 5, 7, 5 syllable structure.", "Lines on the Antiquity of Microbes, also known simply as Fleas is said to be the shortest poem written.", "Lines on the Antiquity of Microbes is made of one brief phrase: Adam. Had 'em."], "decomposition": ["How long is a haiku?", "How long is Lines on the Antiquity of Microbes?", "Is #2 shorter than #1?"], "evidence": [[[["Haiku-2"]], [["Lines on the Antiquity of Microbes-1", "Lines on the Antiquity of Microbes-3"]], ["operation"]], [[["Haiku-2"], "no_evidence"], [["Lines on the Antiquity of Microbes-1"], "operation"], ["no_evidence"]], [[["Haiku-2"]], [["Lines on the Antiquity of Microbes-3"]], ["operation"]]]}
{"qid": "fba624d8c01833419760", "term": "August", "description": "eighth month in the Julian and Gregorian calendars", "question": "Is August a winter month for part of the world?", "answer": true, "facts": ["August is a summer month in the northern hemisphere.", "However, the seasons are opposite south of the Equator.", "August is in the middle of winter for Australia, Antarctica, and parts of Africa and South America."], "decomposition": ["What season is August a part of in the northern hemisphere?", "Does #1 correspond to winter south of the Equator?"], "evidence": [[[["Summer-2"]], [["Summer-1"]]], [[["Summer-1"]], [["Summer-1"]]], [[["August-3"]], [["Winter-1"], "operation"]]]}
{"qid": "ff0c2df8c385ec5189dc", "term": "Sloth", "description": "tree dwelling animal noted for slowness", "question": "Could a sloth hypothetically watch an entire episode of Scrubs underwater?", "answer": true, "facts": ["Sloths can hold their breath underwater for up to 40 minutes.", "The running time of a Scrubs episode is between 20-23 minutes."], "decomposition": ["How long can sloths hold their breath underwater?", "How long is an episode of Scrubs?", "Is #1 greater than or equal to #2?"], "evidence": [[[["Sloth-20"]], [["Scrubs (TV series)-69"]], ["operation"]], [[["Sloth-20"]], ["no_evidence"], ["no_evidence"]], [[["Sloth-20"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "0b0dc8dc326765c1540b", "term": "Cultural hegemony", "description": "Marxist notion of cultural dominance", "question": "Can the theory of cultural hegemony explain global warming?", "answer": false, "facts": ["Cultural hegemony is a theory of social and cultural dominance rooted in Marxism", "Marxism is a philosophy with applications in the social sciences and humanities", "Global warming is a phenomenon dealt with by environmental science"], "decomposition": ["The theory of cultural hegemony is rooted in which philosophy?", "Which branch of science does #1 have applications in?", "Which branch of science does global warming concern?", "Is #2 the same as #3?"], "evidence": [[[["Cultural hegemony-1"]], [["Marxism-3"]], [["Global warming-71", "Svante Arrhenius-1"], "no_evidence"], ["operation"]], [[["Cultural hegemony-1"]], [["Cultural hegemony-2"], "no_evidence"], [["Global warming-19", "Scientific consensus on climate change-43"]], ["operation"]], [[["Cultural hegemony-1"]], [["Marxist philosophy-1"]], [["Atmospheric chemistry-2"]], ["operation"]]]}
{"qid": "0dad98b7dde01ed9f144", "term": "Greyhound", "description": "Dog breed used in dog racing", "question": "Do people associate greyhounds with the movie 'Homeward Bound'?", "answer": false, "facts": ["The movie homeward bound features a golden retriever. ", "The movie homeward bound features a pit bull type dog.", "There are no greyhounds in homeward bound."], "decomposition": ["What are the two types of dogs that are lost in Homeward Bound?", "Is a greyhound listed in #1?"], "evidence": [[[["Homeward Bound: The Incredible Journey-2"]], [["Homeward Bound: The Incredible Journey-2"], "operation"]], [[["Homeward Bound: The Incredible Journey-2"]], ["operation"]], [[["Homeward Bound: The Incredible Journey-2"]], ["operation"]]]}
{"qid": "73c52134ab2a903d86db", "term": "Lemon", "description": "citrus fruit", "question": "Does Lemon enhance the flavor of milk?", "answer": false, "facts": ["When milk becomes acidic, the water and fats separate from each other.", "When the water and fats separate in milk, it becomes clumpy and has a bad texture.", "Lemon is highly acidic."], "decomposition": ["What is the effect of acid on milk?", "Does #1 make milk more desirable?", "Is Lemon acidic?", "Is #2 or #3 negative?"], "evidence": [[[["Curdling-2"], "no_evidence"], ["operation"], [["Lemon-2"]], ["operation"]], [[["Soured milk-1"]], [["Soured milk-1"]], [["Lemon-21"]], ["operation"]], [[["Curdling-2", "Curdling-3"]], [["Curdling-2"], "no_evidence"], [["Lemon-13", "Lemon-15"]], ["operation"]]]}
{"qid": "ab833ae041b323f106cf", "term": "Sesame", "description": "species of plant", "question": "Are sesame seeds glued onto hamburger buns?", "answer": false, "facts": ["Glue is toxic and not used in food production.", "Sesame seeds add texture and visual appeal to hamburger buns.", "Beaten eggwhites are often used to adhere foods to other foods. "], "decomposition": ["What do people usually do with hamburger buns?", "Can you #1 sesame seeds?"], "evidence": [[[["Hamburger-1"]], [["Sesame-1"]]], [[["Bread-1", "Bun-1"]], [["Sesame-2"], "operation"]], [[["Hamburger-1"]], ["no_evidence", "operation"]]]}
{"qid": "cd1a9cb828c1cbc7b2d1", "term": "Swan Lake", "description": "Ballet by Pyotr Ilyich Tchaikovsky", "question": "Does open heart surgery finish before entirety of American Ballet Theatre's Swan Lake?", "answer": false, "facts": ["The American Ballet theatre's Swan Lake has a run time of 145 minutes.", "The National Heart, Lung, and Blood Institute states that a coronary artery bypass takes 3 to 6 hours"], "decomposition": ["How long is a performance of Swan Lake?", "How long does it take to perform a coronary artery bypass?", "Is #1 longer than #2?"], "evidence": [[[["Swan Lake-2"], "no_evidence"], [["Coronary artery bypass surgery-2"], "no_evidence"], ["operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], ["no_evidence"], ["operation"]]]}
{"qid": "1f7ba99375d4fa45119f", "term": "JAG (TV series)", "description": "American legal drama television series (1996-2005)", "question": "Did Joan Crawford guest star on  JAG (TV series)?", "answer": false, "facts": ["JAG began airing in 1995.", "Joan Crawford died in 1977."], "decomposition": ["When did Joan Crawford's career as a television actress come to an end?", "When was the TV series JAG launched?", "Is #2 before #1?"], "evidence": [[[["Joan Crawford-64"]], [["NCIS (TV series)-19"], "no_evidence"], ["operation"]], [[["Joan Crawford-61", "Joan Crawford-64"]], [["JAG (season 1)-1"]], ["operation"]], [[["Joan Crawford-37"]], [["JAG (season 1)-1"]], ["operation"]]]}
{"qid": "68ed0e7f870fb8e2b0e0", "term": "Ringo Starr", "description": "British musician, drummer of the Beatles", "question": "Has Ringo Starr been in a relatively large number of bands?", "answer": false, "facts": ["RIngo Starr has been in three bands besides the Beatles.", "Mike Patton, lead singer of Faith No More, has been in at least 12 bands.", "Dave Grohl, lead singer of the Foo Fighters, has played in over 10 bands."], "decomposition": ["How many bands has Ringo Starr been part of?", "How many bands has Mike Patton been part of?", "How many bands has Dave Grohl been part of?", "Is #1 larger than #2 or #3?"], "evidence": [[[["Plastic Ono Band-2", "Ringo Starr & His All-Starr Band-1", "Rory Storm-1", "The Beatles-1"]], [["Mike Patton-1"]], [["Dave Grohl-1", "Scream (band)-5", "Teenage Time Killers-1"]], ["operation"]], [[["Ringo Starr-13"]], [["Mike Patton-18"]], [["Dave Grohl-28"]], ["operation"]], [[["Ringo Starr-3"], "no_evidence"], [["Mike Patton-1"]], [["Dave Grohl-1"]], ["operation"]]]}
{"qid": "59adb0e59a4f961f1c6f", "term": "Agnosticism", "description": "view that the existence of any deity is unknown or unknowable", "question": "Can a believer in agnosticism become pope?", "answer": false, "facts": ["The pope is the head of the Catholic Church.", "The pope is required to be a devout follower of Christ.", "Popes preach about the teachings of Christ and the belief in one god.", "Agnostics do not acknowledge the existence of god and instead state that no one knows if there is a god or not."], "decomposition": ["What do agnostics believe about the existence of God?", "Which religious group does a pope head?", "What are the beliefs held by #2 concerning God's existence?", "Is #1 in agreement with #3?"], "evidence": [[[["Agnosticism-1"]], [["Pontifex maximus-41"]], [["Catholic Church-3"]], ["operation"]], [[["Agnosticism-1"]], [["Pope-1"]], [["Catholic Church-38"]], ["operation"]], [[["Agnosticism-1"]], [["Pope-37"]], [["Pope-74"]], ["operation"]]]}
{"qid": "66b9bb0849ceff60cfde", "term": "Hepatitis", "description": "inflammation of the liver tissue", "question": "Could a dandelion suffer from hepatitis?", "answer": false, "facts": ["Only creatures that contain a liver can suffer from hepatitis.", "The liver is an organ only found in vertebrates.", "Vertebrates exist in the kingdom Animalia.", "Dandelions are plants in the kingdom Plantae."], "decomposition": ["Hepatitis is the inflammation of what?", "In which kingdom is #1 found?", "In what kingdom are dandelions found?", "Is #3 the same as #2?"], "evidence": [[[["Hepatitis-1"]], [["Animal-1", "Animal-2", "Liver-1", "Vertebrate-1"]], [["Plant-1", "Taraxacum-1"]], ["operation"]], [[["Hepatitis-1"]], [["Liver-1", "Vertebrate-1"]], [["Taraxacum-1"]], ["operation"]], [[["Hepatitis-4"]], [["Liver-98"]], [["Chondrilla (plant)-3"]], ["operation"]]]}
{"qid": "10bc0e26996fa472791d", "term": "Nine Inch Nails", "description": "American industrial rock band", "question": "Did Nine Inch Nails inspire Aretha Franklin's sound?", "answer": false, "facts": ["Nine Inch Nails is a industrial heavy rock band.", "Aretha Franklin was a soul and R&B singer.", "Aretha Franklin began singing in a gospel choir.", "Nine Inch Nails lyrics have been described as profane and anti-God."], "decomposition": ["What genre are Nine Inch Nails' music?", "What genre of songs does Aretha Franklin sing?", "Is #1 the same as #2?"], "evidence": [[[["Nine Inch Nails-1"]], [["Aretha Franklin-27"]], ["operation"]], [[["Nine Inch Nails-1"]], [["Aretha Franklin-27"]], ["operation"]], [[["Nine Inch Nails-1"]], [["Aretha Franklin-1"]], ["operation"]]]}
{"qid": "f2859b2ce17b5f5a6ad9", "term": "Chinchilla", "description": "Rodent genus", "question": "Is a Chinchilla breed of felis catus a type of rodent?", "answer": false, "facts": ["A Chinchilla is a rodent native to the Andes mountains.", "Felis catus is the scientific name for a cat.", "The Chinchilla breed of cats is named for its plush coat which shares similarities to the Chinchilla.", "The Chinchilla cat is really a variant of the Persian breed of cats."], "decomposition": ["Which species are named felis catus?", "What is the most notable feature of the Chinchilla?", "Are Chinchilla breed of #1 so named because they have #2?", "Given that #3 is positive, does that make #1 rodents?"], "evidence": [[[["Cat-1"]], [["Chinchilla-2"]], [["Persian cat-28"], "no_evidence"], ["operation"]], [[["Cat-1"]], [["Chinchilla-2"]], ["no_evidence"], ["no_evidence"]], [[["Cat-13"]], [["Chinchilla-10"], "no_evidence"], [["Persian cat-28", "Rodent-1"], "operation"], ["operation"]]]}
{"qid": "20744bd481b4245333fa", "term": "Gorillaz", "description": "British virtual band", "question": "Has Gorillaz creator been in more bands than Bernard Sumner?", "answer": true, "facts": ["Gorillaz was created by Damon Albarn.", "Damon Albarn has been in five bands: Gorillaz, Blur, The Good, the Bad & the Queen, Elastica, and DRC Music.", "Bernard Sumner has been in three bands: New Order, Joy Division, and Electronic, Bad Lieutenant."], "decomposition": ["Who was the primary creator of Gorillaz?", "How many bands has #1 been a member of?", "How many bands has Bernard Sumner been a member of?", "Is #2 greater than #3?"], "evidence": [[[["Damon Albarn-1"]], [["Damon Albarn-1", "Damon Albarn-3"]], [["Bernard Sumner-1", "Bernard Sumner-2", "Bernard Sumner-6"]], ["operation"]], [[["Gorillaz-1"]], [["Blur (band)-1", "Gorillaz-1", "Rocket Juice & the Moon-1", "The Good, the Bad & the Queen-1"]], [["Bad Lieutenant (band)-1", "Bernard Sumner-4", "Electronic (band)-1", "Joy Division-1"]], ["operation"]], [[["Damon Albarn-1"]], [["Damon Albarn-1", "Damon Albarn-3"]], [["Bernard Sumner-3", "Bernard Sumner-4", "Bernard Sumner-5", "Bernard Sumner-6"]], ["operation"]]]}
{"qid": "e0f36bf27467cd086ecd", "term": "Leonardo da Vinci", "description": "15th and 16th-century Italian Renaissance polymath", "question": "Did Leonardo da Vinci lack contemporary peers in his home city?", "answer": false, "facts": ["Leonardo da Vinci was born in Anchiano, a town in the city of Florence.", "Da Vinci lived during the 15th and 16th century.", "Sandro Boticelli was a Florentine artist 15th and 16th century.", "Donatello was a Florentine artist during the 15th century."], "decomposition": ["Which period did Leonardo da Vinci live through and where was his home city?", "When did Sandro Boticelli live through and where was his home city?", "Where was Donatello's home city and what period did he live through?", "Are #1, #2 and #3 different from one another?"], "evidence": [[[["Leonardo da Vinci-1", "Leonardo da Vinci-2"]], [["Sandro Botticelli-1", "Sandro Botticelli-2"]], [["Donatello-1"]], ["operation"]], [[["Leonardo da Vinci-1"]], [["Sandro Botticelli-1"]], [["Donatello-1"]], ["operation"]], [[["Leonardo da Vinci-3", "Leonardo da Vinci-7"]], [["Sandro Botticelli-1", "Sandro Botticelli-5"]], [["Donatello-1"]], ["operation"]]]}
{"qid": "2549ab4ce062ef762c4c", "term": "Bern", "description": "Place in Switzerland", "question": "Are Citizens of Bern Switzerland are descendants of Genghis Khan?", "answer": true, "facts": ["Genghis Khan had sixteen children.", "1 in 200 men are direct descendants of Genghis Khan.", "Switzerland has a large Asian immigration population which was around 19,000 in 2018."], "decomposition": ["What ethnic groups contain much of Genghis Khan's descendants?", "Is there a large population of any of #1 in Bern?"], "evidence": [[[["Descent from Genghis Khan-2"], "no_evidence"], [["Bern-39"], "no_evidence"]], [[["Descent from Genghis Khan-2", "Descent from Genghis Khan-22"]], ["no_evidence"]], [[["Genghis Khan-2"], "no_evidence"], [["Bern-39"], "no_evidence", "operation"]]]}
{"qid": "f32228b474fc1ff18d59", "term": "Armadillo", "description": "family of mammals", "question": "Would multiple average rulers be necessary to measure the length of a giant armadillo?", "answer": true, "facts": ["The average ruler is 12 inches or 30 centimeters in length.", "The typical length of the giant armadillo is 75\u2013100 cm (30\u201339 in), with the tail adding another 50 cm (20 in)."], "decomposition": ["What length are the best selling rulers on Amazon?", "How long is a typical giant armadillo?", "What is #2 divided by #1?", "Is #3 greater than one?"], "evidence": [[[["Ruler-2"], "no_evidence"], [["Giant armadillo-6"]], ["no_evidence", "operation"], ["no_evidence", "operation"]], [["no_evidence"], [["Giant armadillo-5"]], ["operation"], ["operation"]], [[["Ruler-2"], "no_evidence"], [["Giant armadillo-5"], "no_evidence"], ["operation"], ["operation"]]]}
{"qid": "381d38f377cfce5087b9", "term": "Dementia", "description": "long-term brain disorders causing impaired memory, reasoning, and normal function together with personality changes", "question": "Can dementia be cured with a cast?", "answer": false, "facts": ["Dementia refers to various disorders of the brain.", "Casts are used to help treat broken bones.", "The brain does not contain any bones."], "decomposition": ["What part of the body does Dementia affect?", "What do cast help fix?", "Are there any #2 in #1?"], "evidence": [[[["Dementia-21"]], [["Bone fracture-22"]], [["Bone fracture-22", "Dementia-21"], "operation"]], [[["Dementia-1"]], [["Orthopedic cast-1"]], ["operation"]], [[["Dementia-1"]], [["Orthopedic cast-1"]], [["Brain-1"]]]]}
{"qid": "5165ea01d214c4e74188", "term": "Reconstruction era", "description": "Era of military occupation in the Southern United States after the American Civil War (1865\u20131877)", "question": "Can a Reconstruction era coin buy DJI Mavic Pro Drone?", "answer": true, "facts": ["The DJI Mavic Pro Drone retails for around $1,000 dollars.", "THE Reconstruction Era took place from 1865-1877.", "Mint condition 1870 Seated Liberty Silver Dollar's can sell for between $2,283 to $4,933."], "decomposition": ["How much does a DJI Mavic Pro Drone retail for?", "During what years did the Reconstruction era occur?", "Of the US coins minted during the years in #2, are any of them now worth at least as much as #1?"], "evidence": [[[["DJI-26"], "no_evidence"], [["Reconstruction era-2"]], [["Three-cent silver-28", "Two-cent piece (United States)-21"], "operation"]], [[["DJI-26"], "no_evidence"], [["Reconstruction era-2"]], [["Three-cent piece-4"], "no_evidence", "operation"]], [[["Mavic (UAV)-2"], "no_evidence"], [["Reconstruction era-2"]], [["Economic history of the United States-201"], "no_evidence"]], [[["Mavic (UAV)-17"], "no_evidence"], [["Reconstruction era-1"]], ["no_evidence", "operation"]]]}
{"qid": "f66e34419f26c8027ee6", "term": "Snoopy", "description": "cartoon dog", "question": "Would Taylor Swift refer to Snoopy as oppa?", "answer": true, "facts": ["Oppa is a Korean word used by women to address a man who is 10 or more years older than her", "Snoopy is 47 years old", "Taylor Swift is 30 years old"], "decomposition": ["What is the minimum age difference that a Korean woman would use Oppa to address an older man?", "How old is Snoopy?", "How old is Taylor Swift?", "What is #2 minus #3?", "Is #4 greater than or equal to #1?"], "evidence": [[[["Korean pronouns-20"], "no_evidence"], [["Snoopy-7"]], [["Taylor Swift-1"]], ["operation"], ["operation"]], [[["Third-person pronoun-106"], "no_evidence"], [["Snoopy-1"], "no_evidence"], [["Taylor Swift-1"]], ["operation"], ["operation"]], [[["Korean honorifics-1"], "no_evidence"], [["Snoopy-1"]], [["Taylor Swift-4"]], ["operation"], ["no_evidence", "operation"]]]}
{"qid": "afa32406c205674efb7f", "term": "Amazons", "description": "warrior women from Greek mythology", "question": "Did any of the amazons on Xena: Warrior Princess star on later shows?", "answer": true, "facts": ["Xena\" Warrior Princess was a fantasy TV series based on Greek mythology.", "Amazons on Xena: Warrior Princess were played by numerous actresses including: Danielle Cormack and Melinda Clarke.", "Melinda Clarke starred in numerous TV shows after Xena: Warrior Princess including The O.C. and Nikita."], "decomposition": ["Who played the roles of Amazons on Xena: Warrior Princess?", "Did Melinda Clarke do any other shows after Xena\" Warrior Princess?", "Is #2 listed in #1?"], "evidence": [[[["Melinda Clarke-3"]], [["Melinda Clarke-4"]], ["operation"]], [[["Xena: Warrior Princess-14"], "no_evidence"], [["Melinda Clarke-3"]], ["operation"]], [[["Melinda Clarke-3"]], [["Melinda Clarke-1"]], ["operation"]]]}
{"qid": "e0bfafb25cde72664a3a", "term": "Larry King", "description": "American television and radio host", "question": "Could Larry King's marriages be counted on two feet?", "answer": true, "facts": ["The typical person has 10 toes spread across their two feet.", "Larry King has been married 8 times.", "You can count each marriage on each toe."], "decomposition": ["How many times has Larry King been married?", "How many toes do most people have?", "Is #2 at least as much as #1?"], "evidence": [[[["Larry King-37"]], [["Toe-2"]], ["operation"]], [[["Larry King-43"]], [["Toe-2"]], ["operation"]], [[["Larry King-37"]], [["Toe-2"]], ["operation"]]]}
{"qid": "3fc25e1cccc76bb79a68", "term": "Ludacris", "description": "American rapper and actor", "question": "Does Ludacris perform classical music?", "answer": false, "facts": ["Ludacris is a rap artist.", "Rap and hip hop music are not related to classical music."], "decomposition": ["Which kind of music does Ludacris perform?", "Is #1 the same as classical music?"], "evidence": [[[["Ludacris-6"]], ["operation"]], [[["Ludacris-6"]], ["operation"]], [[["Ludacris-1"]], ["operation"]]]}
{"qid": "1d95c8b85665773de38f", "term": "Herpes simplex virus", "description": "Species of virus", "question": "Can Planned Parenthood tell your University that you have Herpes simplex virus?", "answer": false, "facts": ["Planned Parenthood specializes in reproductive healthcare.", "Planned Parenthood practitioners are bound by HIPAA to not disclose any patient information. "], "decomposition": ["Who works at Planned Parenthood?", "Are #1 bound by any laws in regards to patient information?", "Does #2 allow for patient information to be disclosed?"], "evidence": [[[["Clinical Research Bureau-1"]], [["Confidentiality-16", "Medical privacy-52"]], ["operation"]], [[["Planned Parenthood-2"]], ["no_evidence"], [["Planned Parenthood-36"], "no_evidence", "operation"]], [[["Planned Parenthood-2"]], [["Health Insurance Portability and Accountability Act-11", "Health Insurance Portability and Accountability Act-13"]], ["operation"]]]}
{"qid": "75cb50e207fe81886cfc", "term": "Easy Rider", "description": "1969 film by Dennis Hopper", "question": "Will the producer of Easy Rider become an octogenarian in 2021?", "answer": false, "facts": ["The producer of Easy Rider was Peter Fonda.", "Peter Fonda died in 2019 at the age of 79.", "An octogenarian is someone who is between 80 and 89 years old and is still alive."], "decomposition": ["Who produced Easy Rider?", "What characteristics does someone need to be considered an octogenarian?", "What characteristics does #1 have?", "Are all the characteristics in #2 also in #3?"], "evidence": [[[["Easy Rider-1"]], [["Illustrations of the rule against perpetuities-2"]], [["Peter Fonda-1"]], ["operation"]], [[["Easy Rider-1"]], ["no_evidence"], [["Peter Fonda-1"]], ["operation"]], [[["Easy Rider-1"]], [["Ageing-46"], "no_evidence"], [["Peter Fonda-58"]], ["operation"]]]}
{"qid": "ca296dafd5943d07b01c", "term": "Ariana Grande", "description": "American singer, songwriter, and actress", "question": "Was Ariana Grande inspired by Imogen Heap?", "answer": true, "facts": ["Ariana Grande's song 'Goodnight And Go' uses a sample from a track of the same name.", "\"Goodnight and Go\" is originally an Imogen Heap song."], "decomposition": ["Who was the original singer of Ariana Grande's cover 'Goodnight and Go'", "Is #1 Imogen Heap?"], "evidence": [[[["Goodnight and Go-1", "Sweetener (song)-1"]], ["operation"]], [[["Goodnight and Go-1"]], ["operation"]], [[["Goodnight and Go-1"]], ["operation"]]]}
{"qid": "fedce5dbd46bf58a4e53", "term": "Mike Tyson", "description": "American boxer", "question": "Did Mike Tyson train to use the gogoplata?", "answer": false, "facts": ["Mike Tyson is a boxer", "The gogoplata is a chokehold used in mixed martial arts and various submission grappling disciplines"], "decomposition": ["In what sports is a gogoplata used?", "Did Mike Tyson participate in #1?"], "evidence": [[[["Gogoplata-4"]], [["Mike Tyson-1"], "operation"]], [[["Gogoplata-1"]], [["Mike Tyson-1"]]], [[["Gogoplata-1"]], ["no_evidence"]]]}
{"qid": "51752ec2cb34e4ff1da0", "term": "P. G. Wodehouse", "description": "English author", "question": "Would P. G. Wodehouse be taught in second grade?", "answer": false, "facts": ["Second graders are often aged seven or eight.", "The works of Wodehouse are intended for an adult audience."], "decomposition": ["How old are typical second graders?", "What age group is P. G. Wodehouse works intended for?", "Is there any overlap between #1 and #2?"], "evidence": [[[["Second grade-1"]], [["P. G. Wodehouse-52"], "no_evidence"], ["no_evidence", "operation"]], [[["Second grade-8"]], [["P. G. Wodehouse-14"], "no_evidence"], ["operation"]], [[["Second grade-8"]], [["P. G. Wodehouse-26"], "no_evidence"], ["operation"]]]}
{"qid": "f6b966be1495ead0fe7f", "term": "Metroid", "description": "Video game series", "question": "Did Electronic Arts profit from Metroid sales?", "answer": false, "facts": ["Metroid was created and published by Nintendo.", "Electronic Arts is a video game company that is a competitor to Nintendo.", "Companies cannot profit of the work owned by another company typically.", "Companies do not typically share profits with their competitors."], "decomposition": ["What company created and published Metroid?", "What is the relationship between #1 and Electronic Arts?", "Do two entities engaged in #2 directly benefit each other?"], "evidence": [[[["Metroid-10"]], [["Electronic Arts-15"]], ["operation"]], [[["Metroid-1"]], [["Electronic Arts-15"], "no_evidence"], ["operation"]], [[["Metroid (video game)-8"]], [["Electronic Arts-15"]], ["operation"]]]}
{"qid": "3157a0f428531ebed7b9", "term": "Minor League Baseball", "description": "hierarchy of professional baseball leagues affiliated with Major League Baseball", "question": "Are any minor league baseball teams named after felines?", "answer": true, "facts": ["Felines include cats, tigers, and lions.", "The Sacramento River Cats are a minor league baseball affiliate of the San Francisco Giants.", "The Tri-City Valley Cats are a minor league baseball affiliate of the Houston Astros.", "The Lakeland Flying Tigers are a minor league baseball affiliate of the Detroit Tigers."], "decomposition": ["What are the names of teams in Minor League Baseball?", "Which animals are regarded as felines?", "Does any of #1 include any of #2?"], "evidence": [[[["Lynchburg Hillcats-1"], "no_evidence"], [["Felinae-1"]], ["operation"]], [[["Minor League Baseball-1"], "no_evidence"], [["Felidae-1"]], [["New Hampshire Fisher Cats-1"], "operation"]], [[["New Hampshire Fisher Cats-1", "Sacramento River Cats-1"], "no_evidence"], [["Felidae-1"]], ["operation"]]]}
{"qid": "c681171e816f3117df0b", "term": "Tongue", "description": "mouth organ that tastes and facilitates speech", "question": "Is the tongue part of a creature's head?", "answer": true, "facts": ["A creature's tongue is inside its mouth.", "A creature's mouth is part of its head."], "decomposition": ["In what body part is the tongue located?", "Is #1 located in the head?"], "evidence": [[[["Tongue-1"]], ["no_evidence", "operation"]], [[["Tongue-5"]], [["Tongue-5"]]], [[["Tongue-1"]], [["Head-1"], "operation"]]]}
{"qid": "6f0b33d71d2e65d3b376", "term": "Sonnet", "description": "form of poetry with fourteen lines; by the thirteenth century it signified a poem of fourteen lines that follows a strict rhyme scheme and specific structure", "question": "Did a Polish poet write sonnets about Islamic religion?", "answer": true, "facts": ["Adam Mickiewicz was a Polish poet. ", "Adam Mickiewicz 's sonnet sequence focuses heavily on the culture and Islamic religion of the Crimean Tatars."], "decomposition": ["What were the major focus of Adam Mickiewicz's sonnets?", "Is #1 about Islamic religion?", "Was Adam Mickiewicz a Polish poet?", "Are #2 and #3 positive?"], "evidence": [[[["The Crimean Sonnets-1"]], [["Orientalism-1", "The Crimean Sonnets-2"]], [["Adam Mickiewicz-1"]], ["operation"]], [[["The Crimean Sonnets-2"]], ["no_evidence"], [["Adam Mickiewicz-1"]], ["operation"]], [[["The Crimean Sonnets-1"], "no_evidence"], [["Adam Mickiewicz-23"], "no_evidence", "operation"], [["Adam Mickiewicz-1"]], ["no_evidence", "operation"]]]}
{"qid": "dfdc7f7197f90ec78844", "term": "Pharmacology", "description": "Branch of biology concerning drugs", "question": "Did Julius Caesar read books on Pharmacology?", "answer": false, "facts": ["Pharmacology has its origins in the Middle Ages.", "The Middle Ages took place from 476 AD-1453 AD.", "Julius Caesar lived from 100 BC-44 BC."], "decomposition": ["When did Julius Caesar die?", "When did Pharmacology emerge as a field of study?", "Is #1 after or within #2?"], "evidence": [[[["Assassination of Julius Caesar-1"]], [["Pharmacology-7"]], ["operation"]], [[["Julius Caesar-1"]], [["Pharmacology-4"]], ["operation"]], [[["Julius Caesar-1"]], [["Pharmacology-7"]], ["operation"]]]}
{"qid": "4cdeb92d520f5e531f85", "term": "James Watson", "description": "American molecular biologist, geneticist, and zoologist", "question": "Does James Watson believe that Africans are inferior to Europeans?", "answer": true, "facts": ["James Watson is a geneticist, who believes in his own work.", "James Watson is quoted as saying that genetic testing \"proves\" that Africans aren't as smart."], "decomposition": ["What profession is James Watson in? `", "As #1, what was James quoted with saying about African Americans?", "Did James Watson believe in his own work about #2?"], "evidence": [[[["James Watson-29"]], [["James Watson-48"]], ["operation"]], [[["James Watson-1"]], [["James Watson-48"]], [["James Watson-3"], "operation"]], [[["James Watson-1"]], [["James Watson-48"]], [["James Watson-50"], "operation"]]]}
{"qid": "d38d93ba50044cce053c", "term": "New York Harbor", "description": "harbor in the New York City, U.S.A. metropolitan area", "question": "Does New York Harbor sit on a craton without volcanic activity?", "answer": false, "facts": ["New York Harbor is located on Laurentia craton. ", "The southwestern portion of Laurentia contains numerous large volcanic eruptions."], "decomposition": ["What craton is New York Harbor on?", "Is #1 devoid of volcanic activity?"], "evidence": [[[["Laurentia-3"]], [["Laurentia-6"], "operation"]], [[["Staten Island-42"], "no_evidence"], [["The Palisades (Hudson River)-5"], "no_evidence"]], [[["New York Harbor-1"], "no_evidence"], ["operation"]]]}
{"qid": "ea8a51f7a2d1d21096a5", "term": "Nikola Tesla", "description": "Serbian American inventor", "question": "Was Nikola Tesla's home country involved in the American Civil War?", "answer": false, "facts": ["Nikola Tesla was born in the Austrian Empire", "The American Civil War was a domestic American conflict"], "decomposition": ["What country was Nikola Tesla born in?", "What countries were involved in the American Civil War?", "Is #1 listed in #2?"], "evidence": [[[["Nikola Tesla-5"]], [["American Civil War-1"]], ["operation"]], [[["Nikola Tesla-2"]], [["American Civil War-1", "American Civil War-7"]], ["operation"]], [[["Nikola Tesla-5"]], [["American Civil War-1"]], ["operation"]]]}
{"qid": "533d15de91fbfa97347d", "term": "Pregnancy", "description": "time when children develop inside the mother's body before birth", "question": "Will 2020 elephant pregnancy last past next year with 4 solar eclipses?", "answer": false, "facts": ["The gestation period of elephants are around 95 weeks.", "The year 2029 is the next year with 4 solar eclipses."], "decomposition": ["What is the duration of an elephant's gestation period?", "How many years from 2020 will there be a year with four solar eclipses?", "Is #1 greater than #2?"], "evidence": [[[["Elephant-48"]], [["Solar eclipse-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Elephant-48"]], ["no_evidence"], ["operation"]], [[["Birth-5"], "no_evidence"], [["Solar eclipse-20"]], ["operation"]]]}
{"qid": "7f79c8faf724cc8f0e72", "term": "Frankenstein", "description": "1818 novel by Mary Shelley", "question": "Could Robert Wadlow hypothetically see Frankenstein's monster's bald spot from above?", "answer": true, "facts": ["The monster in Mary Shelley's novel, Frankenstein, was said to be 8 feet tall.", "Robert Wadlow was the world's tallest man.", "Robert Wadlow was 8 feet 11.1 inches tall."], "decomposition": ["How tall is Frankenstein?", "How tall is Robert Wadlow?", "Is #2 greater than #1?"], "evidence": [[[["Frankenstein-8"]], [["Robert Wadlow-2"]], ["operation"]], [[["Frankenstein-8"]], [["Robert Wadlow-2"]], ["operation"]], [[["Frankenstein-8"], "no_evidence"], [["Robert Wadlow-2"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "4c00343e96364ec24227", "term": "Drag king", "description": "female performance artists who dress and behave in masculine way for performance", "question": "Do drag kings take testosterone to look masculine?", "answer": false, "facts": ["Drag Kings will use contouring and makeup to make their facial features appear more masculine and chiseled. ", "Testosterone is prescribed for transgender men to help with transitioning and dysphoria.", "Drag kings often identify as women, but dress as men for show."], "decomposition": ["Which features of themselves do drag kings modify to look masculine?", "Would #1 require testosterone intake?"], "evidence": [[[["Passing (gender)-31"], "no_evidence"], [["Transgender hormone therapy (male-to-female)-42"], "operation"]], [[["Drag king-1"]], ["operation"]], [[["Drag king-1"]], [["Testosterone-1"], "operation"]]]}
{"qid": "08a7de56c14143be3535", "term": "Quran", "description": "The central religious text of Islam", "question": "Would an adherent of Zoroastrianism consult the Quran for religious guidance?", "answer": false, "facts": ["The Quran is the central religious text of Islam", "Zoroastrianism is an ancient religion predating Islam by several centuries"], "decomposition": ["Which religious group mainly uses the Quran for their consultation?", "Is Zoroastrianism closely related to #1?"], "evidence": [[[["Quran-1"]], [["Zoroastrianism-1"], "operation"]], [[["Quran-20"]], [["Zoroastrianism-48"], "operation"]], [[["Quran-1"]], [["Zoroastrianism-1"]]]]}
{"qid": "52f9fdeab2e51f01f3dd", "term": "Clark Gable", "description": "American actor", "question": "Did Clark Gable appear in any movies scored by John Williams?", "answer": false, "facts": ["Clark Gable died in 1960.", "John Williams scored his first movie in 1961."], "decomposition": ["When did Clark Gable die?", "When did John Williams begin creating movie scores?", "Is #2 before #1?"], "evidence": [[[["Clark Gable-1"]], [["John Williams-13"]], ["operation"]], [[["Clark Gable-1"]], [["John Williams-11"]], ["operation"]], [[["Clark Gable-1"]], [["John Williams-14"]], ["operation"]]]}
{"qid": "ee9770dcce6a42b4c97e", "term": "Jackson Pollock", "description": "American painter", "question": "Was Jackson Pollock straight edge?", "answer": false, "facts": ["Jackson Pollock was a famous painter.", "Straight Edge is a punk inspired lifestyle who's adherents abstain from alcohol and drugs.", "Jackson Pollock was an alcoholic.", "Jackson Pollock died in a car crash while driving under the influence of alcohol."], "decomposition": ["What substances do people avoid if they are straight edge?", "Did Jackson Pollock always avoid #1?"], "evidence": [[[["Straight edge-5"]], [["Jackson Pollock-17"], "operation"]], [[["Straight edge-1"]], [["Jackson Pollock-3"]]], [[["Straight edge-1"]], [["Jackson Pollock-3"], "operation"]]]}
{"qid": "2075b087e620fb920439", "term": "Conan O'Brien", "description": "American television show host and comedian", "question": "Would most children be up past their bedtime if they were watching Conan O'Brien?", "answer": true, "facts": ["Conan O'Brien airs at 11 PM. ", "It is recommended that children are in bed before 10PM."], "decomposition": ["When does Conan O' Brian air?", "What is the recommended bedtime for children?", "Does #1 occur after #2?"], "evidence": [[[["Conan (talk show)-1"]], ["no_evidence"], [["Conan (talk show)-1"]]], [[["Conan O'Brien-34"]], [["Bedtime-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Conan (talk show)-1"]], ["no_evidence"], ["operation"]]]}
{"qid": "dc9a0bab0809f6a1b59b", "term": "Star Wars", "description": "Epic science fantasy space opera franchise", "question": "Do Star Wars fans say \"beam me up\" often?", "answer": false, "facts": ["Beam me up is an expression from Star Trek.", "Much to the annoyance of fans, Star Trek and Star Wars are often confused for one another. "], "decomposition": ["Where does the expression beam me up come from?", "Is the answer to #1 the same as Star Wars?"], "evidence": [[[["Beam me up, Scotty-1"]], ["operation"]], [[["Beam me up, Scotty-1"]], ["operation"]], [[["Beam me up, Scotty-1"]], ["operation"]]]}
{"qid": "0cafe7ae4858b90c92ab", "term": "1800", "description": "Year", "question": "Did England win any Olympic gold medals in 1800?", "answer": false, "facts": ["Olympic medals can only be won during the Olympics.", "The Olympics were first held in 1896."], "decomposition": ["Which sporting event would England have to participate in to win an Olympic gold medal?", "When was the first modern edition of #1 held?", "Is #2 before or the same as 1800?"], "evidence": [[[["Gold medal-11"]], [["Olympic Games-2"]], [["Olympic Games-2"]]], [[["Olympic Games-4"]], [["Olympic Games-2"]], ["operation"]], [[["Olympic medal-1"]], [["Olympic Games-2"]], ["operation"]]]}
{"qid": "fc9339f21f44a3841a7c", "term": "Koala", "description": "An arboreal herbivorous marsupial native to Australia.", "question": "Do Koalas prefer Eucalyptus over meat?", "answer": true, "facts": ["Koalas are herbivores.", "Koalas main dietary staple is eucalyptus "], "decomposition": ["What kind of diet do Koalas follow?", "Are Eucalyptus part of #1?"], "evidence": [[[["Koala-2"]], ["operation"]], [[["Koala-2"]], [["Eucalypt-5", "Koala-2"]]], [[["Koala-2"]], ["operation"]]]}
{"qid": "4e598d222fe1001cf4f8", "term": "Kangaroo", "description": "\u0441ommon name of family of marsupials", "question": "Could Scooby Doo fit in a kangaroo pouch?", "answer": false, "facts": ["Scooby Doo is a fictional cartoon Great Dane.", "Great Danes can be 30-34 inches in height.", "Kangaroo babies can fit in their mother's pouch until they're 10 weeks of age.", "A 10 week old kangaroo is much smaller than a Great Dane."], "decomposition": ["What type of creature was Scooby-Doo?", "How large are #1?", "What resides in a kangaroo pouch?", "How large are #3?", "Is #2 approximately equal to #4?"], "evidence": [[[["Scooby-Doo (character)-1"]], [["Great Dane-3"]], [["Pouch (marsupial)-2"]], ["no_evidence"], ["operation"]], [[["Scooby-Doo-1"]], [["Great Dane-10"]], [["Kangaroo-34"]], [["Red kangaroo-13"]], ["operation"]], [[["Scooby-Doo-1"]], [["Great Dane-10"]], [["Marsupial-26"]], [["Red kangaroo-13"], "no_evidence"], ["operation"]]]}
{"qid": "b3b209d7fe1a38ad7844", "term": "Dancing with the Stars", "description": "several international television series based on the format of the British TV series Strictly Come Dancing", "question": "Is double duty an incorrect phrase for host of Dancing With The Stars?", "answer": false, "facts": ["Double duty refers to having more than one job at the same time.", "The host of Dancing WIth The Stars is Tom Bergeron.", "Tom Bergeron is the host of America's Funniest Home Videos."], "decomposition": ["Who is the host of TV series 'Dancing WIth The Stars'?", "Who hosts America's Funniest Home Videos?", "Do #1 and #2 being the same fail to meet the definition of double duty?"], "evidence": [[[["Dancing with the Stars (American TV series)-1"]], [["America's Funniest Home Videos-16"]], ["operation"]], [[["Dancing with the Stars-18"]], [["America's Funniest Home Videos-23"]], ["operation"]], [[["Dancing with the Stars-18"]], [["America's Funniest Home Videos-16"]], [["Double Duty-9"], "operation"]]]}
{"qid": "33f7f8c55b4acedb061a", "term": "Lolcat", "description": "image combining a photograph of a cat with text intended to contribute humour", "question": "Is purchasing food for a Lolcat unnecessary?", "answer": true, "facts": ["An image macro is a piece of digital media featuring a picture, or artwork, superimposed with some form of text.", "Food is any substance consumed to provide nutritional support for an organism.", "An organism is any individual entity that embodies the properties of life.", "Digital media does not embody the properties of life."], "decomposition": ["Which kind of entities require food?", "Is a lolcat excluded from #1?"], "evidence": [[[["Eating-1"]], [["Lolcat-2"]]], [[["Food-1", "Organism-1", "Organism-2"]], [["Image macro-1", "Lolcat-1", "Media (communication)-1"]]], [[["Food-1"]], [["Lolcat-2"], "operation"]]]}
{"qid": "c099aea9bc84f482419d", "term": "Gladiator", "description": "combatant who entertained audiences in the Roman Republic and Roman Empire", "question": "Did a gladiator kill his opponent with a shotgun?", "answer": false, "facts": ["The gladiator games lasted for nearly a thousand years, reaching their peak between the 1st century BC and the 2nd century AD.", "The gladiator games finally declined during the early 5th century.", "The shotgun was not invented until approximately the 18th century."], "decomposition": ["When did the gladiator games take place?", "When was the shotgun invented?", "Is #2 within the range of #1?"], "evidence": [[[["Gladiator-4"]], [["Shotgun-38"]], [["Gladiator-4", "Shotgun-38"], "operation"]], [[["Gladiator-4"]], [["Shotgun-31"]], ["operation"]], [[["Gladiator-4"]], [["Shotgun-32"]], ["operation"]]]}
{"qid": "27368c21e50b6af694ab", "term": "Ethics", "description": "branch of philosophy that systematizes, defends, and recommends concepts of right and wrong conduct", "question": "Would an ethics professor teach a class on Cezanne?", "answer": false, "facts": ["Cezanne was an Impressionist painter", "Aesthetics is the branch of philosophy that deals with the arts"], "decomposition": ["What was Cezanne known for?", "What branch of philosophy would deal with #1?", "Is #2 the same as ethics? "], "evidence": [[[["Paul C\u00e9zanne-1"]], [["Paul C\u00e9zanne-33"], "no_evidence"], [["Ethics-1"], "operation"]], [[["Paul C\u00e9zanne-1"]], [["Aesthetics-1"]], [["Ethics-1"], "operation"]], [[["Paul C\u00e9zanne-1"]], [["Paul C\u00e9zanne-33"]], ["operation"]]]}
{"qid": "9fb41cefb010f47033f3", "term": "Gladiator", "description": "combatant who entertained audiences in the Roman Republic and Roman Empire", "question": "Did Gladiator's weapon of choice require less hands than Soul Calibur's Faust?", "answer": true, "facts": ["Faust is a zweihander sword in the Soul Calibur video game series.", "A zweihander is a giant sword that requires two hands to wield.", "Gladiators used the Gladius which was a short one handed sword."], "decomposition": ["Faust in the Soul Calibur video game series is what kind of sword?", "How many hands would be needed to lift #1?", "How many hands would be needed to lift a typical Gladiator's sword?", "Is #3 less than #2?"], "evidence": [[[["Siegfried and Nightmare-17"]], [["Siegfried and Nightmare-17"]], [["Gladius-1", "Gladius-2"]], ["operation"]], [[["Siegfried and Nightmare-17"]], ["operation"], [["Gladius-20"], "no_evidence"], ["operation"]], [[["Soulcalibur (video game)-1"], "no_evidence"], ["no_evidence"], [["Gladius-1", "Gladius-2"]], ["no_evidence", "operation"]]]}
{"qid": "c32b7909c41d4af5933d", "term": "Sea shanty", "description": "work song sung to accompany labor on board large merchant sailing vessels", "question": "Did travelers sing sea shanties on the Oregon Trail?", "answer": false, "facts": ["Sea shanties are sung on seaborne vessels", "The Oregon Trail was a land-based emigration trail"], "decomposition": ["In what mode of travel are sea shanties typically sang?", "What mode of travel was mostly used on the Oregon Trail?", "Is #1 the same as #2?"], "evidence": [[[["Sea shanty-1"]], [["Oregon Trail-1"]], ["operation"]], [[["Sea Songs-3"]], [["Oregon Trail-116"]], ["operation"]], [[["Sea shanty-1"]], [["Oregon Trail-1"]], ["operation"]]]}
{"qid": "47ba7dfed8eef54588a8", "term": "Toyota Prius", "description": "Hybrid electric automobile", "question": "Can a microwave melt a Toyota Prius battery?", "answer": false, "facts": ["A Toyota Prius uses a 202 V nickel-metal hydride battery.", "Nickel has a melting point of 2651 F.", "Microwaves rarely warm food more than 212 F."], "decomposition": ["What kind of battery does a Toyota Prius use?", "What type of material is #1 made out of?", "What is the melting point of #2?", "Can a microwave's temperature reach at least #3?"], "evidence": [[[["Toyota Prius-53"]], ["operation"], [["Lanthanum-5"]], [["Microwave oven-50"]]], [[["Toyota Prius-53"]], [["Nickel\u2013metal hydride battery-1"]], [["Nickel\u2013cadmium battery-7"], "no_evidence"], [["Microwave oven-45"], "no_evidence", "operation"]], [[["Toyota Prius (XW20)-4"]], [["Toyota Prius (XW20)-4"]], [["Nickel-1"], "no_evidence"], [["Microwave oven-3"], "no_evidence"]]]}
{"qid": "3ca5966b88394e62271e", "term": "University of Pennsylvania", "description": "Private Ivy League research university in Philadelphia, Pennsylvania", "question": "Could Brooke Shields succeed at University of Pennsylvania?", "answer": true, "facts": ["Brooke Shields graduated from Princeton University.", "Princeton is ranked as the number 1 national college by US news.", "University of Pennsylvania is ranked as number 6 national college by US news.", "Princeton only admits around 6 percent of applicants as of 2018.", "University of Pennsylvania accepts around 9% of applicants as of 2018."], "decomposition": ["What college did Brooke Shields go to?", "Out of all colleges in the US, how is #1 ranked?", "Is the ranking of University of Pennsylvania similar to #2?"], "evidence": [[[["Brooke Shields-6"]], [["Princeton University-59"]], [["University of Pennsylvania-48"]]], [[["Brooke Shields-6"]], [["Princeton University-59"]], [["University of Pennsylvania-48"], "operation"]], [[["Brooke Shields-6"]], [["Princeton University-3"], "operation"], [["University of Pennsylvania-47"], "no_evidence"]]]}
{"qid": "d9a89b17f569834014a1", "term": "Daytona 500", "description": "Auto race held in Daytona, Florida, United States", "question": "Did Dale Jr hug his dad after their last Daytona 500 together?", "answer": false, "facts": ["Dale Jr. and his father Dale Sr. last raced together at the Daytona 500 in 2001.", "During the 2001 Daytona 500 Dale Sr. suffered a basilar skull fracture and died. "], "decomposition": ["Which race did Dale Jr and his father participate in last together?", "Which notable incident took place during #1?", "Was Dale Jr.'s father well enough to hug his son after #2?"], "evidence": [[[["Dale Earnhardt Jr.-6"]], [["Dale Earnhardt Jr.-6"]], ["no_evidence", "operation"]], [[["Dale Earnhardt-23"]], [["Dale Earnhardt-23"]], ["operation"]], [[["Dale Earnhardt Jr.-10"]], [["Dale Earnhardt-23"]], ["operation"]]]}
{"qid": "bf5f8d8dc96fe5e04f4b", "term": "Cooper (profession)", "description": "Maker of staved vessels such as barrels", "question": "Are coopers required in the beverage industry?", "answer": true, "facts": ["Coopers make barrels.", "Barrels are used to store certain alcoholic beverages during production."], "decomposition": ["What liquids are barrels made for?", "Are any of #1 part of the beverage industry?"], "evidence": [[[["Barrel-2"]], [["Drink-1"], "operation"]], [[["Barrel-4"]], [["Sake-1"], "operation"]], [[["Barrel-1", "Barrel-2", "Barrel-4"]], ["operation"]]]}
{"qid": "f8cc260e3863b0be4b81", "term": "Hypothermia", "description": "A human body core temperature below 35.0\u00b0C", "question": "Would you be more likely to die of hypothermia in New York than Florida?", "answer": true, "facts": ["Central New York Winters are between 12-30 degrees Fahrenheit.", "Florida winters are between 65 and 77 degrees Fahrenheit."], "decomposition": ["What is the typical temperature range of the coldest time of the year in New York?", "What is the typical temperature range of the coldest time of the year in Florida?", "Is #1 lower than #2?"], "evidence": [[[["New York City-62"], "no_evidence"], [["Climate of Florida-7", "Climate of Florida-8"], "no_evidence"], ["operation"]], [[["New York (state)-43"]], [["Florida-45"]], ["operation"]], [[["New York (state)-43"]], [["Geography of Florida-5"]], ["operation"]]]}
{"qid": "0fe658b221ff8ad08a14", "term": "Roman numerals", "description": "Numbers in the Roman numeral system", "question": "Does the FDA require sell by dates using Roman Numerals?", "answer": false, "facts": ["There are no requirements for food to have sell by dates. ", "Sell by dates on most food items are written using arabic numerals."], "decomposition": ["Is there any regulation on the sell by dates of food products?"], "evidence": [[["no_evidence"]], [[["Shelf life-1", "Shelf life-31"], "operation"]], [[["Shelf life-31"]]]]}
{"qid": "af2d3c137bd3f5230012", "term": "United States Department of Education", "description": "United States government department", "question": "Does the United States Department of Education oversee services benefiting undocumented migrants? ", "answer": true, "facts": ["The United States Department of Education oversees public education across the United States.", "Public education is a service.", "Public education services are given to students of migrant families that may be undocumented."], "decomposition": ["Which service does the United States Department of Education oversee?", "Which services could children from undocumented migrant families benefit from?", "Is #1 included in #2?"], "evidence": [[[["United States Department of Education-3", "United States Department of Education-4"]], [["Office of Migrant Education-1"]], ["operation"]], [[["United States Department of Education-3"]], ["no_evidence"], ["no_evidence", "operation"]], [[["United States Department of Education-3"]], [["Office of Migrant Education-1"], "no_evidence"], ["operation"]]]}
{"qid": "14a891550bef9ab64ef8", "term": "Foot (unit)", "description": "customary unit of length", "question": "When en route from China to France, must pilots know their altitude in the imperial foot?", "answer": true, "facts": ["Most international airports and aviators use the foot to measure altitude ", "China and North Korea require pilots to use meters for altitude", "Pilots must communicate their altitude with local air traffic control "], "decomposition": ["Which unit of altitude does France require pilots to use?", "Which unit of altitude does China require pilots to use?", "Is #1 or #2 the imperial foot?"], "evidence": [[[["Foot (unit)-2"]], [["Foot (unit)-2"]], ["operation"]], [[["Foot (unit)-26"], "no_evidence"], [["Foot (unit)-3"]], ["operation"]], [[["Foot (unit)-3"], "no_evidence"], [["Foot (unit)-3"], "no_evidence"], ["operation"]]]}
{"qid": "ddf1a475bda7523ab5a9", "term": "Holy Land", "description": "Term used by Jews, Christians, and Muslims to describe the Land of Israel and Palestine", "question": "Is the Holy Land important to Eastern religions?", "answer": false, "facts": ["Eastern religions include Hinduism, Buddhism, and Shintoism.", "Hinduism recognizes seven Holy Cities which are Ayodhya, Mathura, Haridwar, Varanasi, Kanchipuram, Dvaraka and Ujjain.", "Bodh Gaya: (in the current Mahabodhi Temple, Bihar, India), is the most important religious site and place of pilgrimage for Buddhists.", "The most sacred Shinto shrine is located in the city of Ise, within the Shima Peninsula of Japan."], "decomposition": ["What are some typical Eastern religions?", "Which place is referred to as the Holy Land?", "Which places do some of #1 consider sacred or holy?", "Is #2 included in #3?"], "evidence": [[[["Eastern religions-1"]], [["Holy Land-1"]], ["no_evidence"], ["no_evidence"]], [[["Eastern religions-1"]], [["Holy Land-1"]], ["no_evidence"], ["no_evidence"]], [[["Eastern religions-1"]], [["Holy Land-1", "Holy Land-4"]], [["Ganga in Hinduism-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "f03fe75dde01742e5a03", "term": "Metropolitan Museum of Art", "description": "Art museum in New York City, New York", "question": "Could Bernie Sanders visit the Metropolitan Museum of Art twenty times for under two hundred dollars?", "answer": false, "facts": ["Bernie Sanders is a senior citizen", "Senior citizens from outside NY, NJ, or CT must pay $17 per visit"], "decomposition": ["What age group would Bernie Sanders be classifed as?", "How much must #1 pay to enter the Metropolitan Museum of Art?", "Is seventeen times #2 less than 200? "], "evidence": [[[["Bernie Sanders-1"]], [["Metropolitan Museum of Art-61"]], [["Metropolitan Museum of Art-61"]]], [[["Bernie Sanders-1", "Discounts and allowances-33"]], [["Metropolitan Museum of Art-50"], "no_evidence"], ["operation"]], [[["Bernie Sanders-5", "Old age-12"]], [["Bernie Sanders-111", "Metropolitan Museum of Art-50"]], ["operation"]]]}
{"qid": "3a810d24f086f07f71bf", "term": "Butler", "description": "male domestic worker in charge of all the male household staff", "question": "Did the butler Eugene Allen retire the same year a centuries-old war ended?", "answer": true, "facts": ["Eugene Allen was a butler at the White House for 34 years until 1986", "The United Kingdom and the Kingdom of the Netherlands ended the Three Hundred and Thirty Five Years' Warnin 1986"], "decomposition": ["In what year did Eugene Allen retire?", "Which war ended in #1?", "How many years did #2 last?", "Is #3 greater than 100?"], "evidence": [[[["Eugene Allen-6"]], [["Three Hundred and Thirty Five Years' War-1"]], [["Three Hundred and Thirty Five Years' War-1"]], ["operation"]], [[["Eugene Allen-1"]], [["Three Hundred and Thirty Five Years' War-1"]], [["Three Hundred and Thirty Five Years' War-1"]], ["operation"]], [[["Eugene Allen-1"]], [["Three Hundred and Thirty Five Years' War-1"]], [["Three Hundred and Thirty Five Years' War-1"]], ["operation"]]]}
{"qid": "45cccf7bbcd884bc0af0", "term": "Led Zeppelin", "description": "English rock band", "question": "Did the band Led Zeppelin own a prime number of gilded gramophones?", "answer": true, "facts": ["5 is a prime number", "A Grammy Award trophy is a gilded gramophone", "Led Zeppelin won 5 Grammy Awards"], "decomposition": ["What award has a trophy which consists of a gilded gramophone?", "How many #1 have Led Zeppelin won?", "Is #2 a prime number?"], "evidence": [[[["Grammy Award-1"]], [["Led Zeppelin-57"], "no_evidence"], [["Prime number-14"]]], [[["Grammy Award-1"]], [["Led Zeppelin-57"]], ["operation"]], [[["Grammy Award-1"]], [["Led Zeppelin-57"]], [["Prime number-1"]]]]}
{"qid": "ef398edbb1efa0d9f33f", "term": "Parc des Princes", "description": "football stadium in Paris, France", "question": "Was the Parc des Princes fully operational during June of 2020?", "answer": false, "facts": ["June of 2020 was marked by a global pandemic.", "During a global pandemic, large events are not permitted to proceed fully."], "decomposition": ["What kind of events are usually held in the Parc des Princes?", "In light of recent developments, are such events as #1 still holding in full capacity as of July, 2020?"], "evidence": [[[["Parc des Princes-1"]], [["Coronavirus disease 2019-1", "Social distancing-15"], "no_evidence", "operation"]], [[["Parc des Princes-1"]], [["Impact of the COVID-19 pandemic on sports-23"], "operation"]], [[["Parc des Princes-1", "Parc des Princes-2"]], ["operation"]]]}
{"qid": "6d62de0fed9d8151b413", "term": "Torah", "description": "First five books of the Hebrew Bible", "question": "Does Happy Gilmore Productions CEO own a Torah?", "answer": true, "facts": ["The CEO of Happy Gilmore Productions is Adam Sandler.", "Adam Sandler's religious beliefs are Judaism. ", "The Torah is the first part of the bible in Judaism."], "decomposition": ["Who is the CEO of Happy Gilmore Productions?", "What religion does #1 follow?", "What religion uses the Torah?", "Is #2 the same as #3?"], "evidence": [[[["Happy Madison Productions-1"], "no_evidence"], [["Adam Sandler-26"]], [["Torah-1"]], ["operation"]], [[["Happy Madison Productions-1"], "no_evidence"], [["Adam Sandler-5"], "no_evidence"], [["Torah-1", "Torah-1"]], ["operation"]], [["no_evidence"], ["no_evidence"], [["Jews-1", "Torah-1"]], ["no_evidence", "operation"]]]}
{"qid": "8dc182aaa2d2117c4091", "term": "CNES", "description": "French space agency", "question": "Has CNES planted a French flag on the lunar surface?", "answer": false, "facts": ["The lunar surface is on the moon.", "CNES has not sent a person to the moon."], "decomposition": ["Where is the lunar surface?", "What country is the CNES part of?", "Which countries have sent people or probes to #1?", "Is #2 included in #3?"], "evidence": [[[["Geology of the Moon-1"]], [["CNES-1"]], [["Space Race-2"]], ["operation"]], [[["Moon-3"]], [["CNES-1"]], [["Chinese Lunar Exploration Program-3", "Exploration of the Moon-11"]], ["operation"]], [[["Moon-3"]], [["CNES-1"]], ["no_evidence"], ["operation"]]]}
{"qid": "36c497860f72d148e4e8", "term": "Donkey", "description": "El burrito de sheck", "question": "Are Donkeys part of Christmas celebrations?", "answer": true, "facts": ["\"Dominic The Donkey\" is a popular Christmas song.", "\"Nestor The Ling Eared Christmas Donkey\" is a popular Christmas Movie."], "decomposition": ["Which animals have been popularly recognized as part of the Christmas culture?", "Are donkeys one of #1?"], "evidence": [[[["Nestor, the Long-Eared Christmas Donkey-2"]], ["operation"]], [[["Christmas-1"], "no_evidence"], [["Nativity of Jesus in art-12"], "no_evidence", "operation"]], [[["Nativity scene-20"]], ["operation"]]]}
{"qid": "58be99559ef0ccdbb36c", "term": "Meatball", "description": "dish made from ground meat rolled into a small ball-like form", "question": "Do restaurants associate meatballs with the wrong country of origin?", "answer": true, "facts": ["Spaghetti and meatballs are a staple on Italian pizzeria menus in the US.", "The Olive Garden, an Italian family restaurant, has several dishes with meatballs.", "Meatballs originated in the Chinese Qin dynasty (221 BC to 207 BC)."], "decomposition": ["In what country is the oldest evidence of people eating meatballs found?", "What dish involving meatballs became popular in the United States after being invented in New York City in the 20th century?", "With which national cuisine do Americans typically associate #2?", "Are #3 and #1 different?"], "evidence": [[[["Meatball-2"]], [["Spaghetti and meatballs-2"]], [["Spaghetti and meatballs-2"]], [["Meatball-2", "Spaghetti and meatballs-2"], "operation"]], [[["Meatball-2"]], [["Meatball-8"]], [["Spaghetti and meatballs-3"]], ["operation"]], [[["Meatball-2"]], [["Spaghetti and meatballs-2"]], [["Spaghetti and meatballs-2"]], ["operation"]]]}
{"qid": "63fb8f40ca6c2226dd01", "term": "Dr. Seuss", "description": "American children's writer and illustrator", "question": "Did the death of Helen Palmer have a significant effect on Dr. Seuss?", "answer": true, "facts": ["Dr. Seuss's real name was Theodor Geisel.", "Theodor Geisel was married to Helen Palmer at the time of her suicide.", "Theodor Geisel is quoted having said he considered suicide after the death of his wife."], "decomposition": ["What relatives did Helen Palmer have when she died?", "What is Dr. Suess's real name?", "Is #2 one of #1?"], "evidence": [[[["Helen Palmer (author)-1"]], [["Dr. Seuss-1"]], ["operation"]], [[["Helen Palmer (author)-1", "Helen Palmer (author)-8"], "no_evidence"], [["Dr. Seuss-1"]], ["operation"]], [[["Helen Palmer (author)-1", "Helen Palmer (author)-8"]], [["Helen Palmer (author)-1"]], ["operation"]]]}
{"qid": "cea31f260dfec9aa0f1f", "term": "Monkey", "description": "Animal of the \"higher primates\" (the simians), but excluding the apes", "question": "Would a monkey outlive a human being on average?", "answer": false, "facts": ["The average human lifespan is 79 years.", "The longest-lived monkey species have a lifespan about 45-50 years in captivity."], "decomposition": ["How long does the average human live?", "What is the longest lifespan of a monkey?", "Is #2 larger than #1?"], "evidence": [[[["Life expectancy-2"]], [["Monkey-20"], "no_evidence"], ["operation"]], [[["Old age-99"]], [["Night monkey-9"], "no_evidence"], ["operation"]], [[["Life expectancy-2"]], [["Little Mama-2"]], ["operation"]]]}
{"qid": "c7a1cb4992a5eafa99ec", "term": "Bengal cat", "description": "Breed of cat", "question": "Would a Bengal cat be afraid of catching a fish?", "answer": false, "facts": ["Fish live in water. ", "Many Bengal owners say that their Bengal naturally retrieves items.", "Bengal cats often enjoy playing in water."], "decomposition": ["Where do fish live?", "What do bengal cats naturally do when they see something?", "Would a bengal cat be able to #2 from #1?"], "evidence": [[[["Fish-1"]], [["Bengal cat-20"], "no_evidence"], ["no_evidence", "operation"]], [[["Fish-1"]], [["Bengal cat-20"]], [["Bengal cat-20"], "operation"]], [[["Fish-5"]], [["Bengal cat-20", "Bengal cat-21"]], ["operation"]]]}
{"qid": "d07d517db865174dcee4", "term": "Soup", "description": "primarily liquid food", "question": "While on a liquid diet, are there some types of soup you cannot eat?", "answer": true, "facts": ["Italian wedding soup has large chunks including meatballs and pasta which require chewing.", "Chicken Noodle soup has chunks of chicken and large noodles in it that require chewing."], "decomposition": ["Are there any soups that contain substantially solid portions?"], "evidence": [[[["Gumbo-1", "Menudo (soup)-1"], "no_evidence"]], [[["Soup-1", "Stew-1"], "operation"]], [[["Chicken soup-1"]]]]}
{"qid": "06215d4b6f1a4b975d9c", "term": "Federal Reserve", "description": "Central banking system of the United States", "question": "Is the Federal Reserve a quick walk from Space Needle?", "answer": false, "facts": ["The Federal Reserve building is headquartered in Washington, D.C.", "The Space Needle is located in Seattle, Washington.", "There are over 2700 miles from Seattle, Washington to Washington, D.C."], "decomposition": ["Where is the Space Needle located?", "Where is the headquarters of Federal Reserve located?", "Can the distance between #1 and #2 be covered quickly by walking?"], "evidence": [[[["Space Needle-1"]], [["Marriner S. Eccles-8"]], ["operation"]], [[["Space Needle-1"]], [["Eccles Building-4"]], ["no_evidence"]], [[["Space Needle-1"]], [["Eccles Building-1"]], ["operation"]]]}
{"qid": "3b70f1178fdb45ad2a24", "term": "Ariana Grande", "description": "American singer, songwriter, and actress", "question": "Does Ariana Grande's signature style combine comfort items and high fashion?", "answer": true, "facts": ["Ariana Grande's signature style is a long, over-sized pullover sweater with thigh high heels.", "Oversized pullovers are considered lounge wear, for relaxing at home in. ", "High heels are associated with high style. "], "decomposition": ["What is Ariana Grande's signature top?", "What is Ariana Grande's signature shoewear?", "What type of clothing is #1 considered?", "Is #3 considered a comfort and item and is #2 considered a high style item?"], "evidence": [[[["Ariana Grande-34"], "no_evidence"], [["Ariana Grande-34"], "no_evidence"], ["no_evidence"], ["no_evidence"]], [[["Ariana Grande-34"]], ["no_evidence"], ["no_evidence"], ["operation"]], [[["Ariana Grande-34"]], [["Ariana Grande-34"]], [["Crop top-3"], "no_evidence"], ["operation"]]]}
{"qid": "10353348b0d7077924be", "term": "Paparazzi", "description": "profession", "question": "Were paparazzi involved in the death of a member of the royal family?", "answer": true, "facts": ["Diana Spencer was being pursued by paparazzi when her vehicle was involved in a fatal accident.", "Diana Spencer was known as 'Princess Diana' and was the Princess of Wales."], "decomposition": ["What were the circumstances surrounding the death of Diana Spencer?", "Is Diana Spencer a member of the royal family?", "Was paparazzi involved in #1?", "Are #2 and #3 positive?"], "evidence": [[[["Diana, Princess of Wales-4"]], [["Diana, Princess of Wales-3"]], [["Death of Diana, Princess of Wales-2"]], ["operation"]], [[["Death of Diana, Princess of Wales-1"]], [["Diana, Princess of Wales-1", "Diana, Princess of Wales-26"]], [["Death of Diana, Princess of Wales-2"]], ["operation"]], [[["Diana, Princess of Wales-53"]], [["Diana, Princess of Wales-1"]], [["Diana, Princess of Wales-53"]], ["operation"]]]}
{"qid": "f3584715f2b8d7894a3a", "term": "Edward Snowden", "description": "American whistleblower and former National Security Agency contractor", "question": "Could Edward Snowden join MENSA?", "answer": true, "facts": ["Snowden scored above 145 on two separate IQ tests.", "The minimum accepted IQ score for MENSA on the Stanford\u2013Binet is 132, while for the Cattell it is 148."], "decomposition": ["What is the minimum accepted IQ score to be admitted to MENSA?", "What is Edward Snowden's IQ?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Mensa International-5"]], [["Edward Snowden-5"]], ["operation"]], [[["Mensa International-5"]], [["Edward Snowden-5"]], [["Edward Snowden-5", "IQ Award-1"], "operation"]], [[["Mensa International-5"]], [["Edward Snowden-5"]], ["operation"]]]}
{"qid": "4f08d9a0fba58ad9ca73", "term": "Taco Bell", "description": "American fast-food chain", "question": "Will more people go in and out of Taco Bell than a Roy Rogers each year?", "answer": true, "facts": ["Taco Bell has over 7,072 restaurants as of 2018.", "Roy Rogers had over 600 restaurants at its peak.", "Roy Rogers has 48 locations as of 2019."], "decomposition": ["How many restaurants does Taco Bell have?", "How many restaurants does Roy Rogers have?", "Is #1 significantly greater than #2?"], "evidence": [[[["Taco Bell-1"]], [["Roy Rogers Restaurants-1"]], ["operation"]], [["no_evidence"], [["Roy Rogers Restaurants-1"]], ["operation"]], [["no_evidence"], [["Roy Rogers Restaurants-1"]], ["no_evidence", "operation"]]]}
{"qid": "141e0ea8af89ad9c91af", "term": "Management", "description": "Coordinating the efforts of people", "question": "In order to work in district management, does one need a car?", "answer": true, "facts": ["District managers are responsible for supervising many stores within an area.", "District managers must travel to the various stores they supervise to ensure peak performance."], "decomposition": ["What is the main responsibility of district managers?", "In order to do #1 efficiently, is a car needed? "], "evidence": [[["no_evidence"], ["no_evidence", "operation"]], [[["Account manager-1"], "no_evidence"], [["Account manager-9"], "operation"]], [[["District Programme Manager-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "4ec8cd118be8a53ec516", "term": "Koala", "description": "An arboreal herbivorous marsupial native to Australia.", "question": "Would Alexander Hamilton have known about koalas?", "answer": false, "facts": ["Alexander Hamilton died in 1804.", "The first published depiction of a koala was in 1810."], "decomposition": ["When were Koalas first sighted?", "When did Alexander Hamilton die?", "Is #1 before #2?"], "evidence": [[[["Koala-33", "Koala-35"]], [["Alexander Hamilton-1"]], ["operation"]], [[["Koala-3"], "no_evidence"], [["Alexander Hamilton-1"]], ["operation"]], [[["Koala-3"]], [["Alexander Hamilton-109"]], ["operation"]]]}
{"qid": "b35f58b61b53c487d1ab", "term": "Polyamory", "description": "Practice of or desire for intimate relationships with more than one partner", "question": "Is polyamory allowed in the Catholic Church?", "answer": false, "facts": ["A central tenet of the Catholic Church is a one-to-one match between man and woman.", "The ten commandments claim that \"coveting your neighbors wife\" is a sin."], "decomposition": ["What is Polyamory?", "Is #1 allowed in catholic churches?"], "evidence": [[[["Polyamory-10"]], [["Polygamy-34"]]], [[["Polyamory-1"]], [["Catholic Church-66"], "operation"]], [[["Polyamory-1"]], [["Religion and sexuality-16"]]]]}
{"qid": "06361fd92f628fe402e6", "term": "World of Warcraft", "description": "video game by Blizzard Entertainment", "question": "Is World of Warcraft heavier than a loaf of bread?", "answer": false, "facts": ["World of Warcraft is a piece of software.", "Software is digital.", "Digital items do not have weight. "], "decomposition": ["What does World of Warcraft refer to?", "Is #1 a tangible item that has weight?"], "evidence": [[[["World of Warcraft-2"]], ["no_evidence", "operation"]], [[["World of Warcraft-2"]], [["Software-1"]]], [[["World of Warcraft-1"]], ["operation"]]]}
{"qid": "1a0dcaf77f1c45f67d25", "term": "Modern Family", "description": "American comedy TV series", "question": "Did Modern Family win a Slammy award?", "answer": false, "facts": ["Modern Family is a television sitcom", "The Slammy Awards were presented to people involved in professional wrestling"], "decomposition": ["What television genre is Modern Family?", "What genre are the Slammy Awards given to?", "Is #1 and #2 the same?"], "evidence": [[[["Modern Family-1"]], [["Slammy Award-1"]], ["operation"]], [[["Modern Family-1"]], [["Slammy Award-1"]], ["operation"]], [[["Modern Family-1"]], [["Slammy Award-1"]], ["operation"]]]}
{"qid": "2ee33d6353893e4bd69c", "term": "Japan Airlines", "description": "airline headquartered in Tokyo, Japan", "question": "Are any of the destinations of Japan Airlines former Axis Powers?", "answer": true, "facts": ["Japan Airlines flies all over the world to places such as Germany, Ireland, and Australia.", "The Axis Powers were the countries that fought against the Allies during World War II.", "Axis Powers included countries such as Germany, Italy, and Japan."], "decomposition": ["Which countries does Japan Airlines fly to?", "Which counties were part of the Axis powers?", "Are there any similarities or overlap between #1 and #2?"], "evidence": [[[["Japan Airlines-2"], "no_evidence"], [["Axis powers-24"]], ["no_evidence"]], [[["Japan Airlines-2", "Japan Airlines-84"], "no_evidence"], [["Axis powers-2"]], ["operation"]], [[["Japan Airlines-63", "Japan Airlines-84"], "no_evidence"], [["Axis powers-1", "Axis powers-225"]], ["operation"]]]}
{"qid": "d9aeae10998c093c0cc9", "term": "Toyota Supra", "description": "A sports car and grand tourer manufactured by Toyota Motor Corporation", "question": "Can a Toyota Supra make a vlog?", "answer": false, "facts": ["A vlog is a \"video blog\" about one's experience", "A Toyota Supra does not have consciousness to recount any experiences"], "decomposition": ["What is a vlog?", "Who makes #1?", "What is a Toyota Supra?", "Is #3 the same as #2?"], "evidence": [[[["Vlog-1"]], [["Vlog-20"]], [["Toyota Supra-1"]], ["operation"]], [[["Vlog-1"]], [["Vlog-14"]], [["Toyota Supra-1"]], ["operation"]], [[["Vlog-1"]], [["Vlog-2"]], [["Toyota Supra-1"]], ["operation"]]]}
{"qid": "40b7c34188d5b36bc486", "term": "Lamborghini", "description": "Italian car manufacturer", "question": "Can Lamborghini's fastest model win a race against a Porsche 911?", "answer": true, "facts": ["Lamborghini's fastest model is the Lamborghini Aventador SVJ Roadster.", "The Lamborghini Aventador SVJ Roadster has a top speed of 217 MPH.", "The Porsche 911 has a top speed of 191 MPH."], "decomposition": ["Which model of Lamborghini is the fastest?", "What is the top speed of #1?", "What is the top speed of a Porsche 911?", "Is #2 greater than #3?"], "evidence": [[[["Lamborghini Veneno-1"]], [["Lamborghini Veneno-7"]], [["Porsche 911-133"]], ["operation"]], [[["Lamborghini Aventador-14"], "no_evidence"], [["Lamborghini Aventador-14"]], [["Porsche 911-129"]], ["operation"]], [[["Fastest Car-1"]], [["Lamborghini Aventador-14"]], [["Porsche 911-94"]], ["operation"]]]}
{"qid": "420837c63ba49f76d2a7", "term": "Earth Day", "description": "Annual event on 22 April", "question": "Is Earth Day celebrated in summer?", "answer": false, "facts": ["Earth Day is celebrated on April 22.", "Summer runs from about June 20 to September 20."], "decomposition": ["What is summer?", "What is the date of Earth day?", "Is #2 in #1?"], "evidence": [[[["Summer-2"]], [["Earth Day-30"]], ["operation"]], [[["Summer-5"]], [["Earth Day-1"]], ["operation"]], [[["Summer-2"]], [["Earth Day-1"]], ["operation"]]]}
{"qid": "f81316ea85357f58284b", "term": "Lord Voldemort", "description": "Fictional character of Harry Potter series", "question": "Would Lord Voldemort have been barred from Hogwarts under his own rules?", "answer": true, "facts": ["Lord Voldemort wanted to rid the wizarding world of half blood wizards.", "Lord Volemort was born a half blood, part muggle part wizard."], "decomposition": ["What kinds of people did Lord Voldemort want to prohibit from Hogwarts?", "What was Lord Voldemort born as?", "Is #1 the same as #2?"], "evidence": [[[["Lord Voldemort-4"]], [["Lord Voldemort-4"]], ["operation"]], [[["Lord Voldemort-2"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Lord Voldemort-2"]], [["Lord Voldemort-33"]], ["operation"]]]}
{"qid": "aed17ee939fc9dbe75fd", "term": "CAPTCHA", "description": "computer test to discriminate human users from spambots", "question": "Are any of the words that CAPTCHA stands for palindromes?", "answer": false, "facts": ["A palindrome is a word that reads the same backwards and forwards like madam.", "CAPTCHA stands for: Completely Automated Public Turing test to tell Computers and Humans Apart."], "decomposition": ["What words does CAPTCHA stand for?", "What is the characteristic of a palindrome?", "Does any word from #1 have the characteristic of #2?"], "evidence": [[[["CAPTCHA-1"]], [["Palindrome-1"]], ["operation"]], [[["CAPTCHA-1"]], [["Palindrome-1"]], ["operation"]], [[["CAPTCHA-1"]], [["Palindrome-1"]], ["operation"]]]}
{"qid": "cf23e1cddf4e7f714ba3", "term": "Drum", "description": "type of musical instrument of the percussion family", "question": "Would a vegan prefer a natural bongo drum over a synthetic one?", "answer": false, "facts": ["Natural bongo drums are made with leather.", "Synthetic bongo drums are made with plastic or leather substitutes.", "Vegans do not use or consume any animal products."], "decomposition": ["Which kind of products would a vegan avoid?", "What are natural Bongo drums made with?", "What are synthetic Bongo drums made with?", "Are #2 included in #1 and #3 excluded?"], "evidence": [[[["Veganism-1"]], [["Drumhead-3"]], [["Drumhead-5"]], ["operation"]], [[["Veganism-1"]], ["no_evidence"], ["no_evidence"], ["operation"]], [[["Veganism-1"]], [["Bongo drum-6"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "91ec6f3b34115feccada", "term": "Ham", "description": "Pork from a leg cut that has been preserved by wet or dry curing, with or without smoking", "question": "Will parma ham be ready for New Year's if the pig is slaughtered in December?", "answer": false, "facts": ["Parma ham requires two months to cure", "New Year's is at most one month away from December"], "decomposition": ["What is the minimum period of time required for parma ham to cure?", "How long is New Year's Day from December?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Prosciutto-5"]], [["New Year's Day-1"]], ["operation"]], [[["Prosciutto-5"]], [["New Year's Day-1"]], ["operation"]], [[["Ham-10"]], [["New Year's Day-8"], "operation"], ["operation"]]]}
{"qid": "956ca4e81d4ec39ab11a", "term": "Guam", "description": "Island territory of the United States of America", "question": "Does Guam have a state capital?", "answer": false, "facts": ["Guam is not a state.", "Only states can have a state capital."], "decomposition": ["Is Guam a country or state?", "Does #1 have state capitals?"], "evidence": [[[["Guam-1"]], [["Hag\u00e5t\u00f1a, Guam-1"]]], [[["Guam-1"], "no_evidence"], [["Guam-1"]]], [[["Guam-1"]], [["Hag\u00e5t\u00f1a, Guam-1"], "operation"]]]}
{"qid": "f240c88676b6ac6896ad", "term": "Kayak", "description": "small boat propelled with a double-bladed paddle", "question": "Is the kayak a traditional boat in New Zealand?", "answer": false, "facts": ["Kayaks were developed by native peoples to hunt in northern waters of the Arctic Ocean, North Atlantic, Bering Sea and North Pacific. ", "New Zealand is in the Southern Hemisphere.", "The native Maori people of New Zealand arrived there in canoes."], "decomposition": ["What cultures invented the kayak?", "What cultures are native to New Zealand?", "Is there overlap between #1 and #2?"], "evidence": [[[["Kayak-5"]], [["New Zealand-7"]], ["operation"]], [[["Kayak-5"]], [["Culture of New Zealand-1"]], ["operation"]], [[["Kayak-4"]], [["M\u0101ori people-1"]], ["operation"]]]}
{"qid": "5ce7ac7909c8331097b5", "term": "Coca", "description": "group of plant varieties cultivated for coca production", "question": "Is a Coca plant farm likely to be found in Yakutsk?", "answer": false, "facts": ["Coca is a plant originating in South America and used as a cash crop.", "Yakutsk is a city in east Siberia.", "The Coca plant grows in a humid tropical climate.", "Siberia has an extremely cold subarctic climate."], "decomposition": ["What kind of climate does the Coca plant grow in?", "What country is Yakutsk located on?", "What is the climate of #2?", "Is #1 the same as #3?"], "evidence": [[[["Coca-16"], "no_evidence"], [["Yakutsk-1"]], [["Yakutsk-2"]], ["operation"]], [[["Coca-16", "Yungas-1"]], [["Yakutsk-1"]], [["Climate of Russia-1", "Russia-84", "Russia-85"]], ["operation"]], [[["Coca-25"]], [["Yakutsk-1"]], [["Yakutsk-2"]], ["operation"]]]}
{"qid": "e76f4ef36aee97eafb49", "term": "Ahura Mazda", "description": "highest deity of Zoroastrianism", "question": "Can you worship Ahura Mazda at a mosque?", "answer": false, "facts": ["Ahura Mazda is a deity in Zoroastrianism", "A mosque is a place of worship for Muslims"], "decomposition": ["Which religious group worships in a mosque?", "Does #1 believe in or worship Ahura Mazda?"], "evidence": [[[["Mosque-1"]], [["Ahura Mazda-1"], "operation"]], [[["Mosque-30"]], [["Ahura Mazda-1", "Zoroastrianism-27"]]], [[["Islam-28"]], [["Ahura Mazda-1"]]]]}
{"qid": "7f4effbc97ab2b5fd4a7", "term": "British cuisine", "description": "culinary traditions of the United Kingdom", "question": "Could an American confuse breakfast in British cuisine for dinner?", "answer": true, "facts": ["In British Cuisine, baked beans are served with toast for breakfast.", "In the US, baked beans are served alongside barbecue dinners.", "British 'Full breakfasts' include grilled vegetables like mushrooms and whole cherry tomatoes.", "Grilled mushrooms and tomatoes are used more often in evening dishes in the US."], "decomposition": ["What foods are part of a traditional British breakfast?", "What foods are part of a traditional American dinner?", "Is there overlap between #1 and #2?"], "evidence": [[[["Breakfast-63"]], [["Meal-16"]], ["operation"]], [[["Breakfast-63"]], [["Burger King breakfast sandwiches-6"]], ["operation"]], [[["Full breakfast-1"]], [["Mushroom-28", "Tomato-85"], "no_evidence"], ["operation"]]]}
{"qid": "46f53b9e0008ad1110ed", "term": "Cuban Revolution", "description": "Revolution in Cuba between 1953 and 1959", "question": "During the Cuban revolution, did the US experience a population boom?", "answer": true, "facts": ["After WWII, the US experienced a baby boom.", "WWII ended in 1945."], "decomposition": ["When was the Cuban Revolution?", "When did the United States experience a rapid growth in its population?", "Does some or all of #2 overlap with #1?"], "evidence": [[[["Cuban Revolution-8"]], [["Baby boom-3"]], [["Baby boom-3", "Cuban Revolution-8"], "operation"]], [[["Cuban Revolution-1"]], [["Mid-twentieth century baby boom-1", "Mid-twentieth century baby boom-3"]], ["operation"]], [[["Cuban Revolution-1"]], [["Mid-twentieth century baby boom-12"]], ["operation"]]]}
{"qid": "d82193894aa1c12fbc40", "term": "Nissan", "description": "Japanese automobile manufacturer", "question": "Do workers at Nissan's headquarters eat with chopsticks?", "answer": true, "facts": ["Nissan's headquarters are located in Yokohama, Japan.", "It is customary to eat with chopsticks in East Asian countries.", "Japan is a country in East Asia."], "decomposition": ["Where is Nissan's headquarters located?", "Do people living in #1 usually eat with chopsticks?"], "evidence": [[[["Nissan-1", "Yokohama-1"]], [["Chopsticks-1"]]], [[["Nissan-1"]], [["Chopsticks-1", "Etiquette in Japan-21"]]], [[["Nissan-3"]], [["Chopsticks-1"], "operation"]]]}
{"qid": "30c3a32157acb4861555", "term": "Armadillo", "description": "family of mammals", "question": "Could someone theoretically use an armadillo as a shield?", "answer": true, "facts": ["Armadillos have hard armor made of dermal bone.", "Humans have ended up in the hospital due to bullets ricocheting against an armadillo's shell."], "decomposition": ["What are the basic features of a shield?", "Does any part of the armadillo's body possess any of #1?"], "evidence": [[[["Shield-1"]], [["Armadillo-2"], "operation"]], [[["Shield-2"]], [["Armadillo-2"], "operation"]], [[["Shield-1"]], [["Armadillo-2"]]]]}
{"qid": "130613016c3647a2f44b", "term": "Honey bee", "description": "Eusocial flying insect of genus Apis, producing surplus honey", "question": "Can a single honey bee sting multiple humans?", "answer": false, "facts": ["When a honey bee stings a human, the stinger becomes stuck in the skin and detaches from the bee.", "This usually results in the bee's death.", "Even if it survives, it no longer has a stinger to attack another person with."], "decomposition": ["What happens to a bee's stinger when it stings a human?", "What happens to a bee when #1 occurs?", "Can #2 sting another person?"], "evidence": [[[["Bee sting-6"]], [["Bee sting-6"]], [["Bee sting-6"], "operation"]], [[["Honey bee-61"]], [["Honey bee-61"]], ["operation"]], [[["Bee sting-8"]], [["Bee sting-8"]], [["Bee sting-8"]]]]}
{"qid": "8aa5c9ba2ae74151dd6e", "term": "Krishna", "description": "Major deity in Hinduism", "question": "Was Krishna skilled at using the bow?", "answer": true, "facts": ["Lord Krishna was known as the eighth manifestation of the god Vishnu.", "Vishnu had a trove of weapons including the Sudarshana Chakra and Sharanga.", "Sharanga was a celestial bow and a favored weapon of Vishnu."], "decomposition": ["Which Hindu god was Krishna known to be a manifestation of?", "Which weapons belonging to #1 were among his favorite?", "Is the bow included in #2?"], "evidence": [[[["Krishna-1"]], [["Sharanga-1"]], [["Sharanga-1"]]], [[["Krishna-1"]], [["Sharanga-1"]], ["operation"]], [[["Krishna-1"]], [["Krishna-24", "Krishna-36", "Sharanga-1"]], ["operation"]]]}
{"qid": "06c7a2b41766c56b48f7", "term": "Nickel", "description": "Chemical element with atomic number 28", "question": "Would nickel boil in the outer core of the earth?", "answer": true, "facts": ["The boiling point of nickel is 3003 Kelvin", "The temperature of earth's outer core is 3,000\u20134,500 Kelvin"], "decomposition": ["What is the boiling point of nickel?", "What the temperature range of the earth's outer core?", "Is #1 within #2?"], "evidence": [[[["Nickel-5"], "no_evidence"], [["Nickel-4"], "no_evidence"], ["no_evidence"]], [["no_evidence"], [["Earth's outer core-3"]], ["operation"]], [["no_evidence"], [["Earth's outer core-3"]], ["operation"]]]}
{"qid": "646d3503f3a3939e2e63", "term": "Sea of Japan", "description": "Marginal sea between Japan, Russia and Korea", "question": "Would the top of Mount Fuji stick out of the Sea of Japan? ", "answer": true, "facts": ["The average depth of the Sea of Japan is  5,748 feet (1,752 metres) and its maximum depth is 12,276 feet (3,742 metres)", "Mount Fuji is 3,776.24 metres (12,389.2 ft) tall. "], "decomposition": ["How tall is Mount Fuji?", "What is the maximum depth of the Sea of Japan?", "Is #1 greater than #2?"], "evidence": [[[["Mount Fuji-18"]], [["Sea of Japan-15"]], ["operation"]], [[["Mount Fuji-1"]], [["Sea of Japan-15"]], ["operation"]], [[["Mount Fuji-1"]], [["Sea of Japan-15"]], ["operation"]]]}
{"qid": "a1db94948b252250102b", "term": "History of the world", "description": "Recorded history of humanity", "question": "Are the events of Star Trek: The Next Generation in the history of the world?", "answer": false, "facts": ["The history of the world includes factual events.", "Star Trek: TNG is a fictional television show. "], "decomposition": ["Which universe is Star Trek: The Next Generation set in?", "Is #1 the same as the real world?"], "evidence": [[[["Star Trek: The Next Generation-1"]], ["no_evidence"]], [[["Star Trek: The Next Generation-1"]], [["Science fiction-1"], "operation"]], [[["Star Trek: The Next Generation-70"]], ["operation"]]]}
{"qid": "2079d6c0fea33860fbc3", "term": "Achilles", "description": "Greek mythological hero", "question": "Does Thiago Moises May 13 2020 submission move hypothetically hurt Achilles?", "answer": true, "facts": ["Thiago Moises is a mixed martial arts fighter in the UFC.", "Thiago Moises beat Michael Johnson by a heel hook submission.", "Greek hero Achilles had one weakness, his heel."], "decomposition": [" What was Thiago Moises' winning move the match he played on May 13 2020?", "Which part of the opponent's body did #1 affect?", "Which part of Achilles' body is his weaknes?", "Is #2 the same as #3?"], "evidence": [[["no_evidence"], ["no_evidence"], [["Achilles-2"]], ["operation"]], [["no_evidence"], [["Heel-1"]], [["Achilles-2"]], ["operation"]], [["no_evidence"], [["Paul Sass-6"], "no_evidence"], [["Achilles-2"]], ["operation"]]]}
{"qid": "c8e267b583f722ff485e", "term": "Constitution of the United States", "description": "Supreme law of the United States of America", "question": "Is the Hobbit more profitable for proofreader than Constitution of the United States?", "answer": true, "facts": ["Proofreaders typically get paid per the number of words in a document.", "The Constitution of the United States contains around 7,500 words.", "The Hobbit contains 95,356 words."], "decomposition": ["How many words are in the US Constitution?", "What classification is the Hobbit?", "How many words do books in #2 have?", "Is #3 greater than #1?"], "evidence": [[[["Constitution-4"], "no_evidence"], [["Hobbit-2"]], [["Artam\u00e8ne-1"], "no_evidence"], ["operation"]], [[["Constitution of the United States-1", "Constitution of the United States-2"]], [["The Hobbit-1"], "no_evidence"], [["The Hobbit-20"], "no_evidence"], ["no_evidence", "operation"]], [[["State constitution (United States)-2"]], [["Hobbit-7"]], [["The Hobbit-1"], "no_evidence"], ["operation"]]]}
{"qid": "c3fa97b16ea3e91e22d8", "term": "Pacific War", "description": "Theater of World War II fought in the Pacific and Asia", "question": "Were muskets used in the Pacific War?", "answer": false, "facts": ["The Pacific War took place between 1941 and 1945.", "The musket became obsolete in modern warfare starting near 1870."], "decomposition": ["When was the Pacific War?", "When did muskets become obsolete?", "Is #1 before #2?"], "evidence": [[[["Pacific War-2"]], [["Musket-29"]], ["operation"]], [[["Pacific War-2"]], [["Musket-1"]], ["operation"]], [[["Pacific War-1"]], [["Musket-1"]], ["operation"]]]}
{"qid": "62ac009461272e979537", "term": "Albany, Georgia", "description": "City in Georgia, United States", "question": "Is Albany, Georgia the most populous US Albany?", "answer": false, "facts": ["Albany, Georgia had a population of 75,249 in 2018.", "Albany, New York had a population of 97,279 in 2018."], "decomposition": ["Which places are known as Albany in the United States?", "What are the respective populations of #1?", "Is the population of Albany, Georgia the greatest of #2?"], "evidence": [[[["Albany, Georgia-1", "Albany, New York-2"]], [["Albany, Georgia-1", "Albany, New York-2"]], ["operation"]], [[["Albany, New York-1"]], [["Albany, New York-2"]], [["Albany, Georgia-1"]]], [[["Albany, Georgia-1", "Albany, New York-2"]], [["Albany, Georgia-1", "Albany, New York-2"]], ["operation"]]]}
{"qid": "af6afbc6da7065d522ee", "term": "Ludacris", "description": "American rapper and actor", "question": "Is Ludacris in same music genre as 2000's Binaural?", "answer": false, "facts": ["Ludacris is a rapper, particularly in the southern rap style.", "Binaural was a 2000 album released by Pearl Jam.", "Pearl Jam is a grunge rock band formed in Seattle."], "decomposition": ["What genre does Ludacris produce music in?", "Who recorded the 2000 album Binaural?", "What genre does #2 produce music in?", "Is #1 the same as #3?"], "evidence": [[[["Hip hop music-1", "Ludacris-1"]], [["Binaural (album)-1"]], [["Binaural (album)-1"]], ["operation"]], [[["Ludacris-1"]], [["Binaural (album)-1"]], [["Pearl Jam-1"]], ["operation"]], [[["Ludacris-1"]], [["Binaural (album)-1"]], [["Pearl Jam-1"]], ["operation"]]]}
{"qid": "cb19ebb5cbaa71bc32d6", "term": "Duck", "description": "common name for many species in the bird family Anatidae", "question": "Would a duck ever need a Caesarean section?", "answer": false, "facts": ["A Caesarean section is a medical procedure in which surgery is performed to remove the baby from inside the mother.", "Ducks do not give live birth, they lay eggs."], "decomposition": ["Cesarean sections are only performed on animals that produce offspring via what method?", "What method do ducks use to produce offspring?", "Is #2 the same as #1?"], "evidence": [[[["Caesarean section-1"]], [["Duck-15"]], ["operation"]], [[["Caesarean section-1"]], [["Mallard-2"], "no_evidence"], ["operation"]], [[["Caesarean section-1"]], [["Duck-15"]], [["Egg-10"], "operation"]]]}
{"qid": "47b4c3e06e1a2f42b91a", "term": "Bipolar disorder", "description": "mental disorder that causes periods of depression and abnormally elevated mood", "question": "Are you more likely to find bipolar disorder in a crowd than diabetes?", "answer": false, "facts": ["Bipolar disorder is a condition that effects around 1% of the population.", "It is estimated that around 10% of the population suffers from diabetes."], "decomposition": ["What percent of the population has bipolar disorder?", "What percent of the population has diabetes?", "Is #1 greater than #2?"], "evidence": [[[["Bipolar disorder-4"]], [["Diabetes-4"]], [["Diabetes-4"]]], [[["Bipolar disorder-4"]], [["Diabetes-4"]], ["operation"]], [[["Bipolar disorder-4"]], [["Diabetes-4"]], ["operation"]]]}
{"qid": "5897ec22db850f7b416e", "term": "John Key", "description": "38th Prime Minister of New Zealand", "question": "As of 2020 have more women succeeded John Key than preceded him?", "answer": false, "facts": ["John Key, the 38th Prime Minister of New Zealand, has had one woman succeed him as Prime Minister.", "John key was preceded by two women as Prime Minister of New Zealand."], "decomposition": ["Which notable position did John Key occupy?", "How many women served as #1 before him?", "How many women have served as #1 after him?", "Is #3 greater than #2?"], "evidence": [[[["John Key-1"], "no_evidence"], [["Helen Clark-1"]], [["Jacinda Ardern-1"]], ["operation"]], [[["John Key-1"]], [["Prime Minister of New Zealand-23"]], [["Prime Minister of New Zealand-23"]], ["operation"]], [[["John Key-1"]], [["Helen Clark-1", "Jenny Shipley-1"]], [["Jacinda Ardern-1"]], ["operation"]]]}
{"qid": "e3253bcbb5125e2d29d9", "term": "Learning disability", "description": "Range of neurodevelopmental conditions", "question": "Do placozoa get learning disabilities?", "answer": false, "facts": ["Learning disabilities are neurodevelopmental conditions afflicting a portion of the human population", "Neurodevelopmental conditions affect the nervous system", "Placozoa are multicellular microscopic organisms which do not have a nervous system"], "decomposition": ["What bodily system do learning disabilities affect?", "Do placozoa possess #1?"], "evidence": [[[["Learning disability-1"]], [["Placozoa-7"], "operation"]], [[["Learning disability-1", "Learning disability-3"], "no_evidence"], [["Placozoa-1"], "operation"]], [[["Learning disability-5"]], [["Placozoa-7"], "operation"]]]}
{"qid": "9ca37a720a283c3d6045", "term": "Common warthog", "description": "Wild member of the pig family", "question": "Would a Common warthog starve in a greenhouse?", "answer": false, "facts": ["A greenhouse is an enclosed building in which plants are grown.", "The Common warthog is an animal that feeds on grasses, roots, berries, and small insects.", "Aphids, fungus gnats, and caterpillars, are common insects found in greenhouses."], "decomposition": ["What kind of things are found in a greenhouse?", "What does the warthog diet consist of?", "Is there significant overlap between #1 and #2?"], "evidence": [[[["Greenhouse-31"]], [["Phacochoerus-2"]], [["Greenhouse-31", "Herbivore-1"]]], [[["Greenhouse-1"]], [["Common warthog-5"]], ["operation"]], [[["Greenhouse-27"]], [["Common warthog-5"]], ["operation"]]]}
{"qid": "4773d577873ff9e04a88", "term": "Woodrow Wilson", "description": "28th president of the United States", "question": "Did Woodrow Wilson consider Blacks to be equal members of society?", "answer": false, "facts": ["Woodrow Wilson supported the Ku Klux Klan.", "The Ku Klux Klan consider Blacks to be inferior. "], "decomposition": ["What group did Woodrow Wilson support?", "Did #1 consider Blacks to be equal members of society?"], "evidence": [[[["Woodrow Wilson-79"]], [["Ku Klux Klan-1", "Ku Klux Klan-2"]]], [[["Woodrow Wilson-79"]], [["Ku Klux Klan-104"]]], [[["Woodrow Wilson-79"], "no_evidence"], [["Woodrow Wilson-76"]]]]}
{"qid": "97c91d5613b99fd4098f", "term": "Gorilla", "description": "Genus of mammals", "question": "Are gorillas closely related to humans?", "answer": true, "facts": ["Gorillas are part of the animal family Hominidae.", "Hominidae also includes the genus Homo, which only contains the human species."], "decomposition": ["What animal family are Gorillas part of?", "Are humans also part of #1?"], "evidence": [[[["Hominidae-1"]], ["operation"]], [[["Gorilla-1"]], [["Primate-2"]]], [[["Hominidae-1"]], [["Hominidae-1"]]]]}
{"qid": "b64be915de0e671e8548", "term": "Easter Bunny", "description": "Folkloric figure and symbol of Easter", "question": "Is the Easter Bunny popular in September?", "answer": false, "facts": ["The Easter Bunny is a symbol of the Christian holiday of Easter", "Easter occurs in March or April each year"], "decomposition": ["What holiday does the Easter Bunny symbolize?", "Is #1 celebrated in September?"], "evidence": [[[["Easter Bunny-1"]], [["Easter-14", "Easter-15"]]], [[["Easter Bunny-1"]], [["Easter-14", "Easter-15"], "operation"]], [[["Easter Bunny-1"]], [["Easter-17"]]]]}
{"qid": "4c7da1c6a6b94f8c44b1", "term": "Saltwater crocodile", "description": "species of reptile", "question": "Are saltwater crocodiles related to alligators?", "answer": true, "facts": ["Crocodiles belong to the family Crocodylinae.", "Alligators belong to the family Alligatoridae.", "Crocodylinae and Alligatoridae both belong to the order Crocodilia."], "decomposition": ["What family do Crocodiles belong to?", "What family do Alligators belong to?", "What order does #1 belong to?", "What order does #2 belong to?", "Are #3 and #4 the same thing?"], "evidence": [[[["Crocodile-1"]], [["Alligator-1"]], [["Crocodile-1"]], [["Alligator-1"]], ["operation"]], [[["Crocodile-35"]], [["American alligator-5"]], [["Crocodile-35"]], [["Alligator-1"]], ["operation"]], [[["Crocodylidae-1"]], [["Alligator-1"]], [["Crocodilia-1"]], [["Crocodilia-1"]], ["operation"]]]}
{"qid": "e43424acbaf3f64feefd", "term": "Brazilian Navy", "description": "Naval warfare branch of Brazil's military forces", "question": "Are some Brazilian Navy ships built in Britian?", "answer": true, "facts": ["The Brazilian Navy stated in 2018 that they had purchased the helicopter carrier ship HMS Ocean.", "HMS stands for \"His/Her Majesty's Ship\", which is emblazoned on ships of the British Royal Navy. ", "Some of the ships in the Brazilian Navy are guided missile frigates built in Britian."], "decomposition": ["Which helicopter carrier ship did the Brazilian Navy announce that they had acquired in 2018?", "Was #1 built in Britain?"], "evidence": [[[["Brazilian Navy-62"]], [["HMS Ocean (L12)-1"]]], [[["HMS Ocean (L12)-2"]], [["HMS Ocean-1"]]], [[["Aircraft carrier-43"]], ["operation"]]]}
{"qid": "67f4435b81df96894ef8", "term": "Middle Ages", "description": "Period of European history from the 5th to the 15th century", "question": "Was dynamite used during Middle Ages warfare?", "answer": false, "facts": ["The Middle Ages ended with the Fall of Constantinople in 1453.", "Dynamite was invented by Swedish chemist Alfred Nobel in the 1870s."], "decomposition": ["When was dynamite invented?", "When did the Middle Ages warfare take place?", "Is #1 within or before #2?"], "evidence": [[[["Dynamite-3"]], [["Middle Ages-7"]], ["operation"]], [[["Dynamite-1"]], [["Middle Ages-1"]], ["operation"]], [[["Dynamite-1"]], [["Medieval warfare-25"]], ["operation"]]]}
{"qid": "8b72c6650e23554f51eb", "term": "Glenn Beck", "description": "American talk radio and television host", "question": "Would Glen Beck and Stephen Colbert be likely to tour together?", "answer": false, "facts": ["Glenn Beck is a right wing commentator known for strong opinions and serious tone.", "Stephen Colbert is a liberal political commentator who takes a comedic approach to his work."], "decomposition": ["What political party does Glen Beck support?", "What political party does Stephen Colbert support?", "Is #1 the same as #2?"], "evidence": [[[["Glenn Beck-49"]], [["Stephen Colbert-62"]], [["Stephen Colbert-62"], "operation"]], [[["Glenn Beck-46"]], [["Stephen Colbert-62"]], ["operation"]], [[["Glenn Beck-46"]], [["Stephen Colbert-3"]], ["operation"]]]}
{"qid": "f486ba373c1b13c27667", "term": "Golden eagle", "description": "species of bird", "question": "Is the Golden eagle considered a scavenger bird?", "answer": false, "facts": ["Scavengers are defined as animals that feed on dead carcasses of animals they have not killed themselves.", "Vultures are scavengers that hover in the air and swoop down to feed once they see an animal killed by another animal.", "The Golden eagle has sharp talons to hunt its own prey.", "Golden eagles kill and feed on hares, rabbits, and ground squirrels."], "decomposition": ["Who kills the prey that scavengers feed on?", "Who kills the prey that Golden eagles feed on?", "Is #1 the same as #2?"], "evidence": [[[["Scavenger-1"]], [["Golden eagle-22"]], ["operation"]], [[["Scavenger-1"]], [["Golden eagle-28"]], ["operation"]], [[["Scavenger-1"]], [["Golden eagle-22"]], ["operation"]]]}
{"qid": "27b84ef72c557aa8fc14", "term": "Watermelon", "description": "A large fruit with a smooth hard rind, of the gourd family", "question": "Is watermelon safe for people with a tricarboxylic acid allergy?", "answer": true, "facts": ["Tricarboxylic acid as an acid that manifests itself in fruits as citric acid.", "Citric acid can be found in citrus fruits such as oranges and lemon.", "Watermelon is not a citrus fruit."], "decomposition": ["What is the most common example of a tricarboxylic acid?", "Which kind of fruits is #1 usually present in?", "Is watermelon excluded from #2?"], "evidence": [[[["Tricarboxylic acid-1"]], [["Citric acid-1"]], [["Citrus-1", "Watermelon-2"], "operation"]], [[["Tricarboxylic acid-2"]], [["Citric acid-14"]], [["Citric acid-14", "Watermelon-8"], "operation"]], [[["Tricarboxylic acid-1"]], [["Citric acid-14"]], ["operation"]]]}
{"qid": "e9e2b22b193fcca2a976", "term": "Cricket (insect)", "description": "small insects of the family Gryllidae", "question": "Would someone buying crickets be likely to own pets?", "answer": true, "facts": ["Reptiles are a popular pet for people.", "Reptiles enjoy eating crickets. ", "Crickets are sold at many pet stores."], "decomposition": ["What are some common animal classes that people keep as pets?", "Do any of #1 usually eat crickets?"], "evidence": [[[["Pet-22"]], [["Crickets as pets-4"]]], [[["Crickets as pets-26", "Pet-2"], "no_evidence"], [["Cricket (insect)-3"], "no_evidence", "operation"]], [[["Pet-2"]], [["Lizard-27"]]]]}
{"qid": "6f4c8a2789c0305c4f63", "term": "Maya Angelou", "description": "American poet, author, and civil rights activist", "question": "Did any of Maya Angelou's children follow in her footsteps?", "answer": true, "facts": ["Maya Angelou was a civil rights activist and author.", "Maya Angelou had a son named Guy Johnson in 1945.", "Guy Johnson is an author that has written over twenty books and essays.", "Guy Johnson's books explore many civil rights themes."], "decomposition": ["What was Maya angelou's profession?", "Who is Maya Angelou's son?", "Did #2 do #1?"], "evidence": [[[["Maya Angelou-1"]], [["Maya Angelou-25"]], [["Maya Angelou-1", "Maya Angelou-25"], "no_evidence"]], [[["Maya Angelou-1"]], [["Maya Angelou-8"]], ["no_evidence", "operation"]], [[["Maya Angelou-1"]], [["Maya Angelou-8"]], ["no_evidence", "operation"]]]}
{"qid": "947a089ce6992869815a", "term": "Swallow", "description": "family of birds", "question": "Did the swallow play a role in a famous film about King Arthur?", "answer": true, "facts": ["Monty Python and the Holy Grail was a famous film about King Arthur", "In Monty Python and the Holy Grail, swallows are mentioned several times"], "decomposition": ["What Monty Python film is about King Arthur?", "Are swallows mentioned several times in #1?"], "evidence": [[[["Monty Python and the Holy Grail-1"]], ["no_evidence", "operation"]], [[["Monty Python and the Holy Grail-1"]], [["Monty Python and the Holy Grail-4"]]], [[["Monty Python and the Holy Grail-2", "Monty Python and the Holy Grail-4", "Monty Python and the Holy Grail-9"]], ["operation"]]]}
{"qid": "e8cc7615cfaf45069eb5", "term": "Ludacris", "description": "American rapper and actor", "question": "Can you watch the Borgia's World of Wonders before Ludacris's Release Therapy finishes?", "answer": true, "facts": ["World of Wonders is an episode of the Showtime TV series The Borgias, with a run time of 49 minutes.", "Ludacris's 2006 album Release Therapy has a run time of 62 minutes."], "decomposition": ["What is the run time of  the Borgia's World of Wonders?", "What is the run time of  Ludacris's Release Therapy?", "Is #1 shorter than #2?"], "evidence": [[[["The Borgias (2011 TV series)-14"], "no_evidence"], [["Release Therapy-1"], "no_evidence"], ["operation"]], [[["The Borgias (2011 TV series)-1", "The Borgias (2011 TV series)-4"], "no_evidence"], [["Release Therapy-1"], "no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "c70d40b57fa67ea13ed6", "term": "Tonsure", "description": "hairstyle related to religious devotion", "question": "Does a person using tonsure have hair at the top of their scalp?", "answer": false, "facts": ["Tonsure involves shaving some or all of the hair from the head.", "Tonsure styles include a large bald spot at the top of the scalp."], "decomposition": ["What parts of the head are shaved for the tonsure hairstyle?", "Is the top of the scalp excluded from #1?"], "evidence": [[[["Tonsure-1"]], ["operation"]], [[["Tonsure-1"]], ["operation"]], [[["Tonsure-1"]], ["operation"]]]}
{"qid": "b6713901d33bc1020596", "term": "Richard Wagner", "description": "German composer", "question": "Was Mozart accused of stealing from Richard Wagner?", "answer": false, "facts": ["Mozart died in 1791.", "Richard Wagner was born in 1813."], "decomposition": ["When did Mozart die?", "When was Richard Wagner born?", "Is #2 an earlier date than #1?"], "evidence": [[[["Wolfgang Amadeus Mozart-1"]], [["Richard Wagner-1"]], ["operation"]], [[["Wolfgang Amadeus Mozart-50"]], [["Richard Wagner-1"]], ["operation"]], [[["Wolfgang Amadeus Mozart-50"]], [["Richard Wagner-1"]], ["operation"]]]}
{"qid": "2def6bb4885a6cc0a6a5", "term": "Mickey Mouse", "description": "Disney cartoon character", "question": "Would Mickey Mouse blend in with the American flag?", "answer": false, "facts": ["The American Flag is colored red, white, and blue.", "Mickey Mouse typically wears red shorts, large yellow shoes, and white gloves.", "The color yellow stands out distinctly from red, white, and blue.", "Things that are colored similarly or identically will blend in with each other."], "decomposition": ["What colors are Mickey Mouse?", "What colors are the American flag?", "Are most of the colors in #1 also found in #2?"], "evidence": [[[["Mickey Mouse-48"]], [["Franco-American Flag-1"]], ["operation"]], [[["Mickey Mouse-1"]], [["Flag of the United States-1"]], ["operation"]], [[["Mickey Mouse-1"]], [["Flag of the United States-1"]], ["operation"]]]}
{"qid": "e5f9336ceb74622c14c0", "term": "Model (person)", "description": "person employed to display, advertise and promote products, or to serve as a visual aid", "question": "Would a model be likely to frequently enjoy the menu at Cookout?", "answer": false, "facts": ["Models are known for being very thin on average.", "Cookout serves high calorie American style barbecue food.", "Models often have pressure put on them to maintain a slim figure."], "decomposition": ["What is the typical body shape of a model?", "What kind of food does a cookout typically have?", "Are #2 foods high in calories?", "In order to maintain #1, what kinds of food must a person eat?", "Does #3 match with #4?"], "evidence": [[[["Model (person)-22"]], [["Cook Out (restaurant)-1"]], [["Food energy-4"]], [["Model (person)-24"], "no_evidence"], ["operation"]], [[["The Thin Ideal-21"]], [["Cook Out (restaurant)-1"]], ["operation"], [["Dieting-13"]], ["operation"]], [[["Model (person)-24"]], [["Cook Out (restaurant)-1"]], [["Fast food-6"]], [["Dieting-1"]], ["operation"]]]}
{"qid": "fab710522fe2f188579d", "term": "Buzz Aldrin", "description": "American astronaut; second person to walk on the Moon", "question": "Could Buzz Aldrin have owned a computer?", "answer": true, "facts": ["Buzz Aldrin was born in 1930 and is still alive in 2020. ", "Home computers were first available for sale in 1977. "], "decomposition": ["When were personal computers made available to the public?", "When was Buzz Aldrin born?", "Is #2 well before #1?"], "evidence": [[[["Personal computer-10"]], [["Buzz Aldrin-1"]], [["Buzz Aldrin-1"], "operation"]], [[["Personal computer-15"]], [["Buzz Aldrin-1"]], ["operation"]], [[["Personal computer-7"]], [["Buzz Aldrin-1"]], ["operation"]]]}
{"qid": "4de177ae8c827fd0ffb1", "term": "Retail", "description": "Sale of goods and services from individuals or businesses to the end-user", "question": "Is retail a job anybody can be suited for?", "answer": false, "facts": ["Most retail jobs require employees to be able to lift, push, and pull 25-50 lbs. ", "Retail positions require employees to interact with customers regularly.", "Various disabilities can diminish one's ability to interact with the public."], "decomposition": ["What are some basic skills that a person employed in retail should have?", "Would every person, even the disabled, possess all of #1?"], "evidence": [[[["Retail clerk-2"]], ["operation"]], [[["Retail-50"], "no_evidence"], [["Disability-3"], "no_evidence", "operation"]], [[["Retail-3"]], ["no_evidence", "operation"]]]}
{"qid": "463567e1582ccab9a048", "term": "Euro", "description": "European currency", "question": "Will a 2 Euro coin float across the Red Sea?", "answer": false, "facts": ["A 2 Euro coin is made of a mix of copper and brass.", "Objects float if their density is less than water.", "Ancient bronze metal ingots were found on the sea floor off the coast of Italy in 2015."], "decomposition": ["What are the material constituents of a 2 Euro coin?", "#1 belong to which family of materials?", "Can non hollow forms of #2 float on water?"], "evidence": [[[["2 euro coin-1"]], [["Metal-1"]], ["operation"]], [[["2 euro coin-1"]], [["Copper-2"]], [["Metal-9"], "no_evidence"]], [[["2 euro coin-8"]], [["Metal-35"]], ["no_evidence"]]]}
{"qid": "4148e19a53dfbb020484", "term": "Anchovy", "description": "Family of fishes", "question": "Are there bones in an anchovy pizza?", "answer": true, "facts": ["Anchovies used on pizza are typically packed whole in oil or water. ", "Anchovies on pizza are not usually cut or filleted in any way."], "decomposition": ["Which fishes are used in anchovy pizza?", "Are #1 usually packed whole into the pizza?"], "evidence": [[[["Anchovies as food-3"]], [["Anchovies as food-2"]]], [[["Anchovies as food-2"]], [["Anchovies as food-2"], "no_evidence", "operation"]], [[["Anchovy-3"]], [["Anchovy-3"]]]]}
{"qid": "ab5cd41c7f7a74451bdf", "term": "Jeremy Irons", "description": "English actor", "question": "Did Jeremy Irons master sweep picking as a child?", "answer": false, "facts": ["Jeremy Irons was the drummer and harmonica player in a four-man school band called the Four Pillars of Wisdom.", "Sweep picking is a guitar playing technique."], "decomposition": ["What kind of musical instrument involves sweet picking?", "What musical instruments did Jeremy Irons play in the school band Four Pillars of Wisdom?", "Is #1 included in #2?"], "evidence": [[[["Sweep picking-1"]], [["Jeremy Irons-5"]], ["operation"]], [[["Sweep picking-1"]], [["Jeremy Irons-5"]], ["operation"]], [[["Guitar picking-14"]], [["Jeremy Irons-5"]], ["operation"]]]}
{"qid": "60c525b944e991fb9821", "term": "Old English", "description": "Early form of English; Anglo-Saxon", "question": "Would a Pict be confused by Old English?", "answer": true, "facts": ["Old English was spoken by the Anglo-Saxons, a Germanic tribe that inhabited England.", "The Picts were a Celtic-speaking people that lived in what is now Scotland.", "The Pictish language died out by 1100AD and was replaced by Gaelic.", "Gaelic and Old English are completely different languages from different branches of the Indo-European language family.", "Gaelic vocabulary is very different from Old English  and verbs are also conjugated differently."], "decomposition": ["What language was spoken by the Picts?", "In what language family is Old English?", "Is #2 not closely related to #1?"], "evidence": [[[["Picts-1"]], [["Old English-2"]], [["Pictish language-2"], "operation"]], [[["Pictish language-1", "Picts-1"]], [["Old English-1"]], [["English language-2", "Picts-36"], "operation"]], [[["Picts-1"]], [["Old English-3"]], [["Celtic languages-1", "West Germanic languages-2"]]]]}
{"qid": "f43533225534420816d6", "term": "Giant squid", "description": "Deep-ocean dwelling squid in the family Architeuthidae", "question": "Can you house a giant squid at Soldier Field?", "answer": true, "facts": ["Soldier Field is a football stadium", "Football fields are 120 yards long, or 360 feet", "The maximum length of a giant squid is 43 feet"], "decomposition": ["How long are giant squid?", "What type of field is Soldier Field?", "How long are #2?", "Is #3 equal to or greater than #1?"], "evidence": [[[["Giant squid-1"]], [["Soldier Field-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Giant squid-1"]], [["Soldier Field-1"]], [["American football-36"]], ["operation"]], [[["Giant squid-1"]], [["Soldier Field-1"]], [["Gridiron football-7"]], ["operation"]]]}
{"qid": "b651b1d70b88ae98bc25", "term": "Ammonia", "description": "Chemical compound of nitrogen and hydrogen", "question": "Is it safe to use Ammonia with Clorox?", "answer": false, "facts": ["Clorox is a brand name of a line of bleach products.", "Ammonia and bleach react together to produce toxic gas."], "decomposition": ["What is the main ingredient in Clorox?", "What happens when you mix ammonia and #1 together?", "Is #2 dangerous?"], "evidence": [[[["Sodium hypochlorite-46"]], [["Sodium hypochlorite-3"]], ["no_evidence"]], [[["Bleach-4", "Clorox-2"]], [["Ammonia-72"]], ["operation"]], [[["Sodium hypochlorite-2"]], [["Sodium hypochlorite-3"]], ["operation"]]]}
{"qid": "787aedef693b5860aac5", "term": "Knight", "description": "An award of an honorary title for past or future service with its roots in chivalry in the Middle Ages", "question": "Are there any official American knights?", "answer": false, "facts": ["The English monarchy bestows the title of knighthood upon deserving English citizens.", "They only knight English people.", "The American government does not do knightings of its own."], "decomposition": ["Which kind government bestows knighthood on its citizens?", "Would #1 confer knighthood on a citizen of another country?", "Is the American government an example of #1?", "Is #2 or #3 positive?"], "evidence": [[[["Knight-1"]], [["Knight-3"], "no_evidence"], [["Federal government of the United States-1"]], ["operation"]], [[["Knight-1", "Orders, decorations, and medals of the United Kingdom-1"], "no_evidence"], [["Order of the British Empire-6"], "no_evidence"], ["no_evidence", "operation"], ["no_evidence", "operation"]], [[["Order of the British Empire-2"]], [["Order of the British Empire-3"]], [["Federal government of the United States-1"], "operation"], ["operation"]]]}
{"qid": "1aa02d78c5add228c611", "term": "Korea under Japanese rule", "description": "Japanese occupation of Korea from 1910\u20131945", "question": "Did people in Korea under Japanese Rule watch a lot of Iron Chef?", "answer": false, "facts": ["The first televisions were sold in 1946.", "Iron Chef started airing in 1993."], "decomposition": ["During what years was Korea under the rule of the Japanese?", "In what year did Iron Chef first appear on television?", "Did #1 occur after #2?"], "evidence": [[[["Korea under Japanese rule-1"]], [["Iron Chef-1"]], ["operation"]], [[["Korea under Japanese rule-1"]], [["Iron Chef-1"]], ["operation"]], [[["World War II by country-161"]], [["Iron Chef-1"]], ["operation"]]]}
{"qid": "bfc739cbf7aaf9f53ada", "term": "The Mentalist", "description": "American police procedural drama television series (2008-2015)", "question": "Was the Mentalist filmed in black and white?", "answer": false, "facts": ["The Mentalist first aired in 2008.", "Black and white television shows were no longer being made in 2008."], "decomposition": ["When did The Mentalist first air?", "When did they stop filming black and white television?", "Was #1 before #2?"], "evidence": [[[["The Mentalist-1"]], [["Black and white-5"]], ["operation"]], [[["The Mentalist-1"]], [["Black and white-5"]], ["operation"]], [[["The Mentalist-1"]], [["Black and white-5"]], ["operation"]]]}
{"qid": "f92ab04a1f144b593809", "term": "British royal family", "description": "Family consisting of close relatives of the monarch of the United Kingdom", "question": "Have any members of the 2020 British royal family allegedly committed a felony?", "answer": true, "facts": ["The 2020 British royal family includes Queen Elizabeth II and her children.", "Prince Andrew is the son of Queen Elizabeth II.", "Prince Andrew was accused of sexual abuse in 2019.", "Sexual assault is classified as a felony."], "decomposition": ["Which royal family does Prince Andrew belong to?", "What is Prince Andrew accused of?", "What type of crime is #2?", "Does #1 have a member accused of #3?"], "evidence": [[[["Prince Andrew, Duke of York-1"]], [["Prince Andrew, Duke of York-22"]], [["Adolescent sexuality in the United States-53"]], [["Prince Andrew, Duke of York-25"]]], [[["Prince Andrew, Duke of York-6"]], [["Prince Andrew, Duke of York-22", "Prince Andrew, Duke of York-25"]], [["Prince Andrew, Duke of York-22"]], [["Prince Andrew, Duke of York-25"], "operation"]], [[["Prince Andrew, Duke of York-1"]], [["Prince Andrew, Duke of York-3"]], [["Felony-6"]], ["operation"]]]}
{"qid": "3c354ae95bfcbd8e8664", "term": "Railroad engineer", "description": "person who operates a train on a railroad or railway", "question": "Did Jesus go to school to study railroad engineering?", "answer": false, "facts": ["The steam locomotive to drive a train was invented in the 19th century.", "Jesus lived around 0 AD. "], "decomposition": ["When was the steam locomotive invented?", "When did Jesus die?", "Was #1 before #2?"], "evidence": [[[["Steam locomotive-2"]], [["Jesus-1"]], ["operation"]], [[["Steam locomotive-2"]], [["Jesus-1"]], ["operation"]], [[["Steam locomotive-6"]], [["Crucifixion of Jesus-1"]], ["operation"]]]}
{"qid": "fe5e84a00c13770bf65a", "term": "Paramount leader", "description": "The highest leader of China, usually the General Secretary or Chairman of Chinese Communist Party.", "question": "Did the Paramount leader produce Titanic?", "answer": false, "facts": ["The Paramount leader is the highest leader of China", "Titanic was produced by Paramount Pictures", "Paramount Pictures is an American film studio"], "decomposition": ["Who is the Paramount leader?", "Who produced Titanic?", "Is #1 the same as #2?"], "evidence": [[[["Jim Gianopulos-1"]], [["Titanic (1997 film)-1", "Titanic (1997 film)-12"]], ["operation"]], [[["Paramount leader-1"]], [["Titanic (1997 film)-1"]], ["operation"]], [[["Paramount leader-1"]], [["Titanic (1997 film)-43"]], ["operation"]]]}
{"qid": "347eea662abc9467ed18", "term": "Jason", "description": "Greek mythological hero", "question": "Could the children of Greek hero Jason hypothetically fill a polo team?", "answer": true, "facts": ["The Greek mythological hero is known for his quest to obtain the Golden Fleece.", "The Greek mythological hero had four children: Euneus, Nebrophonus, Mermerus, and Pheres.", "Polo is a sport played between two teams of 4 players."], "decomposition": ["How many children did Greek mythological hero Jason have?", "How many people are needed to make a polo team?", "Is #1 equal to or more than #2?"], "evidence": [[["no_evidence"], [["Polo-51"]], ["operation"]], [[["Medea-10"]], [["Polo-4"]], ["operation"]], [[["Medea-10"]], [["Water polo-1"]], ["operation"]]]}
{"qid": "8eecf2ff459ef5a9b98a", "term": "Cactus", "description": "Family of mostly succulent plants, adapted to dry environments", "question": "Would an aerodynamic cactus benefit from more frequently closed stomata?", "answer": true, "facts": ["Cactus spines help the plant retain water by reducing air flow around the plant", "Aerodynamic objects have smooth surfaces ", "Crassulacean acid metabolism is used by cactuses ", "Crassulacean acid metabolism is when a plant's stomata stay closed during daylight or times of drought to prevent water loss"], "decomposition": ["What helps cacti conserve water?", "Of #1, what methods do not involve protrusions that might restrict air flow?", "Are closed stoma one of #2?"], "evidence": [[[["Cactus-28", "Cactus-29"]], [["Cactus-34"]], ["operation"]], [[["Cactus-1"]], [["Cactus-35"]], ["operation"]], [[["Cactus-13", "Cactus-14"], "no_evidence"], [["Cactus-13", "Cactus-14"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "3ae8644164c547560eda", "term": "King Arthur", "description": "legendary British leader of the late 5th and early 6th centuries", "question": "Was King Arthur at the beheading of Anne Boleyn?", "answer": false, "facts": ["King Arthur was a legendary British leader who, according to medieval histories and romances, led the defence of Britain against Saxon invaders in the late 5th and early 6th centuries.", "Anne Boleyn was beheaded May 19, 1536."], "decomposition": ["When is King Arthur thought to have died?", "When was Anne Boleyn born?", "Is #2 before #1?"], "evidence": [[[["King Arthur-1"], "no_evidence"], [["Anne Boleyn-1"]], ["operation"]], [[["Battle of Camlann-1"]], [["Anne Boleyn-1"]], ["operation"]], [[["King Arthur-6"]], [["Anne Boleyn-6"]], ["operation"]]]}
{"qid": "69e6a75f195a68d1bf7e", "term": "New Mexico", "description": "U.S. state in the United States", "question": "Is the largest city in New Mexico also known as Yoot\u00f3?", "answer": false, "facts": ["Yoot\u00f3 stands for Bead Water Place.", "The area Santa Fe occupied was known by the Navajo people as Yoot\u00f3.", "The largest city in New Mexico is Albuquerque."], "decomposition": ["What is the largest city in New Mexico?", "Is #1 known as Yoot\u00f3?"], "evidence": [[[["Albuquerque, New Mexico-1"]], ["operation"]], [[["Albuquerque, New Mexico-1"]], ["operation"]], [["no_evidence"], [["Santa Fe, New Mexico-1"]]]]}
{"qid": "e9e78aa7b0c1ec3f9cf9", "term": "Comma", "description": "Punctuation mark", "question": "Is average number of peas in a pod enough commas for a billion?", "answer": true, "facts": ["The average number of peas in a pod is 6 or 7.", "A billion is a number that has three commas in it."], "decomposition": ["How many peas are in the average pod?", "How many commas are needed for a billion?", "Is #1 at least equal to #2?"], "evidence": [[[["Pea-1"], "no_evidence"], [["Billion-2"]], ["no_evidence", "operation"]], [[["Pea-1"], "no_evidence"], [["Billion-2"]], ["operation"]], [[["Pea-1"]], [["1,000,000,000-1"]], ["operation"]]]}
{"qid": "2295eaf3cdbecc17ca0a", "term": "Bucharest", "description": "Capital of Romania", "question": "Was historical Dracula from a town in Bucharest?", "answer": false, "facts": ["Vlad III Prince of Wallachia, also called Vlad the Impaler, is believed to be the historical inspiration for Dracula.", "Vlad III was born in Sighi\u0219oara, Romania, which is located in the historic region of Transylvania.", "Bucharest is located 276 km away from Transylvania."], "decomposition": ["What was Dracula's real name?", "Where was #1 born?", "What is the distance from #2 to Bucharest?"], "evidence": [[[["Count Dracula-1"]], [["Vlad the Impaler-8"], "no_evidence"], ["operation"]], [[["Vlad the Impaler-1"]], [["Vlad the Impaler-8"]], ["no_evidence"]], [[["Vlad the Impaler-1"]], [["Vlad the Impaler-8"]], [["Bucharest-1"], "no_evidence", "operation"]]]}
{"qid": "e740feb0c2f9aa799675", "term": "B", "description": "letter in the Latin alphabet", "question": "Would early Eastern Canadian Natives language have use of the letter B?", "answer": false, "facts": ["The Early Eastern Canadian Natives were a group of people that spoke the Inuktitut language.", "The Inuktitut language began as an oral language with no letters, only uvular sounds.", "The later Inuktitut language has no letters that resemble the Latin alphabet."], "decomposition": ["What language did Eastern Canadian Natives speak?", "What kind of language is #1?", "Does #2 involve the use of letters?"], "evidence": [[[["Inuktitut-1"]], [["Inuktitut-30"]], [["Syllabary-1"]]], [[["M\u00e9tis-1"], "no_evidence"], ["no_evidence"], [["Indigenous peoples in Canada-59"], "no_evidence", "operation"]], [[["Inuktitut-1"]], [["Inuktitut-1"]], [["Inuktitut-1"], "operation"]]]}
{"qid": "2cc59f4d25398d251fd6", "term": "Olympia, Washington", "description": "State capital and city in Washington, United States", "question": "Is Olympia, Washington part of \"Ish river country\"?", "answer": true, "facts": ["Poet Robert Sund called the Puget Sound region \"Ish River country\".", "Olympia is in the Puget Sound region."], "decomposition": ["Where is Ish river country? ", "What cities are located in #1?", "Is Olympia included in the list in #2?"], "evidence": [[[["Puget Sound region-1", "Puget Sound region-2"]], [["Washington (state)-79"]], ["operation"]], [[["Puget Sound region-1", "Puget Sound region-2"]], [["Puget Sound region-1"], "no_evidence"], [["Washington (state)-1"], "operation"]], [[["Puget Sound region-2"]], [["Puget Sound-4"]], ["operation"]]]}
{"qid": "4d20bb8dc217f39ee929", "term": "New York Public Library", "description": "Public library system in New York City", "question": "Could you go to New York Public Library and the Six Flags Great Escape in the same day?", "answer": true, "facts": ["Six Flags Great Escape is located in Lake George, NY.", "New York Public Library is located in New York City.", "Lake George is 3.5 driving hours from New York City."], "decomposition": ["Where is Six Flags Great Escape located?", "Where is The New York Public Library located?", "How long does it take to drive from #1 to #2?", "Is #3 less than 24 hours?"], "evidence": [[[["The Great Escape and Hurricane Harbor-1"]], [["New York Public Library-1"]], ["no_evidence"], ["no_evidence"]], [[["The Great Escape and Hurricane Harbor-1"]], [["New York Public Library Main Branch-1"]], ["no_evidence"], ["operation"]], [[["The Great Escape and Hurricane Harbor-1"]], [["New York Public Library-1"]], ["no_evidence", "operation"], ["no_evidence", "operation"]]]}
{"qid": "73520a07f183b7111236", "term": "Karaoke", "description": "form of entertainment involving singing to recorded music", "question": "Were karaoke and the turtle power tiller patented in the same country?", "answer": true, "facts": ["Roberto L. del Rosario holds the patent for the karaoke system", "del Rosario is Filipino", "Magdalena Smith Villaruz patented the turtle power tiller", "Villaruz is Filipino "], "decomposition": ["Who is the patent holder of the karaoke system?", "Which country is #1 from?", "Who patented the turtle power tiller?", "Which country is #3 from?", "Is #2 the same as #4?"], "evidence": [[[["Karaoke-8"]], [["Roberto del Rosario-1"]], [["Magdalena Villaruz-2"]], [["Magdalena Villaruz-1"]], ["operation"]], [[["Karaoke-5"], "no_evidence"], [["Daisuke Inoue-3"]], [["Magdalena Villaruz-1"]], [["Magdalena Villaruz-1"]], ["operation"]], [[["Roberto del Rosario-2"]], [["Philippines-1", "Roberto del Rosario-1"]], [["Magdalena Villaruz-1"]], [["Magdalena Villaruz-1"]], ["operation"]]]}
{"qid": "443f5ef5e6d353f28eda", "term": "Lord Voldemort", "description": "Fictional character of Harry Potter series", "question": "Would Lord Voldemort hypothetically be an effective fighter after Final Fantasy silence is cast?", "answer": false, "facts": ["Lord Voldemort is a powerful wizard from the Harry Potter Series.", "Lord Voldemort casts magical curses and charms on his enemies.", "Silence spell in Final Fantasy mutes the enemies spells.", "Mute makes it impossible for characters to cast any spells."], "decomposition": ["What does Lord Voldemort use in combat against enemies?", "What would Lord Voldemort have to do in order to cast #1?", "Which ability does the silence spell in Final Fantasy affect?", "Can all of #2 still be done when #3 is gone?"], "evidence": [[[["Lord Voldemort-15"], "no_evidence"], [["Incantation-1"], "no_evidence"], [["Speech-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Lord Voldemort-28"], "no_evidence"], [["Lord Voldemort-29"], "no_evidence"], ["no_evidence"], ["operation"]], [[["Lord Voldemort-2", "Lord Voldemort-30"]], ["no_evidence"], ["no_evidence"], ["operation"]]]}
{"qid": "51cfdfc9c52aeed3a1cc", "term": "Mount Sharp", "description": "mountain on Mars", "question": "Do bald eagles nest on Mount Sharp?", "answer": false, "facts": ["Bald eagles are birds found on earth", "Mount Sharp is a mountain on Mars", "To date, no life forms have been detected on Mars"], "decomposition": ["Where is Mount Sharp located?", "Has any form of life ever been discovered on #1?"], "evidence": [[[["Mount Sharp-1"]], [["Mars-4"]]], [[["Mount Sharp-1"]], [["Planetary habitability-64"]]], [[["Mount Sharp-1"]], [["Life on Mars-1"]]]]}
{"qid": "81af1391cbdbf67be3f7", "term": "Parachuting", "description": "action sport of exiting an aircraft and returning to Earth using a parachute", "question": "Is coal needed to practice parachuting?", "answer": true, "facts": ["Parachuting requires a parachute.", "Parachutes are made from nylon.", "Nylon is made from coal. "], "decomposition": ["What is one of the most important items that you need to go parachuting?", "What is #1 made out of?", "Is #2 originally made from coal?"], "evidence": [[[["Parachute-1"]], [["Nylon riots-3"]], [["Nylon-21"]]], [[["Parachute-1"]], [["Gerard B\u00e9rchet-2"]], [["Nylon-16"]]], [[["Parachute-1"]], [["Parachute-1"]], [["Nylon-16"], "operation"]]]}
{"qid": "21dd2c3906362e8860d3", "term": "Macbeth", "description": "play by William Shakespeare", "question": "Would costumes with robes and pointy hats be helpful for Macbeth?", "answer": true, "facts": ["Macbeth features scenes with three witches throughout the play. ", "Witches are often displayed with pointy hats and long black robes."], "decomposition": ["What characters are in Macbeth?", "What characters wear pointy hats and robes?", "Would any of #1 wear #2?"], "evidence": [[[["Macbeth-2"], "no_evidence"], [["Cloak-10", "Pointed hat-5"]], ["operation"]], [[["Macbeth-5"]], ["no_evidence"], ["operation"]], [[["Macbeth-2"]], [["Witch hat-1"]], ["operation"]]]}
{"qid": "ef8cd9d65ecb85d74a19", "term": "Will Ferrell", "description": "American actor, comedian, producer, writer and businessman", "question": "Would it be difficult for Will Ferrell to win Empire Award for Best Newcomer?", "answer": true, "facts": ["The Empire Award for Best Newcomer was awarded for an actor in their debut role.", "Will Ferrell debuted in 1995."], "decomposition": ["When do actors get to win the Empire Award for Best Newcomer?", "When did Will Ferrell participate in #1?", "Is #2 a long time ago?"], "evidence": [[[["Empire Award for Best Newcomer-1"]], [["Will Ferrell-1"]], ["operation"]], [[["23rd Empire Awards-1", "Empire Award for Best Male Newcomer-1"]], [["Will Ferrell-1"]], ["operation"]], [[["Empire Award for Best Newcomer-1"]], [["On Our Own (1994 TV series)-2"], "no_evidence"], ["operation"]]]}
{"qid": "6c43fa359095fd0845f5", "term": "Camel", "description": "Genus of mammals", "question": "Is Bactrian Camel most impressive animal when it comes to number of humps?", "answer": false, "facts": ["The Bactrian Camel is a camel with two humps native to Central Asia.", "Three humped camels were discovered on the Arabian peninsula in 2019."], "decomposition": ["How many humps does the Bactrian Camel have?", "What is the most number of humps seen on a camel?", "Is #1 greater than #2?"], "evidence": [[[["Bactrian camel-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Camel-1"]], ["no_evidence"], ["operation"]], [[["Bactrian camel-1"]], [["Dromedary-1"], "no_evidence"], ["operation"]]]}
{"qid": "6265249e94a68463f6fe", "term": "DC Comics", "description": "U.S. comic book publisher", "question": "Did President William Howard Taft read DC Comics?", "answer": false, "facts": ["DC Comics were founded in 1934.", "President William Howard Taft died on March 8, 1930."], "decomposition": ["When was DC Comics founded?", "When did President William Howard Taft die?", "Is #1 before #2?"], "evidence": [[[["DC Comics-4"]], [["William Howard Taft-1"]], ["operation"]], [[["DC Comics-4"]], [["William Howard Taft-1"]], ["operation"]], [[["DC Comics-4"]], [["William Howard Taft-1"]], ["operation"]]]}
{"qid": "3e5437a7c20da69c6778", "term": "Edgar Allan Poe", "description": "19th-century American author, poet, editor and literary critic", "question": "Was proofreading Edgar Allan Poe works lucrative?", "answer": false, "facts": ["Proofreaders get paid a set rate based on the number of words in a document.", "Edgar Allan Poe wrote many short stories including the Oval Portrait which is two pages in length.", "Edgar Allan Poe's only complete novel: The Narrative of Arthur Gordon Pym of Nantucket was a mere 166 pages.", "A book like Jeyamohan's Venmurasu is 11,159 pages."], "decomposition": ["What is the typical length of each of Edgar Allan Poe's works?", "Is #1 relatively long?"], "evidence": [[[["Edgar Allan Poe-1"]], [["Artam\u00e8ne-1", "Short story-7"], "operation"]], [[["Edgar Allan Poe-1"]], ["operation"]], [[["Edgar Allan Poe-1"]], ["operation"]]]}
{"qid": "93f0f18ac8c96a44b849", "term": "Lil Jon", "description": "American rapper, record producer and DJ from Georgia", "question": "Was Lil Jon's top ranked Billboard song a collaboration with a member of The Lox?", "answer": false, "facts": ["Lil Jon's highest ranked billboard song was Yeah.", "Yeah was a collaboration between Lil Jon, Usher, and Ludacris.", "The Lox is a rap trio consisting of: Styles P, Sheek Louch, and Jadakiss."], "decomposition": ["What is Lil Jon's top ranked Billboard song?", "What artists contributed to #1?", "Who makes up the group The Lox?", "Is any element of #3 also an element of #2?"], "evidence": [[[["Yeah! (Usher song)-1"]], [["Yeah! (Usher song)-1"]], [["The Lox-1"]], [["The Lox-1", "Yeah! (Usher song)-7"]]], [[["Lil Jon-1", "Yeah! (Usher song)-2"]], [["Yeah! (Usher song)-10"]], [["The Lox-1"]], ["operation"]], [[["Lil Jon-1"]], [["Yeah! (Usher song)-1"]], [["The Lox-1"]], ["operation"]]]}
{"qid": "236c7a57f3788a60e47f", "term": "Gandalf", "description": "Fictional character created by J. R. R. Tolkien", "question": "Was Gandalf present at the death of Eomer?", "answer": false, "facts": ["Eomer died in a skirmish with orcs outside Rohan at the beginning of Two Towers.", "Gandalf had been killed by the Balrog at the end of Fellowship of the Ring.", "Gandalf returns with improved powers later on in Two Towers."], "decomposition": ["In which LOTR installment was Gandalf first killed?", "At what point in the LOTR franchise did Eomer die?", "When did Gandalf first reappear after #1?", "Did #2 take place outside of the period between #1 and #3?"], "evidence": [[[["The Lord of the Rings: The Fellowship of the Ring-8"]], [["The Lord of the Rings: The Return of the King-10"], "no_evidence"], [["The Lord of the Rings: The Two Towers-6"]], ["no_evidence", "operation"]], [[["The Lord of the Rings: The Fellowship of the Ring-8"]], [["The Lord of the Rings: The Return of the King-10"]], [["The Lord of the Rings: The Two Towers-2"]], ["operation"]], [[["Gandalf-27"], "no_evidence"], [["\u00c9omer-6"], "no_evidence"], [["Gandalf-28"]], [["Gandalf-31"], "no_evidence", "operation"]]]}
{"qid": "c862ea1f376d312249b8", "term": "Darth Vader", "description": "fictional character in the Star Wars franchise", "question": "Does Darth Vader's character resemble Severus Snape?", "answer": false, "facts": ["Darth Vader is portrayed as a man who always appears in black full-body armor and a mask.", "Severus Snape is portrayed as a white man with long, greasy black hair who often wears a cloak. "], "decomposition": ["What type of clothing does Darth Vader wear?", "What type of clothing does Severus Snape wear?", "Are there any significant similarities between #1 and #2?"], "evidence": [[[["Darth Vader-16"]], [["Severus Snape-35"]], ["operation"]], [[["Darth Vader-15", "Darth Vader-33"]], [["Severus Snape-35"]], ["operation"]], [[["Darth Vader-15"]], [["Severus Snape-35"]], ["operation"]]]}
{"qid": "9332b9062a1b5c8109b0", "term": "Christopher Columbus", "description": "Italian explorer, navigator, and colonizer", "question": "Did Christopher Columbus condone multiple deadly sins?", "answer": true, "facts": ["The seven deadly sins are:  pride, greed, wrath, envy, lust, gluttony, and sloth.", "Under Columbus, every native of fourteen years of age or upward was to pay a large hawk's bell of gold dust or cotton and those who could not pay were punished.", " in just two years under Columbus's governorship, over 125,000 of the 250,000\u2013300,000 natives in Haiti were dead."], "decomposition": ["What are the deadly sins?", "What were Christopher Columbus's actions in the New World?", "Did #2 include more than one of #1?"], "evidence": [[[["Seven deadly sins-1"]], [["Christopher Columbus-56", "Christopher Columbus-68"]], ["operation"]], [[["Seven deadly sins-1"]], [["Christopher Columbus-93"], "no_evidence"], ["no_evidence", "operation"]], [[["Seven deadly sins-1"]], [["Christopher Columbus-43", "Christopher Columbus-98"]], ["operation"]]]}
{"qid": "3a373a74e76c72176e39", "term": "B\u00f6rek", "description": "Stuffed phyllo pastry", "question": "Would \u015eerafeddin Sabuncuo\u011flu have eaten B\u00f6rek?", "answer": true, "facts": ["B\u00f6rek originated in Ottoman cuisine", "\u015eerafeddin Sabuncuo\u011flu was an Ottoman scientist"], "decomposition": ["Where did Borek originate from?", "Was Serafeddin Sabuncuoglu from #1?"], "evidence": [[[["B\u00f6rek-1"]], [["Ottoman Empire-1", "Sabuncuo\u011flu \u015eerafeddin-1"], "operation"]], [[["B\u00f6rek-3"]], [["Sabuncuo\u011flu \u015eerafeddin-2"]]], [[["B\u00f6rek-1"]], [["Amasya-1", "Sabuncuo\u011flu \u015eerafeddin-2"]]]]}
{"qid": "18dbd6d87964d2b0a443", "term": "New Testament", "description": "Second division of the Christian biblical canon", "question": "Was Daniel thrown into the lion's den in the New Testament?", "answer": false, "facts": ["The Book of Daniel is a book in the Old Testament of the Bible.", "The Bible is divided into the Old Testament and the New Testament.", "The New Testament focuses on four Gospels regarding the life of Jesus."], "decomposition": ["Which book of the Bible has the story of Daniel in the lions' den?", "Is #1 in the New Testament of the Bible?"], "evidence": [[[["Daniel in the lions' den-1"]], ["operation"]], [[["Book of Daniel-13"]], [["Old Testament-16"], "operation"]], [[["Daniel in the lions' den-1"]], [["Book of Daniel-2"]]]]}
{"qid": "82e32a0627566be76a90", "term": "Friday", "description": "day of the week", "question": "Did goddess Friday is named after despise felines?", "answer": false, "facts": ["Felines are a species of animals that include lions, tigers, and domestic cats.", "Friday is named after the Norse goddess Freya. ", "Freya is often depicted in art with cats.", "Freya had two cats that pulled her magical chariot."], "decomposition": ["Which goddess is Friday named after?", "Which animals pulled #1's chariots?", "Are felines excluded from #2?"], "evidence": [[[["Friday-3"]], [["Frigg-27"]], ["operation"]], [[["Friday-3"]], [["Venus (mythology)-1"]], [["Venus (mythology)-1"]]], [[["Friday-3"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "e2affa461f20218463a4", "term": "Romani people", "description": "Ethnic group living mostly in Europe and the Americas", "question": "Is the use of the word Gypsy by non-Romani people considered okay?", "answer": false, "facts": ["'Gypsy' is considered a slur in the Americas by Romani people.", "Lady Gaga has faced online criticism regarding her use of the word 'Gypsy' as the title and lyrics of a song."], "decomposition": ["What kind of word is Gypsy considered in the Americas by Romani people?", "Would using #1 types of words be considered okay?"], "evidence": [[[["Names of the Romani people-11"], "no_evidence"], [["Antiziganism-1"]]], [[["Names of the Romani people-11"]], ["operation"]], [[["Names of the Romani people-11"]], [["Pejorative-1"], "operation"]]]}
{"qid": "13f14adc86f66c7d620a", "term": "Reiki", "description": "Pseudoscientific healing technique", "question": "Would somebody leave reiki with bruises?", "answer": false, "facts": ["Bruises are caused by blunt trauma to the body.", "Reiki is performed without touching the recipient. "], "decomposition": ["What are the processes involved in Reiki?", "Does any of #1 involve physical contact with the body?"], "evidence": [[[["Reiki-1"]], [["Reiki-15"]]], [[["Reiki-1"]], [["Reiki-1"]]], [[["Reiki-1"]], ["operation"]]]}
{"qid": "593e66cbdec8e3a15852", "term": "Ancient Greek", "description": "Version of the Greek language used from roughly the 9th century BCE to the 6th century CE", "question": "Are seasons of Survivor surpassed by number of Ancient Greek letters?", "answer": false, "facts": ["The reality show Survivor has aired 40 seasons as of 2020.", "The Ancient Greek alphabet consisted of 24 letters."], "decomposition": ["How many seasons of Survivor have there been as of 2020?", "How many letters were in the Ancient Greek alphabet?", "Is #2 greater than #1?"], "evidence": [[[["Survivor (American TV series)-4"]], [["Greek alphabet-2"]], ["operation"]], [[["Survivor (American TV series)-4"]], [["Greek alphabet-2"]], ["operation"]], [[["Survivor: Winners at War-1"]], [["Greek alphabet-2"]], ["operation"]]]}
{"qid": "d8ba1dd2575be52d80be", "term": "Peach", "description": "species of fruit tree (for the fruit use Q13411121)", "question": "Are peaches best eaten when firm?", "answer": false, "facts": ["Peaches are sweeter and easier to digest when they are soft to the touch.", "People tend to let their peaches sit until they soften. "], "decomposition": ["When a peach is considered best to be eaten, what characteristics does it have?", "When a peach is firm, does it have most of the characteristics listed in #1?"], "evidence": [[[["Peach-38"], "no_evidence"], [["Peach-38"], "no_evidence"]], [[["Peach-38"]], [["Peach (fruit)-5"]]], [[["Peach (fruit)-5"], "no_evidence"], ["operation"]]]}
{"qid": "75cff4dab3152b768aa9", "term": "Cerebral palsy", "description": "A group of disorders affecting the development of movement and posture, often accompanied by disturbances of sensation, perception, cognition, and behavior. It results from damage to the fetal or infant brain.", "question": "Could a young Wizard of Oz Scarecrow have gotten Cerebral palsy?", "answer": false, "facts": ["Cerebral palsy is a disease that results from damage to a young person's brain.", "The Scarecrow in the Wizard of Oz did not have a brain and was on a quest to get one."], "decomposition": ["Which organ of the body can cerebral palsy be traced back to?", "Did the Scarecrow in Wizard of Oz initially have #1 ?"], "evidence": [[[["Cerebral palsy-5"]], [["Scarecrow (Oz)-3"], "operation"]], [[["Cerebral palsy-2"]], [["Scarecrow (Oz)-1"], "operation"]], [[["Cerebral palsy-2"]], [["The Wizard of Oz (1939 film)-6"]]]]}
{"qid": "0688bd3291c81ffcfea1", "term": "Radioactive waste", "description": "wastes that contain nuclear material", "question": "Does the United States Navy create radioactive waste?", "answer": true, "facts": ["Radioactive waste is created by nuclear material processing", "The United States Navy uses many nuclear submarines"], "decomposition": ["Radioactive waste is a byproduct of what process?", "Does the US Navy engage in any of the activities in #1?"], "evidence": [[[["Radioactive waste-1"]], [["Nuclear submarine-4"]]], [[["Radioactive waste-1"]], [["United States Navy Nuclear Propulsion-1"], "operation"]], [[["Radioactive waste-1"]], [["United States Navy-5"], "no_evidence", "operation"]]]}
{"qid": "d98cd1c63297e18c77d9", "term": "Underworld", "description": "The mythic Relm of the Dead, located far underground (aka, Hades; Underworld)", "question": "Does Hades have a loose grip on the Underworld?", "answer": false, "facts": ["Hades alone can allow passage out of the Underworld.", "Hades created a terribly difficult task for Orpheus to complete to bring Eurydice from the Underworld. ", "The subjects of Hades in the Underworld are under his complete control."], "decomposition": ["In whose power is it solely within to allow passage out of the underworld?", "Whose rule are the subjects in the Underworld under?", "Is #1 or #2 not Hades?"], "evidence": [[[["Hades-11"]], [["Hades-1"]], ["operation"]], [[["Hades-13"]], [["Hades-11"]], ["operation"]], [[["Hades-11"]], [["Hades-11"]], ["operation"]], [[["Hades-1"]], [["Hades-11"]], ["operation"]]]}
{"qid": "be1c91b7d7c455b614bc", "term": "Diamond", "description": "Allotrope of carbon often used as a gemstone and an abrasive", "question": "Can a diamond float on water?", "answer": false, "facts": ["Diamonds are formed by extreme heat and pressure being applied to carbon under the earth's crust.", "The density of a diamond is 3.51 g/cm\u00b3.", "The density of water is 997 kg/m\u00b3.", "A diamond is more dense than water.", "A diamond will sink in water."], "decomposition": ["What is the density of a diamond?", "What is the density of water?", "Is #1 less than #2?"], "evidence": [[["no_evidence"], [["Maximum density-3"]], ["operation"]], [[["Diamond-5"]], [["Water-7"]], ["no_evidence"]], [[["Diamond-5"]], [["Water-7"]], ["operation"]]]}
{"qid": "28cb9d93e3a0f58e6350", "term": "Operation Barbarossa", "description": "1941 German invasion of the Soviet Union during the Second World War", "question": "Did Operation Barbarossa or Barbarossa's last expedition succeed?", "answer": false, "facts": ["Operation Barbarossa was the Nazi advance on Russia during World War II.", "Operation Barbarossa was a failure that resulted in Nazi Germany being pushed back by a Soviet counter offensive.", "Operation Barbarossa was named after Holy Roman Emperor Frederick Barbarossa.", "On his final expedition, Frederick Barbarossa drowned while leading an army to help the Crusaders during the Third Crusade.", "The Crusaders failed to recapture Jerusalem during the Third Crusade without the support of Barbarossa and his troops."], "decomposition": ["What was the objective of Operation Barbarossa?", "What was the goal of the final expedition of Frederick Barbarossa?", "Did #1 and #2 succeed?"], "evidence": [[[["Operation Barbarossa-1"]], [["Frederick I, Holy Roman Emperor-44"]], [["Frederick I, Holy Roman Emperor-46", "Operation Barbarossa-4"]]], [[["Operation Barbarossa-1"]], [["Frederick I, Holy Roman Emperor-37"]], [["Frederick I, Holy Roman Emperor-46", "Operation Barbarossa-4"], "operation"]], [[["Operation Barbarossa-1"]], [["Frederick I, Holy Roman Emperor-36"]], [["Frederick I, Holy Roman Emperor-44", "Operation Barbarossa-4"]]]]}
{"qid": "f4ac300578dfab653d3f", "term": "Pompey", "description": "1st/2nd-century BC Roman general", "question": "Has type of political association Pompey had with Caesar influenced reality TV?", "answer": true, "facts": ["Pompey, Julius Caesar, and Marcus Licinius Crassus formed a political association called a triumvirate.", "A triumvirate spits rule between three powerful people that get to make decisions.", "Reality show The Challenge: Total Madness appoints three weekly winners to make decisions for the group, known as the Tribunal.", "Reality show American Idol has had three judges making decisions about which contestants advance."], "decomposition": ["Which political association did Pompey form with Julius Caesar and Marcus Licinius Crassus?", "How many people does #1 typically involve?", "How many judges are on reality show American Idol?", "Is #2 equal to #3?"], "evidence": [[[["First Triumvirate-1"]], [["Triumvirate-1"]], [["American Idol-10", "American Idol-9"]], ["operation"]], [[["Pompey-2"]], [["First Triumvirate-1"]], [["American Idol-3"]], ["operation"]], [[["Triumvirate-5"]], [["Triumvirate-3"]], [["American Idol-3"]], ["operation"]]]}
{"qid": "740b4c542a9c9512c3e3", "term": "Giraffe", "description": "Tall African ungulate", "question": "Is it foolish to stand on giraffe's head to see over Eiffel Tower?", "answer": true, "facts": ["The neck of a giraffe can be up to 7 feet in length.", "Including their necks, giraffes can be as tall as 20 feet.", "The Eiffel Tower is 1,063 feet tall."], "decomposition": ["How tall is a giraffe?", "How tall is the Eiffel Tower?", "Is #1 greater than #2?"], "evidence": [[[["Giraffe-16"]], [["Eiffel Tower-3"]], ["operation"]], [[["Giraffe-16"]], [["Eiffel Tower-3"]], ["operation"]], [[["Giraffe-16"]], [["Eiffel Tower-3"]], ["operation"]]]}
{"qid": "e684937aefb2df3eebcf", "term": "H", "description": "letter in the Latin alphabet", "question": "Is H's most common two letter pair partner a freebie in Wheel of Fortune bonus round?", "answer": true, "facts": ["H forms the most common two letter pair in the English language along with the letter T.", "The Wheel of Fortune bonus round gives the player six free letters: R, S, T, L, N, E."], "decomposition": ["What letter forms the most common two letter pair in English along with the letter H?", "What free letters does the Wheel of Fortune bonus round give players?", "Is #1 included in #2?"], "evidence": [[[["Th (digraph)-1"]], [["Wheel of Fortune (American game show)-13"]], ["operation"]], [[["Letter frequency-11"]], [["Wheel of Fortune (Australian game show)-33"]], ["operation"]], [[["Most common words in English-5"], "no_evidence"], [["Wheel of Fortune (Australian game show)-33"]], ["operation"]]]}
{"qid": "eb7c254ac7ae82656aee", "term": "Rhinoceros", "description": "family of mammals", "question": "Have rhinoceroses been killed to improve human sex lives?", "answer": true, "facts": ["Rhinoceros horns are used for folk treatment of sexual impotency.", "Rhinoceroses are killed to remove their horns."], "decomposition": ["Which part of the Rhinoceros do most poachers hunt and kill it for?", "What are some common traditional uses of #1?", "Is treatment of sexual impotency included in #2?"], "evidence": [[[["Rhinoceros-31"]], [["Rhinoceros-32"]], ["operation"]], [[["Rhinoceros-3"]], [["Rhinoceros-32", "Rhinoceros-34"]], ["operation"]], [[["Rhinoceros-3"]], [["Rhinoceros-32"]], [["Aphrodisiac-1"], "operation"]]]}
{"qid": "2cb0bc060c5fb708a43f", "term": "Leopard seal", "description": "Species of mammal", "question": "Is Sea World hazardous to leopard seal's health?", "answer": true, "facts": ["Leopard seals have only one natural predator, the killer whale.", "Sea World is an aquatic show that involves many water animals.", "Killer Whales, such as Tilikum, are headliners at Sea World."], "decomposition": ["What is the leopard seals's predator?", "Would one find a #1 at Sea World?"], "evidence": [[[["Leopard seal-1"]], [["Kamogawa Sea World-15"]]], [[["Leopard seal-1"]], [["Shamu-1"], "operation"]], [[["Killer whale-7", "Leopard seal-1"]], [["SeaWorld-1"], "operation"]]]}
{"qid": "0eb259222f89112e1486", "term": "Shiva", "description": "One of the principal deities of Hinduism.", "question": "Does Sam Harris worship Shiva?", "answer": false, "facts": ["Sam Harris is an atheist.", "Atheism is, in the broadest sense, an absence of belief in the existence of deities."], "decomposition": ["What is Sam Harris' religious affiliation?", "Does a #1 worship any gods?"], "evidence": [[[["Sam Harris-1"]], [["Atheism-1"]]], [[["Sam Harris-1"]], [["Atheism-1"]]], [[["Sam Harris-12"]], ["operation"]]]}
{"qid": "cdc5da16ca1bb2a4edf7", "term": "United States Air Force", "description": "Air and space warfare branch of the United States Armed Forces", "question": "Would United States Air Force consider Return of the Jedi's Han Solo bad hypothetical candidate?", "answer": true, "facts": ["Han Solo is an ace pilot ally in the Star Wars universe.", "The US Air Force requires candidates to be between 18 and 35 years old.", "Return of the Jedi's Han Solo is 36 years of age.", "The US Air Force requires a candidate to be an American citizen.", "Han Solo is from the planet Corellia in a galaxy far, far, away."], "decomposition": ["What requirements does the US Air Force demand of potential candidates?", "What are the characteristics of character Han Solo as featured in Return of the Jedi?", "Does #2 fail to satisfy all of #1?"], "evidence": [[[["United States Air Force-60"], "no_evidence"], [["Han Solo-12"]], ["no_evidence"]], [[["United States Air Force Basic Military Training-34"]], [["Han Solo-36"]], ["operation"]], [[["United States Air Force Fitness Assessment-1"], "no_evidence"], [["Han Solo-11", "Han Solo-12"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "1e8d7da6c0e0fea74a09", "term": "War", "description": "Intense violent conflict between states", "question": "Could casualties from deadliest war rival France's population?", "answer": false, "facts": ["The deadliest war in history was World War II.", "Over 56 million people died during World War II.", "The population of France as of 2019 is 66 million."], "decomposition": ["What is the population of France?", "What was the deadliest war?", "How many people died in #2?", "Is #3 greater than #1?"], "evidence": [[[["France-1"]], [["World War II-1"]], [["World War II-103"]], ["operation"]], [[["France-1"]], [["World War II casualties-1"]], [["World War II casualties-1"]], ["operation"]], [[["France-1"]], [["World War II-1"]], [["World War II-1"]], ["operation"]]]}
{"qid": "d0ad95f36e42f85cc94d", "term": "Linus Torvalds", "description": "Creator and lead developer of Linux kernel", "question": "Is Maruti Suzuki Baleno an efficient car for Linus Torvald's family?", "answer": true, "facts": ["Linus Torvald has a family consisting of five people including his wife and children.", "The Maruti Suzuki Baleno is and Indian car that can seat five people."], "decomposition": ["How many people can sit in a  Maruti Suzuki Baleno?", "How many people are in Linus Torvald's family?", "Is #1 at least equal or greater than #2?"], "evidence": [[[["Suzuki Baleno (2015)-4"]], [["Linus Torvalds-20"]], ["operation"]], [[["Suzuki Baleno (2015)-14"], "no_evidence"], [["Linus Torvalds-20"]], ["no_evidence", "operation"]], [["no_evidence"], [["Linus Torvalds-20"]], ["no_evidence", "operation"]]]}
{"qid": "131abc946e1ea9ebc87c", "term": "Parachuting", "description": "action sport of exiting an aircraft and returning to Earth using a parachute", "question": "Would Matt Damon be afraid of parachuting?", "answer": true, "facts": ["Parachuting involves jumping from high places or airplanes.", "Matt Damon is afraid of heights. "], "decomposition": ["What is Matt Damon afraid of?", "Does parachuting involve #1?"], "evidence": [[[["Matt Damon-1"], "no_evidence"], [["Parachuting-1"], "no_evidence", "operation"]], [["no_evidence"], ["no_evidence"]], [["no_evidence"], ["no_evidence"]]]}
{"qid": "6e47423b2fdc8bc3130c", "term": "Winter", "description": "one of the Earth's four temperate seasons, occurring between autumn and spring", "question": "Are there multiple American government holidays during winter?", "answer": true, "facts": ["Winter runs from about December 20 to about March 20.", "Government holidays include Christmas, New Year, King Day, and President's Day.", "Christmas is always December 25, New Year is always January 1, King Day is a Monday in the middle of January, and President's Day is a Monday in late February."], "decomposition": ["Through which period of the year does winter usually last in the US?", "How many government holidays fall within the span of #1?", "Is #2 considerably greater than one?"], "evidence": [[[["Winter-1"], "no_evidence"], [["Federal holidays in the United States-14", "Thanksgiving (United States)-1", "Veterans Day-10", "Washington's Birthday-1"], "no_evidence"], ["operation"]], [[["Northern Hemisphere-2"]], [["Christmas-28", "Federal holidays in the United States-6", "New Year's Day-12"]], ["operation"]], [[["Winter-9"]], [["Holiday-6"]], ["operation"]]]}
{"qid": "183a6e39a27a2432989c", "term": "Christopher Nolan", "description": "British\u2013American film director, screenwriter, and producer", "question": "Could Christopher Nolan borrow pants from Danny Devito?", "answer": false, "facts": ["Christopher Nolan is 6 feet tall.", "Danny Devito is 4'10\" tall.", "Pant sizes relate to height."], "decomposition": ["How tall is Christopher Nolan?", "What was Danny Devito's height?", "Does #1 match #2?"], "evidence": [[["no_evidence"], [["Danny DeVito-4"], "no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], [["Danny DeVito-4"], "no_evidence"], ["operation"]], [["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "ae7daa98394767229b6d", "term": "Narcissism", "description": "Personality trait of self love of a fake perfect self.", "question": "Is narcissism's origin a rare place to get modern words from?", "answer": false, "facts": ["Narcissism comes from the ancient Greek story of Narcissus, who fell in love with his own reflection.", "Aphrodisiac comes from stories about the ancient Greek goddess Aphrodite.", "Europe comes from Europa, an ancient Greek princess.", "The word stygian relates to the river of Hades in Greek mythology.", "Hypnosis comes from Hypnos, the Greek god of sleep."], "decomposition": ["From what culture does the word \"narcissism\" come? ", "What percent of English words come from #1?", "Is #2 small enough to be considered \"rare\"?"], "evidence": [[[["Narcissism-5"]], [["English words of Greek origin-34"]], ["operation"]], [[["Narcissism-1"]], [["English language-105", "English language-108", "English words of Greek origin-1"], "no_evidence"], ["operation"]], [[["Narcissism-5"]], [["English words of Greek origin-4"], "no_evidence"], ["operation"]]]}
{"qid": "91a3d81584c66d26d49a", "term": "Fear", "description": "Basic emotion induced by a perceived threat", "question": "Is an espresso likely to assuage fear?", "answer": false, "facts": ["Fear raises heart rate", "Caffeine raises heart rate", "Coffee may also increase symptoms such as jitteriness and nausea "], "decomposition": ["What does fear typically do to a person's heart rate?", "What does espresso typically do to a person's heart rate?", "Is #1 the opposite of #2?"], "evidence": [[[["Fear-4"]], [["Caffeine-32", "Espresso-2"]], ["operation"]], [[["Heart rate-15"]], [["Caffeine-3"]], ["operation"]], [[["Fear-20"]], [["Caffeine-44", "Espresso-2"]], ["operation"]]]}
{"qid": "a7e8f2cbec209b317b8f", "term": "Menstruation", "description": "Regular discharge of blood and tissue from the inner lining of the uterus through the vagina", "question": "Are there people who are men who experience menstruation?", "answer": true, "facts": ["Menstruation can occur in any human being who has a uterus and vagina. ", "People who are born with a vagina may transition socially and/or medically to being male. ", "Someone with a vagina who has transitioned to being male is a man. "], "decomposition": ["What body organs are involved in menstruation?", "Do some men possess #1? "], "evidence": [[[["Menstruation-9"]], [["Transgender pregnancy-2"], "operation"]], [[["Menstruation-1"]], [["Male menstruation-1"], "no_evidence", "operation"]], [[["Menstruation-1"]], [["Sex and gender distinction-1"], "operation"]]]}
{"qid": "ff2f4c5a037ca826fe2a", "term": "Downton Abbey", "description": "British historical drama television series", "question": "Would Downton Abbey finale viewership defeat every Kazakhstan citizen in tug of war?", "answer": false, "facts": ["Downton Abbey's finale had a total of 9.6 million viewers.", "Kazakhstan has 18.7 million citizens as of 2020."], "decomposition": ["How many people watched Downton Abbey finale?", "How many people are Kazakh citizens?", "Is #1 greater than #2?"], "evidence": [[["no_evidence"], [["Kazakhstan-2"]], ["no_evidence", "operation"]], [["no_evidence"], [["Kazakhstan-167"]], ["operation"]], [["no_evidence"], [["Demographics of Kazakhstan-2"]], ["operation"]]]}
{"qid": "1d0e6d453ffcf9094140", "term": "Honey bee", "description": "Eusocial flying insect of genus Apis, producing surplus honey", "question": "Can a honey bee sting a human more than once?", "answer": false, "facts": ["Human skin is tough, and the bee's stinger gets lodged in the skin.", "The stinger becomes separated from the bee which dies soon after."], "decomposition": ["What happens to a bee's stinger when it stings a human?", "Are bees able to survive if #1 happens?"], "evidence": [[[["Bee sting-6"], "no_evidence"], ["no_evidence", "operation"]], [[["Stinger-7"]], [["Stinger-7"]]], [[["Honey bee-61"]], ["operation"]]]}
{"qid": "d402074eec03cd7ea06e", "term": "Underworld", "description": "The mythic Relm of the Dead, located far underground (aka, Hades; Underworld)", "question": "Would Hades and Osiris hypothetically compete for real estate in the Underworld?", "answer": true, "facts": ["Hades was the Greek god of death and the Underworld.", "Osiris was the Egyptian god of the Underworld."], "decomposition": ["What was Hades the God of?", "What was Osiris the God of?", "Is there any overlap between #1 and #2?"], "evidence": [[[["Hades-1"]], [["Osiris-1"]], ["operation"]], [[["Hades-1"]], [["Osiris-1"]], ["operation"]], [[["Hades-1"]], [["Osiris-1"]], ["operation"]]]}
{"qid": "9e6de7de5577b59708ed", "term": "San Antonio", "description": "City in Texas, United States", "question": "Was San Antonio the site of a major battle in the 19th century?", "answer": true, "facts": ["The Alamo is located in San Antonio.", "The Alamo was the site of a major battle during the Texan Revolution against Mexico in 1836."], "decomposition": ["Where did the most notable battle during the Texas Revolution take place?", "Is #1 located in San Antonio in present day US?", "Did the Texas revolution happen during the 19th century?", "Are #2 and #3 positive?"], "evidence": [[[["Battle of the Alamo-1"]], [["Battle of the Alamo-1"]], [["19th century-1"]], ["operation"]], [[["Battle of the Alamo-1"]], [["Battle of the Alamo-1"]], [["19th century-1", "Battle of the Alamo-1"]], ["operation"]], [[["Battle of the Alamo-1"]], ["operation"], ["operation"], ["operation"]]]}
{"qid": "44875993b96eb08c70b4", "term": "Jennifer Lawrence", "description": "American actress", "question": "Is Jennifer Lawrence's middle name similar to the name of a Scorsese collaborator?", "answer": true, "facts": ["Jennifer Lawrence's middle name is Shrader.", "Paul Schrader is a screenwriter and director.", "Paul Schrader wrote the screenplay for Taxi Driver, Raging Bull, The Last Temptation of Christ, and Bringing Out the Dead.", "Martin Scorsese directed Taxi Driver, Raging Bull, The Last Temptation of Christ, and Bringing Out the Dead."], "decomposition": ["What is Jennifer Lawrence's middle name?", "Who has collaborated with Scorsese?", "Does #2 include someone with #1 in their name?"], "evidence": [[[["Jennifer Lawrence-1"]], [["Paul Schrader-1"]], ["operation"]], [[["Jennifer Lawrence-1"]], [["Paul Schrader-1"], "no_evidence"], ["operation"]], [[["Jennifer Lawrence-1"]], [["Paul Schrader-1"]], ["operation"]]]}
{"qid": "efffc81b286925c40b89", "term": "Benito Mussolini", "description": "Fascist leader of Italy", "question": "Would Benito Mussolini hypothetically play well in the NBA?", "answer": false, "facts": ["Height is an important factor in playing basketball at a high level.", "The average NBA player is 6 feet 7 inches tall.", "Benito Mussolini was 5 feet 6.5 inches tall."], "decomposition": ["What is the height of Benito Mussolini?", "On average, what is the height of an NBA player?", "Is #1 comparable to #2?"], "evidence": [[["no_evidence"], [["Basketball-85"]], ["operation"]], [["no_evidence"], [["Basketball-85"]], ["no_evidence"]], [[["Benito Mussolini-1"], "no_evidence"], [["Basketball-85"]], ["operation"]]]}
{"qid": "53115231af1cbf1ad33a", "term": "Sudoku", "description": "Logic-based number-placement puzzle", "question": "Could an infant solve a sudoku puzzle?", "answer": false, "facts": ["Solving a sudoku puzzle requires the use of logic and a basic understanding of numbers.", "Infants are too young to understand the numerical system involved in sudoku."], "decomposition": ["What is the skill set of an infant?", "What skills are required for sudoku?", "Is #2 included in #1?"], "evidence": [[[["Infant-2"], "no_evidence"], [["Sudoku-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Sudoku-11"]], [["Logic puzzle-1"]], [["Sudoku-1"]]], [[["Infant cognitive development-12"]], [["Sudoku code-6"]], [["Infant cognitive development-12", "Sudoku code-6"], "operation"]]]}
{"qid": "a905e30e6cfc76377348", "term": "Bitcoin", "description": "decentralized cryptocurrency", "question": "Could a single bitcoin ever cover cost of a Volkswagen Jetta?", "answer": true, "facts": ["The all time high price of bitcoin was $19,783 in 2017.", "The suggested retail price of a 2020 Volkswagen Jetta is $18,895."], "decomposition": ["What is the highest price for a bitcoin?", "What is the cheapest price of a Jetta?", "Is #1 greater than #2?"], "evidence": [[[["Bitcoin-22"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Bitcoin-22"]], ["no_evidence"], ["operation"]], [[["Economics of bitcoin-16"]], [["Volkswagen Jetta-1"], "no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "e1463ddc36ea8cfc9074", "term": "Scientific Revolution", "description": "Beginnings of modern science that occured in Europe towards the end of the Renaissance", "question": "Did the iPhone usher in the scientific revolution?", "answer": false, "facts": ["The scientific revolution took place in the 16th and 17th centuries.", "The iPhone came out in the 21st century."], "decomposition": ["When did the Scientific Revolution begin?", "When did the iPhone come out?", "Did #2 occur before #1?"], "evidence": [[[["Scientific Revolution-1"]], [["IPhone-1"]], ["operation"]], [[["Scientific Revolution-4"]], [["IPhone-1"]], ["operation"]], [[["Scientific Revolution-1"]], [["IPhone-1"]], ["operation"]]]}
{"qid": "542b24d74ac340348171", "term": "Camel", "description": "Genus of mammals", "question": "Could a camel fit in a dog house?", "answer": false, "facts": ["Camels are approximately 5.5 to 6 feet tall.", "The largest dog ever was 3'8\" tall.", "Dog houses are built to fit dogs."], "decomposition": ["How large are camels?", "How large is a dog house?", "Is #1 less than or equal to #2?"], "evidence": [[[["Camel-4"]], ["no_evidence"], ["operation"]], [[["Camel-4"]], [["Dog-9"]], [["Camel-4", "Dog-9"], "operation"]], [[["Camel-4"]], [["Doghouse-1", "Great Dane-10"], "no_evidence"], ["operation"]]]}
{"qid": "fa160aa61805e9d27398", "term": "Great Lakes", "description": "System of interconnected, large lakes in North America", "question": "Are the Great Lakes part of an international border?", "answer": true, "facts": ["The lakes are bordered on the north by Canada.", "The lakes are bordered on the south by United States.", "Canada and United States are two different countries."], "decomposition": ["What borders the great lakes to the north?", "What borders the great lakes to the south?", "Are #1 and #2 different countries? "], "evidence": [[[["Great Lakes-1", "Great Lakes-19"]], [["Great Lakes-5"]], ["operation"]], [[["Great Lakes-5"]], [["Great Lakes-5"]], ["no_evidence"]], [[["Great Lakes-1"]], [["Great Lakes-1"]], ["operation"]]]}
{"qid": "948bbb81c0395227d3c6", "term": "Metropolitan Museum of Art", "description": "Art museum in New York City, New York", "question": "Could someone in Tokyo take a taxi to the The Metropolitan Museum of Art?", "answer": false, "facts": ["Tokyo is located in Japan.", "Japan and the United States are separated by the Pacific Ocean.", "A taxi is not capable of travelling over water."], "decomposition": ["Where is Tokyo?", "Where is the Metropolitan Museum of Art?", "What separates #1 and #2?", "Can a taxi drive on #3?"], "evidence": [[[["Tokyo-1"]], [["Metropolitan Museum of Art-1"]], [["Pacific Ocean-1"]], [["Taxicab-44", "Water taxi-1"]]], [[["Tokyo City-5"]], [["Metropolitan Museum of Art-3"]], [["Ocean-3"], "operation"], [["Ocean-3"]]], [[["Tokyo-1"]], [["Metropolitan Museum of Art-58"]], [["Pacific Ocean-1"]], [["Taxicab-1"], "no_evidence", "operation"]]]}
{"qid": "6a698f75fc0cd0f9799b", "term": "Uranium", "description": "Chemical element with atomic number 92", "question": "Is eating a Dicopomorpha echmepterygis size Uranium pellet fatal?", "answer": false, "facts": ["Dicopomorpha echmepterygis is a wingless insect that is .13mm large.", "Uranium is a radioactive element that is dangerous if ingested in large doses.", "25mg of Uranium would cause kidney damage, while 50mg would cause complete kidney failure in humans."], "decomposition": ["How much does a Dicopomorpha echmepterygis weigh?", "How much ingested Uranium is fatal for a human?", "Is #1 greater than #2?"], "evidence": [[[["Dicopomorpha echmepterygis-1", "Micrometre-1"], "no_evidence"], [["Iron tris(dimethyldithiocarbamate)-7"], "no_evidence"], ["operation"]], [[["Dicopomorpha echmepterygis-1"], "no_evidence"], [["Uranium-40"], "no_evidence"], ["no_evidence", "operation"]], [[["Dicopomorpha echmepterygis-1"], "no_evidence"], [["Self-harm-12"], "no_evidence"], ["operation"]]]}
{"qid": "8716b85472632d6e200e", "term": "Disneyland Paris", "description": "Theme park resort in France owned by The Walt Disney Company", "question": "Is Disneyland Paris the largest Disney resort?", "answer": false, "facts": ["Disneyland Paris contains two parks, several hotels, and a shopping district.", "By comparison, Walt Disney World in Florida contains four parks, two waterparks, a shopping district, and many hotels.", "Disney World is bigger than Disneyland Paris Resort and Disneyland California Resort combined."], "decomposition": ["How big is Disneyland Paris in square miles?", "How big is Walt Disney World in square miles?", "Is #1 larger than #2?"], "evidence": [[[["Disneyland Paris-40"]], [["Walt Disney World-1"]], ["operation"]], [[["Disneyland Paris-6"]], [["Walt Disney World-1"]], ["operation"]], [[["Disneyland Paris-40"]], [["Walt Disney World-1"]], ["operation"]]]}
{"qid": "8c3ca12decfff256eddb", "term": "Lord Voldemort", "description": "Fictional character of Harry Potter series", "question": "Is Lord Voldemort associated with a staff member of Durmstrang?", "answer": true, "facts": ["Igor Karkaroff is the headmaster of Durmstrang school.", "Karkaroff is a former Death Eater.", "The Death Eaters were Voldemort's minions."], "decomposition": ["Who is the headmaster of Durmstrang school?", "What did #1 part of in the past?", "Is #2 related to Lord Voldemort?"], "evidence": [[[["Places in Harry Potter-31"], "no_evidence"], [["Places in Harry Potter-32"]], ["no_evidence"]], [[["Death Eater-30"]], [["Death Eater-31"]], [["Death Eater-1"]]], [[["Places in Harry Potter-31"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "45605f9dbc0cf85f668f", "term": "Atlantic salmon", "description": "species of fish", "question": "Would Atlantic Salmon be within David Duchovny's dietary guidelines?", "answer": true, "facts": ["David Duchovny is a pescatarian. ", "Pescatarians do not eat chicken, pork, or beef, but will eat fish."], "decomposition": ["What kind of diet does David Duchovny follow?", "What type of food is Atlantic Salmon?", "Do people who follow #1 diets eat #2?"], "evidence": [[[["David Duchovny-12"]], [["Atlantic salmon-1"]], [["Pescetarianism-1"]]], [[["David Duchovny-12"]], [["Atlantic salmon-1", "Seafood-1"]], [["Pescetarianism-1"]]], [[["David Duchovny-3"], "no_evidence"], [["Atlantic salmon-1"]], ["operation"]]]}
{"qid": "c234a28480510591980d", "term": "Justin Timberlake", "description": "American singer, record producer, and actor", "question": "Has Justin Timberlake ever written a song about Britney Spears?", "answer": true, "facts": ["Justin Timberlake and Britney Spears dated in 1999.", "In 2002, Justin Timberlake released a music video for his breakup song 'Cry Me A River' and featured an actress who resembled his then ex Britney Spears."], "decomposition": ["Who did Justin Timberlake date in 1999?", "Who was the song 'Cry Me A River' by Justin timberlake about?", "Is #1 and #2 the same?"], "evidence": [[[["Justin Timberlake-32"]], [["Cry Me a River (Justin Timberlake song)-1"]], ["operation"]], [[["Justin Timberlake-32"]], [["Cry Me a River (Justin Timberlake song)-1"]], ["operation"]], [[["Justin Timberlake-32"]], [["Cry Me a River (Justin Timberlake song)-1"]], ["operation"]]]}
{"qid": "d9987847af1ab751c75a", "term": "White blood cell", "description": "type of cells of the immunological system", "question": "Will someone die without white blood cells?", "answer": true, "facts": ["White blood cells protect people against disease.", "Disease kills people."], "decomposition": ["What function do white blood cells serve in the body?", "Can a human live without #1?"], "evidence": [[[["White blood cell-1"]], [["White blood cell-15"], "no_evidence", "operation"]], [[["Blood cell-7"]], [["Blood cell-9"]]], [[["Innate immune system-11"]], ["operation"]]]}
{"qid": "ac37cfbe97efb67fde55", "term": "Silverfish", "description": "species of insect", "question": "Could a silverfish reach the top of the Empire State Building?", "answer": false, "facts": ["Silverfish cannot fly.", "Animals that cannot fly can only access objects at or near ground level without mechanical assistance.", "The top of the Empire State Building is \t1,454 ft high."], "decomposition": ["How high is the Empire State Building?", "What class of animals do silverfish belong to?", "Can #2 typically get to heights of #1 without assistance?"], "evidence": [[[["Empire State Building-1"]], [["Silverfish-1"]], [["Silverfish-1"]]], [[["Empire State Building-1"]], [["Silverfish-1"]], ["operation"]], [[["Empire State Building-1"]], [["Silverfish-1"]], ["operation"]]]}
{"qid": "811f06c3d045430a5359", "term": "Black", "description": "The darkest shade, resulting from the absence or complete absorption of light. Like white and grey, it has no hue", "question": "Is Anakin Skywalker from Star Wars associated with the color black?", "answer": true, "facts": ["As a Jedi during the Clone Wars, Anakin Skywalker often wore black robes.", "After he was burned and transformed into the cyborg Darth Vader, he received a distinctive and famous all-black outfit including a black mask."], "decomposition": ["What is the color of most outfits worn by Star Wars' Anakin Skywalker?", "Is #1 the same as black?"], "evidence": [[[["Darth Vader-1", "Darth Vader-15"]], ["operation"]], [[["Darth Vader-15"]], ["operation"]], [[["Darth Vader-1", "Darth Vader-15"]], ["operation"]]]}
{"qid": "91da868cfe707bfa9d4e", "term": "South Pole", "description": "Southern point where the Earth's axis of rotation intersects its surface", "question": "Do children send their Christmas letters to the South Pole?", "answer": false, "facts": ["Children send Christmas letters to Santa Claus.", "Santa Claus is fabled to live in the North Pole."], "decomposition": ["Who do children send their Christmas letters to?", "Does #1 supposedly live in the South Pole?"], "evidence": [[[["North Pole-61", "Santa's workshop-9"]], ["operation"]], [[["Santa Claus-55"]], [["North Pole-61"], "operation"]], [[["Santa Claus-55"]], [["Santa Claus-3"]]]]}
{"qid": "c77b8685911cb05e618b", "term": "Jack Black", "description": "American actor, comedian, musician, music producer and youtuber.", "question": "Is Jack Black's height enough to satisfy Coronavirus distancing?", "answer": false, "facts": ["Jack Black is 5'6\" tall.", "The CDC recommends people stay 6 feet apart."], "decomposition": ["How tall is Jack Black?", "What is the minimum recommended length for social distancing?", "Is #1 at least #2?"], "evidence": [[["no_evidence"], [["Social distancing-9"]], ["operation"]], [["no_evidence"], [["Social distancing-9"]], ["no_evidence", "operation"]], [[["Jack Black-1"], "no_evidence"], [["Social distancing-9"]], ["no_evidence", "operation"]]]}
{"qid": "b1e061a88d467fdb632e", "term": "2009", "description": "Year", "question": "Could $1 for each 2009 eclipse buy a copy of TIME magazine in 2020?", "answer": true, "facts": ["The 2020 Newsstand price of TIME magazine is $5.99.", "There were six eclipses in 2009 including 2 solar and 4 lunar eclipses."], "decomposition": ["What was the price of a single issue of TIME magazine in 2020?", "How many solar eclipses were there in 2009?", "How many lunar eclipses were there in 2009?", "What is #2 plus #3?", "Is #4 greater than or equal to #1?"], "evidence": [[[["Time (magazine)-5"], "no_evidence"], [["July 2009 lunar eclipse-6"], "no_evidence"], [["July 2009 lunar eclipse-4"], "no_evidence"], ["operation"], ["operation"]], [[["Time (magazine)-5"], "no_evidence"], [["Solar eclipse of January 26, 1990-1", "Solar eclipse of July 22, 2009-1"]], [["August 2009 lunar eclipse-1"]], ["operation"], ["operation"]], [[["Time (magazine)-22", "Time (magazine)-5"], "no_evidence"], [["Solar eclipse-3"], "no_evidence"], [["Lunar eclipse-23"], "no_evidence"], ["no_evidence", "operation"], ["no_evidence", "operation"]]]}
{"qid": "898ff9314804144d6f90", "term": "Johann Sebastian Bach", "description": "German composer", "question": "Did Johann Sebastian Bach influence heavy metal?", "answer": true, "facts": ["Johann Sebastian Bach was a classical German composer born in 1685.", "Lead singer of heavy metal band Skid Row, Sebastian Bach, took his name from German composer Johann Sebastian Bach.", "Heavy Metal band Metallica released a live album with the San Francisco Symphony.", "Deep Purple, n English hard rock/heavy metal band has cited classical musicians as their inspiration.", "Deep Purple's keyboard and guitar solos on \"Highway Star,\" have been called Bach-like in harmonic progression and virtuosic arpeggio figuration."], "decomposition": ["Who is the lead singer of \"Skid Row\"?", "Who did #1 name himself after?", "Which classic musician's work have Deep Purple's solo on \"Highway Star\" been compared with?", "Are #2 and #3 Johann Sebastian Bach and both bands heavy metal?"], "evidence": [[[["Sebastian Bach-1"]], [["Johann Sebastian Bach-1"], "no_evidence"], [["Highway Star (song)-4"]], [["Deep Purple-1", "Skid Row (American band) discography-2"], "operation"]], [[["Skid Row (American band)-1"]], [["Johann Sebastian Bach-1"]], [["Highway Star (song)-3"]], ["operation"]], [[["Sebastian Bach-1"]], [["Johann Sebastian Bach-1"]], [["Highway Star (song)-3"]], [["Deep Purple-1", "Skid Row (American band)-1"], "operation"]]]}
{"qid": "d949f30354c842f5562a", "term": "Monarch butterfly", "description": "milkweed butterfly in the family Nymphalidae", "question": "Could a monarch butterfly rule a kingdom?", "answer": false, "facts": ["A monarch butterfly would be easily killed by a human due to its small size.", "A monarch butterfly does not have the intellectual capacity to rule over a kingdom of humans."], "decomposition": ["Does a monarch butterfly have the physical capacity to rule over humans?", "Does a monarch butterfly have the intellectual ability to rule over humans?", "Is #1 or #2 positive?"], "evidence": [[[["Monarch butterfly-1"]], [["Monarch butterfly-1"]], [["Monarch butterfly-1"]]], [[["Monarch butterfly-1"]], [["Butterfly-15"], "no_evidence"], ["operation"]], [[["Monarch butterfly-1"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "95b3654439ebaf17f4da", "term": "Orange County, California", "description": "County in California, United States", "question": "Did the founders of the biggest city in Orange County, California speak Italian?", "answer": false, "facts": ["Anaheim is the biggest city in Orange County, California", "Anaheim was founded by fifty German families", "People from Germany speak German"], "decomposition": ["What is the biggest city in Orange County, California?", "Who founded #1?", "Did #2's speak Italian? "], "evidence": [[[["Anaheim, California-1"]], [["Anaheim, California-5"]], [["Anaheim, California-5"]]], [[["Anaheim, California-1"], "no_evidence"], [["Anaheim, California-2"]], ["no_evidence", "operation"]], [[["Anaheim, California-1"]], [["Anaheim, California-5"]], [["German language-1", "Italian language-1"], "operation"]]]}
{"qid": "e263728bd940c5c71bdf", "term": "Hydropower", "description": "energy derived from falling or running water", "question": "Is chaff produced by hydropower?", "answer": true, "facts": ["Chaff is excess material from milled grain.", "Some mills use hydropower to mill grain."], "decomposition": ["Where does Chaff come from?", "Do some #1's use hydropower to do it's function?"], "evidence": [[[["Chaff-1"]], [["Winnowing (sedimentology)-1"]]], [[["Chaff-1"]], [["Hydropower-1"], "operation"]], [[["Chaff-5"]], [["Hydropower-1"], "operation"]]]}
{"qid": "8cc7153ec5a527748adc", "term": "Firewall (computing)", "description": "Software or hardware-based network security system", "question": "Can a firewall protect against a short circuit?", "answer": false, "facts": ["A firewall is a computer program that protects unwanted attacks from penetrating a computer.", "Firewalls are installed on computers and conduct routine background maintenance.", "A short circuit is an electrical failure resulting from wires unable to conduct currents.", "Short circuits, especially during updates can lead to the dreaded Windows Blue Screen of Death in which a computer is unable to restart."], "decomposition": ["What kind of threats does a firewall protect a computer system against?", "What are the possible causes and results of a short circuit as concerning computers?", "Is any of #2 included in #1?"], "evidence": [[[["Firewall (computing)-13"]], [["Short circuit-7", "Short circuit-9"]], ["operation"]], [[["Windows Firewall-2"]], [["Short circuit-7"]], [["Short circuit-7"], "operation"]], [[["Firewall (computing)-1"]], [["Short circuit-1", "Short circuit-10", "Short circuit-7"]], ["operation"]]]}
{"qid": "5179b1021cc1b2fe1aa6", "term": "Uranium", "description": "Chemical element with atomic number 92", "question": "Would Gordon Ramsey use uranium as a seasoning?", "answer": false, "facts": ["Gordon Ramsey is a chef known for producing high quality food ", "Uranium is a toxic and weakly radioactive metal"], "decomposition": ["What was Gordon Ramsay's major occupation?", "Is Uranium commonly used as seasoning by a #1?"], "evidence": [[[["Gordon Ramsay-1"]], [["Uranium-13"], "operation"]], [[["Gordon Ramsay-1"]], [["Depleted uranium-50", "Seasoning-2", "Uranium-3"]]], [[["Gordon Ramsay-1"]], [["Uranium-3"], "operation"]]]}
{"qid": "28ae8f739494f6b0d307", "term": "Godzilla", "description": "Giant monster or kaiju", "question": "Is Godzilla's image likely grounds for a lawsuit in 2050?", "answer": false, "facts": ["The copyright for Godzilla is owned by Toho Company Limited.", "The first Godzilla film was released by Toho in 1954.", "Works that are significantly old enter the public domain and can be used without copyright permission.", "Godzilla will enter the public domain in the year 2049."], "decomposition": ["When can a copyrighted item be used without permission?", "In what year will Godzilla as a creative piece of work attain #1 status?", "Is #2 after 2050?"], "evidence": [[[["Copyright term-2"]], ["operation"], ["operation"]], [[["Copyright-4"]], [["Godzilla-1", "Tomoyuki Tanaka-1"]], ["operation"]], [[["Public domain-16"]], [["Godzilla-1"], "no_evidence"], ["operation"]]]}
{"qid": "563394228ae6952dd267", "term": "Coca", "description": "group of plant varieties cultivated for coca production", "question": "Would someone with a nosebleed benefit from Coca?", "answer": true, "facts": ["Coca constricts blood vessels.", "As a result, it serves to stop bleeding. ", "Someone with a nosebleed would want the bleeding to stop."], "decomposition": ["What does Coca do to blood vessels?", "What happens to blood when #1 occurs?", "Would someone with a nose want #2 to occur?"], "evidence": [[[["Coca-30"]], [["Blood vessel-16"]], ["operation"]], [[["Coca-30"]], ["no_evidence"], ["no_evidence"]], [[["Coca-30"]], ["no_evidence"], ["operation"]]]}
{"qid": "c2bbc9f09c8ac750e8bd", "term": "Bodybuilding", "description": "use of progressive resistance exercise to control and develop musculature", "question": "Would a bodybuilder enjoy wearing a cast for several weeks?", "answer": false, "facts": ["Casts encase a limb and prevent it from moving.", "Movement of limbs under resistance promote muscle growth.", "An absence of limb movement will result in decreased muscle size.", "The goal of bodybuilding is to increase the size of your muscles.", "Individuals are not happy when they are prevented from pursuing their goals."], "decomposition": ["What does a bodybuilder need to do on a daily basis?", "What does a cast limit freedom of?", "Does the limit on #2 make #1 possible?"], "evidence": [[[["Bodybuilding-1"]], [["Orthopedic cast-1"]], [["Muscle atrophy-1", "Muscle atrophy-7"]]], [[["Bodybuilding-1"]], [["Orthopedic cast-1"]], ["no_evidence"]], [[["Bodybuilding-37"], "no_evidence"], [["Orthopedic cast-1"]], ["operation"]]]}
{"qid": "26813dc7504fd7355c8c", "term": "KFC", "description": "American fast food restaurant chain", "question": "Does Magnus Carlsen enjoy KFC?", "answer": false, "facts": ["Magnus Carlsen is a chess grandmaster from Norway", "There are no KFC locations in Norway"], "decomposition": ["What country is Magnus Carlsen from?", "In what countries does KFC have a location?", "Is #1 included in #2?"], "evidence": [[[["Magnus Carlsen-1"]], [["KFC-3"]], ["operation"]], [[["Magnus Carlsen-1"]], [["KFC-1"], "no_evidence"], ["no_evidence"]], [[["Magnus Carlsen-1"]], [["KFC-51"], "no_evidence"], ["operation"]]]}
{"qid": "ac61d110f57cd7855686", "term": "Goofy", "description": "Disney cartoon character", "question": "Can voice actors for Goofy and Bugs Bunny each get one stripe from American flag?", "answer": true, "facts": ["The American flag has 13 stripes on it.", "Since the role originated in 1932, six people have voiced the character of Goofy.", "Since 1940, seven people have voiced the character of Bugs Bunny."], "decomposition": ["How many stripes does the American flag have?", "How many people have been the voice of Goofy?", "How many people have been the voice of Bugs Bunny?", "What is #2 plus #3?", "Is #1 equal to or greater than #4?"], "evidence": [[[["Flag of the United States-1"]], [["Bill Farmer-1", "Hal Smith (actor)-16", "Pinto Colvig-1", "Stuart Buchanan-1", "Tony Pope-2"], "no_evidence"], [["Bugs Bunny-26", "Bugs Bunny-41"]], ["operation"], ["operation"]], [[["Flag of the United States-1"]], [["Goofy-43"]], [["Billy West-1", "Eric Bauza-1", "Greg Burson-2", "Jeff Bergman-1", "Joe Alaskey-2", "Mel Blanc-1", "Sam Vincent (voice actor)-1"]], ["operation"], ["operation"]], [[["Flag of the United States-1"]], [["Goofy-43"]], [["Bugs Bunny-41"], "no_evidence"], ["no_evidence", "operation"], ["no_evidence", "operation"]]]}
{"qid": "625080d6e74261c523f6", "term": "Bohai Sea", "description": "The innermost gulf of the Yellow Sea and Korea Bay on the coast of Northeastern and North China", "question": "Would Statue of Liberty be visible if submerged in Bohai Sea?", "answer": true, "facts": ["The Bohai Sea is 230 feet deep.", "The Statue of Liberty is 305 feet tall."], "decomposition": ["How deep is the Bohai Sea?", "How tall is the Statue of Liberty?", "Is #2 greater than #1?"], "evidence": [[["no_evidence"], [["Statue of Liberty-18"]], ["operation"]], [["no_evidence"], [["Statue of Liberty-18"]], ["no_evidence"]], [["no_evidence"], [["Statue of Liberty-18"]], ["no_evidence", "operation"]]]}
{"qid": "b76f30e808b1bfdbee2b", "term": "John Lennon", "description": "English singer and songwriter, founding member of the Beatles", "question": "Did Cynthia Powell celebrate a silver anniversary with John Lennon?", "answer": false, "facts": ["A silver anniversary takes place during the 25th year of marriage.", "Cynthia Powell married John Lennon in 1962.", "Cynthia Powell and John Lennon got divorced in 1968."], "decomposition": ["People have to be married for how many years for them to celebrate a silver anniversary?", "When did Cynthia Powell marry John Lennon?", "When Cynthia Powell divorce John Lennon?", "What is #3 minus #2?", "Is #4 greater than or equal to #1?"], "evidence": [[[["Silver jubilee-1"]], [["Cynthia Lennon-12"]], [["Cynthia Lennon-31"]], ["no_evidence"], ["operation"]], [[["Silver jubilee-1"]], [["Cynthia Lennon-12"]], [["Cynthia Lennon-31"]], ["operation"], ["operation"]], [[["Silver jubilee-1"]], [["Cynthia Lennon-12"]], [["John Lennon-41"]], ["operation"], ["operation"]]]}
{"qid": "ed28d8dc67d5ee85b85c", "term": "Hepatitis", "description": "inflammation of the liver tissue", "question": "Can you cure hepatitis with a tonsillectomy?", "answer": false, "facts": ["A tonsillectomy removes the tonsils, glands found in the back of the throat", "Hepatitis is a disease that targets the liver"], "decomposition": ["What organ does hepatitis affect? ", "What organs are removed during a tonsillectomy?", "Is #1 the same as #2?"], "evidence": [[[["Hepatitis-1"]], [["Tonsillectomy-1"]], ["operation"]], [[["Hepatitis-1"]], [["Tonsillectomy-1"]], ["operation"]], [[["Hepatitis-1"]], [["Tonsillectomy-1"]], ["operation"]]]}
{"qid": "5c03103b5a70117cbdf0", "term": "Elizabeth I of England", "description": "Queen regnant of England and Ireland from 17 November 1558 until 24 March 1603", "question": "Could Elizabeth I of England have seen the play Dido, Queen of Carthage ?", "answer": true, "facts": ["Elizabeth I of England lived from 1533 - 1603.", "Dido, Queen of Carthage is a short play written by the English playwright Christopher Marlowe.", " It was probably written between 1587 and 1593."], "decomposition": ["When was the play Dido, Queen of Carthage written?", "Was Elizabeth I of England alive during the period covered by #1?"], "evidence": [[[["Dido, Queen of Carthage (play)-1"]], [["Elizabeth I of England-1"]]], [[["Dido, Queen of Carthage (play)-1"]], [["Elizabeth I of England-1"]]], [[["Dido, Queen of Carthage (play)-1"]], [["Elizabeth I of England-1"]]]]}
{"qid": "ae4cedb73e82c7f8de75", "term": "Art dealer", "description": "person that buys and sells works of art", "question": "Would an art dealer prize a print of a Van Goh? ", "answer": false, "facts": ["Van Goh painted many valuable pieces of artwork in his lifetime.", "Prints of Van Goh's artwork are readily available at a low price."], "decomposition": ["What kind of art do art dealers typically look for?", "What is the cost of a typically Van Goh print?", "Is something priced as #2 considered #1?"], "evidence": [[[["Art dealer-2"]], [["Dutch art-15"]], ["operation"]], [[["Art dealer-1"], "no_evidence"], [["Art forgery-18"], "no_evidence"], ["operation"]], [[["Art dealer-2"], "no_evidence"], [["Vincent van Gogh-4"], "no_evidence"], ["operation"]]]}
{"qid": "69ccc55206ac47a0d312", "term": "Seinfeld", "description": "American sitcom", "question": "Could you watch a new Seinfeld episode every day for a year?", "answer": false, "facts": ["There are 365 days in a year.", "There are a total of 180 Seinfeld episodes."], "decomposition": ["How many days are there in a year?", "How many Seinfeld episodes are there?", "Is #2 greater than or equal to #1?"], "evidence": [[[["Seinfeld-31"]], [["Year-3"]], ["operation"]], [[["Seinfeld-1"]], [["Year-4"]], ["operation"]], [[["Year-3"]], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "fd6c86e0bccd5157cfd9", "term": "Jews", "description": "Ancient nation and ethnoreligious group from the Levant", "question": "Do Jews believe in any New Testament angels?", "answer": true, "facts": ["The New Testament is a book central to Christianity.", "The New Testament features a number of angels including Michael, and Gabriel.", "The Talmud is the central text of Rabbinic Judaism.", "The Talmud names four angels who would later be known as archangels, surrounding God's throne: Michael, Gabriel, Uriel, and Raphael."], "decomposition": ["What book is the central text of Rabbinic Judaism?", "Does #1 mention any angels?", "Are the angels mentioned in #2 also mentioned in the New testament?"], "evidence": [[[["Rabbinic Judaism-3"]], [["Angels in Judaism-1"]], [["Angels in Judaism-1"]]], [[["Rabbinic Judaism-3", "Talmud-1"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Hebrew Bible-1"]], [["Book of Daniel-2", "Michael (archangel)-2"]], [["Michael (archangel)-3"], "operation"]]]}
{"qid": "3f09ce8b018df4527e20", "term": "Sea turtle", "description": "superfamily of reptiles", "question": "Are sea turtles enjoying life during quarantine?", "answer": true, "facts": ["Sea turtles nest on beaches", "Quarantine due to COVID has resulted in far fewer people using beaches", "More sea turtles have been able to nest and reproduce on beaches during quarantine"], "decomposition": ["What elements comprise \"enjoying life\" for a sea turtle?", "Where do the elements in #1 occur?", "How prevalent were humans in the areas in #2 pre-Covid-19?", "In the areas in #2, are humans less prevalent now than in #3?"], "evidence": [[[["Sea turtle-11"], "no_evidence"], [["Sea turtle-45"]], [["Sea turtle-13"]], ["operation"]], [[["Sea turtle-14"], "no_evidence"], [["Sea turtle migration-6"], "no_evidence"], ["no_evidence"], [["Sea turtle-13"], "no_evidence", "operation"]], [[["Green sea turtle-30"]], [["Sea turtle-12"]], [["Tourism-47"], "no_evidence"], [["Sea turtle-13"], "operation"]]]}
{"qid": "97ffbaa790ff9df718ec", "term": "Atmosphere of Mars", "description": "atmosphere", "question": "Are all the elements plants need for photosynthesis present in atmosphere of Mars?", "answer": true, "facts": ["Plants need three elements for photosynthesis: Hydrogen, Oxygen, and Carbon.", "The atmosphere of Mars is composed of carbon dioxide, nitrogen, argon, and trace levels of water vapor, oxygen, carbon monoxide, hydrogen and other noble gases."], "decomposition": ["What are the elements needed by plants need for photosynthesis?", "Which elements are found in the atmosphere?", "Are #1 included in #2?"], "evidence": [[[["Photosynthesis-11"]], [["Atmosphere of Mars-11"]], ["operation"]], [[["Photosynthesis-72"], "no_evidence", "operation"], [["Atmosphere-14"], "operation"], ["no_evidence"]], [[["Photosynthesis-10"]], [["Atmosphere-14"]], ["operation"]]]}
{"qid": "ee95615e3dafa5e19020", "term": "Darth Vader", "description": "fictional character in the Star Wars franchise", "question": "Is watching  Star Wars necessary to know who Darth Vader is?", "answer": false, "facts": ["Star Wars is one of the most widely parodied film series to be produced.", "Star Wars merchandise, from tees to Halloween costumes, is widely available and is plentiful. "], "decomposition": ["Has Star Wars inspired many parody films?", "Are Star Wars merchandise depicting characters from the movie available?", "Considering #1 and #2, are there no depictions of characters outside the movie?"], "evidence": [[[["Robot Chicken: Star Wars-8"]], [["Lego Star Wars-1"]], [["Lego Star Wars-1", "Robot Chicken: Star Wars-8"]]], [[["Cultural impact of Star Wars-1", "Star Wars: The Vintage Collection-1"], "no_evidence"], [["Star Wars-1"], "no_evidence"], ["operation"]], [[["Lego Star Wars-9", "Spaceballs-2"]], [["Walker (Star Wars)-33"]], ["operation"]]]}
{"qid": "52c712384f56ec6347ad", "term": "Mail carrier", "description": "employee of the post office or postal service, who delivers mail to residences and businesses", "question": "Do mail carriers need multiple uniforms?", "answer": true, "facts": ["Mail carriers work throughout the year independent of the weather.", "Mail carriers must often leave their vehicle in various weather conditions."], "decomposition": ["What seasons do mail carriers work through?", "In order to make it through all of #1, does one need different clothing pieces?"], "evidence": [[[["United States Postal Service-145"], "no_evidence"], [["Clothing-2"]]], [[["United States Postal Service creed-1"], "no_evidence"], [["Winter clothing-2"], "operation"]], [[["Season-1"], "no_evidence"], [["Mail carrier-8"], "no_evidence", "operation"]]]}
{"qid": "139d12df0ad15cc0347c", "term": "Washington Monument", "description": "Obelisk in Washington, D.C.", "question": "Did Sojourner Truth use the elevator at the Washington Monument?", "answer": false, "facts": ["The Washington Monument was opened to the public in October 1888.", "Sojourner Truth died November 26, 1883. "], "decomposition": ["When did Sojourner Truth pass away?", "When was the Washington Monument opened to the public?", "Is #2 before #1?"], "evidence": [[[["Sojourner Truth-1"]], [["Washington Monument-26"]], [["Washington Monument-26"], "operation"]], [[["Sojourner Truth-1"]], [["Washington Monument-2"]], ["operation"]], [[["Sojourner Truth-1"]], [["Washington Monument-2"]], ["operation"]]]}
{"qid": "1b747c9c67380c83b6d5", "term": "Alexander Graham Bell", "description": "scientist and inventor known for his work on the telephone", "question": "Did the phone Alexander Graham Bell use have call waiting?", "answer": false, "facts": ["Call waiting was invented in the 1970's to allow phone users to suspend one call to accept another.", "Alexander Graham Bell's phone was used in 1876."], "decomposition": ["When was call waiting service introduced?", "When was Alexander Graham Bell's phone used?", "Is #1 before #2?"], "evidence": [[[["Call waiting-9"]], [["Alexander Graham Bell-29"]], ["operation"]], [[["Call waiting-9"]], [["Alexander Graham Bell-2"]], [["Alexander Graham Bell-2", "Call waiting-9"], "operation"]], [[["Call waiting-9"]], [["Alexander Graham Bell-2"]], ["operation"]]]}
{"qid": "7fa631340ce8c42aba53", "term": "1980 United States presidential election", "description": "49th quadrennial presidential election in the United States", "question": "Were there greater landslides than 1980 United States presidential election?", "answer": true, "facts": ["A landslide refers to a competitor beating their opponent by a wide margin.", "Ronald Reagan defeated Jimmy carter in the 1980 United States presidential election by around 8 million votes.", "Franklin D. Roosevelt won the 1936 United States presidential election over Alf Landon by more than 11 million votes.", "In 1804 Thomas Jefferson received 162 (92%) of the electoral votes while Charles Cotesworth Pinckney received only 14 (8%)."], "decomposition": ["By what votes margin did Ronald Reagan defeat Jimmy Carter in the 1980 US Presidential election?", "By how many votes was Franklin D. Roosevelt leading Alf Landon in the 1936 US Presidential election?", "How many more votes did Thomas Jefferson receive than Charles Cotesworth Pinckney in the 1804 United States presidential election?", "Are #2 and #3 greater individually than #1?"], "evidence": [[[["Ronald Reagan-50"]], [["Franklin D. Roosevelt-52"]], [["Thomas Jefferson-73"], "no_evidence"], ["operation"]], [[["1980 United States presidential election-50"]], [["1936 United States presidential election-4"]], [["1804 United States presidential election-3", "Thomas Jefferson-73"]], ["operation"]], [[["1980 United States presidential election-4"]], [["1936 United States presidential election-4"]], [["1804 United States presidential election-3"]], ["operation"]]]}
{"qid": "cee315334a0a8419283c", "term": "Rumi", "description": "13th-century Persian poet", "question": "Was Rumi's work serialized in a magazine?", "answer": false, "facts": ["Rumi was a poet who wrote poetry", "Magazines serialize long-form prose like novels"], "decomposition": ["When was the first magazine ever published?", "When was the poet Rumi active?", "Was #1 before #2?"], "evidence": [[[["Magazine-8"]], [["Rumi-1"]], ["operation"]], [[["The Gentleman's Magazine-1"]], [["Rumi-1"]], ["operation"]], [[["Magazine-8"]], [["Rumi-1"]], ["operation"]]]}
{"qid": "9d5af50292804754a5d2", "term": "Supreme Court of Canada", "description": "highest court of Canada", "question": "Is clerk of Supreme Court of Canada safe profession for someone with seismophobia?", "answer": true, "facts": ["Seismophobia is the extreme fear of earthquakes.", "The Supreme Court of Canada is located in Ottawa.", "The Ottawa-Gattineau region is located far from active tectonic plates."], "decomposition": ["What is seismophobia a fear of?", "Movement of what causes #1?", "Where is the Supreme Court of Canada located?", "Is #3 located near active #2's?"], "evidence": [[[["2019\u201320 Puerto Rico earthquakes-23"]], [["Earthquake-3"]], ["no_evidence"], [["Earthquake-25"], "operation"]], [[["Earthquake-1"], "no_evidence"], [["Earthquake-3"]], [["Supreme Court of Canada-19"]], [["Ottawa-16"], "operation"]], [[["2019\u201320 Puerto Rico earthquakes-23"], "no_evidence"], [["Seismology-5"]], [["Supreme Court of Canada-19"]], [["Ottawa-16"], "operation"]]]}
{"qid": "a4819e1c28b5e1eb4b09", "term": "Helium", "description": "Chemical element with atomic number 2", "question": "Does the density of helium cause voices to sound deeper?", "answer": false, "facts": ["Helium is less dense than air.", "Sound travels more quickly through helium than it does through air. ", "When sound travels more quickly, the tone of it raises and sounds higher."], "decomposition": ["What is the density of helium compared to air?", "As a result of #1, what is the speed in which air travel throughs helium compared to air", "When #2 happens, does the tone go deeper?"], "evidence": [[[["Lifting gas-1"]], [["Lifting gas-6"], "no_evidence"], [["Helium-4"], "no_evidence"]], [[["Helium-1"], "no_evidence"], [["Helium-77"]], ["operation"]], [[["Helium-64"]], [["Helium-27"]], [["Helium-77"], "operation"]]]}
{"qid": "6ef0bafcb42de140de17", "term": "Eagle", "description": "large carnivore bird", "question": "Can shooting bald eagle get a person more prison time than Michael Vick?", "answer": true, "facts": ["Michael Vick spent 21 months in prison for an illegal dog fighting ring.", "Shooting a bald eagle carries a penalty of up to two years in prison for a second conviction."], "decomposition": ["How long of a penalty is it for shooting a bald eagle?", "How many months did Michael Vick serve in prison?", "Is #1 longer than #2?"], "evidence": [[[["Bald and Golden Eagle Protection Act-18"]], [["Michael Vick-2"]], ["operation"]], [[["Bald and Golden Eagle Protection Act-4"]], [["Michael Vick-2"]], ["no_evidence", "operation"]], [[["Bald and Golden Eagle Protection Act-18"]], [["Michael Vick-2"]], ["operation"]]]}
{"qid": "79a254c885843d905da3", "term": "Jay-Z", "description": "American rapper, entrepreneur, record executive, songwriter, producer and investor from New York", "question": "Did Jay-Z ever collaborate with Louis Armstrong?", "answer": false, "facts": ["Jay-Z was born in 1969.", "Louis Armstrong died in 1971."], "decomposition": ["What year did Jay-Z make his first recording?", "When did Louis Armstrong die?", "Is #1 before #2?"], "evidence": [[[["Jay-Z-2"]], [["Louis Armstrong-87"]], ["operation"]], [[["Jay-Z albums discography-2"]], [["Louis Armstrong-1"]], ["no_evidence"]], [[["Jay-Z-11"]], [["Louis Armstrong-1"]], ["operation"]]]}
{"qid": "80b3ba19b90c340ea5cc", "term": "Surveillance", "description": "monitoring of behavior, activities, or other changing information", "question": "Is video surveillance of a room possible without an obvious camera or new item?", "answer": true, "facts": ["Surveillance cameras can be built into light socket covers that look no different from a normal one.", "Surveillance cameras can be installed in special light bulbs to document activity in a room."], "decomposition": ["What are the various types of surveillance cameras based on installation?", "Are some of installed so as to be #1 hidden from view?"], "evidence": [[[["Closed-circuit television-2", "Closed-circuit television-3", "Closed-circuit television-4"]], [["Hidden camera-2"]]], [[["Hidden camera-1"], "no_evidence"], ["operation"]], [[["Hidden camera-1"]], [["Hidden camera-2"]]]]}
{"qid": "502d4dae6f08e73a5569", "term": "Crucifixion", "description": "Method of capital punishment in which the victim is tied or nailed to a large wooden beam and left to hang until eventual death", "question": "Is Home Depot a one stop shop for crucifixion supplies?", "answer": true, "facts": ["A one stop shop is a store where multiple items are supplied.", "Crucifixion is a form of punishment in which a person is nailed to a wooden cross.", "Home Depot sells numerous supplies including: hammers, nails, and wood."], "decomposition": ["What is the definition of a one stop shop?", "What tools are necessary for Crucifixion?", "Is Home Depot a #1 for all of #2?"], "evidence": [[[["One stop shop-1"]], [["Crucifixion-1"]], ["operation"]], [[["One stop shop-1"]], [["Descriptions in antiquity of the execution cross-6"], "no_evidence"], [["The Home Depot-1"], "operation"]], [[["One stop shop-1"]], [["Crucifixion-1"]], [["The Home Depot-1"], "operation"]]]}
{"qid": "f1e48f5dc1662a84942b", "term": "Harvey Milk", "description": "American politician who became a martyr in the gay community", "question": "Did Harvey Milk ever run for governor?", "answer": false, "facts": ["In 1977 Harvey Milk was elected to the San Francisco Board of Supervisors.", "Less than a year later, he was assassinated before he could run for higher offices."], "decomposition": ["What were Harvey Milk's political campaigns?", "Does #1 include a gubernatorial campaign?"], "evidence": [[[["Harvey Milk-1"]], [["Harvey Milk-1"]]], [[["Harvey Milk-2", "Jim Foster (activist)-4"]], ["operation"]], [[["Harvey Milk-1"]], [["Governor-4"], "operation"]]]}
{"qid": "92087ad2756a238bad74", "term": "Fever", "description": "common medical sign characterized by elevated body temperature", "question": "Will a person survive a fever of NY's highest recorded temperature?", "answer": false, "facts": ["The highest recorded temperature in NY was 108 degrees Fahrenheit.", "A temperature of 104 degrees Fahrenheit is life threatening and requires immediate medical attention."], "decomposition": ["What was NY's highest recorded temperature?", "Above what temperature will a fever become life-threatening?", "Is #1 less than #2?"], "evidence": [[[["Climate of New York-7"]], [["Fever-1"]], ["operation"]], [[["Climate of New York-7"]], [["Human body temperature-35"]], ["operation"]], [[["New York City-62"]], [["Fever-1"]], ["operation"]]]}
{"qid": "16d8da02bc5e1975a1d9", "term": "Christmas carol", "description": "Song or hymn or carol on the theme of Christmas", "question": "When the shuttle Columbia 11 landed, was it the season for Christmas carols?", "answer": true, "facts": ["The Columbia 11 shuttle landed on December 10th 1990.", "Christmas is celebrated during the month of December every year."], "decomposition": ["What month did the space shuttle Columbia 11 land?", "In what month are Christmas carols typically sung?", "Are #1 and #2 the same answer?"], "evidence": [[[["STS-40-1"], "no_evidence"], [["Christmas-1"]], ["operation"]], [[["STS-40-7"]], [["Christmas and holiday season-1", "Christmas carol-1"]], ["operation"]], [[["Space Shuttle Columbia-1"], "no_evidence"], [["Christmas and holiday season-1", "Christmas carol-1"]], ["no_evidence", "operation"]]]}
{"qid": "704003c5c9786ae43746", "term": "Nicole Kidman", "description": "Australian-American actress and film producer", "question": "Does Nicole Kidman know any Scientologists?", "answer": true, "facts": ["Nicole Kidman was married to Tom Cruise.", "Tom Cruise is a Scientologist. "], "decomposition": ["Who has Nicole Kidman been married to?", "Have any of #1 practiced Scientology?"], "evidence": [[[["Nicole Kidman-4"]], [["Tom Cruise-36"], "operation"]], [[["Nicole Kidman-32"]], [["Tom Cruise-4"]]], [[["Nicole Kidman-4"]], [["Tom Cruise-4"]]]]}
{"qid": "89e1a3d04dc74dc36dac", "term": "Justin Bieber", "description": "Canadian singer-songwriter and actor", "question": "Will Justin Bieber take over Mike Pence's position in 2020?", "answer": false, "facts": ["Mike Pence is Vice President of the United States.", "The Vice President must be a US citizen.", "The Vice President must be at least 35 years of age.", "Justin Bieber is a Canadian citizen.", "Justin Bieber is 26 years old in 2020."], "decomposition": ["What is Mike Pence's present position?", "What is the age/nationality requirement to be a #1?", "What is Justin Bieber's age/nationality by 2020?", "Does #3 match #2?"], "evidence": [[[["Mike Pence-4"]], [["Age of candidacy-8"]], [["Justin Bieber-1"]], ["operation"]], [[["Mike Pence-4"]], ["no_evidence"], [["Justin Bieber-1"]], [["Justin Bieber-1"], "operation"]], [[["Natural-born-citizen clause-1", "Vice President of the United States-24"]], [["Vice President of the United States-25"]], [["Justin Bieber-1"]], ["operation"]]]}
{"qid": "47e4f407f7186ba6b86f", "term": "Chipmunk", "description": "Tribe of mammals (rodent (marmot))", "question": "Is an Eastern chipmunk likely to die before seeing two leap years?", "answer": true, "facts": ["A leap year happens every four years.", "The Eastern chipmunk has an average lifespan of three years."], "decomposition": ["What is the average lifespan of an Eastern chipmunk?", "How often does a leap year occur?", "Is #2 greater than #1?"], "evidence": [[[["Eastern chipmunk-7"]], [["Leap year-6"]], ["operation"]], [[["Chipmunk-11"]], [["Leap year-2"]], ["operation"]], [[["Chipmunk-11"]], [["Leap year-2"]], ["operation"]]]}
{"qid": "7e80945a93300f55f479", "term": "Parsley", "description": "species of plant, herb", "question": "Does parsley sink in milk?", "answer": false, "facts": ["Items sink if they are denser than the surrounding material.", "Parsley has a density of 0.26 g/cm^3 when fresh.", "Milk has a density of 1.026 g/cm^3."], "decomposition": ["What is the density of parsley?", "What is the density of milk?", "Is #1 greater than #2?"], "evidence": [[["no_evidence"], ["no_evidence"], ["no_evidence", "operation"]], [[["Parsley-1"], "no_evidence"], [["Milk-1"], "no_evidence"], ["no_evidence", "operation"]], [["no_evidence"], ["no_evidence"], ["operation"]]]}
{"qid": "6b86b4445e7fa97f52c6", "term": "Bartender", "description": "person who serves usually alcoholic beverages behind the bar in a licensed establishment", "question": "Does a person need a college degree to become a bartender?", "answer": false, "facts": ["College degrees require at least 2 years of study to obtain.", "Bartender training generally takes 40 hours."], "decomposition": ["How much hours of training does it take to become a bartender?", "How many years does it take to get the lowest college degree?", "Is #2 less than #1?"], "evidence": [[[["Bartending school-2"]], [["Associate degree-1"]], [["Year-57"], "operation"]], [[["Bartender-12"]], [["Associate degree-17"]], ["operation"]], [[["Bartender-12"], "no_evidence"], [["Associate degree-1", "Bachelor's degree-131"]], ["operation"]]]}
{"qid": "caad75c2382565a4668c", "term": "French Revolution", "description": "Revolution in France, 1789 to 1798", "question": "Did France win the French Revolution?", "answer": false, "facts": ["The French Revolution was a period of  social and political upheaval in France and its colonies.", "War is an intense military conflict between two states.", "The French Revolution involved only France as citizens overthrew the monarchy."], "decomposition": ["Which parties were involved in the French Revolution?", "Did #1 involve France and another country or state?"], "evidence": [[[["French Revolution-1"]], ["operation"]], [[["French Revolution-1"]], [["The Old Regime and the Revolution-3"], "operation"]], [[["French Revolution-1"]], ["operation"]]]}
{"qid": "5278f0501c540dff6407", "term": "Freemasonry", "description": "group of fraternal organizations", "question": "Has Freemasonry been represented on the Moon?", "answer": true, "facts": ["Freemasonry is a group of fraternal organizations rooted in fraternities of stonemasons of the fourteenth century.", "Buzz Aldrin was initiated into the Freemason fraternity in 1955", "Buzz Aldrin and Neil Armstrong were the first men to land on the moon in 1969."], "decomposition": ["What occupation goes into space?", "Have any #1 been Free Masons?", "Have any people listed in #2 been to the moon?"], "evidence": [[[["Astronaut-1"]], [["James Irwin-1", "James Irwin-23"]], [["James Irwin-1"]]], [[["Astronaut-1"]], [["Buzz Aldrin-1"], "no_evidence"], ["no_evidence", "operation"]], [[["Astronaut-1"]], [["John Glenn-62"]], [["John Glenn-3"], "operation"]]]}
{"qid": "b8df6ac181c4c5b280f9", "term": "Bottlenose dolphin", "description": "genus of dolphin", "question": "Can bottlenose dolphins hypothetically outbreed human women?", "answer": false, "facts": ["Bottlenose dolphins have a gestation period of 12 months.", "Human women have a gestation period around 9 months."], "decomposition": ["What is the gestation period of bottlenose dolphins?", "What is the gestation period of humans?", "Is #1 lower than #2?"], "evidence": [[[["Bottlenose dolphin-42"]], [["Gestation-5"]], ["operation"]], [[["Bottlenose dolphin-42"]], [["Human-55"]], ["operation"]], [[["Bottlenose dolphin-42"]], [["Pregnancy-1"]], ["operation"]]]}
{"qid": "7d6b8191f43b8526074e", "term": "Halloween", "description": "Holiday celebrated October 31", "question": "Will Chick Fil A be open on Halloween 2021?", "answer": false, "facts": ["Chick Fil A restaurants close on Sundays.", "Halloween 2021 falls on a Sunday."], "decomposition": ["What day of the week does Halloween fall on in 2021?", "What days of the week is Chick Fil A closed?", "Is #1 included in #2?"], "evidence": [[["no_evidence"], [["Chick-fil-A-18"]], ["no_evidence", "operation"]], [["no_evidence"], [["Chick-fil-A-2"]], ["operation"]], [["no_evidence"], [["Chick-fil-A-2"]], ["operation"]]]}
{"qid": "4c088a5366459f2256c6", "term": "Mental disorder", "description": "Distressing thought or behavior pattern", "question": "Did Van Gogh suffer from a mental disorder?", "answer": true, "facts": ["Mental disorders can be characterized by psychotic episodes and delusions", "Van Gogh suffered from psychotic episodes and delusions"], "decomposition": ["What are mental disorders characterized as?", "What issues did Van Gogh suffer from?", "Is #1 the same as #2?"], "evidence": [[[["Mental disorder-40"]], [["Vincent van Gogh-3"]], ["operation"]], [[["Mental disorder-1"]], [["Vincent van Gogh-3"]], ["operation"]], [[["Causes of mental disorders-58"], "operation"], [["Van Gogh syndrome-4"], "no_evidence"], ["no_evidence"]]]}
{"qid": "18a2f43c7c4e9dfe85a4", "term": "Cell biology", "description": "Scientific Discipline that Studies Cells", "question": "Does cell biology teach about the life cycle of Al Qaeda?", "answer": false, "facts": ["Cell biology is a subdiscipline of biology that deals with the structure and function of cells in living organisms", "Al Qaeda is made up of terrorist cells", "Terrorist cells are small groups of terrorists acting semi-independently for the same cause"], "decomposition": ["What is the main topic that people learn about in Cell biology?", "What is Al Qaeda made up of?", "Is #1 the same as #2?"], "evidence": [[[["Cell biology-1"]], [["Al-Qaeda-2"]], ["operation"]], [[["Cell biology-1"]], [["Al-Qaeda-1"]], ["operation"]], [[["Cell biology-1"]], [["Al-Qaeda-2"]], ["operation"]]]}
{"qid": "d477996cc5bfc3451a92", "term": "Middle Ages", "description": "Period of European history from the 5th to the 15th century", "question": "Were there fifty English kings throughout the Middle Ages?", "answer": false, "facts": ["The Middle Ages was a period of history from 476-1453 AD.", "From 476 to 1453 AD  there were around 36 Kings of England including disputed claimants to the throne."], "decomposition": ["Which span of time is referred to as the Middle Ages?", "How many kings ruled England through #1?", "Is #2 equal to fifty?"], "evidence": [[[["Middle Ages-1"]], ["no_evidence"], ["operation"]], [[["Outline of the Middle Ages-2"]], ["no_evidence"], ["no_evidence", "operation"]], [[["Middle Ages-1"]], [["History of Anglo-Saxon England-35"], "no_evidence"], ["operation"]]]}
{"qid": "f6184f20db14b18f1401", "term": "Hamlet", "description": "tragedy by William Shakespeare", "question": "Did Hamlet's author use email?", "answer": false, "facts": ["Hamlet was written by William Shakespeare.", "William Shakespeare was born in 1564.", "Email was not widely used until the 1970s."], "decomposition": ["Who was the author of Hamlet?", "When did #1 pass away?", "When did email become commonly used?", "Did #3 occur before #2?"], "evidence": [[[["Hamlet-1"]], [["William Shakespeare-17"]], [["Email-1"]], ["operation"]], [[["Hamlet-4"]], [["William Shakespeare-5"]], [["History of email-12"]], ["operation"]], [[["Hamlet-2"]], [["William Shakespeare-17"]], [["Email-1"]], ["operation"]]]}
{"qid": "a2dd0493fc87bb64e1fa", "term": "Hundred Years' War", "description": "Series of conflicts and wars between England and France during the 14th and 15th-century", "question": "Did the first Duke of Valentinois play a key role in the Hundred Years' War?", "answer": false, "facts": ["The Hundred Years' War was a conflict between England and France from 1337-1453", "Cesare Borgia, the son of Pope Alexander VI, was the first Duke of Valentinois.", "Cesare Borgia was born in 1475."], "decomposition": ["When did the Hundred Years' War end?", "Who was the first Duke of Valentinois?", "When was #2 born?", "Is #3 before #1?"], "evidence": [[[["Hundred Years' War (1415\u20131453)-1"]], [["Duke of Valentinois-6"]], [["Honor\u00e9 II, Prince of Monaco-1"]], ["operation"]], [[["Hundred Years' War-1"]], [["Cesare Borgia-7"]], [["Cesare Borgia-1"]], ["operation"]], [[["Hundred Years' War-1"]], [["Cesare Borgia-7"]], [["Cesare Borgia-1"]], ["operation"]]]}
{"qid": "8ec0f7fd908451102838", "term": "JPEG", "description": "Lossy compression method for reducing the size of digital images", "question": "Does the JPEG acronym stand for a joint committee?", "answer": true, "facts": ["The term \"JPEG\" is an initialism/acronym for the Joint Photographic Experts Group.", "They created the standard in 1992.", "The Joint Photographic Experts Group (JPEG) is the joint committee between ISO/IEC JTC 1 and ITU-T Study Group 16 (formerly CCITT) . ", "The Joint Photographic Experts Group created and maintains the JPEG, JPEG 2000, and JPEG XR standards. "], "decomposition": ["What does the acronym JPEG represent?", "Is #1 a coalition of different groups?"], "evidence": [[[["JPEG-1"]], [["Coalition-1"]]], [[["JPEG-2"]], [["Joint Photographic Experts Group-1"], "operation"]], [[["JPEG-2"]], [["Joint Photographic Experts Group-1"]]]]}
{"qid": "e5fa5f6c12bfa1aed955", "term": "Audiobook", "description": "recording of a text being read", "question": "Do Youtube viewers get unsolicited audiobook advice often?", "answer": true, "facts": ["Audible is one of the most common sponsors for Youtubers to have.", "Audible is an audiobook subscription service. ", "Audible ads typically involve discussing a book that the speaker has recently listened to."], "decomposition": ["What company is one of the most common sponsors for Youtubers to have?", "What do the ads for #1 typically involve?", "Does #2 involve someone giving audiobook advice?"], "evidence": [[[["Audible (store)-1"], "no_evidence"], [["Audible (store)-11"], "no_evidence"], ["operation"]], [[["YouTube-3"], "no_evidence"], [["YouTube-3"]], ["no_evidence"]], [[["Audible (store)-16"], "no_evidence"], ["no_evidence"], ["no_evidence", "operation"]]]}
{"qid": "4fe90b9eab197be78729", "term": "Jack Kerouac", "description": "American writer", "question": "Was ethanol beneficial to Jack Kerouac's health?", "answer": false, "facts": ["In 1969, at age 47, Kerouac died from an abdominal hemorrhage caused by a lifetime of heavy drinking of alcohol.", "Ethanol is the main ingredient in alcoholic beverages."], "decomposition": ["What did Jack Kerouac die from?", "Is there ethanol in #1? "], "evidence": [[[["Jack Kerouac-41"]], [["Ethanol-1"], "operation"]], [[["Jack Kerouac-41"]], [["Jack Kerouac-41"], "no_evidence"]], [[["Jack Kerouac-41"]], [["Ethanol-1"]]]]}
{"qid": "80b883ce348170c85aed", "term": "Clementine", "description": "nothospecies of plant, Clementine", "question": "Is clementine pith highly sought after?", "answer": false, "facts": ["Pith is the white part of the clementine fruit between the orange colored peel and the edible fruit.", "Most people discard the pith after peeling."], "decomposition": ["What is a pith?", "Do people usually like to keep #1 after peeling?"], "evidence": [[[["Pith-1"]], [["Pith-1"]]], [[["Pith-1"]], [["Clementine-1"], "no_evidence", "operation"]], [[["Pith-3"]], ["no_evidence"]]]}
{"qid": "69f1599823635bfc075b", "term": "Cosmic microwave background", "description": "Universe events since the Big Bang 13.8 billion years ago", "question": "Can food be cooked in the cosmic microwave background?", "answer": false, "facts": ["The cosmic microwave background is faint electromagnetic radiation in space that is a remnant of the Big Bang.", "Food can be cooked in a microwave oven, but not in the remnants of space radiation."], "decomposition": ["What kind of radiation is used in microwave ovens?", "What kind of radiation is produced in the cosmic microwave background?", "Is #1 the same as #2?"], "evidence": [[[["Microwave oven-1"]], [["Cosmic microwave background-1"]], ["operation"]], [[["Microwave oven-1"]], [["Cosmic microwave background-1"]], ["operation"]], [[["Microwave oven-1"]], [["Cosmic microwave background-1"]], ["operation"]]]}
{"qid": "b15c390b221b7e0f9b1e", "term": "Legend", "description": "Traditional story of heroic humans.", "question": "Are all characters in Legend of Robin Hood fictional?", "answer": false, "facts": ["The Legend of Robin Hood tells of an archer that stole from the rich and gave to the poor.", "Robin Hood's main antagonist is the Sheriff of Nottingham.", "The Sheriff of Nottingham is an agent for Prince John who has usurped the throne from his brother Richard.", "Richard I was King of England from 1189-1199.", "Prince John became John, King of England and reigned from 1199-1216."], "decomposition": ["Who is Robin Hood's main antagonist in the Legend of Robin Hood?", "Who is #1's employer?", "Who is #2's brother who was usurped from the throne by him?", "Are #2 and #3 completely fictional characters?"], "evidence": [[[["Robin Hood-2"]], [["Sheriff of Nottingham-3"]], [["The Legend of Robin Hood-2"]], [["John, King of England-1"], "operation"]], [[["Sheriff of Nottingham-1"]], [["Sheriff of Nottingham-5"]], [["John, King of England-67"]], [["John, King of England-1", "Sheriff of Nottingham-2"]]], [[["Sheriff of Nottingham-1"]], [["Sheriff of Nottingham-5"]], [["The Legend of Robin Hood-2"]], [["Richard I of England-1"], "operation"]]]}
{"qid": "bad3d5551705406fe58d", "term": "Snowboarding", "description": "winter sport", "question": "Would it be difficult to snowboard on Venus?", "answer": true, "facts": ["Snowboarding involves descending a snow-covered slope while standing on a snowboard.", "Snow is formed by the freezing of water.", "Water has a freezing point of 32\u00b0F.", "Venus has a mean surface temperature of 737 K (464 \u00b0C; 867 \u00b0F)."], "decomposition": ["What kind of surface is suitable for snowboarding?", "What temperature range facilitates the formation of #1?", "What is the average surface temperature on Venus?", "Is #3 within #2?"], "evidence": [[[["Snowboarding-1"]], [["Snow-16"]], [["Venus-2"]], ["operation"]], [[["Snowboarding-1"]], [["Freezing-5"], "no_evidence"], [["Venus-2"]], ["operation"]], [[["Snowboarding-1"]], [["Snow-3"], "no_evidence"], [["Venus-2"]], ["operation"]]]}
{"qid": "684d4c03be354635b80f", "term": "Christians", "description": "people who adhere to Christianity", "question": "Do Christians anticipate an existence in Sheol after death?", "answer": false, "facts": ["Sheol appears in the Christian Bible, in the Old Testament.", "Christians do not recognize Sheol as part of their afterlife."], "decomposition": ["Which Testament of the Bible makes reference to Sheol?", "Is #1 the New Testament?", "Is Sheol included in Christians' concept of afterlife as expressed in the New Testament?", "Is #2 or #3 positive?"], "evidence": [[[["Sheol-2"]], ["operation"], [["Heaven-15", "Hell-34"], "no_evidence"], ["operation"]], [[["Sheol-1"]], [["New Testament-1"], "operation"], [["New Testament-11"], "no_evidence"], ["operation"]], [[["Sheol-2"]], [["Sheol-1"]], [["Afterlife-44"]], ["operation"]]]}
{"qid": "dca314ab2d3166f19182", "term": "Rabbi", "description": "teacher of Torah in Judaism", "question": "Would a Rabbi celebrate Christmas?", "answer": false, "facts": ["A Rabbi is a spiritual leader or religious teacher in Judaism.", "Christmas is a holiday observed by Christians."], "decomposition": ["What religion do Rabbis belong to?", "Which religion celebrates Christmas?", "Is #1 the same as #2?"], "evidence": [[[["Rabbi-17"]], [["Christmas-7"]], ["operation"]], [[["Rabbi-1"]], [["Christmas-1"]], ["operation"]], [[["Rabbi-1"]], [["Christmas-1"]], ["operation"]]]}
{"qid": "c2d2b9ff5a1e682c88dc", "term": "Shrimp", "description": "Decapod crustaceans", "question": "Is shrimp scampi definitely free of plastic?", "answer": false, "facts": ["Shrimp scampi is a dish made with shrimp.", "Shrimp have been found to contain microplastics.", "Microplastics are plastic material."], "decomposition": ["What protein is Shrimp scampi made out of?", "What have #1 been found to contain?", "Are #2 free from plastic?"], "evidence": [[[["Scampi-1"]], [["Plastic pollution-31", "Plastic pollution-48"], "no_evidence"], ["no_evidence", "operation"]], [[["Fish-92", "Scampi-2"]], [["Microplastics-12"]], [["Microplastics-1"]]], [[["Scampi-8"]], ["no_evidence"], ["no_evidence"]]]}
{"qid": "ed99d136038b850040f5", "term": "Stroke", "description": "Medical condition where poor blood flow to the brain causes cell death", "question": "Is it impossible to tell if someone is having a stroke?", "answer": false, "facts": ["Strokes have numerous physical symptoms including facial unevenness and trouble walking.", "Strokes have behavioral symptoms including slurred speech, disorientation, and trouble understanding speech."], "decomposition": ["What are the symptoms of a stroke?", "Are all of #1 hidden from physical observation?"], "evidence": [[[["Stroke-1"]], ["operation"]], [[["FAST (stroke)-2"]], ["no_evidence"]], [[["Stroke-15"]], [["Stroke-15"], "no_evidence"]]]}
{"qid": "905f2b35daf680a54787", "term": "The Jackson 5", "description": "American pop music family group", "question": "Could the Jackson 5 play a full game of rugby with each other?", "answer": false, "facts": ["The Jackson 5 consisted of five members.", "A full game of rugby is played between 2 teams of 15 players each."], "decomposition": ["How many members are in the Jackson 5?", "How many players are there in a full game of rugby?", "Is #1 greater than or equal to #2?"], "evidence": [[[["The Jackson 5-1"]], [["Rugby union-1"]], ["operation"]], [[["The Jackson 5-1"]], [["Rugby union-1"]], ["operation"]], [[["The Jackson 5-1"]], [["Rugby league positions-1"]], ["operation"]]]}
{"qid": "e1f93419cb9a2f1d06ca", "term": "Christians", "description": "people who adhere to Christianity", "question": "Does Hammurabi's Code violate Christians Golden Rule?", "answer": true, "facts": ["The Golden Rule of Christianity states to do unto others as you would want them to do to you.", "Hammurabi's Code states an eye for an eye and a tooth for a tooth."], "decomposition": ["What is the golden rule in Christianity? ", "What does the Code of Hammurabi state?", "Is #1 the same meaning as #2?"], "evidence": [[[["Golden Rule-1", "Golden Rule-20"]], [["Code of Hammurabi-15", "Shofetim (parsha)-26"], "no_evidence"], ["operation"]], [[["Golden Rule-1"]], [["Code of Hammurabi-1"]], [["Eye for an eye-1"], "operation"]], [[["Golden Rule-21"]], [["Code of Hammurabi-2"]], ["operation"]]]}
{"qid": "904898291b7b33f260e7", "term": "Richard Dawkins", "description": "English ethologist, evolutionary biologist and author", "question": "Would Jacques Du\u00e8ze have been friends with Richard Dawkins?", "answer": false, "facts": ["Jacques Du\u00e8ze was later Pope John XXII.", "The Pope is the head of the Catholic Church, a Christian organization.", "Christianity is a religion.", "Richard Dawkins is a prominent critic of religion."], "decomposition": ["What is the occupation of Jacques Du\u00e8ze?", "In what field or industry is #1?", "Is #2 a field or industry which Richard Dawkins supports?"], "evidence": [[[["Pope John XXII-1"]], [["Pope-1"]], [["Richard Dawkins-4"], "operation"]], [[["Pope John XXII-2"]], [["Pope John XXII-1"]], [["Richard Dawkins-1", "Richard Dawkins-3"], "operation"]], [[["Pope John XXII-1"]], [["Catholic Church-1", "Christianity-1"]], [["Atheism-1", "Richard Dawkins-3"]]]]}
{"qid": "0b7782218af2a65a6094", "term": "Astronomer", "description": "Scientist who studies celestial bodies", "question": "Does James Webb Space Telescope fail astronomer in locating planet Krypton?", "answer": true, "facts": ["The James Webb Space Telescope is the most powerful telescope created.", "Krypton is a planet in the fictional Superman comic book series."], "decomposition": ["Which universe does the planet Krypton exist in?", "Does the James Webb Space Telescope as we know it exist in a universe different from #1?"], "evidence": [[[["Krypton (comics)-1"]], [["James Webb Space Telescope-1"], "no_evidence"]], [[["Krypton (comics)-1"]], [["James Webb Space Telescope-1"]]], [[["Krypton (comics)-1"]], [["James Webb Space Telescope-1"], "operation"]]]}
{"qid": "97d147b2e3e29fa85a71", "term": "Ukrainian Greek Catholic Church", "description": "Byzantine Rite Eastern Catholic Church", "question": "Does Ukrainian Greek Catholic Church recognize Alexander Nevsky as a saint?", "answer": false, "facts": ["Alexander Nevsky was a Prince of Novgorod that fought against German and Swiss Invaders.", "The Russian Orthodox Church named Alexander Nevsky.a saint in 1547.", "The Russian Orthodox Church is a member of the Eastern Orthodox Church and has their own list of saints.", "The Catholic Church and the Eastern Orthodox Church have been in a state of official schism since the East\u2013West Schism of 1054.", "The Ukrainian Greek Catholic Church is a branch of the Catholic Church."], "decomposition": ["In which religion is Alexander Nevsky considered a saint?", "What religion is the Ukrainian Greek Catholic Church a part of?", "Is #1 and #2 the same?"], "evidence": [[[["Alexander Nevsky-2"]], [["Ukrainian Greek Catholic Church-1"]], [["Russian Orthodox Church-73"], "operation"]], [[["Alexander Nevsky-2"]], [["Ukrainian Greek Catholic Church-1"]], ["operation"]], [[["Alexander Nevsky-2"]], [["Ukrainian Greek Catholic Church-31"]], ["operation"]]]}
{"qid": "0024b8ff404e3b5f5c3b", "term": "Easter", "description": "Major Christian festival celebrating the resurrection of Jesus", "question": "Would Jesus understand the Easter Bunny?", "answer": false, "facts": ["During the time of Jesus, Easter was not a holiday yet.", "Rabbits were not of any profound significance to Jesus."], "decomposition": ["When did Easter become a holiday?", "In what year did Jesus die?", "Did #1 occur before #2?"], "evidence": [[[["Easter-1"]], [["Jesus-1"]], ["operation"]], [[["Easter-10"]], [["Jesus-1"]], ["operation"]], [[["Easter-1"], "no_evidence"], [["English festivals-15"]], ["no_evidence", "operation"]]]}
{"qid": "5232dce14487fa43d416", "term": "Infantry", "description": "military personnel who travel and fight on foot", "question": "Do members of NFL teams receive infantry training?", "answer": false, "facts": ["Members of NFL teams play football", "Infantry training is provided to members of the US armed forces"], "decomposition": ["Which group(s) are entitled to infantry training?", "Are members of the NFL team one of #1?"], "evidence": [[[["Infantry-47"]], [["Infantry-47"]]], [[["Infantry-47"]], [["National Football League-1"], "operation"]], [[["United States Marine Corps School of Infantry-1"]], [["National Football League-1"]]]]}
{"qid": "a11f537f67260464d010", "term": "Mitsubishi", "description": "group of autonomous, Japanese multinational companies", "question": "Can someone in Uberlandia work for Mitsubishi?", "answer": true, "facts": ["Mitsubishi is a Japanese auto manufacturer", "Mitsubishi operates a plant in Catalao, Brazil", "Uberlandia is just under 70 miles from Catalao"], "decomposition": ["How far is Uberlandia from Catalao?", "Is #1 within reasonable distance to commute to work?", "Is there a Mitsubishi organization in Catalao?", "Are #2 and #3 positive?"], "evidence": [[[["Catal\u00e3o-1", "Uberl\u00e2ndia-1"], "no_evidence"], ["operation"], ["no_evidence"], ["operation"]], [[["Catal\u00e3o-4"]], ["operation"], [["Catal\u00e3o-1"]], ["operation"]], [[["Catal\u00e3o-1", "Uberl\u00e2ndia-1"], "no_evidence"], ["no_evidence", "operation"], [["Catal\u00e3o-1"], "operation"], ["no_evidence", "operation"]]]}
{"qid": "26aefc40b2d04ca6b78b", "term": "Xenophobia", "description": "dislike of that which is perceived to be foreign or strange", "question": "Is xenophobia hypothetically unimportant between Saladin and Ali Askari?", "answer": true, "facts": ["Xenophobia is the dislike of someone that is foreign or from a different background.", "Saladin was a Kurdish leader that became sultan of Egypt.", "Ali Askari was a Kurdish politician."], "decomposition": ["Which relation between two parties could lead bring about xenophobia?", "What was Saladin's ethnicity?", "What was Ali Askari's ethnicity?", "Does the relation between #2 and #3 fail to describe #1?"], "evidence": [[[["Xenophobia-1"]], [["Saladin-1"]], [["Ali Askari-3"]], ["operation"]], [[["Xenophobia-1"]], [["Saladin-1"]], [["Ali Askari-2"]], ["operation"]], [[["Xenophobia-1"]], [["Saladin-1"]], [["Ali Askari-3"]], [["In-group and out-group-1"]]]]}
{"qid": "49228a8553a4448fa366", "term": "Christmas carol", "description": "Song or hymn or carol on the theme of Christmas", "question": "Did the writer of Christmas carol fast during Ramadan? ", "answer": false, "facts": ["The writer of Christmas carol is Charles Dickens, who is a Christian. ", "Christians do not fast during Ramadan. "], "decomposition": ["Which group of people fast during Ramadan?", "Christmas carols are composed by and for which group of people?", "Are #2 and #1 the same?"], "evidence": [[[["Ramadan-1"]], [["Christmas and holiday season-2", "Christmas carol-1"]], ["operation"]], [[["Ramadan-1"]], [["Christmas carol-1", "Christmas-1"]], ["operation"]], [[["Ramadan-1"]], [["Christmas carol-10"]], ["operation"]]]}
{"qid": "baf402d780174b669286", "term": "Rosemary", "description": "species of plant, rosemary", "question": "Are looks the easiest way to tell rosemary from lavender? ", "answer": false, "facts": ["Before blooming, lavender and rosemary look remarkably similar.", "Rosemary has a pine-like scent.", "Lavender has a lighter, more floral scent."], "decomposition": ["What does rosemary look like?", "What does lavender look like?", "Are there significant differences between #1 and #2?"], "evidence": [[[["Rosemary-1"]], [["Lavandula-5"]], ["operation"]], [[["Rosemary-1"]], [["Lavandula-5"]], ["no_evidence", "operation"]], [[["Rosemary-1"]], [["Lavandula-26"]], ["operation"]]]}
{"qid": "957adcdf1c676bc082da", "term": "Riksdag", "description": "Legislative body of Sweden", "question": "Is the Riksdag a political entity in Scandinavia?", "answer": true, "facts": ["The Riksdag is the legislative branch of the Swedish government.", "Sweden is part of Scandinavia."], "decomposition": ["What country does the Riksdag belong to?", "Which countries are part of Scandinavia?", "Is #1 included in #2?"], "evidence": [[[["Riksdag-1"]], [["Scandinavia-1"]], ["operation"]], [[["Riksdag-1"]], [["Scandinavia-1"]], ["operation"]], [[["Riksdag-1"]], [["Scandinavia-1"]], ["operation"]]]}
{"qid": "9163ac8f2409fe39c3b2", "term": "Sea of Japan", "description": "Marginal sea between Japan, Russia and Korea", "question": "Is the Sea of Japan landlocked within Japan?", "answer": false, "facts": ["The sea of Japan touches Japan, Russia and the Koreas", "Japan has no landlocked sea"], "decomposition": ["Which countries have a shoreline that touches the Sea of Japan?", "Is Japan the only item in #1?"], "evidence": [[[["Sea of Japan-1"]], ["operation"]], [[["Sea of Japan-13"]], ["operation"]], [[["Sea of Japan-1"]], ["operation"]]]}